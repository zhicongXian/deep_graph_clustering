### Starting TaskPrologue of job 2609094 on a0703 at Thu May  1 18:15:50 CEST 2025
Running on cores 48-63 with governor ondemand
Thu May  1 18:15:50 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:4F:00.0 Off |                    0 |
| N/A   44C    P0             62W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

INFO - 05/01/25 18:17:09 - 0:00:00 - {'dataset': 'SeNet', 'task': 'Clustering', 'root_path': './datasets', 'eval_freq': 100, 'exp_iters': 5, 'version': 'run', 'log_path': './results/run/SeNet.log', 'pre_epochs': 1000, 'epochs': 5000, 'height': 3, 'lr_pre': 0.01, 'lr': 0.01, 'w_decay': 0.0, 'decay_rate': 9, 'max_nums': None, 'embed_dim': 32, 'hidden_dim_enc': 64, 'hidden_dim': 64, 'dropout': 0.0, 'nonlin': None, 'temperature': 0.2, 'n_cluster_trials': 5, 't': 1.0, 'r': 2.0, 'patience': 5, 'save_path': 'model.pt', 'use_gpu': True, 'gpu': 0, 'devices': '0,1', 'data_path': './datasets/affinity_matrix_from_senet_sparse_1000.npz', 'label_path': './datasets/senet_label_1000.csv'}
INFO - 05/01/25 18:17:09 - 0:00:00 - Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
INFO - 05/01/25 18:17:10 - 0:00:00 - 
                                     train iters 0
INFO - 05/01/25 18:17:16 - 0:00:07 - Epoch 1: train_loss=5.855743408203125
INFO - 05/01/25 18:17:20 - 0:00:11 - Epoch 2: train_loss=4.892094135284424
INFO - 05/01/25 18:17:25 - 0:00:15 - Epoch 3: train_loss=4.351752758026123
INFO - 05/01/25 18:17:28 - 0:00:19 - Epoch 4: train_loss=3.9550721645355225
INFO - 05/01/25 18:17:32 - 0:00:23 - Epoch 5: train_loss=3.6261770725250244
INFO - 05/01/25 18:17:36 - 0:00:26 - Epoch 6: train_loss=3.3326239585876465
INFO - 05/01/25 18:17:40 - 0:00:30 - Epoch 7: train_loss=3.155409336090088
INFO - 05/01/25 18:17:44 - 0:00:34 - Epoch 8: train_loss=3.0120596885681152
INFO - 05/01/25 18:17:47 - 0:00:38 - Epoch 9: train_loss=2.8540990352630615
INFO - 05/01/25 18:17:51 - 0:00:42 - Epoch 10: train_loss=2.6922285556793213
INFO - 05/01/25 18:17:55 - 0:00:45 - Epoch 11: train_loss=2.536440849304199
INFO - 05/01/25 18:17:59 - 0:00:49 - Epoch 12: train_loss=2.39567232131958
INFO - 05/01/25 18:18:03 - 0:00:53 - Epoch 13: train_loss=2.2833986282348633
INFO - 05/01/25 18:18:06 - 0:00:57 - Epoch 14: train_loss=2.1906726360321045
INFO - 05/01/25 18:18:10 - 0:01:01 - Epoch 15: train_loss=2.097522497177124
INFO - 05/01/25 18:18:14 - 0:01:04 - Epoch 16: train_loss=2.0020365715026855
INFO - 05/01/25 18:18:18 - 0:01:08 - Epoch 17: train_loss=1.907323956489563
INFO - 05/01/25 18:18:22 - 0:01:12 - Epoch 18: train_loss=1.8157414197921753
INFO - 05/01/25 18:18:25 - 0:01:16 - Epoch 19: train_loss=1.7292766571044922
INFO - 05/01/25 18:18:29 - 0:01:20 - Epoch 20: train_loss=1.6599457263946533
INFO - 05/01/25 18:18:33 - 0:01:23 - Epoch 21: train_loss=1.599320650100708
INFO - 05/01/25 18:18:37 - 0:01:27 - Epoch 22: train_loss=1.5370479822158813
INFO - 05/01/25 18:18:41 - 0:01:31 - Epoch 23: train_loss=1.474801778793335
INFO - 05/01/25 18:18:44 - 0:01:35 - Epoch 24: train_loss=1.41403329372406
INFO - 05/01/25 18:18:48 - 0:01:39 - Epoch 25: train_loss=1.3537530899047852
INFO - 05/01/25 18:18:52 - 0:01:42 - Epoch 26: train_loss=1.2979270219802856
INFO - 05/01/25 18:18:56 - 0:01:46 - Epoch 27: train_loss=1.2528209686279297
INFO - 05/01/25 18:19:00 - 0:01:50 - Epoch 28: train_loss=1.2092580795288086
INFO - 05/01/25 18:19:03 - 0:01:54 - Epoch 29: train_loss=1.1667225360870361
INFO - 05/01/25 18:19:07 - 0:01:58 - Epoch 30: train_loss=1.1244909763336182
INFO - 05/01/25 18:19:11 - 0:02:01 - Epoch 31: train_loss=1.0827425718307495
INFO - 05/01/25 18:19:15 - 0:02:05 - Epoch 32: train_loss=1.0438647270202637
INFO - 05/01/25 18:19:19 - 0:02:09 - Epoch 33: train_loss=1.0107837915420532
INFO - 05/01/25 18:19:22 - 0:02:13 - Epoch 34: train_loss=0.9804881811141968
INFO - 05/01/25 18:19:26 - 0:02:17 - Epoch 35: train_loss=0.9485868215560913
INFO - 05/01/25 18:19:30 - 0:02:20 - Epoch 36: train_loss=0.9216759204864502
INFO - 05/01/25 18:19:34 - 0:02:24 - Epoch 37: train_loss=0.890509843826294
INFO - 05/01/25 18:19:38 - 0:02:28 - Epoch 38: train_loss=0.8658077120780945
INFO - 05/01/25 18:19:41 - 0:02:32 - Epoch 39: train_loss=0.8363485932350159
INFO - 05/01/25 18:19:45 - 0:02:36 - Epoch 40: train_loss=0.8167308568954468
INFO - 05/01/25 18:19:49 - 0:02:39 - Epoch 41: train_loss=0.7922235727310181
INFO - 05/01/25 18:19:53 - 0:02:43 - Epoch 42: train_loss=0.7726852297782898
INFO - 05/01/25 18:19:56 - 0:02:47 - Epoch 43: train_loss=0.7523147463798523
INFO - 05/01/25 18:20:00 - 0:02:51 - Epoch 44: train_loss=0.7341572046279907
INFO - 05/01/25 18:20:04 - 0:02:55 - Epoch 45: train_loss=0.7139033675193787
INFO - 05/01/25 18:20:08 - 0:02:58 - Epoch 46: train_loss=0.7002593874931335
INFO - 05/01/25 18:20:12 - 0:03:02 - Epoch 47: train_loss=0.6795198321342468
INFO - 05/01/25 18:20:15 - 0:03:06 - Epoch 48: train_loss=0.6720930337905884
INFO - 05/01/25 18:20:19 - 0:03:10 - Epoch 49: train_loss=0.656013548374176
INFO - 05/01/25 18:20:23 - 0:03:14 - Epoch 50: train_loss=0.6414960622787476
INFO - 05/01/25 18:20:27 - 0:03:17 - Epoch 51: train_loss=0.629021167755127
INFO - 05/01/25 18:20:31 - 0:03:21 - Epoch 52: train_loss=0.614851713180542
INFO - 05/01/25 18:20:34 - 0:03:25 - Epoch 53: train_loss=0.6028000116348267
INFO - 05/01/25 18:20:38 - 0:03:29 - Epoch 54: train_loss=0.5911223292350769
INFO - 05/01/25 18:20:42 - 0:03:33 - Epoch 55: train_loss=0.5792714953422546
INFO - 05/01/25 18:20:46 - 0:03:36 - Epoch 56: train_loss=0.5702970027923584
INFO - 05/01/25 18:20:50 - 0:03:40 - Epoch 57: train_loss=0.5601952075958252
INFO - 05/01/25 18:20:53 - 0:03:44 - Epoch 58: train_loss=0.5482205152511597
INFO - 05/01/25 18:20:57 - 0:03:48 - Epoch 59: train_loss=0.5420299768447876
INFO - 05/01/25 18:21:01 - 0:03:52 - Epoch 60: train_loss=0.5300442576408386
INFO - 05/01/25 18:21:05 - 0:03:55 - Epoch 61: train_loss=0.5244789719581604
INFO - 05/01/25 18:21:09 - 0:03:59 - Epoch 62: train_loss=0.514300525188446
INFO - 05/01/25 18:21:12 - 0:04:03 - Epoch 63: train_loss=0.5079999566078186
INFO - 05/01/25 18:21:16 - 0:04:07 - Epoch 64: train_loss=0.5006362795829773
INFO - 05/01/25 18:21:20 - 0:04:11 - Epoch 65: train_loss=0.49089473485946655
INFO - 05/01/25 18:21:24 - 0:04:14 - Epoch 66: train_loss=0.4860740005970001
INFO - 05/01/25 18:21:28 - 0:04:18 - Epoch 67: train_loss=0.47789040207862854
INFO - 05/01/25 18:21:31 - 0:04:22 - Epoch 68: train_loss=0.4709932506084442
INFO - 05/01/25 18:21:35 - 0:04:26 - Epoch 69: train_loss=0.46709945797920227
INFO - 05/01/25 18:21:39 - 0:04:30 - Epoch 70: train_loss=0.45846620202064514
INFO - 05/01/25 18:21:43 - 0:04:33 - Epoch 71: train_loss=0.4553026854991913
INFO - 05/01/25 18:21:47 - 0:04:37 - Epoch 72: train_loss=0.44899892807006836
INFO - 05/01/25 18:21:50 - 0:04:41 - Epoch 73: train_loss=0.4417683482170105
INFO - 05/01/25 18:21:54 - 0:04:45 - Epoch 74: train_loss=0.4407169222831726
INFO - 05/01/25 18:21:58 - 0:04:48 - Epoch 75: train_loss=0.4327491819858551
INFO - 05/01/25 18:22:02 - 0:04:52 - Epoch 76: train_loss=0.431938499212265
INFO - 05/01/25 18:22:06 - 0:04:56 - Epoch 77: train_loss=0.4272276759147644
INFO - 05/01/25 18:22:09 - 0:05:00 - Epoch 78: train_loss=0.4184757173061371
INFO - 05/01/25 18:22:13 - 0:05:04 - Epoch 79: train_loss=0.41516798734664917
INFO - 05/01/25 18:22:17 - 0:05:07 - Epoch 80: train_loss=0.4097954034805298
INFO - 05/01/25 18:22:21 - 0:05:11 - Epoch 81: train_loss=0.40544527769088745
INFO - 05/01/25 18:22:25 - 0:05:15 - Epoch 82: train_loss=0.40134263038635254
INFO - 05/01/25 18:22:28 - 0:05:19 - Epoch 83: train_loss=0.3964668810367584
INFO - 05/01/25 18:22:32 - 0:05:23 - Epoch 84: train_loss=0.39337003231048584
INFO - 05/01/25 18:22:36 - 0:05:26 - Epoch 85: train_loss=0.3887685239315033
INFO - 05/01/25 18:22:40 - 0:05:30 - Epoch 86: train_loss=0.3861476182937622
INFO - 05/01/25 18:22:44 - 0:05:34 - Epoch 87: train_loss=0.38172081112861633
INFO - 05/01/25 18:22:47 - 0:05:38 - Epoch 88: train_loss=0.3790712058544159
INFO - 05/01/25 18:22:51 - 0:05:42 - Epoch 89: train_loss=0.3727875351905823
INFO - 05/01/25 18:22:55 - 0:05:45 - Epoch 90: train_loss=0.3757239282131195
INFO - 05/01/25 18:22:59 - 0:05:49 - Epoch 91: train_loss=0.37321653962135315
INFO - 05/01/25 18:23:03 - 0:05:53 - Epoch 92: train_loss=0.36345747113227844
INFO - 05/01/25 18:23:06 - 0:05:57 - Epoch 93: train_loss=0.3683486580848694
INFO - 05/01/25 18:23:10 - 0:06:01 - Epoch 94: train_loss=0.36758866906166077
INFO - 05/01/25 18:23:14 - 0:06:04 - Epoch 95: train_loss=0.35844704508781433
=== JOB_STATISTICS ===
=== current date     : Fri May  2 18:15:56 CEST 2025
= Job-ID             : 2609094 on alex
= Job-Name           : lsenet_hpo
= Job-Command        : /home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/fau_alex_job_script_hpo.sh
= Initial workdir    : /home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering
= Queue/Partition    : a100
= Slurm account      : v100dd with QOS=normal
= Features           : a100_40
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 1-00:00:12
= Total RAM usage    : 5.3 GiB of assigned  GiB (%)
= Node list          : a0703
= Subm/Elig/Start/End: 2025-04-30T10:15:57 / 2025-04-30T10:15:57 / 2025-05-01T18:15:41 / 2025-05-02T18:15:53
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           30.2G   104.9G   209.7G        N/A      56K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:4F:00.0, 445975, 94 %, 18 %, 32542 MiB, 86367779 ms
