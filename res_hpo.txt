### Starting TaskPrologue of job 2557724 on a0633 at Tue Apr 15 16:29:56 CEST 2025
Running on cores 32-47 with governor ondemand
Tue Apr 15 16:29:56 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:49:00.0 Off |                    0 |
| N/A   35C    P0             60W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

INFO - 04/15/25 16:31:16 - 0:00:00 - {'dataset': 'SeNet', 'task': 'Clustering', 'root_path': './datasets', 'eval_freq': 100, 'exp_iters': 5, 'version': 'run', 'log_path': './results/run/SeNet.log', 'pre_epochs': 1000, 'epochs': 5000, 'height': 3, 'lr_pre': 0.01, 'lr': 0.01, 'w_decay': 0.0, 'decay_rate': 9, 'max_nums': None, 'embed_dim': 32, 'hidden_dim_enc': 64, 'hidden_dim': 64, 'dropout': 0.0, 'nonlin': None, 'temperature': 0.2, 'n_cluster_trials': 5, 't': 1.0, 'r': 2.0, 'patience': 5, 'save_path': 'model.pt', 'use_gpu': True, 'gpu': 0, 'devices': '0,1', 'data_path': './datasets/affinity_matrix_from_senet_sparse_1000.npz', 'label_path': './datasets/senet_label_1000.csv'}
INFO - 04/15/25 16:31:16 - 0:00:00 - Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py:128: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`
  print(torch.cuda.memory_cached() / 1024 ** 2)
INFO - 04/15/25 16:31:18 - 0:00:01 - 
                                     train iters 0
WARNING - 04/15/25 16:31:28 - 0:00:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:31:28 - 0:00:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 137, in train
                                            ari = exp.train()
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/exp.py", line 56, in train
                                            nmi, ari = self.train_clu(data, model, optimizer, logger, device, exp_iter)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/exp.py", line 85, in train_clu
                                            loss = model.loss(data, data['edge_index'], data['neg_edge_index'], device, pretrain=True)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/hyperSE.py", line 65, in loss
                                            embeddings, clu_mat = self.encoder(features, adj)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/l_se_net.py", line 55, in forward
                                            z, edge, ass = layer(z, edge)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/layers.py", line 151, in forward
                                            ass = self.assignor(x, adj)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/layers.py", line 129, in forward
                                            ass = self.assign_linear(self.proj(x), adj).narrow(-1, 1, self.num_assign)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/layers.py", line 24, in forward
                                            h = self.linear(x)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/layers.py", line 54, in forward
                                            x = self.weight(self.dropout(x))
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 125, in forward
                                            return F.linear(input, self.weight, self.bias)
                                        torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 67.39 GiB. GPU 0 has a total capacity of 79.25 GiB of which 34.94 GiB is free. Including non-PyTorch memory, this process has 44.30 GiB memory in use. Of the allocated memory 34.32 GiB is allocated by PyTorch, and 9.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
                                        
                                        
INFO - 04/15/25 16:31:28 - 0:00:11 - Added config 1d9742 as new incumbent because there are no incumbents yet.
INFO - 04/15/25 16:31:28 - 0:00:00 - 
                                     train iters 0
WARNING - 04/15/25 16:31:35 - 0:00:07 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:31:35 - 0:00:07 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 137, in train
                                            ari = exp.train()
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/exp.py", line 56, in train
                                            nmi, ari = self.train_clu(data, model, optimizer, logger, device, exp_iter)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/exp.py", line 85, in train_clu
                                            loss = model.loss(data, data['edge_index'], data['neg_edge_index'], device, pretrain=True)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/hyperSE.py", line 65, in loss
                                            embeddings, clu_mat = self.encoder(features, adj)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/l_se_net.py", line 55, in forward
                                            z, edge, ass = layer(z, edge)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/layers.py", line 151, in forward
                                            ass = self.assignor(x, adj)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/layers.py", line 129, in forward
                                            ass = self.assign_linear(self.proj(x), adj).narrow(-1, 1, self.num_assign)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/layers.py", line 24, in forward
                                            h = self.linear(x)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/models/layers.py", line 54, in forward
                                            x = self.weight(self.dropout(x))
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
                                            return self._call_impl(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
                                            return forward_call(*args, **kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 125, in forward
                                            return F.linear(input, self.weight, self.bias)
                                        torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 67.39 GiB. GPU 0 has a total capacity of 79.25 GiB of which 34.96 GiB is free. Including non-PyTorch memory, this process has 44.29 GiB memory in use. Of the allocated memory 34.32 GiB is allocated by PyTorch, and 9.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
                                        
                                        
INFO - 04/15/25 16:31:37 - 0:00:00 - 
                                     train iters 0
INFO - 04/15/25 16:31:37 - 0:00:01 - Epoch 1: train_loss=5.834128379821777
INFO - 04/15/25 16:31:37 - 0:00:01 - Epoch 2: train_loss=2.914794683456421
INFO - 04/15/25 16:31:38 - 0:00:01 - Epoch 3: train_loss=2.083066940307617
INFO - 04/15/25 16:31:38 - 0:00:01 - Epoch 4: train_loss=1.4048538208007812
INFO - 04/15/25 16:31:38 - 0:00:01 - Epoch 5: train_loss=1.1933112144470215
INFO - 04/15/25 16:31:38 - 0:00:01 - Epoch 6: train_loss=1.005194067955017
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 7: train_loss=0.835628867149353
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 8: train_loss=0.6767343878746033
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 9: train_loss=0.5940264463424683
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 10: train_loss=0.5585442781448364
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 11: train_loss=0.5231587886810303
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 12: train_loss=0.4744597375392914
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 13: train_loss=0.4122861623764038
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 14: train_loss=0.37986457347869873
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 15: train_loss=0.38582879304885864
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 16: train_loss=0.3853670060634613
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 17: train_loss=0.3660798668861389
INFO - 04/15/25 16:31:38 - 0:00:02 - Epoch 18: train_loss=0.32999274134635925
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 19: train_loss=0.3026399314403534
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 20: train_loss=0.3147447109222412
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 21: train_loss=0.3213003873825073
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 22: train_loss=0.310713529586792
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 23: train_loss=0.290078341960907
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 24: train_loss=0.27616792917251587
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 25: train_loss=0.2814706563949585
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 26: train_loss=0.2851341962814331
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 27: train_loss=0.28016746044158936
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 28: train_loss=0.26853105425834656
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 29: train_loss=0.2600206434726715
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 30: train_loss=0.26315250992774963
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 31: train_loss=0.2661038339138031
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 32: train_loss=0.26116788387298584
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 33: train_loss=0.2533096969127655
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 34: train_loss=0.25519728660583496
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 35: train_loss=0.25453799962997437
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 36: train_loss=0.25124844908714294
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 37: train_loss=0.2508668005466461
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 38: train_loss=0.24855457246303558
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 39: train_loss=0.2444809526205063
INFO - 04/15/25 16:31:39 - 0:00:02 - Epoch 40: train_loss=0.2434581220149994
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 41: train_loss=0.24202239513397217
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 42: train_loss=0.24053996801376343
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 43: train_loss=0.24144455790519714
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 44: train_loss=0.24072733521461487
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 45: train_loss=0.23682136833667755
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 46: train_loss=0.23629023134708405
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 47: train_loss=0.2408229112625122
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 48: train_loss=0.23558610677719116
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 49: train_loss=0.23679092526435852
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 50: train_loss=0.2343655526638031
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 51: train_loss=0.235227569937706
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 52: train_loss=0.2362772822380066
INFO - 04/15/25 16:31:39 - 0:00:03 - Epoch 53: train_loss=0.23262113332748413
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 54: train_loss=0.2322433590888977
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 55: train_loss=0.23257996141910553
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 56: train_loss=0.23118986189365387
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 57: train_loss=0.22870486974716187
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 58: train_loss=0.2313169240951538
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 59: train_loss=0.22833232581615448
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 60: train_loss=0.22597573697566986
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 61: train_loss=0.22649303078651428
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 62: train_loss=0.2294131964445114
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 63: train_loss=0.22478774189949036
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 64: train_loss=0.22807054221630096
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 65: train_loss=0.22459469735622406
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 66: train_loss=0.22628168761730194
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 67: train_loss=0.22197510302066803
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 68: train_loss=0.2274203598499298
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 69: train_loss=0.22017522156238556
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 70: train_loss=0.22927969694137573
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 71: train_loss=0.22445674240589142
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 72: train_loss=0.2261970490217209
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 73: train_loss=0.22481948137283325
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 74: train_loss=0.22211332619190216
INFO - 04/15/25 16:31:40 - 0:00:03 - Epoch 75: train_loss=0.22666221857070923
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 76: train_loss=0.22283749282360077
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 77: train_loss=0.22507041692733765
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 78: train_loss=0.22231581807136536
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 79: train_loss=0.22431892156600952
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 80: train_loss=0.21977001428604126
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 81: train_loss=0.2250177562236786
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 82: train_loss=0.21924073994159698
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 83: train_loss=0.2271580547094345
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 84: train_loss=0.22456949949264526
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 85: train_loss=0.22176943719387054
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 86: train_loss=0.22074617445468903
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 87: train_loss=0.22153569757938385
INFO - 04/15/25 16:31:40 - 0:00:04 - Epoch 88: train_loss=0.21853356063365936
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 89: train_loss=0.22247108817100525
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 90: train_loss=0.22115768492221832
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 91: train_loss=0.2168292999267578
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 92: train_loss=0.21600960195064545
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 93: train_loss=0.2192639857530594
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 94: train_loss=0.21552664041519165
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 95: train_loss=0.2212017923593521
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 96: train_loss=0.21995820105075836
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 97: train_loss=0.21476472914218903
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 98: train_loss=0.2168530970811844
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 99: train_loss=0.2135084569454193
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 100: train_loss=0.21307143568992615
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 101: train_loss=0.21719223260879517
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 102: train_loss=0.21218793094158173
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 103: train_loss=0.21768277883529663
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 104: train_loss=0.21599584817886353
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 105: train_loss=0.2131706178188324
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 106: train_loss=0.21590517461299896
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 107: train_loss=0.20998314023017883
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 108: train_loss=0.2191387563943863
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 109: train_loss=0.21387003362178802
INFO - 04/15/25 16:31:41 - 0:00:04 - Epoch 110: train_loss=0.21950240433216095
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 111: train_loss=0.2148265242576599
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 112: train_loss=0.22007089853286743
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 113: train_loss=0.21776431798934937
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 114: train_loss=0.21579115092754364
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 115: train_loss=0.21447275578975677
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 116: train_loss=0.21628344058990479
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 117: train_loss=0.21321430802345276
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 118: train_loss=0.21713568270206451
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 119: train_loss=0.21624019742012024
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 120: train_loss=0.2106260508298874
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 121: train_loss=0.20937134325504303
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 122: train_loss=0.2158423811197281
INFO - 04/15/25 16:31:41 - 0:00:05 - Epoch 123: train_loss=0.2118738442659378
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 124: train_loss=0.21589910984039307
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 125: train_loss=0.2149808555841446
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 126: train_loss=0.21088573336601257
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 127: train_loss=0.21047037839889526
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 128: train_loss=0.2118392437696457
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 129: train_loss=0.2088259905576706
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 130: train_loss=0.21511246263980865
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 131: train_loss=0.21401023864746094
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 132: train_loss=0.2084169089794159
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 133: train_loss=0.20877444744110107
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 134: train_loss=0.2097582072019577
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 135: train_loss=0.20579548180103302
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 136: train_loss=0.21552906930446625
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 137: train_loss=0.2146252542734146
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 138: train_loss=0.20586775243282318
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 139: train_loss=0.20940084755420685
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 140: train_loss=0.20534078776836395
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 141: train_loss=0.20318683981895447
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 142: train_loss=0.21300643682479858
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 143: train_loss=0.2073669582605362
INFO - 04/15/25 16:31:42 - 0:00:05 - Epoch 144: train_loss=0.21416880190372467
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 145: train_loss=0.21246547996997833
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 146: train_loss=0.20995445549488068
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 147: train_loss=0.210955411195755
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 148: train_loss=0.20760087668895721
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 149: train_loss=0.21184416115283966
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 150: train_loss=0.2089359164237976
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 151: train_loss=0.21026557683944702
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 152: train_loss=0.20940746366977692
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 153: train_loss=0.2075459510087967
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 154: train_loss=0.20814168453216553
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 155: train_loss=0.20502114295959473
INFO - 04/15/25 16:31:42 - 0:00:06 - Epoch 156: train_loss=0.20796331763267517
INFO - 04/15/25 16:31:43 - 0:00:06 - Epoch 157: train_loss=0.20192652940750122
INFO - 04/15/25 16:31:43 - 0:00:06 - Epoch 158: train_loss=0.21292057633399963
INFO - 04/15/25 16:31:43 - 0:00:06 - Epoch 159: train_loss=0.20696716010570526
INFO - 04/15/25 16:31:43 - 0:00:06 - Epoch 160: train_loss=0.21441884338855743
INFO - 04/15/25 16:31:45 - 0:00:06 - Epoch 161: train_loss=0.21373984217643738
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 162: train_loss=0.20630082488059998
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 163: train_loss=0.20841483771800995
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 164: train_loss=0.20546376705169678
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 165: train_loss=0.20401574671268463
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 166: train_loss=0.2104823887348175
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 167: train_loss=0.20523908734321594
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 168: train_loss=0.21310727298259735
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 169: train_loss=0.21212919056415558
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 170: train_loss=0.20719613134860992
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 171: train_loss=0.20881304144859314
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 172: train_loss=0.20531262457370758
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 173: train_loss=0.21001563966274261
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 174: train_loss=0.20354102551937103
INFO - 04/15/25 16:31:45 - 0:00:08 - Epoch 175: train_loss=0.21437497437000275
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 176: train_loss=0.21018147468566895
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 177: train_loss=0.21096353232860565
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 178: train_loss=0.2099691927433014
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 179: train_loss=0.20859694480895996
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 180: train_loss=0.2068709135055542
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 181: train_loss=0.20890991389751434
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 182: train_loss=0.20479190349578857
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 183: train_loss=0.21058569848537445
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 184: train_loss=0.20629985630512238
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 185: train_loss=0.21056042611598969
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 186: train_loss=0.2084825038909912
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 187: train_loss=0.20782217383384705
INFO - 04/15/25 16:31:45 - 0:00:09 - Epoch 188: train_loss=0.20590300858020782
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 189: train_loss=0.20859616994857788
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 190: train_loss=0.204877108335495
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 191: train_loss=0.21072693169116974
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 192: train_loss=0.20825296640396118
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 193: train_loss=0.20658817887306213
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 194: train_loss=0.2057541459798813
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 195: train_loss=0.2064848691225052
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 196: train_loss=0.20416879653930664
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 197: train_loss=0.20871230959892273
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 198: train_loss=0.2074546068906784
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 199: train_loss=0.2036476582288742
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 200: train_loss=0.20208124816417694
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 201: train_loss=0.20797063410282135
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 202: train_loss=0.2062317281961441
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 203: train_loss=0.20392143726348877
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 204: train_loss=0.20275624096393585
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 205: train_loss=0.2060958296060562
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 206: train_loss=0.20428432524204254
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 207: train_loss=0.20473447442054749
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 208: train_loss=0.20359490811824799
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 209: train_loss=0.2041109800338745
INFO - 04/15/25 16:31:46 - 0:00:09 - Epoch 210: train_loss=0.2025490701198578
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 211: train_loss=0.20480021834373474
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 212: train_loss=0.20372125506401062
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 213: train_loss=0.20325906574726105
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 214: train_loss=0.2020644098520279
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 215: train_loss=0.20393766462802887
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 216: train_loss=0.2026134431362152
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 217: train_loss=0.2029827982187271
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 218: train_loss=0.20205608010292053
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 219: train_loss=0.20277726650238037
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 220: train_loss=0.20160691440105438
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 221: train_loss=0.20308157801628113
INFO - 04/15/25 16:31:46 - 0:00:10 - Epoch 222: train_loss=0.20211546123027802
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 223: train_loss=0.201943501830101
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 224: train_loss=0.20039716362953186
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 225: train_loss=0.20284190773963928
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 226: train_loss=0.20197245478630066
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 227: train_loss=0.2011357694864273
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 228: train_loss=0.20030871033668518
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 229: train_loss=0.20242297649383545
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 230: train_loss=0.2011869251728058
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 231: train_loss=0.20113378763198853
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 232: train_loss=0.2001299411058426
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 233: train_loss=0.20095062255859375
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 234: train_loss=0.1994340419769287
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 235: train_loss=0.2021673023700714
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 236: train_loss=0.20114925503730774
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 237: train_loss=0.19925092160701752
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 238: train_loss=0.19854167103767395
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 239: train_loss=0.20103205740451813
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 240: train_loss=0.19890984892845154
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 241: train_loss=0.20190675556659698
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 242: train_loss=0.20156671106815338
INFO - 04/15/25 16:31:47 - 0:00:10 - Epoch 243: train_loss=0.1973995566368103
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 244: train_loss=0.19827543199062347
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 245: train_loss=0.20218664407730103
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 246: train_loss=0.19931618869304657
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 247: train_loss=0.2019592821598053
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 248: train_loss=0.2018858939409256
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 249: train_loss=0.19564001262187958
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 250: train_loss=0.20621995627880096
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 251: train_loss=0.19601671397686005
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 252: train_loss=0.21955843269824982
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 253: train_loss=0.22358711063861847
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 254: train_loss=0.200140118598938
INFO - 04/15/25 16:31:47 - 0:00:11 - Epoch 255: train_loss=0.22341954708099365
INFO - 04/15/25 16:31:48 - 0:00:11 - Epoch 256: train_loss=0.23563487827777863
INFO - 04/15/25 16:31:50 - 0:00:11 - Epoch 257: train_loss=0.2223963886499405
INFO - 04/15/25 16:31:50 - 0:00:14 - Epoch 258: train_loss=0.2035357654094696
INFO - 04/15/25 16:31:50 - 0:00:14 - Epoch 259: train_loss=0.215428426861763
INFO - 04/15/25 16:31:50 - 0:00:14 - Epoch 260: train_loss=0.21664175391197205
INFO - 04/15/25 16:31:50 - 0:00:14 - Epoch 261: train_loss=0.2106379270553589
INFO - 04/15/25 16:31:50 - 0:00:14 - Epoch 262: train_loss=0.20571129024028778
INFO - 04/15/25 16:31:50 - 0:00:14 - Epoch 263: train_loss=0.20864993333816528
INFO - 04/15/25 16:31:50 - 0:00:14 - Epoch 264: train_loss=0.21153880655765533
INFO - 04/15/25 16:31:50 - 0:00:14 - Epoch 265: train_loss=0.19950339198112488
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 266: train_loss=0.21204137802124023
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 267: train_loss=0.21809716522693634
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 268: train_loss=0.20256878435611725
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 269: train_loss=0.2105851173400879
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 270: train_loss=0.21846097707748413
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 271: train_loss=0.20681214332580566
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 272: train_loss=0.205376535654068
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 273: train_loss=0.20978128910064697
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 274: train_loss=0.20480337738990784
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 275: train_loss=0.2033749371767044
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 276: train_loss=0.20315448939800262
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 277: train_loss=0.2038472294807434
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 278: train_loss=0.19922733306884766
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 279: train_loss=0.2032468169927597
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 280: train_loss=0.20242935419082642
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 281: train_loss=0.19738328456878662
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 282: train_loss=0.19927063584327698
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 283: train_loss=0.1973385512828827
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 284: train_loss=0.19661612808704376
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 285: train_loss=0.19800233840942383
INFO - 04/15/25 16:31:51 - 0:00:14 - Epoch 286: train_loss=0.1944522112607956
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 287: train_loss=0.20003007352352142
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 288: train_loss=0.1961757242679596
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 289: train_loss=0.2019132375717163
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 290: train_loss=0.20096926391124725
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 291: train_loss=0.19736221432685852
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 292: train_loss=0.19728168845176697
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 293: train_loss=0.1984860748052597
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 294: train_loss=0.19642309844493866
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 295: train_loss=0.19890965521335602
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 296: train_loss=0.1980704814195633
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 297: train_loss=0.19657574594020844
INFO - 04/15/25 16:31:51 - 0:00:15 - Epoch 298: train_loss=0.19595427811145782
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 299: train_loss=0.19750404357910156
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 300: train_loss=0.19464150071144104
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 301: train_loss=0.19999687373638153
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 302: train_loss=0.19816219806671143
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 303: train_loss=0.19756482541561127
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 304: train_loss=0.19701819121837616
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 305: train_loss=0.19672900438308716
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 306: train_loss=0.1953471302986145
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 307: train_loss=0.19775977730751038
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 308: train_loss=0.19564485549926758
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 309: train_loss=0.1985691338777542
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 310: train_loss=0.19741885364055634
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 311: train_loss=0.19584429264068604
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 312: train_loss=0.19504931569099426
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 313: train_loss=0.1972292959690094
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 314: train_loss=0.19543157517910004
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 315: train_loss=0.19744309782981873
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 316: train_loss=0.1965760737657547
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 317: train_loss=0.1961134672164917
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 318: train_loss=0.19536082446575165
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 319: train_loss=0.19591565430164337
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 320: train_loss=0.19463230669498444
INFO - 04/15/25 16:31:52 - 0:00:15 - Epoch 321: train_loss=0.19673803448677063
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 322: train_loss=0.1954430490732193
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 323: train_loss=0.19593556225299835
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 324: train_loss=0.1950358897447586
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 325: train_loss=0.1954645961523056
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 326: train_loss=0.1946365088224411
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 327: train_loss=0.19572943449020386
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 328: train_loss=0.19425706565380096
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 329: train_loss=0.19592879712581635
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 330: train_loss=0.1948421597480774
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 331: train_loss=0.19505831599235535
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 332: train_loss=0.193954735994339
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 333: train_loss=0.19560137391090393
INFO - 04/15/25 16:31:52 - 0:00:16 - Epoch 334: train_loss=0.1941060572862625
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 335: train_loss=0.19506153464317322
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 336: train_loss=0.19435343146324158
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 337: train_loss=0.1947634220123291
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 338: train_loss=0.1940309703350067
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 339: train_loss=0.194324791431427
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 340: train_loss=0.1933140605688095
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 341: train_loss=0.19496357440948486
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 342: train_loss=0.19442014396190643
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 343: train_loss=0.1939162015914917
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 344: train_loss=0.19278156757354736
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 345: train_loss=0.19537986814975739
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 346: train_loss=0.19433611631393433
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 347: train_loss=0.19331076741218567
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 348: train_loss=0.19189348816871643
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 349: train_loss=0.19588810205459595
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 350: train_loss=0.19530266523361206
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 351: train_loss=0.19185693562030792
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 352: train_loss=0.19070887565612793
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 353: train_loss=0.19596858322620392
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 354: train_loss=0.19483666121959686
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 355: train_loss=0.19238035380840302
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 356: train_loss=0.19158117473125458
INFO - 04/15/25 16:31:53 - 0:00:16 - Epoch 357: train_loss=0.1949142962694168
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 358: train_loss=0.19386997818946838
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 359: train_loss=0.19299019873142242
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 360: train_loss=0.1923905313014984
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 361: train_loss=0.19330783188343048
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 362: train_loss=0.1920822411775589
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 363: train_loss=0.19372129440307617
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 364: train_loss=0.19310741126537323
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 365: train_loss=0.19204045832157135
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 366: train_loss=0.19124846160411835
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 367: train_loss=0.19391506910324097
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 368: train_loss=0.19329462945461273
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 369: train_loss=0.191767618060112
INFO - 04/15/25 16:31:53 - 0:00:17 - Epoch 370: train_loss=0.19139587879180908
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 371: train_loss=0.19345727562904358
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 372: train_loss=0.1923731565475464
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 373: train_loss=0.19261136651039124
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 374: train_loss=0.19185659289360046
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 375: train_loss=0.19246479868888855
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 376: train_loss=0.19126684963703156
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 377: train_loss=0.19269779324531555
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 378: train_loss=0.19143182039260864
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 379: train_loss=0.19276385009288788
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 380: train_loss=0.19158023595809937
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 381: train_loss=0.19226795434951782
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 382: train_loss=0.1919027715921402
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 383: train_loss=0.19162026047706604
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 384: train_loss=0.1903945952653885
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 385: train_loss=0.192568838596344
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 386: train_loss=0.1924629509449005
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 387: train_loss=0.18993128836154938
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 388: train_loss=0.18946242332458496
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 389: train_loss=0.19427822530269623
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 390: train_loss=0.19346556067466736
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 391: train_loss=0.19033405184745789
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 392: train_loss=0.1921021193265915
INFO - 04/15/25 16:31:54 - 0:00:17 - Epoch 393: train_loss=0.190581813454628
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 394: train_loss=0.19167503714561462
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 395: train_loss=0.19032804667949677
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 396: train_loss=0.18996387720108032
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 397: train_loss=0.19209112226963043
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 398: train_loss=0.1893269568681717
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 399: train_loss=0.1921481192111969
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 400: train_loss=0.18978318572044373
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 401: train_loss=0.19193877279758453
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 402: train_loss=0.19007575511932373
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 403: train_loss=0.19289526343345642
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 404: train_loss=0.19292233884334564
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 405: train_loss=0.18796789646148682
INFO - 04/15/25 16:31:54 - 0:00:18 - Epoch 406: train_loss=0.19108974933624268
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 407: train_loss=0.1922307014465332
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 408: train_loss=0.1883123815059662
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 409: train_loss=0.19378143548965454
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 410: train_loss=0.19094432890415192
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 411: train_loss=0.191757470369339
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 412: train_loss=0.19353003799915314
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 413: train_loss=0.1870088279247284
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 414: train_loss=0.20525242388248444
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 415: train_loss=0.20622657239437103
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 416: train_loss=0.18997950851917267
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 417: train_loss=0.20512261986732483
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 418: train_loss=0.20903195440769196
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 419: train_loss=0.1993436962366104
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 420: train_loss=0.1987844705581665
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 421: train_loss=0.20011422038078308
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 422: train_loss=0.20007692277431488
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 423: train_loss=0.19847890734672546
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 424: train_loss=0.19169938564300537
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 425: train_loss=0.19899505376815796
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 426: train_loss=0.1950376331806183
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 427: train_loss=0.19407959282398224
INFO - 04/15/25 16:31:55 - 0:00:18 - Epoch 428: train_loss=0.19607330858707428
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 429: train_loss=0.18906301259994507
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 430: train_loss=0.19534265995025635
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 431: train_loss=0.19155217707157135
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 432: train_loss=0.19570136070251465
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 433: train_loss=0.1938430368900299
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 434: train_loss=0.19519491493701935
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 435: train_loss=0.19249078631401062
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 436: train_loss=0.19645534455776215
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 437: train_loss=0.19571617245674133
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 438: train_loss=0.19077520072460175
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 439: train_loss=0.19206736981868744
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 440: train_loss=0.19046738743782043
INFO - 04/15/25 16:31:55 - 0:00:19 - Epoch 441: train_loss=0.18895083665847778
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 442: train_loss=0.19342269003391266
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 443: train_loss=0.1884859800338745
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 444: train_loss=0.1973584145307541
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 445: train_loss=0.19543276727199554
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 446: train_loss=0.1923423707485199
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 447: train_loss=0.19352711737155914
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 448: train_loss=0.1905101090669632
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 449: train_loss=0.19445471465587616
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 450: train_loss=0.18895882368087769
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 451: train_loss=0.20138069987297058
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 452: train_loss=0.2001858502626419
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 453: train_loss=0.19069497287273407
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 454: train_loss=0.19286958873271942
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 455: train_loss=0.192480206489563
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 456: train_loss=0.18984267115592957
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 457: train_loss=0.19435648620128632
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 458: train_loss=0.19169148802757263
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 459: train_loss=0.19366146624088287
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 460: train_loss=0.1913800835609436
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 461: train_loss=0.19363822042942047
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 462: train_loss=0.19076500833034515
INFO - 04/15/25 16:31:56 - 0:00:19 - Epoch 463: train_loss=0.19318822026252747
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 464: train_loss=0.19096088409423828
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 465: train_loss=0.19181682169437408
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 466: train_loss=0.1911899447441101
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 467: train_loss=0.18984538316726685
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 468: train_loss=0.19118580222129822
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 469: train_loss=0.18855370581150055
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 470: train_loss=0.19043688476085663
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 471: train_loss=0.1889486014842987
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 472: train_loss=0.18869492411613464
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 473: train_loss=0.18983139097690582
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 474: train_loss=0.18632745742797852
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 475: train_loss=0.19474385678768158
INFO - 04/15/25 16:31:56 - 0:00:20 - Epoch 476: train_loss=0.1895166039466858
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 477: train_loss=0.19870522618293762
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 478: train_loss=0.19972087442874908
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 479: train_loss=0.18767699599266052
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 480: train_loss=0.19635418057441711
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 481: train_loss=0.19496789574623108
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 482: train_loss=0.19079190492630005
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 483: train_loss=0.19236204028129578
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 484: train_loss=0.19094941020011902
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 485: train_loss=0.19128072261810303
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 486: train_loss=0.18878720700740814
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 487: train_loss=0.19226279854774475
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 488: train_loss=0.18728159368038177
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 489: train_loss=0.19720202684402466
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 490: train_loss=0.196882963180542
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 491: train_loss=0.18602794408798218
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 492: train_loss=0.19067783653736115
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 493: train_loss=0.18606382608413696
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 494: train_loss=0.19164329767227173
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 495: train_loss=0.18787866830825806
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 496: train_loss=0.19307707250118256
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 497: train_loss=0.19064882397651672
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 498: train_loss=0.19271625578403473
INFO - 04/15/25 16:31:57 - 0:00:20 - Epoch 499: train_loss=0.19062086939811707
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 500: train_loss=0.19300998747348785
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 501: train_loss=0.1921791434288025
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 502: train_loss=0.18989314138889313
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 503: train_loss=0.18962574005126953
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 504: train_loss=0.1906057447195053
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 505: train_loss=0.18825465440750122
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 506: train_loss=0.1929074227809906
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 507: train_loss=0.19073820114135742
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 508: train_loss=0.191830113530159
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 509: train_loss=0.19140228629112244
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 510: train_loss=0.18956482410430908
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 511: train_loss=0.18919123709201813
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 512: train_loss=0.1900564283132553
INFO - 04/15/25 16:31:57 - 0:00:21 - Epoch 513: train_loss=0.1880721002817154
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 514: train_loss=0.19145169854164124
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 515: train_loss=0.18933716416358948
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 516: train_loss=0.1915462762117386
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 517: train_loss=0.19067099690437317
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 518: train_loss=0.18947654962539673
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 519: train_loss=0.18911823630332947
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 520: train_loss=0.18948394060134888
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 521: train_loss=0.18804442882537842
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 522: train_loss=0.1907382607460022
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 523: train_loss=0.18911558389663696
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 524: train_loss=0.19038769602775574
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 525: train_loss=0.18958300352096558
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 526: train_loss=0.1892606019973755
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 527: train_loss=0.18847501277923584
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 528: train_loss=0.18990124762058258
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 529: train_loss=0.18862465023994446
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 530: train_loss=0.1902119517326355
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 531: train_loss=0.18957310914993286
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 532: train_loss=0.18853889405727386
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 533: train_loss=0.1874389797449112
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 534: train_loss=0.19091308116912842
INFO - 04/15/25 16:31:58 - 0:00:21 - Epoch 535: train_loss=0.19015982747077942
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 536: train_loss=0.1877860426902771
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 537: train_loss=0.18674471974372864
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 538: train_loss=0.19122539460659027
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 539: train_loss=0.19049742817878723
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 540: train_loss=0.1870226263999939
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 541: train_loss=0.18645820021629333
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 542: train_loss=0.19047358632087708
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 543: train_loss=0.1891908347606659
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 544: train_loss=0.1884823888540268
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 545: train_loss=0.1878603845834732
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 546: train_loss=0.18901236355304718
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 547: train_loss=0.18799099326133728
INFO - 04/15/25 16:31:58 - 0:00:22 - Epoch 548: train_loss=0.1891716867685318
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 549: train_loss=0.18835598230361938
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 550: train_loss=0.18861976265907288
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 551: train_loss=0.18796882033348083
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 552: train_loss=0.1883232593536377
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 553: train_loss=0.18729832768440247
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 554: train_loss=0.18939320743083954
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 555: train_loss=0.188703253865242
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 556: train_loss=0.18757346272468567
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 557: train_loss=0.18687671422958374
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 558: train_loss=0.18884898722171783
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 559: train_loss=0.1877877116203308
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 560: train_loss=0.1883779913187027
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 561: train_loss=0.18765687942504883
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 562: train_loss=0.18818284571170807
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 563: train_loss=0.18750052154064178
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 564: train_loss=0.18798990547657013
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 565: train_loss=0.186997190117836
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 566: train_loss=0.1886204183101654
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 567: train_loss=0.18803958594799042
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 568: train_loss=0.18714362382888794
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 569: train_loss=0.1862965226173401
INFO - 04/15/25 16:31:59 - 0:00:22 - Epoch 570: train_loss=0.18881314992904663
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 571: train_loss=0.18800215423107147
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 572: train_loss=0.18709993362426758
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 573: train_loss=0.1864221692085266
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 574: train_loss=0.18839101493358612
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 575: train_loss=0.1875307261943817
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 576: train_loss=0.18730302155017853
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 577: train_loss=0.18652166426181793
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 578: train_loss=0.1881544291973114
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 579: train_loss=0.18748266994953156
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 580: train_loss=0.18699413537979126
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 581: train_loss=0.18612827360630035
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 582: train_loss=0.1884530931711197
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 583: train_loss=0.18788348138332367
INFO - 04/15/25 16:31:59 - 0:00:23 - Epoch 584: train_loss=0.18624408543109894
INFO - 04/15/25 16:32:00 - 0:00:23 - Epoch 585: train_loss=0.18524222075939178
INFO - 04/15/25 16:32:01 - 0:00:23 - Epoch 586: train_loss=0.18917417526245117
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 587: train_loss=0.18867187201976776
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 588: train_loss=0.18512248992919922
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 589: train_loss=0.18450048565864563
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 590: train_loss=0.1900758296251297
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 591: train_loss=0.1890421211719513
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 592: train_loss=0.18593961000442505
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 593: train_loss=0.18978796899318695
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 594: train_loss=0.18255965411663055
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 595: train_loss=0.2032240778207779
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 596: train_loss=0.20613506436347961
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 597: train_loss=0.1907874047756195
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 598: train_loss=0.20142792165279388
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 599: train_loss=0.2090362161397934
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 600: train_loss=0.19951662421226501
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 601: train_loss=0.19409576058387756
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 602: train_loss=0.19839167594909668
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 603: train_loss=0.19427764415740967
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 604: train_loss=0.19583851099014282
INFO - 04/15/25 16:32:01 - 0:00:24 - Epoch 605: train_loss=0.19286823272705078
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 606: train_loss=0.19230243563652039
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 607: train_loss=0.19483008980751038
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 608: train_loss=0.1842012107372284
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 609: train_loss=0.19821690022945404
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 610: train_loss=0.19861747324466705
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 611: train_loss=0.18382243812084198
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 612: train_loss=0.20023594796657562
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 613: train_loss=0.20365700125694275
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 614: train_loss=0.19365932047367096
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 615: train_loss=0.19475270807743073
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 616: train_loss=0.19749225676059723
INFO - 04/15/25 16:32:01 - 0:00:25 - Epoch 617: train_loss=0.19188307225704193
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 618: train_loss=0.19472618401050568
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 619: train_loss=0.1926964372396469
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 620: train_loss=0.18998822569847107
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 621: train_loss=0.1928366720676422
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 622: train_loss=0.18779154121875763
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 623: train_loss=0.19109870493412018
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 624: train_loss=0.19176846742630005
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 625: train_loss=0.1872619241476059
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 626: train_loss=0.18938131630420685
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 627: train_loss=0.18953131139278412
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 628: train_loss=0.18636074662208557
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 629: train_loss=0.18807323276996613
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 630: train_loss=0.18718773126602173
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 631: train_loss=0.18652287125587463
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 632: train_loss=0.1868140697479248
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 633: train_loss=0.18570837378501892
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 634: train_loss=0.18770982325077057
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 635: train_loss=0.18598945438861847
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 636: train_loss=0.1884285807609558
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 637: train_loss=0.18618997931480408
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 638: train_loss=0.1895361989736557
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 639: train_loss=0.18753431737422943
INFO - 04/15/25 16:32:02 - 0:00:25 - Epoch 640: train_loss=0.1888238489627838
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 641: train_loss=0.18875718116760254
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 642: train_loss=0.18597617745399475
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 643: train_loss=0.1865811049938202
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 644: train_loss=0.18556037545204163
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 645: train_loss=0.1866377890110016
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 646: train_loss=0.18400657176971436
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 647: train_loss=0.19052694737911224
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 648: train_loss=0.18871374428272247
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 649: train_loss=0.18769149482250214
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 650: train_loss=0.18727923929691315
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 651: train_loss=0.1878792643547058
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 652: train_loss=0.18687500059604645
INFO - 04/15/25 16:32:02 - 0:00:26 - Epoch 653: train_loss=0.18810349702835083
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 654: train_loss=0.18731647729873657
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 655: train_loss=0.1874975562095642
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 656: train_loss=0.18635660409927368
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 657: train_loss=0.1887250542640686
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 658: train_loss=0.18766668438911438
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 659: train_loss=0.18719980120658875
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 660: train_loss=0.1867174655199051
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 661: train_loss=0.1872214525938034
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 662: train_loss=0.1859051138162613
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 663: train_loss=0.18868406116962433
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 664: train_loss=0.1879628449678421
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 665: train_loss=0.1862223595380783
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 666: train_loss=0.18553635478019714
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 667: train_loss=0.18797922134399414
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 668: train_loss=0.18674716353416443
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 669: train_loss=0.18730582296848297
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 670: train_loss=0.18665051460266113
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 671: train_loss=0.18677735328674316
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 672: train_loss=0.18592694401741028
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 673: train_loss=0.18734894692897797
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 674: train_loss=0.1862526684999466
INFO - 04/15/25 16:32:03 - 0:00:26 - Epoch 675: train_loss=0.18709918856620789
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 676: train_loss=0.18649819493293762
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 677: train_loss=0.18630991876125336
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 678: train_loss=0.18540382385253906
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 679: train_loss=0.18730506300926208
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 680: train_loss=0.18638569116592407
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 681: train_loss=0.18643192946910858
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 682: train_loss=0.18580500781536102
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 683: train_loss=0.1864098608493805
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 684: train_loss=0.18555203080177307
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 685: train_loss=0.18661469221115112
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 686: train_loss=0.18570491671562195
INFO - 04/15/25 16:32:03 - 0:00:27 - Epoch 687: train_loss=0.18644776940345764
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 688: train_loss=0.18575429916381836
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 689: train_loss=0.18593935668468475
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 690: train_loss=0.1851656436920166
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 691: train_loss=0.18641632795333862
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 692: train_loss=0.18563948571681976
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 693: train_loss=0.18591643869876862
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 694: train_loss=0.18524013459682465
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 695: train_loss=0.18598905205726624
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 696: train_loss=0.18513867259025574
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 697: train_loss=0.18606743216514587
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 698: train_loss=0.1853829324245453
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 699: train_loss=0.18568971753120422
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 700: train_loss=0.18502630293369293
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 701: train_loss=0.1858658492565155
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 702: train_loss=0.18512041866779327
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 703: train_loss=0.18577083945274353
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 704: train_loss=0.1851252317428589
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 705: train_loss=0.18553419411182404
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 706: train_loss=0.1848411113023758
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 707: train_loss=0.1856822818517685
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 708: train_loss=0.1850888431072235
INFO - 04/15/25 16:32:04 - 0:00:27 - Epoch 709: train_loss=0.1853337436914444
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 710: train_loss=0.18463940918445587
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 711: train_loss=0.1856611967086792
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 712: train_loss=0.1850530356168747
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 713: train_loss=0.18504881858825684
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 714: train_loss=0.18442445993423462
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 715: train_loss=0.1856149435043335
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 716: train_loss=0.18504656851291656
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 717: train_loss=0.18479686975479126
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 718: train_loss=0.18415236473083496
INFO - 04/15/25 16:32:04 - 0:00:28 - Epoch 719: train_loss=0.18569257855415344
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 720: train_loss=0.1850980520248413
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 721: train_loss=0.18453383445739746
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 722: train_loss=0.1838037669658661
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 723: train_loss=0.18576329946517944
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 724: train_loss=0.1852303296327591
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 725: train_loss=0.18410220742225647
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 726: train_loss=0.18340912461280823
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 727: train_loss=0.18598896265029907
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 728: train_loss=0.1854337453842163
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 729: train_loss=0.18366676568984985
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 730: train_loss=0.18300238251686096
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 731: train_loss=0.1861102283000946
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 732: train_loss=0.18558774888515472
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 733: train_loss=0.1832762509584427
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 734: train_loss=0.18265114724636078
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 735: train_loss=0.18644939363002777
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 736: train_loss=0.18596075475215912
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 737: train_loss=0.18269892036914825
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 738: train_loss=0.18426412343978882
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 739: train_loss=0.18517906963825226
INFO - 04/15/25 16:32:05 - 0:00:28 - Epoch 740: train_loss=0.18322525918483734
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 741: train_loss=0.18360531330108643
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 742: train_loss=0.181794211268425
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 743: train_loss=0.19034364819526672
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 744: train_loss=0.1895093023777008
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 745: train_loss=0.18612883985042572
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 746: train_loss=0.1865590661764145
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 747: train_loss=0.18759682774543762
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 748: train_loss=0.18146444857120514
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 749: train_loss=0.18273687362670898
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 750: train_loss=0.1871703565120697
INFO - 04/15/25 16:32:05 - 0:00:29 - Epoch 751: train_loss=0.18286164104938507
INFO - 04/15/25 16:32:06 - 0:00:29 - Epoch 752: train_loss=0.18912871181964874
INFO - 04/15/25 16:32:06 - 0:00:29 - Epoch 753: train_loss=0.18737250566482544
INFO - 04/15/25 16:32:06 - 0:00:29 - Epoch 754: train_loss=0.1874551624059677
INFO - 04/15/25 16:32:06 - 0:00:29 - Epoch 755: train_loss=0.18512019515037537
INFO - 04/15/25 16:32:06 - 0:00:29 - Epoch 756: train_loss=0.18738940358161926
INFO - 04/15/25 16:32:06 - 0:00:29 - Epoch 757: train_loss=0.18215879797935486
INFO - 04/15/25 16:32:06 - 0:00:29 - Epoch 758: train_loss=0.18396243453025818
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 759: train_loss=0.1862168312072754
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 760: train_loss=0.1821727305650711
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 761: train_loss=0.19516655802726746
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 762: train_loss=0.19028013944625854
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 763: train_loss=0.19222503900527954
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 764: train_loss=0.18736854195594788
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 765: train_loss=0.18830084800720215
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 766: train_loss=0.18575043976306915
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 767: train_loss=0.19244161248207092
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 768: train_loss=0.19228440523147583
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 769: train_loss=0.1847841739654541
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 770: train_loss=0.18497300148010254
INFO - 04/15/25 16:32:06 - 0:00:30 - Epoch 771: train_loss=0.1906735599040985
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 772: train_loss=0.18656648695468903
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 773: train_loss=0.1930861473083496
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 774: train_loss=0.1943291872739792
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 775: train_loss=0.18573608994483948
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 776: train_loss=0.1897934228181839
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 777: train_loss=0.1884750872850418
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 778: train_loss=0.1867295354604721
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 779: train_loss=0.1893533617258072
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 780: train_loss=0.18704935908317566
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 781: train_loss=0.19139723479747772
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 782: train_loss=0.1906278133392334
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 783: train_loss=0.1872049868106842
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 784: train_loss=0.18664319813251495
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 785: train_loss=0.18980136513710022
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 786: train_loss=0.1882399171590805
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 787: train_loss=0.1889035403728485
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 788: train_loss=0.18860094249248505
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 789: train_loss=0.1870793104171753
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 790: train_loss=0.1864294409751892
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 791: train_loss=0.18816187977790833
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 792: train_loss=0.18668031692504883
INFO - 04/15/25 16:32:07 - 0:00:30 - Epoch 793: train_loss=0.1888117641210556
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 794: train_loss=0.18813952803611755
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 795: train_loss=0.18689045310020447
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 796: train_loss=0.18621638417243958
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 797: train_loss=0.18823358416557312
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 798: train_loss=0.1870463341474533
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 799: train_loss=0.18763422966003418
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 800: train_loss=0.1872505247592926
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 801: train_loss=0.18647363781929016
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 802: train_loss=0.18549902737140656
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 803: train_loss=0.1883491724729538
INFO - 04/15/25 16:32:07 - 0:00:31 - Epoch 804: train_loss=0.18742352724075317
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 805: train_loss=0.1862335354089737
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 806: train_loss=0.18555912375450134
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 807: train_loss=0.18761689960956573
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 808: train_loss=0.18678002059459686
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 809: train_loss=0.18626508116722107
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 810: train_loss=0.18560513854026794
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 811: train_loss=0.18701206147670746
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 812: train_loss=0.1861571967601776
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 813: train_loss=0.18644385039806366
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 814: train_loss=0.1856541484594345
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 815: train_loss=0.18676410615444183
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 816: train_loss=0.18604248762130737
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 817: train_loss=0.18599864840507507
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 818: train_loss=0.18522244691848755
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 819: train_loss=0.1867469996213913
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 820: train_loss=0.18592461943626404
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 821: train_loss=0.18571925163269043
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 822: train_loss=0.18507510423660278
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 823: train_loss=0.1863500475883484
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 824: train_loss=0.18559172749519348
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 825: train_loss=0.18557606637477875
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 826: train_loss=0.18496106564998627
INFO - 04/15/25 16:32:08 - 0:00:31 - Epoch 827: train_loss=0.18614909052848816
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 828: train_loss=0.18544460833072662
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 829: train_loss=0.1853644847869873
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 830: train_loss=0.18461716175079346
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 831: train_loss=0.18614618480205536
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 832: train_loss=0.1855842024087906
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 833: train_loss=0.18481417000293732
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 834: train_loss=0.1839703917503357
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 835: train_loss=0.1864311546087265
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 836: train_loss=0.18593169748783112
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 837: train_loss=0.18405850231647491
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 838: train_loss=0.18325084447860718
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 839: train_loss=0.1869487166404724
INFO - 04/15/25 16:32:08 - 0:00:32 - Epoch 840: train_loss=0.1863984912633896
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 841: train_loss=0.18320730328559875
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 842: train_loss=0.1823822259902954
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 843: train_loss=0.18735551834106445
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 844: train_loss=0.1868806928396225
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 845: train_loss=0.18247680366039276
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 846: train_loss=0.1817653775215149
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 847: train_loss=0.187680184841156
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 848: train_loss=0.18689805269241333
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 849: train_loss=0.1827402114868164
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 850: train_loss=0.18435434997081757
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 851: train_loss=0.18274317681789398
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 852: train_loss=0.1800113171339035
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 853: train_loss=0.1902070939540863
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 854: train_loss=0.18909890949726105
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 855: train_loss=0.18338260054588318
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 856: train_loss=0.18753400444984436
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 857: train_loss=0.18570302426815033
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 858: train_loss=0.1854555904865265
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 859: train_loss=0.18546177446842194
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 860: train_loss=0.18412241339683533
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 861: train_loss=0.18484258651733398
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 862: train_loss=0.1822478324174881
INFO - 04/15/25 16:32:09 - 0:00:32 - Epoch 863: train_loss=0.18835851550102234
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 864: train_loss=0.18571913242340088
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 865: train_loss=0.18786582350730896
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 866: train_loss=0.18741975724697113
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 867: train_loss=0.18596245348453522
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 868: train_loss=0.18510651588439941
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 869: train_loss=0.18723629415035248
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 870: train_loss=0.184427872300148
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 871: train_loss=0.18938571214675903
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 872: train_loss=0.18952184915542603
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 873: train_loss=0.18227656185626984
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 874: train_loss=0.18610742688179016
INFO - 04/15/25 16:32:09 - 0:00:33 - Epoch 875: train_loss=0.18215344846248627
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 876: train_loss=0.18774442374706268
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 877: train_loss=0.18633417785167694
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 878: train_loss=0.18445083498954773
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 879: train_loss=0.18405641615390778
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 880: train_loss=0.18540255725383759
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 881: train_loss=0.18421144783496857
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 882: train_loss=0.18552029132843018
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 883: train_loss=0.1845250129699707
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 884: train_loss=0.18503962457180023
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 885: train_loss=0.1843499094247818
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 886: train_loss=0.18478725850582123
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 887: train_loss=0.18407240509986877
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 888: train_loss=0.18478122353553772
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 889: train_loss=0.1832951456308365
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 890: train_loss=0.18609857559204102
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 891: train_loss=0.18512402474880219
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 892: train_loss=0.1847100555896759
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 893: train_loss=0.18455299735069275
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 894: train_loss=0.18397262692451477
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 895: train_loss=0.1838693469762802
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 896: train_loss=0.18321281671524048
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 897: train_loss=0.18379229307174683
INFO - 04/15/25 16:32:10 - 0:00:33 - Epoch 898: train_loss=0.18208907544612885
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 899: train_loss=0.1856393963098526
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 900: train_loss=0.18228936195373535
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 901: train_loss=0.189611554145813
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 902: train_loss=0.19032427668571472
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 903: train_loss=0.18034441769123077
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 904: train_loss=0.19288726150989532
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 905: train_loss=0.19475606083869934
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 906: train_loss=0.18455760180950165
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 907: train_loss=0.19311074912548065
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 908: train_loss=0.19908353686332703
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 909: train_loss=0.19249583780765533
INFO - 04/15/25 16:32:10 - 0:00:34 - Epoch 910: train_loss=0.18434461951255798
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 911: train_loss=0.18868224322795868
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 912: train_loss=0.18163900077342987
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 913: train_loss=0.1929381787776947
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 914: train_loss=0.19551604986190796
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 915: train_loss=0.18633577227592468
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 916: train_loss=0.19105614721775055
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 917: train_loss=0.1962224841117859
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 918: train_loss=0.19093695282936096
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 919: train_loss=0.18505850434303284
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 920: train_loss=0.1896371692419052
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 921: train_loss=0.18641884624958038
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 922: train_loss=0.18696676194667816
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 923: train_loss=0.1879703402519226
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 924: train_loss=0.183257058262825
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 925: train_loss=0.18607878684997559
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 926: train_loss=0.18473264575004578
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 927: train_loss=0.1846705824136734
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 928: train_loss=0.18443545699119568
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 929: train_loss=0.18390265107154846
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 930: train_loss=0.1834472119808197
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 931: train_loss=0.1837962567806244
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 932: train_loss=0.18307960033416748
INFO - 04/15/25 16:32:11 - 0:00:34 - Epoch 933: train_loss=0.1842210590839386
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 934: train_loss=0.18323363363742828
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 935: train_loss=0.18415918946266174
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 936: train_loss=0.18341368436813354
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 937: train_loss=0.18370643258094788
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 938: train_loss=0.18308259546756744
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 939: train_loss=0.18412795662879944
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 940: train_loss=0.18275900185108185
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 941: train_loss=0.18435783684253693
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 942: train_loss=0.1835232377052307
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 943: train_loss=0.18366402387619019
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 944: train_loss=0.18337929248809814
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 945: train_loss=0.18316316604614258
INFO - 04/15/25 16:32:11 - 0:00:35 - Epoch 946: train_loss=0.18243783712387085
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 947: train_loss=0.1842041164636612
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 948: train_loss=0.18353143334388733
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 949: train_loss=0.18338808417320251
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 950: train_loss=0.18297924101352692
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 951: train_loss=0.18343570828437805
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 952: train_loss=0.18277478218078613
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 953: train_loss=0.1839819848537445
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 954: train_loss=0.18363215029239655
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 955: train_loss=0.1826738715171814
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 956: train_loss=0.18234534561634064
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 957: train_loss=0.18352092802524567
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 958: train_loss=0.18239134550094604
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 959: train_loss=0.1844567358493805
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 960: train_loss=0.18444634974002838
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 961: train_loss=0.1813228279352188
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 962: train_loss=0.18275760114192963
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 963: train_loss=0.18300743401050568
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 964: train_loss=0.18189223110675812
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 965: train_loss=0.18234722316265106
INFO - 04/15/25 16:32:12 - 0:00:35 - Epoch 966: train_loss=0.17988775670528412
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 967: train_loss=0.18692828714847565
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 968: train_loss=0.18708394467830658
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 969: train_loss=0.17983418703079224
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 970: train_loss=0.1901484876871109
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 971: train_loss=0.1908976435661316
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 972: train_loss=0.1845034509897232
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 973: train_loss=0.18636000156402588
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 974: train_loss=0.18922588229179382
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 975: train_loss=0.18596406280994415
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 976: train_loss=0.1839108020067215
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 977: train_loss=0.1857350617647171
INFO - 04/15/25 16:32:12 - 0:00:36 - Epoch 978: train_loss=0.1824178844690323
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 979: train_loss=0.1843346506357193
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 980: train_loss=0.18387843668460846
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 981: train_loss=0.1828124076128006
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 982: train_loss=0.1830742210149765
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 983: train_loss=0.18228968977928162
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 984: train_loss=0.1820148229598999
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 985: train_loss=0.18332631886005402
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 986: train_loss=0.18180306255817413
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 987: train_loss=0.18313457071781158
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 988: train_loss=0.182097390294075
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 989: train_loss=0.18320512771606445
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 990: train_loss=0.18328873813152313
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 991: train_loss=0.18085046112537384
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 992: train_loss=0.18206317722797394
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 993: train_loss=0.18224123120307922
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 994: train_loss=0.1821696162223816
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 995: train_loss=0.18275520205497742
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 996: train_loss=0.18046574294567108
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 997: train_loss=0.18357862532138824
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 998: train_loss=0.18211610615253448
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 999: train_loss=0.18238478899002075
INFO - 04/15/25 16:32:13 - 0:00:36 - --------------------------Training Start-------------------------
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 1: train_loss=10.319554328918457
INFO - 04/15/25 16:32:13 - 0:00:36 - Epoch 2: train_loss=10.416502952575684
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 3: train_loss=10.36745548248291
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 4: train_loss=10.301230430603027
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 5: train_loss=10.253119468688965
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 6: train_loss=10.220989227294922
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 7: train_loss=10.177619934082031
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 8: train_loss=10.143742561340332
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 9: train_loss=10.137165069580078
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 10: train_loss=10.13508129119873
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 11: train_loss=10.11793327331543
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 12: train_loss=10.093564987182617
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 13: train_loss=10.091218948364258
INFO - 04/15/25 16:32:13 - 0:00:37 - Epoch 14: train_loss=10.09880542755127
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 15: train_loss=10.095415115356445
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 16: train_loss=10.085487365722656
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 17: train_loss=10.080469131469727
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 18: train_loss=10.081985473632812
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 19: train_loss=10.080734252929688
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 20: train_loss=10.077754020690918
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 21: train_loss=10.075544357299805
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 22: train_loss=10.07545280456543
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 23: train_loss=10.075233459472656
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 24: train_loss=10.07330322265625
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 25: train_loss=10.072417259216309
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 26: train_loss=10.071094512939453
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 27: train_loss=10.069561958312988
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 28: train_loss=10.069933891296387
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 29: train_loss=10.068798065185547
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 30: train_loss=10.069002151489258
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 31: train_loss=10.067742347717285
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 32: train_loss=10.066705703735352
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 33: train_loss=10.065897941589355
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 34: train_loss=10.066604614257812
INFO - 04/15/25 16:32:14 - 0:00:37 - Epoch 35: train_loss=10.065984725952148
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 36: train_loss=10.064912796020508
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 37: train_loss=10.065105438232422
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 38: train_loss=10.063569068908691
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 39: train_loss=10.065258979797363
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 40: train_loss=10.064624786376953
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 41: train_loss=10.064393043518066
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 42: train_loss=10.065499305725098
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 43: train_loss=10.067644119262695
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 44: train_loss=10.063424110412598
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 45: train_loss=10.064037322998047
INFO - 04/15/25 16:32:14 - 0:00:38 - Epoch 46: train_loss=10.065335273742676
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 47: train_loss=10.066935539245605
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 48: train_loss=10.063016891479492
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 49: train_loss=10.06631088256836
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 50: train_loss=10.065947532653809
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 51: train_loss=10.062837600708008
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 52: train_loss=10.066038131713867
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 53: train_loss=10.064901351928711
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 54: train_loss=10.06265926361084
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 55: train_loss=10.063081741333008
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 56: train_loss=10.067414283752441
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 57: train_loss=10.062477111816406
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 58: train_loss=10.068394660949707
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 59: train_loss=10.06454849243164
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 60: train_loss=10.068706512451172
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 61: train_loss=10.064864158630371
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 62: train_loss=10.068930625915527
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 63: train_loss=10.066594123840332
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 64: train_loss=10.068811416625977
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 65: train_loss=10.065999984741211
INFO - 04/15/25 16:32:15 - 0:00:38 - Epoch 66: train_loss=10.069616317749023
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 67: train_loss=10.068826675415039
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 68: train_loss=10.066245079040527
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 69: train_loss=10.066267013549805
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 70: train_loss=10.066341400146484
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 71: train_loss=10.064552307128906
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 72: train_loss=10.068740844726562
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 73: train_loss=10.067024230957031
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 74: train_loss=10.066672325134277
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 75: train_loss=10.066675186157227
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 76: train_loss=10.065052032470703
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 77: train_loss=10.063807487487793
INFO - 04/15/25 16:32:15 - 0:00:39 - Epoch 78: train_loss=10.068105697631836
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 79: train_loss=10.067232131958008
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 80: train_loss=10.064691543579102
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 81: train_loss=10.064300537109375
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 82: train_loss=10.066276550292969
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 83: train_loss=10.064821243286133
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 84: train_loss=10.066852569580078
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 85: train_loss=10.06607723236084
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 86: train_loss=10.06521987915039
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 87: train_loss=10.064701080322266
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 88: train_loss=10.065803527832031
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 89: train_loss=10.064543724060059
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 90: train_loss=10.06637954711914
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 91: train_loss=10.06602954864502
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 92: train_loss=10.063950538635254
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 93: train_loss=10.063153266906738
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 94: train_loss=10.06666088104248
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 95: train_loss=10.065858840942383
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 96: train_loss=10.064069747924805
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 97: train_loss=10.06351375579834
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 98: train_loss=10.065852165222168
INFO - 04/15/25 16:32:16 - 0:00:39 - Epoch 99: train_loss=10.06500244140625
INFO - 04/15/25 16:32:16 - 0:00:40 - Epoch 100: train_loss=10.064464569091797
INFO - 04/15/25 16:32:16 - 0:00:40 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:16 - 0:00:40 - Decoding cost time:  0.182 s
INFO - 04/15/25 16:32:17 - 0:00:40 - ------------------Saving best model-------------------
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 100: ACC: 0.0, NMI: 0.31908907945604603, F1: 0.0, ARI: 0.05872043844086181
INFO - 04/15/25 16:32:17 - 0:00:40 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 101: train_loss=10.063830375671387
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 102: train_loss=10.065391540527344
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 103: train_loss=10.06472110748291
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 104: train_loss=10.064264297485352
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 105: train_loss=10.063464164733887
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 106: train_loss=10.065468788146973
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 107: train_loss=10.064923286437988
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 108: train_loss=10.063645362854004
INFO - 04/15/25 16:32:17 - 0:00:40 - Epoch 109: train_loss=10.062834739685059
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 110: train_loss=10.065740585327148
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 111: train_loss=10.065214157104492
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 112: train_loss=10.063034057617188
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 113: train_loss=10.062403678894043
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 114: train_loss=10.065693855285645
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 115: train_loss=10.064982414245605
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 116: train_loss=10.063119888305664
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 117: train_loss=10.062625885009766
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 118: train_loss=10.064959526062012
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 119: train_loss=10.06418228149414
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 120: train_loss=10.063742637634277
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 121: train_loss=10.063241004943848
INFO - 04/15/25 16:32:17 - 0:00:41 - Epoch 122: train_loss=10.064210891723633
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 123: train_loss=10.063603401184082
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 124: train_loss=10.063846588134766
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 125: train_loss=10.0631685256958
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 126: train_loss=10.064203262329102
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 127: train_loss=10.063755989074707
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 128: train_loss=10.06334400177002
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 129: train_loss=10.062664031982422
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 130: train_loss=10.064465522766113
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 131: train_loss=10.064045906066895
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 132: train_loss=10.062692642211914
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 133: train_loss=10.06198787689209
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 134: train_loss=10.064850807189941
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 135: train_loss=10.064417839050293
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 136: train_loss=10.062055587768555
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 137: train_loss=10.06140422821045
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 138: train_loss=10.065106391906738
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 139: train_loss=10.06467342376709
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 140: train_loss=10.061600685119629
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 141: train_loss=10.061089515686035
INFO - 04/15/25 16:32:18 - 0:00:41 - Epoch 142: train_loss=10.064910888671875
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 143: train_loss=10.064220428466797
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 144: train_loss=10.062000274658203
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 145: train_loss=10.061688423156738
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 146: train_loss=10.064011573791504
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 147: train_loss=10.06329345703125
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 148: train_loss=10.062752723693848
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 149: train_loss=10.062488555908203
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 150: train_loss=10.062950134277344
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 151: train_loss=10.062241554260254
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 152: train_loss=10.063494682312012
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 153: train_loss=10.063072204589844
INFO - 04/15/25 16:32:18 - 0:00:42 - Epoch 154: train_loss=10.062381744384766
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 155: train_loss=10.0619478225708
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 156: train_loss=10.06334400177002
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 157: train_loss=10.062759399414062
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 158: train_loss=10.062705039978027
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 159: train_loss=10.062397956848145
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 160: train_loss=10.062582969665527
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 161: train_loss=10.061955451965332
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 162: train_loss=10.063301086425781
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 163: train_loss=10.06291389465332
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 164: train_loss=10.061936378479004
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 165: train_loss=10.06153678894043
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 166: train_loss=10.06338882446289
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 167: train_loss=10.062832832336426
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 168: train_loss=10.062013626098633
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 169: train_loss=10.062174797058105
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 170: train_loss=10.06217098236084
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 171: train_loss=10.061095237731934
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 172: train_loss=10.063667297363281
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 173: train_loss=10.063210487365723
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 174: train_loss=10.06138801574707
INFO - 04/15/25 16:32:19 - 0:00:42 - Epoch 175: train_loss=10.061474800109863
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 176: train_loss=10.063000679016113
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 177: train_loss=10.06208610534668
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 178: train_loss=10.06222915649414
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 179: train_loss=10.062238693237305
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 180: train_loss=10.062100410461426
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 181: train_loss=10.061363220214844
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 182: train_loss=10.062606811523438
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 183: train_loss=10.061854362487793
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 184: train_loss=10.062752723693848
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 185: train_loss=10.062657356262207
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 186: train_loss=10.06109619140625
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 187: train_loss=10.060591697692871
INFO - 04/15/25 16:32:19 - 0:00:43 - Epoch 188: train_loss=10.064432144165039
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 189: train_loss=10.063820838928223
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 190: train_loss=10.061708450317383
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 191: train_loss=10.065815925598145
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 192: train_loss=10.063579559326172
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 193: train_loss=10.065744400024414
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 194: train_loss=10.065549850463867
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 195: train_loss=10.0645170211792
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 196: train_loss=10.062690734863281
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 197: train_loss=10.067137718200684
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 198: train_loss=10.065614700317383
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 199: train_loss=10.064200401306152
INFO - 04/15/25 16:32:20 - 0:00:43 - Epoch 200: train_loss=10.064274787902832
INFO - 04/15/25 16:32:20 - 0:00:43 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:20 - 0:00:43 - Decoding cost time:  0.115 s
INFO - 04/15/25 16:32:20 - 0:00:44 - ------------------Saving best model-------------------
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 200: ACC: 0.0, NMI: 0.3924143953842758, F1: 0.0, ARI: 0.14548203542856403
INFO - 04/15/25 16:32:24 - 0:00:47 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 201: train_loss=10.063872337341309
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 202: train_loss=10.062509536743164
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 203: train_loss=10.066282272338867
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 204: train_loss=10.064830780029297
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 205: train_loss=10.064760208129883
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 206: train_loss=10.064803123474121
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 207: train_loss=10.063005447387695
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 208: train_loss=10.06240463256836
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 209: train_loss=10.064610481262207
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 210: train_loss=10.063217163085938
INFO - 04/15/25 16:32:24 - 0:00:47 - Epoch 211: train_loss=10.064824104309082
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 212: train_loss=10.064260482788086
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 213: train_loss=10.063429832458496
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 214: train_loss=10.063142776489258
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 215: train_loss=10.063453674316406
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 216: train_loss=10.062597274780273
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 217: train_loss=10.063835144042969
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 218: train_loss=10.062973976135254
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 219: train_loss=10.0636568069458
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 220: train_loss=10.063187599182129
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 221: train_loss=10.062944412231445
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 222: train_loss=10.062383651733398
INFO - 04/15/25 16:32:24 - 0:00:48 - Epoch 223: train_loss=10.063661575317383
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 224: train_loss=10.062993049621582
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 225: train_loss=10.06308364868164
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 226: train_loss=10.062551498413086
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 227: train_loss=10.063243865966797
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 228: train_loss=10.062707901000977
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 229: train_loss=10.062820434570312
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 230: train_loss=10.0623140335083
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 231: train_loss=10.062896728515625
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 232: train_loss=10.062314987182617
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 233: train_loss=10.062828063964844
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 234: train_loss=10.062323570251465
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 235: train_loss=10.062593460083008
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 236: train_loss=10.0620756149292
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 237: train_loss=10.062630653381348
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 238: train_loss=10.062252044677734
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 239: train_loss=10.06227970123291
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 240: train_loss=10.061759948730469
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 241: train_loss=10.062603950500488
INFO - 04/15/25 16:32:25 - 0:00:48 - Epoch 242: train_loss=10.062061309814453
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 243: train_loss=10.062285423278809
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 244: train_loss=10.061952590942383
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 245: train_loss=10.061943054199219
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 246: train_loss=10.061423301696777
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 247: train_loss=10.062484741210938
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 248: train_loss=10.061997413635254
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 249: train_loss=10.061711311340332
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 250: train_loss=10.061467170715332
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 251: train_loss=10.061887741088867
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 252: train_loss=10.061260223388672
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 253: train_loss=10.062298774719238
INFO - 04/15/25 16:32:25 - 0:00:49 - Epoch 254: train_loss=10.062024116516113
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 255: train_loss=10.061161041259766
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 256: train_loss=10.06078052520752
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 257: train_loss=10.062456130981445
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 258: train_loss=10.062009811401367
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 259: train_loss=10.061103820800781
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 260: train_loss=10.06104850769043
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 261: train_loss=10.061952590942383
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 262: train_loss=10.061380386352539
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 263: train_loss=10.0610990524292
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 264: train_loss=10.06068229675293
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 265: train_loss=10.06289005279541
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 266: train_loss=10.062384605407715
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 267: train_loss=10.060826301574707
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 268: train_loss=10.06437873840332
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 269: train_loss=10.061216354370117
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 270: train_loss=10.067726135253906
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 271: train_loss=10.0684232711792
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 272: train_loss=10.06237506866455
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 273: train_loss=10.065692901611328
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 274: train_loss=10.065059661865234
INFO - 04/15/25 16:32:26 - 0:00:49 - Epoch 275: train_loss=10.065361976623535
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 276: train_loss=10.06234073638916
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 277: train_loss=10.067004203796387
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 278: train_loss=10.068278312683105
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 279: train_loss=10.060552597045898
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 280: train_loss=10.069913864135742
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 281: train_loss=10.072864532470703
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 282: train_loss=10.068333625793457
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 283: train_loss=10.065914154052734
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 284: train_loss=10.066059112548828
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 285: train_loss=10.066320419311523
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 286: train_loss=10.067893981933594
INFO - 04/15/25 16:32:26 - 0:00:50 - Epoch 287: train_loss=10.063460350036621
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 288: train_loss=10.065736770629883
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 289: train_loss=10.06862735748291
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 290: train_loss=10.064175605773926
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 291: train_loss=10.064866065979004
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 292: train_loss=10.06541919708252
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 293: train_loss=10.064464569091797
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 294: train_loss=10.064591407775879
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 295: train_loss=10.061285972595215
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 296: train_loss=10.064789772033691
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 297: train_loss=10.062697410583496
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 298: train_loss=10.064173698425293
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 299: train_loss=10.0645112991333
INFO - 04/15/25 16:32:27 - 0:00:50 - Epoch 300: train_loss=10.061456680297852
INFO - 04/15/25 16:32:27 - 0:00:50 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:27 - 0:00:50 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 300: ACC: 0.0, NMI: 0.28784596289077685, F1: 0.0, ARI: 0.08113124533733078
INFO - 04/15/25 16:32:27 - 0:00:51 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 301: train_loss=10.062116622924805
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 302: train_loss=10.062255859375
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 303: train_loss=10.061477661132812
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 304: train_loss=10.062934875488281
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 305: train_loss=10.062026977539062
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 306: train_loss=10.063249588012695
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 307: train_loss=10.061901092529297
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 308: train_loss=10.064159393310547
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 309: train_loss=10.064004898071289
INFO - 04/15/25 16:32:27 - 0:00:51 - Epoch 310: train_loss=10.060933113098145
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 311: train_loss=10.060759544372559
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 312: train_loss=10.06340503692627
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 313: train_loss=10.061636924743652
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 314: train_loss=10.064380645751953
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 315: train_loss=10.064864158630371
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 316: train_loss=10.05955982208252
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 317: train_loss=10.061342239379883
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 318: train_loss=10.0614595413208
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 319: train_loss=10.059897422790527
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 320: train_loss=10.064449310302734
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 321: train_loss=10.062426567077637
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 322: train_loss=10.064434051513672
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 323: train_loss=10.06392765045166
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 324: train_loss=10.062726020812988
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 325: train_loss=10.063801765441895
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 326: train_loss=10.061935424804688
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 327: train_loss=10.06549072265625
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 328: train_loss=10.06562614440918
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 329: train_loss=10.061555862426758
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 330: train_loss=10.06330394744873
INFO - 04/15/25 16:32:28 - 0:00:51 - Epoch 331: train_loss=10.061875343322754
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 332: train_loss=10.064062118530273
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 333: train_loss=10.06358814239502
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 334: train_loss=10.061894416809082
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 335: train_loss=10.06246280670166
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 336: train_loss=10.060649871826172
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 337: train_loss=10.064208030700684
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 338: train_loss=10.060672760009766
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 339: train_loss=10.068551063537598
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 340: train_loss=10.068516731262207
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 341: train_loss=10.060522079467773
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 342: train_loss=10.064932823181152
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 343: train_loss=10.063261985778809
INFO - 04/15/25 16:32:28 - 0:00:52 - Epoch 344: train_loss=10.063669204711914
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 345: train_loss=10.062767028808594
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 346: train_loss=10.063186645507812
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 347: train_loss=10.062439918518066
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 348: train_loss=10.061836242675781
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 349: train_loss=10.063872337341309
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 350: train_loss=10.061756134033203
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 351: train_loss=10.065933227539062
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 352: train_loss=10.06636905670166
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 353: train_loss=10.061119079589844
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 354: train_loss=10.064144134521484
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 355: train_loss=10.063899040222168
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 356: train_loss=10.060952186584473
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 357: train_loss=10.063996315002441
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 358: train_loss=10.061274528503418
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 359: train_loss=10.065982818603516
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 360: train_loss=10.065250396728516
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 361: train_loss=10.06298828125
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 362: train_loss=10.063264846801758
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 363: train_loss=10.062893867492676
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 364: train_loss=10.062195777893066
INFO - 04/15/25 16:32:29 - 0:00:52 - Epoch 365: train_loss=10.063529014587402
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 366: train_loss=10.062299728393555
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 367: train_loss=10.06447982788086
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 368: train_loss=10.062529563903809
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 369: train_loss=10.065579414367676
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 370: train_loss=10.06580638885498
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 371: train_loss=10.06026554107666
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 372: train_loss=10.060616493225098
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 373: train_loss=10.064122200012207
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 374: train_loss=10.061933517456055
INFO - 04/15/25 16:32:29 - 0:00:53 - Epoch 375: train_loss=10.065717697143555
INFO - 04/15/25 16:32:30 - 0:00:53 - Epoch 376: train_loss=10.065901756286621
INFO - 04/15/25 16:32:30 - 0:00:53 - Epoch 377: train_loss=10.060815811157227
INFO - 04/15/25 16:32:30 - 0:00:53 - Epoch 378: train_loss=10.06208324432373
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 379: train_loss=10.062180519104004
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 380: train_loss=10.060434341430664
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 381: train_loss=10.064528465270996
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 382: train_loss=10.063551902770996
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 383: train_loss=10.062956809997559
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 384: train_loss=10.062228202819824
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 385: train_loss=10.063886642456055
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 386: train_loss=10.063058853149414
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 387: train_loss=10.062973976135254
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 388: train_loss=10.062417984008789
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 389: train_loss=10.063455581665039
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 390: train_loss=10.062573432922363
INFO - 04/15/25 16:32:30 - 0:00:54 - Epoch 391: train_loss=10.063459396362305
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 392: train_loss=10.062908172607422
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 393: train_loss=10.06296157836914
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 394: train_loss=10.062444686889648
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 395: train_loss=10.063008308410645
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 396: train_loss=10.062395095825195
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 397: train_loss=10.06314754486084
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 398: train_loss=10.062607765197754
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 399: train_loss=10.062795639038086
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 400: train_loss=10.06209659576416
INFO - 04/15/25 16:32:31 - 0:00:54 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:31 - 0:00:54 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 400: ACC: 0.0, NMI: 0.33210071968611166, F1: 0.0, ARI: 0.10661883084012777
INFO - 04/15/25 16:32:31 - 0:00:54 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 401: train_loss=10.063282012939453
INFO - 04/15/25 16:32:31 - 0:00:54 - Epoch 402: train_loss=10.062915802001953
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 403: train_loss=10.062148094177246
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 404: train_loss=10.061553001403809
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 405: train_loss=10.063423156738281
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 406: train_loss=10.06272029876709
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 407: train_loss=10.062500953674316
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 408: train_loss=10.06202220916748
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 409: train_loss=10.062870979309082
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 410: train_loss=10.062358856201172
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 411: train_loss=10.06253719329834
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 412: train_loss=10.061952590942383
INFO - 04/15/25 16:32:31 - 0:00:55 - Epoch 413: train_loss=10.062968254089355
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 414: train_loss=10.062569618225098
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 415: train_loss=10.062043190002441
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 416: train_loss=10.061400413513184
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 417: train_loss=10.063331604003906
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 418: train_loss=10.062867164611816
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 419: train_loss=10.061657905578613
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 420: train_loss=10.061156272888184
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 421: train_loss=10.063179016113281
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 422: train_loss=10.062519073486328
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 423: train_loss=10.062066078186035
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 424: train_loss=10.061676025390625
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 425: train_loss=10.062506675720215
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 426: train_loss=10.061935424804688
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 427: train_loss=10.06236743927002
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 428: train_loss=10.061800003051758
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 429: train_loss=10.062470436096191
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 430: train_loss=10.062126159667969
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 431: train_loss=10.062010765075684
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 432: train_loss=10.061403274536133
INFO - 04/15/25 16:32:32 - 0:00:55 - Epoch 433: train_loss=10.062615394592285
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 434: train_loss=10.062148094177246
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 435: train_loss=10.06195068359375
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 436: train_loss=10.061524391174316
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 437: train_loss=10.062314987182617
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 438: train_loss=10.061714172363281
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 439: train_loss=10.06221866607666
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 440: train_loss=10.061722755432129
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 441: train_loss=10.062114715576172
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 442: train_loss=10.061690330505371
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 443: train_loss=10.061982154846191
INFO - 04/15/25 16:32:32 - 0:00:56 - Epoch 444: train_loss=10.061420440673828
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 445: train_loss=10.0621919631958
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 446: train_loss=10.061694145202637
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 447: train_loss=10.06189250946045
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 448: train_loss=10.06142520904541
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 449: train_loss=10.061992645263672
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 450: train_loss=10.061503410339355
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 451: train_loss=10.061928749084473
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 452: train_loss=10.061476707458496
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 453: train_loss=10.061907768249512
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 454: train_loss=10.061492919921875
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 455: train_loss=10.061803817749023
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 456: train_loss=10.061367988586426
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 457: train_loss=10.06191635131836
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 458: train_loss=10.061545372009277
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 459: train_loss=10.06169605255127
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 460: train_loss=10.061285972595215
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 461: train_loss=10.061904907226562
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 462: train_loss=10.061463356018066
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 463: train_loss=10.061657905578613
INFO - 04/15/25 16:32:33 - 0:00:56 - Epoch 464: train_loss=10.061217308044434
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 465: train_loss=10.061768531799316
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 466: train_loss=10.06137466430664
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 467: train_loss=10.061698913574219
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 468: train_loss=10.061304092407227
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 469: train_loss=10.061537742614746
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 470: train_loss=10.061121940612793
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 471: train_loss=10.06180191040039
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 472: train_loss=10.061433792114258
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 473: train_loss=10.06136703491211
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 474: train_loss=10.061020851135254
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 475: train_loss=10.061665534973145
INFO - 04/15/25 16:32:33 - 0:00:57 - Epoch 476: train_loss=10.061212539672852
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 477: train_loss=10.061548233032227
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 478: train_loss=10.061236381530762
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 479: train_loss=10.061314582824707
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 480: train_loss=10.060782432556152
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 481: train_loss=10.061933517456055
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 482: train_loss=10.061722755432129
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 483: train_loss=10.060698509216309
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 484: train_loss=10.06027603149414
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 485: train_loss=10.06237506866455
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 486: train_loss=10.062122344970703
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 487: train_loss=10.060293197631836
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 488: train_loss=10.05980396270752
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 489: train_loss=10.062736511230469
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 490: train_loss=10.062461853027344
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 491: train_loss=10.059823036193848
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 492: train_loss=10.059996604919434
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 493: train_loss=10.063186645507812
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 494: train_loss=10.061684608459473
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 495: train_loss=10.062307357788086
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 496: train_loss=10.062838554382324
INFO - 04/15/25 16:32:34 - 0:00:57 - Epoch 497: train_loss=10.06070327758789
INFO - 04/15/25 16:32:34 - 0:00:58 - Epoch 498: train_loss=10.066458702087402
INFO - 04/15/25 16:32:34 - 0:00:58 - Epoch 499: train_loss=10.066789627075195
INFO - 04/15/25 16:32:34 - 0:00:58 - Epoch 500: train_loss=10.06149673461914
INFO - 04/15/25 16:32:34 - 0:00:58 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:34 - 0:00:58 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:32:34 - 0:00:58 - Epoch 500: ACC: 0.0, NMI: 0.35031410056403084, F1: 0.0, ARI: 0.1074769552766199
INFO - 04/15/25 16:32:34 - 0:00:58 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 501: train_loss=10.063821792602539
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 502: train_loss=10.06456470489502
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 503: train_loss=10.06213092803955
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 504: train_loss=10.064321517944336
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 505: train_loss=10.065389633178711
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 506: train_loss=10.060689926147461
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 507: train_loss=10.06404972076416
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 508: train_loss=10.065422058105469
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 509: train_loss=10.060379981994629
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 510: train_loss=10.066468238830566
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 511: train_loss=10.069500923156738
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 512: train_loss=10.066147804260254
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 513: train_loss=10.061169624328613
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 514: train_loss=10.06666374206543
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 515: train_loss=10.068399429321289
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 516: train_loss=10.062832832336426
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 517: train_loss=10.064785957336426
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 518: train_loss=10.067124366760254
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 519: train_loss=10.065887451171875
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 520: train_loss=10.061735153198242
INFO - 04/15/25 16:32:35 - 0:00:58 - Epoch 521: train_loss=10.066498756408691
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 522: train_loss=10.068914413452148
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 523: train_loss=10.064159393310547
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 524: train_loss=10.064165115356445
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 525: train_loss=10.065032005310059
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 526: train_loss=10.065855979919434
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 527: train_loss=10.062946319580078
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 528: train_loss=10.064282417297363
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 529: train_loss=10.065925598144531
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 530: train_loss=10.062312126159668
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 531: train_loss=10.062597274780273
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 532: train_loss=10.064151763916016
INFO - 04/15/25 16:32:35 - 0:00:59 - Epoch 533: train_loss=10.063447952270508
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 534: train_loss=10.060676574707031
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 535: train_loss=10.061773300170898
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 536: train_loss=10.060476303100586
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 537: train_loss=10.062880516052246
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 538: train_loss=10.06192684173584
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 539: train_loss=10.062369346618652
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 540: train_loss=10.061041831970215
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 541: train_loss=10.06182861328125
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 542: train_loss=10.061184883117676
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 543: train_loss=10.060176849365234
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 544: train_loss=10.062183380126953
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 545: train_loss=10.061053276062012
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 546: train_loss=10.061453819274902
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 547: train_loss=10.061384201049805
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 548: train_loss=10.060553550720215
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 549: train_loss=10.06273078918457
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 550: train_loss=10.06218433380127
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 551: train_loss=10.061895370483398
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 552: train_loss=10.06076717376709
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 553: train_loss=10.062847137451172
INFO - 04/15/25 16:32:36 - 0:00:59 - Epoch 554: train_loss=10.060151100158691
INFO - 04/15/25 16:32:36 - 0:01:00 - Epoch 555: train_loss=10.065691947937012
INFO - 04/15/25 16:32:36 - 0:01:00 - Epoch 556: train_loss=10.06556224822998
INFO - 04/15/25 16:32:36 - 0:01:00 - Epoch 557: train_loss=10.059821128845215
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 558: train_loss=10.061826705932617
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 559: train_loss=10.060718536376953
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 560: train_loss=10.059649467468262
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 561: train_loss=10.064297676086426
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 562: train_loss=10.06368350982666
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 563: train_loss=10.062408447265625
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 564: train_loss=10.062088012695312
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 565: train_loss=10.061938285827637
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 566: train_loss=10.062122344970703
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 567: train_loss=10.061452865600586
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 568: train_loss=10.060726165771484
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 569: train_loss=10.0628023147583
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 570: train_loss=10.06173038482666
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 571: train_loss=10.063039779663086
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 572: train_loss=10.061847686767578
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 573: train_loss=10.063371658325195
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 574: train_loss=10.063591957092285
INFO - 04/15/25 16:32:37 - 0:01:00 - Epoch 575: train_loss=10.060818672180176
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 576: train_loss=10.062085151672363
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 577: train_loss=10.060001373291016
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 578: train_loss=10.062666893005371
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 579: train_loss=10.05894660949707
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 580: train_loss=10.06482219696045
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 581: train_loss=10.06293773651123
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 582: train_loss=10.064096450805664
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 583: train_loss=10.063990592956543
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 584: train_loss=10.061681747436523
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 585: train_loss=10.061976432800293
INFO - 04/15/25 16:32:37 - 0:01:01 - Epoch 586: train_loss=10.062104225158691
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 587: train_loss=10.061247825622559
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 588: train_loss=10.061445236206055
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 589: train_loss=10.061765670776367
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 590: train_loss=10.060063362121582
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 591: train_loss=10.064478874206543
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 592: train_loss=10.06229305267334
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 593: train_loss=10.064922332763672
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 594: train_loss=10.065641403198242
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 595: train_loss=10.059216499328613
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 596: train_loss=10.061267852783203
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 597: train_loss=10.061132431030273
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 598: train_loss=10.060317993164062
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 599: train_loss=10.060609817504883
INFO - 04/15/25 16:32:38 - 0:01:01 - Epoch 600: train_loss=10.06093692779541
INFO - 04/15/25 16:32:38 - 0:01:01 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:38 - 0:01:01 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 600: ACC: 0.0, NMI: 0.36035187110138645, F1: 0.0, ARI: 0.10654482233976208
INFO - 04/15/25 16:32:38 - 0:01:02 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 601: train_loss=10.060601234436035
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 602: train_loss=10.059279441833496
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 603: train_loss=10.062373161315918
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 604: train_loss=10.059810638427734
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 605: train_loss=10.063462257385254
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 606: train_loss=10.060750007629395
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 607: train_loss=10.064973831176758
INFO - 04/15/25 16:32:38 - 0:01:02 - Epoch 608: train_loss=10.065594673156738
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 609: train_loss=10.0607271194458
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 610: train_loss=10.064962387084961
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 611: train_loss=10.065030097961426
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 612: train_loss=10.059884071350098
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 613: train_loss=10.065170288085938
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 614: train_loss=10.064409255981445
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 615: train_loss=10.06076431274414
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 616: train_loss=10.061880111694336
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 617: train_loss=10.061239242553711
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 618: train_loss=10.061295509338379
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 619: train_loss=10.06053638458252
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 620: train_loss=10.061821937561035
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 621: train_loss=10.060086250305176
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 622: train_loss=10.06214427947998
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 623: train_loss=10.060640335083008
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 624: train_loss=10.061802864074707
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 625: train_loss=10.060900688171387
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 626: train_loss=10.061543464660645
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 627: train_loss=10.06042194366455
INFO - 04/15/25 16:32:39 - 0:01:02 - Epoch 628: train_loss=10.062032699584961
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 629: train_loss=10.060186386108398
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 630: train_loss=10.063669204711914
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 631: train_loss=10.06291675567627
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 632: train_loss=10.06149673461914
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 633: train_loss=10.061945915222168
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 634: train_loss=10.060942649841309
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 635: train_loss=10.061845779418945
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 636: train_loss=10.060002326965332
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 637: train_loss=10.063799858093262
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 638: train_loss=10.062496185302734
INFO - 04/15/25 16:32:39 - 0:01:03 - Epoch 639: train_loss=10.062582969665527
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 640: train_loss=10.062646865844727
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 641: train_loss=10.061739921569824
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 642: train_loss=10.061616897583008
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 643: train_loss=10.061480522155762
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 644: train_loss=10.061619758605957
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 645: train_loss=10.060354232788086
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 646: train_loss=10.064363479614258
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 647: train_loss=10.064085960388184
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 648: train_loss=10.060688972473145
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 649: train_loss=10.061559677124023
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 650: train_loss=10.06102180480957
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 651: train_loss=10.061574935913086
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 652: train_loss=10.060203552246094
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 653: train_loss=10.064002990722656
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 654: train_loss=10.063902854919434
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 655: train_loss=10.060604095458984
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 656: train_loss=10.062152862548828
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 657: train_loss=10.061234474182129
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 658: train_loss=10.06188678741455
INFO - 04/15/25 16:32:40 - 0:01:03 - Epoch 659: train_loss=10.061370849609375
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 660: train_loss=10.06170654296875
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 661: train_loss=10.06119155883789
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 662: train_loss=10.061534881591797
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 663: train_loss=10.061259269714355
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 664: train_loss=10.060546875
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 665: train_loss=10.061732292175293
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 666: train_loss=10.059231758117676
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 667: train_loss=10.0623779296875
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 668: train_loss=10.060334205627441
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 669: train_loss=10.062281608581543
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 670: train_loss=10.061318397521973
INFO - 04/15/25 16:32:40 - 0:01:04 - Epoch 671: train_loss=10.061655044555664
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 672: train_loss=10.060870170593262
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 673: train_loss=10.061195373535156
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 674: train_loss=10.060394287109375
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 675: train_loss=10.061426162719727
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 676: train_loss=10.058713912963867
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 677: train_loss=10.065503120422363
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 678: train_loss=10.06446647644043
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 679: train_loss=10.061091423034668
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 680: train_loss=10.061629295349121
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 681: train_loss=10.0620756149292
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 682: train_loss=10.06026554107666
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 683: train_loss=10.064286231994629
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 684: train_loss=10.062677383422852
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 685: train_loss=10.063301086425781
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 686: train_loss=10.063164710998535
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 687: train_loss=10.06158447265625
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 688: train_loss=10.060810089111328
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 689: train_loss=10.06389045715332
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 690: train_loss=10.062952041625977
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 691: train_loss=10.06220531463623
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 692: train_loss=10.061856269836426
INFO - 04/15/25 16:32:41 - 0:01:04 - Epoch 693: train_loss=10.062627792358398
INFO - 04/15/25 16:32:41 - 0:01:05 - Epoch 694: train_loss=10.061922073364258
INFO - 04/15/25 16:32:41 - 0:01:05 - Epoch 695: train_loss=10.062933921813965
INFO - 04/15/25 16:32:41 - 0:01:05 - Epoch 696: train_loss=10.062520980834961
INFO - 04/15/25 16:32:41 - 0:01:05 - Epoch 697: train_loss=10.062027931213379
INFO - 04/15/25 16:32:41 - 0:01:05 - Epoch 698: train_loss=10.061474800109863
INFO - 04/15/25 16:32:41 - 0:01:05 - Epoch 699: train_loss=10.062995910644531
INFO - 04/15/25 16:32:41 - 0:01:05 - Epoch 700: train_loss=10.062419891357422
INFO - 04/15/25 16:32:41 - 0:01:05 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:41 - 0:01:05 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 700: ACC: 0.0, NMI: 0.35570107620909747, F1: 0.0, ARI: 0.11709947373111704
INFO - 04/15/25 16:32:42 - 0:01:05 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 701: train_loss=10.062254905700684
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 702: train_loss=10.061935424804688
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 703: train_loss=10.062287330627441
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 704: train_loss=10.061549186706543
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 705: train_loss=10.063005447387695
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 706: train_loss=10.062676429748535
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 707: train_loss=10.061392784118652
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 708: train_loss=10.060613632202148
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 709: train_loss=10.06378173828125
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 710: train_loss=10.063380241394043
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 711: train_loss=10.060805320739746
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 712: train_loss=10.060294151306152
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 713: train_loss=10.06363296508789
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 714: train_loss=10.062883377075195
INFO - 04/15/25 16:32:42 - 0:01:05 - Epoch 715: train_loss=10.061517715454102
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 716: train_loss=10.061232566833496
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 717: train_loss=10.062575340270996
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 718: train_loss=10.06175422668457
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 719: train_loss=10.062532424926758
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 720: train_loss=10.062216758728027
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 721: train_loss=10.06170654296875
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 722: train_loss=10.061149597167969
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 723: train_loss=10.062736511230469
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 724: train_loss=10.06214714050293
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 725: train_loss=10.061846733093262
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 726: train_loss=10.061463356018066
INFO - 04/15/25 16:32:42 - 0:01:06 - Epoch 727: train_loss=10.062294006347656
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 728: train_loss=10.061653137207031
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 729: train_loss=10.062259674072266
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 730: train_loss=10.061870574951172
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 731: train_loss=10.061895370483398
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 732: train_loss=10.061275482177734
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 733: train_loss=10.062487602233887
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 734: train_loss=10.06192684173584
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 735: train_loss=10.061810493469238
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 736: train_loss=10.061266899108887
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 737: train_loss=10.06235408782959
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 738: train_loss=10.061817169189453
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 739: train_loss=10.061873435974121
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 740: train_loss=10.061432838439941
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 741: train_loss=10.062174797058105
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 742: train_loss=10.0615873336792
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 743: train_loss=10.06202220916748
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 744: train_loss=10.061519622802734
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 745: train_loss=10.06200122833252
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 746: train_loss=10.061488151550293
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 747: train_loss=10.062036514282227
INFO - 04/15/25 16:32:43 - 0:01:06 - Epoch 748: train_loss=10.061440467834473
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 749: train_loss=10.062016487121582
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 750: train_loss=10.061572074890137
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 751: train_loss=10.061918258666992
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 752: train_loss=10.061351776123047
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 753: train_loss=10.062060356140137
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 754: train_loss=10.06151008605957
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 755: train_loss=10.061896324157715
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 756: train_loss=10.0614595413208
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 757: train_loss=10.061857223510742
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 758: train_loss=10.06131362915039
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 759: train_loss=10.062063217163086
INFO - 04/15/25 16:32:43 - 0:01:07 - Epoch 760: train_loss=10.061515808105469
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 761: train_loss=10.061707496643066
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 762: train_loss=10.061220169067383
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 763: train_loss=10.061856269836426
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 764: train_loss=10.061232566833496
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 765: train_loss=10.061954498291016
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 766: train_loss=10.061556816101074
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 767: train_loss=10.061539649963379
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 768: train_loss=10.061053276062012
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 769: train_loss=10.061795234680176
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 770: train_loss=10.061222076416016
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 771: train_loss=10.061880111694336
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 772: train_loss=10.061466217041016
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 773: train_loss=10.061367988586426
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 774: train_loss=10.060853004455566
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 775: train_loss=10.0619478225708
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 776: train_loss=10.061470031738281
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 777: train_loss=10.061300277709961
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 778: train_loss=10.060916900634766
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 779: train_loss=10.061779022216797
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 780: train_loss=10.061300277709961
INFO - 04/15/25 16:32:44 - 0:01:07 - Epoch 781: train_loss=10.061315536499023
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 782: train_loss=10.060842514038086
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 783: train_loss=10.061792373657227
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 784: train_loss=10.061493873596191
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 785: train_loss=10.06086254119873
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 786: train_loss=10.060218811035156
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 787: train_loss=10.06256103515625
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 788: train_loss=10.062420845031738
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 789: train_loss=10.05965518951416
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 790: train_loss=10.058886528015137
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 791: train_loss=10.063677787780762
INFO - 04/15/25 16:32:44 - 0:01:08 - Epoch 792: train_loss=10.063410758972168
INFO - 04/15/25 16:32:45 - 0:01:08 - Epoch 793: train_loss=10.058650016784668
INFO - 04/15/25 16:32:45 - 0:01:08 - Epoch 794: train_loss=10.058205604553223
INFO - 04/15/25 16:32:45 - 0:01:08 - Epoch 795: train_loss=10.063706398010254
INFO - 04/15/25 16:32:45 - 0:01:08 - Epoch 796: train_loss=10.062829971313477
INFO - 04/15/25 16:32:45 - 0:01:08 - Epoch 797: train_loss=10.060176849365234
INFO - 04/15/25 16:32:45 - 0:01:08 - Epoch 798: train_loss=10.061145782470703
INFO - 04/15/25 16:32:45 - 0:01:08 - Epoch 799: train_loss=10.059659004211426
INFO - 04/15/25 16:32:45 - 0:01:08 - Epoch 800: train_loss=10.061722755432129
INFO - 04/15/25 16:32:45 - 0:01:08 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:45 - 0:01:08 - Decoding cost time:  0.129 s
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 800: ACC: 0.0, NMI: 0.3454852698653455, F1: 0.0, ARI: 0.1151720559682251
INFO - 04/15/25 16:32:45 - 0:01:09 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 801: train_loss=10.059830665588379
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 802: train_loss=10.062225341796875
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 803: train_loss=10.06174373626709
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 804: train_loss=10.060790061950684
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 805: train_loss=10.061760902404785
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 806: train_loss=10.060824394226074
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 807: train_loss=10.061939239501953
INFO - 04/15/25 16:32:45 - 0:01:09 - Epoch 808: train_loss=10.061774253845215
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 809: train_loss=10.060977935791016
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 810: train_loss=10.06065559387207
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 811: train_loss=10.060798645019531
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 812: train_loss=10.06075668334961
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 813: train_loss=10.059721946716309
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 814: train_loss=10.062504768371582
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 815: train_loss=10.061952590942383
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 816: train_loss=10.061332702636719
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 817: train_loss=10.06076431274414
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 818: train_loss=10.061582565307617
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 819: train_loss=10.059443473815918
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 820: train_loss=10.060832977294922
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 821: train_loss=10.059529304504395
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 822: train_loss=10.060596466064453
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 823: train_loss=10.058785438537598
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 824: train_loss=10.060003280639648
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 825: train_loss=10.060431480407715
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 826: train_loss=10.058536529541016
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 827: train_loss=10.06005859375
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 828: train_loss=10.059396743774414
INFO - 04/15/25 16:32:46 - 0:01:09 - Epoch 829: train_loss=10.059101104736328
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 830: train_loss=10.058991432189941
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 831: train_loss=10.061005592346191
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 832: train_loss=10.058379173278809
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 833: train_loss=10.064541816711426
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 834: train_loss=10.064661979675293
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 835: train_loss=10.0596342086792
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 836: train_loss=10.063285827636719
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 837: train_loss=10.063250541687012
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 838: train_loss=10.061797142028809
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 839: train_loss=10.061070442199707
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 840: train_loss=10.062097549438477
INFO - 04/15/25 16:32:46 - 0:01:10 - Epoch 841: train_loss=10.062272071838379
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 842: train_loss=10.05945873260498
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 843: train_loss=10.060789108276367
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 844: train_loss=10.060482025146484
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 845: train_loss=10.059852600097656
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 846: train_loss=10.060941696166992
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 847: train_loss=10.060670852661133
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 848: train_loss=10.060444831848145
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 849: train_loss=10.059511184692383
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 850: train_loss=10.06096363067627
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 851: train_loss=10.059420585632324
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 852: train_loss=10.06119441986084
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 853: train_loss=10.060331344604492
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 854: train_loss=10.060903549194336
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 855: train_loss=10.059831619262695
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 856: train_loss=10.060711860656738
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 857: train_loss=10.059876441955566
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 858: train_loss=10.06004524230957
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 859: train_loss=10.060309410095215
INFO - 04/15/25 16:32:47 - 0:01:10 - Epoch 860: train_loss=10.05928897857666
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 861: train_loss=10.06183910369873
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 862: train_loss=10.061081886291504
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 863: train_loss=10.061066627502441
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 864: train_loss=10.06075382232666
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 865: train_loss=10.060973167419434
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 866: train_loss=10.060311317443848
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 867: train_loss=10.061595916748047
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 868: train_loss=10.060691833496094
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 869: train_loss=10.061552047729492
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 870: train_loss=10.061553001403809
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 871: train_loss=10.059850692749023
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 872: train_loss=10.059404373168945
INFO - 04/15/25 16:32:47 - 0:01:11 - Epoch 873: train_loss=10.061943054199219
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 874: train_loss=10.061331748962402
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 875: train_loss=10.06067943572998
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 876: train_loss=10.060436248779297
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 877: train_loss=10.061135292053223
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 878: train_loss=10.060599327087402
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 879: train_loss=10.061174392700195
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 880: train_loss=10.0609130859375
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 881: train_loss=10.060535430908203
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 882: train_loss=10.06016731262207
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 883: train_loss=10.061163902282715
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 884: train_loss=10.060705184936523
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 885: train_loss=10.060823440551758
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 886: train_loss=10.06045913696289
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 887: train_loss=10.060906410217285
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 888: train_loss=10.060565948486328
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 889: train_loss=10.060747146606445
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 890: train_loss=10.060327529907227
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 891: train_loss=10.060918807983398
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 892: train_loss=10.060622215270996
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 893: train_loss=10.060582160949707
INFO - 04/15/25 16:32:48 - 0:01:11 - Epoch 894: train_loss=10.060094833374023
INFO - 04/15/25 16:32:48 - 0:01:12 - Epoch 895: train_loss=10.0611572265625
INFO - 04/15/25 16:32:48 - 0:01:12 - Epoch 896: train_loss=10.06085205078125
INFO - 04/15/25 16:32:48 - 0:01:12 - Epoch 897: train_loss=10.060297966003418
INFO - 04/15/25 16:32:48 - 0:01:12 - Epoch 898: train_loss=10.059844970703125
INFO - 04/15/25 16:32:48 - 0:01:12 - Epoch 899: train_loss=10.061258316040039
INFO - 04/15/25 16:32:48 - 0:01:12 - Epoch 900: train_loss=10.060952186584473
INFO - 04/15/25 16:32:48 - 0:01:12 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:48 - 0:01:12 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 900: ACC: 0.0, NMI: 0.3763610396308861, F1: 0.0, ARI: 0.15886314943047683
INFO - 04/15/25 16:32:49 - 0:01:12 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 901: train_loss=10.060127258300781
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 902: train_loss=10.059749603271484
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 903: train_loss=10.061280250549316
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 904: train_loss=10.060904502868652
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 905: train_loss=10.06009578704834
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 906: train_loss=10.059784889221191
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 907: train_loss=10.061176300048828
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 908: train_loss=10.06078052520752
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 909: train_loss=10.060134887695312
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 910: train_loss=10.05978775024414
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 911: train_loss=10.061028480529785
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 912: train_loss=10.060613632202148
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 913: train_loss=10.060418128967285
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 914: train_loss=10.060196876525879
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 915: train_loss=10.060494422912598
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 916: train_loss=10.060022354125977
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 917: train_loss=10.060932159423828
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 918: train_loss=10.060667991638184
INFO - 04/15/25 16:32:49 - 0:01:12 - Epoch 919: train_loss=10.060054779052734
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 920: train_loss=10.059697151184082
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 921: train_loss=10.061126708984375
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 922: train_loss=10.060728073120117
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 923: train_loss=10.060123443603516
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 924: train_loss=10.05982780456543
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 925: train_loss=10.060907363891602
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 926: train_loss=10.060476303100586
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 927: train_loss=10.060359954833984
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 928: train_loss=10.060077667236328
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 929: train_loss=10.060523986816406
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 930: train_loss=10.060126304626465
INFO - 04/15/25 16:32:49 - 0:01:13 - Epoch 931: train_loss=10.060588836669922
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 932: train_loss=10.06031322479248
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 933: train_loss=10.060239791870117
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 934: train_loss=10.059897422790527
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 935: train_loss=10.060722351074219
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 936: train_loss=10.06039810180664
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 937: train_loss=10.060131072998047
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 938: train_loss=10.059791564941406
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 939: train_loss=10.0607271194458
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 940: train_loss=10.06043529510498
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 941: train_loss=10.060070037841797
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 942: train_loss=10.059795379638672
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 943: train_loss=10.060647964477539
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 944: train_loss=10.060310363769531
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 945: train_loss=10.060227394104004
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 946: train_loss=10.060019493103027
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 947: train_loss=10.060314178466797
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 948: train_loss=10.059929847717285
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 949: train_loss=10.060587882995605
INFO - 04/15/25 16:32:50 - 0:01:13 - Epoch 950: train_loss=10.060285568237305
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 951: train_loss=10.06009578704834
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 952: train_loss=10.05979061126709
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 953: train_loss=10.060599327087402
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 954: train_loss=10.060250282287598
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 955: train_loss=10.06014633178711
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 956: train_loss=10.05989933013916
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 957: train_loss=10.060367584228516
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 958: train_loss=10.060037612915039
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 959: train_loss=10.06026840209961
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 960: train_loss=10.059942245483398
INFO - 04/15/25 16:32:50 - 0:01:14 - Epoch 961: train_loss=10.06039047241211
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 962: train_loss=10.060111999511719
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 963: train_loss=10.060155868530273
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 964: train_loss=10.059842109680176
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 965: train_loss=10.06045913696289
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 966: train_loss=10.060142517089844
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 967: train_loss=10.060065269470215
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 968: train_loss=10.059687614440918
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 969: train_loss=10.060565948486328
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 970: train_loss=10.06030559539795
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 971: train_loss=10.059890747070312
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 972: train_loss=10.059579849243164
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 973: train_loss=10.060600280761719
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 974: train_loss=10.060254096984863
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 975: train_loss=10.05992603302002
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 976: train_loss=10.059670448303223
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 977: train_loss=10.060497283935547
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 978: train_loss=10.06014633178711
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 979: train_loss=10.059969902038574
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 980: train_loss=10.059683799743652
INFO - 04/15/25 16:32:51 - 0:01:14 - Epoch 981: train_loss=10.06053638458252
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 982: train_loss=10.06019115447998
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 983: train_loss=10.059839248657227
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 984: train_loss=10.059507369995117
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 985: train_loss=10.060998916625977
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 986: train_loss=10.060831069946289
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 987: train_loss=10.059103012084961
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 988: train_loss=10.061521530151367
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 989: train_loss=10.057893753051758
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 990: train_loss=10.059828758239746
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 991: train_loss=10.059574127197266
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 992: train_loss=10.061328887939453
INFO - 04/15/25 16:32:51 - 0:01:15 - Epoch 993: train_loss=10.058296203613281
INFO - 04/15/25 16:32:52 - 0:01:15 - Epoch 994: train_loss=10.064933776855469
INFO - 04/15/25 16:32:53 - 0:01:15 - Epoch 995: train_loss=10.064955711364746
INFO - 04/15/25 16:32:53 - 0:01:17 - Epoch 996: train_loss=10.061184883117676
INFO - 04/15/25 16:32:53 - 0:01:17 - Epoch 997: train_loss=10.062605857849121
INFO - 04/15/25 16:32:53 - 0:01:17 - Epoch 998: train_loss=10.063680648803711
INFO - 04/15/25 16:32:53 - 0:01:17 - Epoch 999: train_loss=10.061695098876953
INFO - 04/15/25 16:32:53 - 0:01:17 - Epoch 1000: train_loss=10.0613431930542
INFO - 04/15/25 16:32:53 - 0:01:17 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:53 - 0:01:17 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1000: ACC: 0.0, NMI: 0.3108203447957006, F1: 0.0, ARI: 0.10756326433161087
INFO - 04/15/25 16:32:54 - 0:01:17 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1001: train_loss=10.0625638961792
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1002: train_loss=10.06009578704834
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1003: train_loss=10.063346862792969
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1004: train_loss=10.063959121704102
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1005: train_loss=10.060243606567383
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1006: train_loss=10.062161445617676
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1007: train_loss=10.063007354736328
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1008: train_loss=10.060901641845703
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1009: train_loss=10.061429977416992
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1010: train_loss=10.062323570251465
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1011: train_loss=10.060235977172852
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1012: train_loss=10.061456680297852
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1013: train_loss=10.06159496307373
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1014: train_loss=10.060576438903809
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1015: train_loss=10.061113357543945
INFO - 04/15/25 16:32:54 - 0:01:17 - Epoch 1016: train_loss=10.060741424560547
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1017: train_loss=10.060650825500488
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1018: train_loss=10.06047248840332
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1019: train_loss=10.0604887008667
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1020: train_loss=10.059333801269531
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1021: train_loss=10.061878204345703
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1022: train_loss=10.061493873596191
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1023: train_loss=10.061009407043457
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1024: train_loss=10.060243606567383
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1025: train_loss=10.060249328613281
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1026: train_loss=10.060013771057129
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1027: train_loss=10.060551643371582
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1028: train_loss=10.059825897216797
INFO - 04/15/25 16:32:54 - 0:01:18 - Epoch 1029: train_loss=10.059249877929688
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1030: train_loss=10.06059741973877
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1031: train_loss=10.06065845489502
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1032: train_loss=10.059234619140625
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1033: train_loss=10.062247276306152
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1034: train_loss=10.060933113098145
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1035: train_loss=10.062626838684082
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1036: train_loss=10.060586929321289
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1037: train_loss=10.063384056091309
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1038: train_loss=10.062684059143066
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1039: train_loss=10.06219482421875
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1040: train_loss=10.062402725219727
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1041: train_loss=10.060415267944336
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1042: train_loss=10.0610933303833
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1043: train_loss=10.060416221618652
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1044: train_loss=10.061431884765625
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1045: train_loss=10.059063911437988
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1046: train_loss=10.064040184020996
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1047: train_loss=10.062875747680664
INFO - 04/15/25 16:32:55 - 0:01:18 - Epoch 1048: train_loss=10.062088966369629
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1049: train_loss=10.061923027038574
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1050: train_loss=10.061702728271484
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1051: train_loss=10.061233520507812
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1052: train_loss=10.062180519104004
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1053: train_loss=10.061403274536133
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1054: train_loss=10.062440872192383
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1055: train_loss=10.061761856079102
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1056: train_loss=10.062143325805664
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1057: train_loss=10.061785697937012
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1058: train_loss=10.061640739440918
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1059: train_loss=10.060975074768066
INFO - 04/15/25 16:32:55 - 0:01:19 - Epoch 1060: train_loss=10.06237506866455
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1061: train_loss=10.06156063079834
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1062: train_loss=10.06248664855957
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1063: train_loss=10.062231063842773
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1064: train_loss=10.060802459716797
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1065: train_loss=10.060171127319336
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1066: train_loss=10.06337833404541
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1067: train_loss=10.062671661376953
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1068: train_loss=10.060672760009766
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1069: train_loss=10.06039810180664
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1070: train_loss=10.06287956237793
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1071: train_loss=10.061878204345703
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1072: train_loss=10.061466217041016
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1073: train_loss=10.061217308044434
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1074: train_loss=10.062350273132324
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1075: train_loss=10.061419486999512
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1076: train_loss=10.06180191040039
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1077: train_loss=10.061318397521973
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1078: train_loss=10.062403678894043
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1079: train_loss=10.061776161193848
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1080: train_loss=10.061217308044434
INFO - 04/15/25 16:32:56 - 0:01:19 - Epoch 1081: train_loss=10.060660362243652
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1082: train_loss=10.063023567199707
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1083: train_loss=10.062220573425293
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1084: train_loss=10.060892105102539
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1085: train_loss=10.060532569885254
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1086: train_loss=10.062798500061035
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1087: train_loss=10.062063217163086
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1088: train_loss=10.061060905456543
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1089: train_loss=10.060611724853516
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1090: train_loss=10.06258487701416
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1091: train_loss=10.062042236328125
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1092: train_loss=10.060955047607422
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1093: train_loss=10.060483932495117
INFO - 04/15/25 16:32:56 - 0:01:20 - Epoch 1094: train_loss=10.0625
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1095: train_loss=10.062021255493164
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1096: train_loss=10.060632705688477
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1097: train_loss=10.060128211975098
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1098: train_loss=10.062601089477539
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1099: train_loss=10.061989784240723
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1100: train_loss=10.060587882995605
INFO - 04/15/25 16:32:57 - 0:01:20 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:32:57 - 0:01:20 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1100: ACC: 0.0, NMI: 0.2907122451084256, F1: 0.0, ARI: 0.09521884954906354
INFO - 04/15/25 16:32:57 - 0:01:20 - -------------------------------------------------------------------------
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1101: train_loss=10.060142517089844
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1102: train_loss=10.062662124633789
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1103: train_loss=10.062167167663574
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1104: train_loss=10.060236930847168
INFO - 04/15/25 16:32:57 - 0:01:20 - Epoch 1105: train_loss=10.0596342086792
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1106: train_loss=10.063103675842285
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1107: train_loss=10.062703132629395
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1108: train_loss=10.059484481811523
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1109: train_loss=10.058945655822754
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1110: train_loss=10.063529968261719
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1111: train_loss=10.063246726989746
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1112: train_loss=10.0589017868042
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1113: train_loss=10.058611869812012
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1114: train_loss=10.063346862792969
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1115: train_loss=10.062715530395508
INFO - 04/15/25 16:32:57 - 0:01:21 - Epoch 1116: train_loss=10.059615135192871
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1117: train_loss=10.059795379638672
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1118: train_loss=10.061224937438965
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1119: train_loss=10.059995651245117
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1120: train_loss=10.062606811523438
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1121: train_loss=10.062599182128906
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1122: train_loss=10.059178352355957
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1123: train_loss=10.059576034545898
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1124: train_loss=10.060903549194336
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1125: train_loss=10.059061050415039
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1126: train_loss=10.063873291015625
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1127: train_loss=10.064396858215332
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1128: train_loss=10.05854606628418
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1129: train_loss=10.066636085510254
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1130: train_loss=10.069076538085938
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1131: train_loss=10.064215660095215
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1132: train_loss=10.061704635620117
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1133: train_loss=10.06489086151123
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1134: train_loss=10.06167984008789
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1135: train_loss=10.062227249145508
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1136: train_loss=10.06402587890625
INFO - 04/15/25 16:32:58 - 0:01:21 - Epoch 1137: train_loss=10.059762954711914
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1138: train_loss=10.064785957336426
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1139: train_loss=10.066824913024902
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1140: train_loss=10.062317848205566
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1141: train_loss=10.062588691711426
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1142: train_loss=10.065171241760254
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1143: train_loss=10.062076568603516
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1144: train_loss=10.06186580657959
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1145: train_loss=10.063667297363281
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1146: train_loss=10.06008243560791
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1147: train_loss=10.063546180725098
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1148: train_loss=10.065006256103516
INFO - 04/15/25 16:32:58 - 0:01:22 - Epoch 1149: train_loss=10.061267852783203
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1150: train_loss=10.06273078918457
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1151: train_loss=10.064146041870117
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1152: train_loss=10.061501502990723
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1153: train_loss=10.061478614807129
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1154: train_loss=10.062610626220703
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1155: train_loss=10.060948371887207
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1156: train_loss=10.060892105102539
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1157: train_loss=10.061274528503418
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1158: train_loss=10.060519218444824
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1159: train_loss=10.060247421264648
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1160: train_loss=10.060983657836914
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1161: train_loss=10.058480262756348
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1162: train_loss=10.063533782958984
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1163: train_loss=10.062942504882812
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1164: train_loss=10.060214042663574
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1165: train_loss=10.06202507019043
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1166: train_loss=10.06156063079834
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1167: train_loss=10.059815406799316
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1168: train_loss=10.05971622467041
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1169: train_loss=10.060532569885254
INFO - 04/15/25 16:32:59 - 0:01:22 - Epoch 1170: train_loss=10.060190200805664
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1171: train_loss=10.05984878540039
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1172: train_loss=10.059615135192871
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1173: train_loss=10.061033248901367
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1174: train_loss=10.060111045837402
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1175: train_loss=10.061123847961426
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1176: train_loss=10.060981750488281
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1177: train_loss=10.059688568115234
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1178: train_loss=10.062334060668945
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1179: train_loss=10.060430526733398
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1180: train_loss=10.063559532165527
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1181: train_loss=10.063958168029785
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1182: train_loss=10.06003475189209
INFO - 04/15/25 16:32:59 - 0:01:23 - Epoch 1183: train_loss=10.061592102050781
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1184: train_loss=10.0616455078125
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1185: train_loss=10.059385299682617
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1186: train_loss=10.063788414001465
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1187: train_loss=10.063078880310059
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1188: train_loss=10.060179710388184
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1189: train_loss=10.060297966003418
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1190: train_loss=10.061373710632324
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1191: train_loss=10.059769630432129
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1192: train_loss=10.062684059143066
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1193: train_loss=10.06134033203125
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1194: train_loss=10.062356948852539
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1195: train_loss=10.061873435974121
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1196: train_loss=10.061670303344727
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1197: train_loss=10.061121940612793
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1198: train_loss=10.061925888061523
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1199: train_loss=10.061422348022461
INFO - 04/15/25 16:33:00 - 0:01:23 - Epoch 1200: train_loss=10.061219215393066
INFO - 04/15/25 16:33:00 - 0:01:23 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:00 - 0:01:24 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:33:00 - 0:01:24 - Epoch 1200: ACC: 0.0, NMI: 0.31980004110041893, F1: 0.0, ARI: 0.08731508150755907
INFO - 04/15/25 16:33:00 - 0:01:24 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:00 - 0:01:24 - Epoch 1201: train_loss=10.060606002807617
INFO - 04/15/25 16:33:00 - 0:01:24 - Epoch 1202: train_loss=10.061988830566406
INFO - 04/15/25 16:33:00 - 0:01:24 - Epoch 1203: train_loss=10.061164855957031
INFO - 04/15/25 16:33:00 - 0:01:24 - Epoch 1204: train_loss=10.061738967895508
INFO - 04/15/25 16:33:00 - 0:01:24 - Epoch 1205: train_loss=10.061103820800781
INFO - 04/15/25 16:33:00 - 0:01:24 - Epoch 1206: train_loss=10.061787605285645
INFO - 04/15/25 16:33:00 - 0:01:24 - Epoch 1207: train_loss=10.061120986938477
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1208: train_loss=10.061663627624512
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1209: train_loss=10.061027526855469
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1210: train_loss=10.06167984008789
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1211: train_loss=10.061145782470703
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1212: train_loss=10.061272621154785
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1213: train_loss=10.060672760009766
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1214: train_loss=10.061829566955566
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1215: train_loss=10.061197280883789
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1216: train_loss=10.061232566833496
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1217: train_loss=10.060748100280762
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1218: train_loss=10.061583518981934
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1219: train_loss=10.061025619506836
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1220: train_loss=10.061298370361328
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1221: train_loss=10.060956001281738
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1222: train_loss=10.061223983764648
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1223: train_loss=10.060829162597656
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1224: train_loss=10.061274528503418
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1225: train_loss=10.060836791992188
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1226: train_loss=10.061306953430176
INFO - 04/15/25 16:33:01 - 0:01:24 - Epoch 1227: train_loss=10.060874938964844
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1228: train_loss=10.061018943786621
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1229: train_loss=10.060476303100586
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1230: train_loss=10.061480522155762
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1231: train_loss=10.061110496520996
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1232: train_loss=10.060734748840332
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1233: train_loss=10.060198783874512
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1234: train_loss=10.061713218688965
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1235: train_loss=10.06120491027832
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1236: train_loss=10.060667991638184
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1237: train_loss=10.0602445602417
INFO - 04/15/25 16:33:01 - 0:01:25 - Epoch 1238: train_loss=10.061410903930664
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1239: train_loss=10.060761451721191
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1240: train_loss=10.06115436553955
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1241: train_loss=10.060729026794434
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1242: train_loss=10.060911178588867
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1243: train_loss=10.060379028320312
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1244: train_loss=10.061297416687012
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1245: train_loss=10.060799598693848
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1246: train_loss=10.06089973449707
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1247: train_loss=10.060562133789062
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1248: train_loss=10.060891151428223
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1249: train_loss=10.060359954833984
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1250: train_loss=10.061201095581055
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1251: train_loss=10.060871124267578
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1252: train_loss=10.060585021972656
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1253: train_loss=10.060113906860352
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1254: train_loss=10.06125259399414
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1255: train_loss=10.060807228088379
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1256: train_loss=10.06058406829834
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1257: train_loss=10.060147285461426
INFO - 04/15/25 16:33:02 - 0:01:25 - Epoch 1258: train_loss=10.061083793640137
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1259: train_loss=10.060649871826172
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1260: train_loss=10.060647964477539
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1261: train_loss=10.06015682220459
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1262: train_loss=10.061080932617188
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1263: train_loss=10.060730934143066
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1264: train_loss=10.060507774353027
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1265: train_loss=10.059995651245117
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1266: train_loss=10.06128978729248
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1267: train_loss=10.060829162597656
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1268: train_loss=10.060389518737793
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1269: train_loss=10.059943199157715
INFO - 04/15/25 16:33:02 - 0:01:26 - Epoch 1270: train_loss=10.061166763305664
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1271: train_loss=10.060699462890625
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1272: train_loss=10.060437202453613
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1273: train_loss=10.060088157653809
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1274: train_loss=10.060775756835938
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1275: train_loss=10.060330390930176
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1276: train_loss=10.060741424560547
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1277: train_loss=10.060227394104004
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1278: train_loss=10.060795783996582
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1279: train_loss=10.06049633026123
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1280: train_loss=10.060335159301758
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1281: train_loss=10.05978012084961
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1282: train_loss=10.061203002929688
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1283: train_loss=10.060917854309082
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1284: train_loss=10.059710502624512
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1285: train_loss=10.059176445007324
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1286: train_loss=10.061712265014648
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1287: train_loss=10.061407089233398
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1288: train_loss=10.059086799621582
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1289: train_loss=10.058469772338867
INFO - 04/15/25 16:33:03 - 0:01:26 - Epoch 1290: train_loss=10.0623779296875
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1291: train_loss=10.06218433380127
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1292: train_loss=10.05812931060791
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1293: train_loss=10.058014869689941
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1294: train_loss=10.062067985534668
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1295: train_loss=10.060944557189941
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1296: train_loss=10.060386657714844
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1297: train_loss=10.060652732849121
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1298: train_loss=10.059572219848633
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1299: train_loss=10.059772491455078
INFO - 04/15/25 16:33:03 - 0:01:27 - Epoch 1300: train_loss=10.059065818786621
INFO - 04/15/25 16:33:03 - 0:01:27 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:04 - 0:01:27 - Decoding cost time:  0.129 s
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1300: ACC: 0.0, NMI: 0.35113784566841943, F1: 0.0, ARI: 0.10866046305823893
INFO - 04/15/25 16:33:04 - 0:01:27 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1301: train_loss=10.059611320495605
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1302: train_loss=10.059426307678223
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1303: train_loss=10.057879447937012
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1304: train_loss=10.061882019042969
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1305: train_loss=10.06008529663086
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1306: train_loss=10.062446594238281
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1307: train_loss=10.062705993652344
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1308: train_loss=10.059029579162598
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1309: train_loss=10.061436653137207
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1310: train_loss=10.059985160827637
INFO - 04/15/25 16:33:04 - 0:01:27 - Epoch 1311: train_loss=10.061135292053223
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1312: train_loss=10.060996055603027
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1313: train_loss=10.059898376464844
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1314: train_loss=10.059603691101074
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1315: train_loss=10.060660362243652
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1316: train_loss=10.05949878692627
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1317: train_loss=10.061807632446289
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1318: train_loss=10.061498641967773
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1319: train_loss=10.058939933776855
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1320: train_loss=10.060019493103027
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1321: train_loss=10.05878734588623
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1322: train_loss=10.060164451599121
INFO - 04/15/25 16:33:04 - 0:01:28 - Epoch 1323: train_loss=10.058467864990234
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1324: train_loss=10.061463356018066
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1325: train_loss=10.060589790344238
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1326: train_loss=10.060098648071289
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1327: train_loss=10.059934616088867
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1328: train_loss=10.060420036315918
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1329: train_loss=10.05945873260498
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1330: train_loss=10.061018943786621
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1331: train_loss=10.060437202453613
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1332: train_loss=10.060709953308105
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1333: train_loss=10.060623168945312
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1334: train_loss=10.059598922729492
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1335: train_loss=10.059061050415039
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1336: train_loss=10.061354637145996
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1337: train_loss=10.060934066772461
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1338: train_loss=10.059183120727539
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1339: train_loss=10.058671951293945
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1340: train_loss=10.061887741088867
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1341: train_loss=10.061370849609375
INFO - 04/15/25 16:33:05 - 0:01:28 - Epoch 1342: train_loss=10.058880805969238
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1343: train_loss=10.058789253234863
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1344: train_loss=10.060888290405273
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1345: train_loss=10.059834480285645
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1346: train_loss=10.06088924407959
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1347: train_loss=10.06075382232666
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1348: train_loss=10.059550285339355
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1349: train_loss=10.059389114379883
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1350: train_loss=10.060233116149902
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1351: train_loss=10.059199333190918
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1352: train_loss=10.061314582824707
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1353: train_loss=10.061330795288086
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1354: train_loss=10.058263778686523
INFO - 04/15/25 16:33:05 - 0:01:29 - Epoch 1355: train_loss=10.058417320251465
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1356: train_loss=10.060815811157227
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1357: train_loss=10.059446334838867
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1358: train_loss=10.061448097229004
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1359: train_loss=10.061603546142578
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1360: train_loss=10.058804512023926
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1361: train_loss=10.061454772949219
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1362: train_loss=10.059882164001465
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1363: train_loss=10.061972618103027
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1364: train_loss=10.062368392944336
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1365: train_loss=10.058568954467773
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1366: train_loss=10.061163902282715
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1367: train_loss=10.059964179992676
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1368: train_loss=10.06080150604248
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1369: train_loss=10.061046600341797
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1370: train_loss=10.05850887298584
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1371: train_loss=10.059661865234375
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1372: train_loss=10.057960510253906
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1373: train_loss=10.058477401733398
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1374: train_loss=10.058218002319336
INFO - 04/15/25 16:33:06 - 0:01:29 - Epoch 1375: train_loss=10.060325622558594
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1376: train_loss=10.057458877563477
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1377: train_loss=10.062739372253418
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1378: train_loss=10.061978340148926
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1379: train_loss=10.059285163879395
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1380: train_loss=10.060708045959473
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1381: train_loss=10.059184074401855
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1382: train_loss=10.061646461486816
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1383: train_loss=10.061287879943848
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1384: train_loss=10.059548377990723
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1385: train_loss=10.059636116027832
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1386: train_loss=10.059791564941406
INFO - 04/15/25 16:33:06 - 0:01:30 - Epoch 1387: train_loss=10.059240341186523
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1388: train_loss=10.059514999389648
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1389: train_loss=10.059157371520996
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1390: train_loss=10.059531211853027
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1391: train_loss=10.0581693649292
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1392: train_loss=10.062423706054688
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1393: train_loss=10.062201499938965
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1394: train_loss=10.058542251586914
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1395: train_loss=10.060755729675293
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1396: train_loss=10.059244155883789
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1397: train_loss=10.061707496643066
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1398: train_loss=10.062042236328125
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1399: train_loss=10.057707786560059
INFO - 04/15/25 16:33:07 - 0:01:30 - Epoch 1400: train_loss=10.06204605102539
INFO - 04/15/25 16:33:07 - 0:01:30 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:07 - 0:01:30 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1400: ACC: 0.0, NMI: 0.31445852115816014, F1: 0.0, ARI: 0.11104254287375463
INFO - 04/15/25 16:33:07 - 0:01:31 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1401: train_loss=10.061179161071777
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1402: train_loss=10.059525489807129
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1403: train_loss=10.05986499786377
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1404: train_loss=10.059391021728516
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1405: train_loss=10.05955982208252
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1406: train_loss=10.058527946472168
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1407: train_loss=10.060158729553223
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1408: train_loss=10.058732032775879
INFO - 04/15/25 16:33:07 - 0:01:31 - Epoch 1409: train_loss=10.059976577758789
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1410: train_loss=10.059625625610352
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1411: train_loss=10.058629989624023
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1412: train_loss=10.06090259552002
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1413: train_loss=10.05905818939209
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1414: train_loss=10.062664031982422
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1415: train_loss=10.062774658203125
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1416: train_loss=10.059073448181152
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1417: train_loss=10.060546875
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1418: train_loss=10.060349464416504
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1419: train_loss=10.059121131896973
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1420: train_loss=10.061223983764648
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1421: train_loss=10.060596466064453
INFO - 04/15/25 16:33:08 - 0:01:31 - Epoch 1422: train_loss=10.059747695922852
INFO - 04/15/25 16:33:09 - 0:01:31 - Epoch 1423: train_loss=10.059636116027832
INFO - 04/15/25 16:33:09 - 0:01:32 - Epoch 1424: train_loss=10.059953689575195
INFO - 04/15/25 16:33:09 - 0:01:32 - Epoch 1425: train_loss=10.058501243591309
INFO - 04/15/25 16:33:09 - 0:01:32 - Epoch 1426: train_loss=10.05996036529541
INFO - 04/15/25 16:33:09 - 0:01:32 - Epoch 1427: train_loss=10.057977676391602
INFO - 04/15/25 16:33:09 - 0:01:32 - Epoch 1428: train_loss=10.059579849243164
INFO - 04/15/25 16:33:09 - 0:01:32 - Epoch 1429: train_loss=10.058300971984863
INFO - 04/15/25 16:33:09 - 0:01:32 - Epoch 1430: train_loss=10.059331893920898
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1431: train_loss=10.058023452758789
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1432: train_loss=10.060741424560547
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1433: train_loss=10.059551239013672
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1434: train_loss=10.060667991638184
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1435: train_loss=10.059903144836426
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1436: train_loss=10.060893058776855
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1437: train_loss=10.060141563415527
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1438: train_loss=10.0604248046875
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1439: train_loss=10.060149192810059
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1440: train_loss=10.059736251831055
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1441: train_loss=10.059820175170898
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1442: train_loss=10.059662818908691
INFO - 04/15/25 16:33:09 - 0:01:33 - Epoch 1443: train_loss=10.059094429016113
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1444: train_loss=10.059008598327637
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1445: train_loss=10.059486389160156
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1446: train_loss=10.05831241607666
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1447: train_loss=10.059535026550293
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1448: train_loss=10.058257102966309
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1449: train_loss=10.058948516845703
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1450: train_loss=10.05813217163086
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1451: train_loss=10.059053421020508
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1452: train_loss=10.05782413482666
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1453: train_loss=10.058996200561523
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1454: train_loss=10.058349609375
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1455: train_loss=10.058052062988281
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1456: train_loss=10.058999061584473
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1457: train_loss=10.057700157165527
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1458: train_loss=10.059988975524902
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1459: train_loss=10.059382438659668
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1460: train_loss=10.057904243469238
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1461: train_loss=10.058134078979492
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1462: train_loss=10.058271408081055
INFO - 04/15/25 16:33:10 - 0:01:33 - Epoch 1463: train_loss=10.057271003723145
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1464: train_loss=10.057316780090332
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1465: train_loss=10.059070587158203
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1466: train_loss=10.057718276977539
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1467: train_loss=10.0601806640625
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1468: train_loss=10.060434341430664
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1469: train_loss=10.057239532470703
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1470: train_loss=10.058905601501465
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1471: train_loss=10.058174133300781
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1472: train_loss=10.057929992675781
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1473: train_loss=10.05895709991455
INFO - 04/15/25 16:33:10 - 0:01:34 - Epoch 1474: train_loss=10.057644844055176
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1475: train_loss=10.05960750579834
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1476: train_loss=10.059538841247559
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1477: train_loss=10.058088302612305
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1478: train_loss=10.058782577514648
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1479: train_loss=10.05859375
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1480: train_loss=10.058005332946777
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1481: train_loss=10.057997703552246
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1482: train_loss=10.0575532913208
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1483: train_loss=10.058662414550781
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1484: train_loss=10.058343887329102
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1485: train_loss=10.057828903198242
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1486: train_loss=10.058358192443848
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1487: train_loss=10.057881355285645
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1488: train_loss=10.059098243713379
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1489: train_loss=10.058435440063477
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1490: train_loss=10.058708190917969
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1491: train_loss=10.057297706604004
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1492: train_loss=10.058173179626465
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1493: train_loss=10.057598114013672
INFO - 04/15/25 16:33:11 - 0:01:34 - Epoch 1494: train_loss=10.057326316833496
INFO - 04/15/25 16:33:11 - 0:01:35 - Epoch 1495: train_loss=10.057073593139648
INFO - 04/15/25 16:33:11 - 0:01:35 - Epoch 1496: train_loss=10.059822082519531
INFO - 04/15/25 16:33:11 - 0:01:35 - Epoch 1497: train_loss=10.057554244995117
INFO - 04/15/25 16:33:11 - 0:01:35 - Epoch 1498: train_loss=10.061874389648438
INFO - 04/15/25 16:33:11 - 0:01:35 - Epoch 1499: train_loss=10.061684608459473
INFO - 04/15/25 16:33:11 - 0:01:35 - Epoch 1500: train_loss=10.057191848754883
INFO - 04/15/25 16:33:11 - 0:01:35 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:11 - 0:01:35 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1500: ACC: 0.0, NMI: 0.1894650712873252, F1: 0.0, ARI: 0.02137086009872679
INFO - 04/15/25 16:33:12 - 0:01:35 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1501: train_loss=10.062163352966309
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1502: train_loss=10.062589645385742
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1503: train_loss=10.059130668640137
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1504: train_loss=10.06107234954834
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1505: train_loss=10.060559272766113
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1506: train_loss=10.060110092163086
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1507: train_loss=10.058965682983398
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1508: train_loss=10.059276580810547
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1509: train_loss=10.059934616088867
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1510: train_loss=10.057644844055176
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1511: train_loss=10.059052467346191
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1512: train_loss=10.058634757995605
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1513: train_loss=10.057600021362305
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1514: train_loss=10.057660102844238
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1515: train_loss=10.057912826538086
INFO - 04/15/25 16:33:12 - 0:01:35 - Epoch 1516: train_loss=10.056188583374023
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1517: train_loss=10.057577133178711
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1518: train_loss=10.056824684143066
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1519: train_loss=10.05761432647705
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1520: train_loss=10.05689811706543
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1521: train_loss=10.056343078613281
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1522: train_loss=10.057724952697754
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1523: train_loss=10.056516647338867
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1524: train_loss=10.057406425476074
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1525: train_loss=10.05645751953125
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1526: train_loss=10.058060646057129
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1527: train_loss=10.05650520324707
INFO - 04/15/25 16:33:12 - 0:01:36 - Epoch 1528: train_loss=10.05603313446045
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1529: train_loss=10.05814266204834
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1530: train_loss=10.056501388549805
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1531: train_loss=10.059856414794922
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1532: train_loss=10.059803009033203
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1533: train_loss=10.056729316711426
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1534: train_loss=10.058019638061523
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1535: train_loss=10.057125091552734
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1536: train_loss=10.057494163513184
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1537: train_loss=10.05629825592041
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1538: train_loss=10.056721687316895
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1539: train_loss=10.056989669799805
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1540: train_loss=10.056595802307129
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1541: train_loss=10.059039115905762
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1542: train_loss=10.057334899902344
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1543: train_loss=10.059532165527344
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1544: train_loss=10.058696746826172
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1545: train_loss=10.058640480041504
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1546: train_loss=10.05848503112793
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1547: train_loss=10.057395935058594
INFO - 04/15/25 16:33:13 - 0:01:36 - Epoch 1548: train_loss=10.0589599609375
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1549: train_loss=10.055670738220215
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1550: train_loss=10.06176471710205
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1551: train_loss=10.0604829788208
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1552: train_loss=10.05863094329834
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1553: train_loss=10.059088706970215
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1554: train_loss=10.05824089050293
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1555: train_loss=10.059423446655273
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1556: train_loss=10.058919906616211
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1557: train_loss=10.058424949645996
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1558: train_loss=10.058074951171875
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1559: train_loss=10.058111190795898
INFO - 04/15/25 16:33:13 - 0:01:37 - Epoch 1560: train_loss=10.058161735534668
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1561: train_loss=10.056711196899414
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1562: train_loss=10.059099197387695
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1563: train_loss=10.05600643157959
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1564: train_loss=10.061511039733887
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1565: train_loss=10.060276985168457
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1566: train_loss=10.058408737182617
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1567: train_loss=10.058744430541992
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1568: train_loss=10.057927131652832
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1569: train_loss=10.057881355285645
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1570: train_loss=10.057496070861816
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1571: train_loss=10.058015823364258
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1572: train_loss=10.056583404541016
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1573: train_loss=10.0600004196167
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1574: train_loss=10.059154510498047
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1575: train_loss=10.058265686035156
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1576: train_loss=10.057807922363281
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1577: train_loss=10.058731079101562
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1578: train_loss=10.057517051696777
INFO - 04/15/25 16:33:14 - 0:01:37 - Epoch 1579: train_loss=10.059117317199707
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1580: train_loss=10.057872772216797
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1581: train_loss=10.058507919311523
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1582: train_loss=10.057772636413574
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1583: train_loss=10.058341026306152
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1584: train_loss=10.05733871459961
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1585: train_loss=10.058015823364258
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1586: train_loss=10.057356834411621
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1587: train_loss=10.057500839233398
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1588: train_loss=10.057366371154785
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1589: train_loss=10.056010246276855
INFO - 04/15/25 16:33:14 - 0:01:38 - Epoch 1590: train_loss=10.059410095214844
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1591: train_loss=10.056984901428223
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1592: train_loss=10.060118675231934
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1593: train_loss=10.060196876525879
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1594: train_loss=10.057098388671875
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1595: train_loss=10.055742263793945
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1596: train_loss=10.061196327209473
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1597: train_loss=10.060627937316895
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1598: train_loss=10.056608200073242
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1599: train_loss=10.056792259216309
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1600: train_loss=10.059221267700195
INFO - 04/15/25 16:33:15 - 0:01:38 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:15 - 0:01:38 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1600: ACC: 0.0, NMI: 0.3540250536644213, F1: 0.0, ARI: 0.07744397052635958
INFO - 04/15/25 16:33:15 - 0:01:38 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:15 - 0:01:38 - Epoch 1601: train_loss=10.057954788208008
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1602: train_loss=10.05943489074707
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1603: train_loss=10.059161186218262
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1604: train_loss=10.057467460632324
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1605: train_loss=10.057019233703613
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1606: train_loss=10.059032440185547
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1607: train_loss=10.058192253112793
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1608: train_loss=10.058366775512695
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1609: train_loss=10.057962417602539
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1610: train_loss=10.05753231048584
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1611: train_loss=10.057038307189941
INFO - 04/15/25 16:33:15 - 0:01:39 - Epoch 1612: train_loss=10.058085441589355
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1613: train_loss=10.057073593139648
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1614: train_loss=10.05911922454834
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1615: train_loss=10.058817863464355
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1616: train_loss=10.056842803955078
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1617: train_loss=10.056239128112793
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1618: train_loss=10.059114456176758
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1619: train_loss=10.057804107666016
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1620: train_loss=10.058974266052246
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1621: train_loss=10.058816909790039
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1622: train_loss=10.056718826293945
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1623: train_loss=10.056856155395508
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1624: train_loss=10.057312965393066
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1625: train_loss=10.056127548217773
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1626: train_loss=10.058084487915039
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1627: train_loss=10.055848121643066
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1628: train_loss=10.055667877197266
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1629: train_loss=10.048407554626465
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1630: train_loss=10.059110641479492
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1631: train_loss=10.08426570892334
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1632: train_loss=10.131349563598633
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1633: train_loss=10.081409454345703
INFO - 04/15/25 16:33:16 - 0:01:39 - Epoch 1634: train_loss=10.07949447631836
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1635: train_loss=10.074287414550781
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1636: train_loss=10.076433181762695
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1637: train_loss=10.078858375549316
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1638: train_loss=10.078680038452148
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1639: train_loss=10.074466705322266
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1640: train_loss=10.075678825378418
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1641: train_loss=10.07767105102539
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1642: train_loss=10.074239730834961
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1643: train_loss=10.072471618652344
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1644: train_loss=10.07419204711914
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1645: train_loss=10.072562217712402
INFO - 04/15/25 16:33:16 - 0:01:40 - Epoch 1646: train_loss=10.071094512939453
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1647: train_loss=10.070094108581543
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1648: train_loss=10.07015609741211
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1649: train_loss=10.07016658782959
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1650: train_loss=10.069069862365723
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1651: train_loss=10.068378448486328
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1652: train_loss=10.068521499633789
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1653: train_loss=10.067557334899902
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1654: train_loss=10.068459510803223
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1655: train_loss=10.066938400268555
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1656: train_loss=10.067359924316406
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1657: train_loss=10.06525993347168
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1658: train_loss=10.068044662475586
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1659: train_loss=10.067631721496582
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1660: train_loss=10.06525993347168
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1661: train_loss=10.066174507141113
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1662: train_loss=10.065155029296875
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1663: train_loss=10.065337181091309
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1664: train_loss=10.064258575439453
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1665: train_loss=10.065173149108887
INFO - 04/15/25 16:33:17 - 0:01:40 - Epoch 1666: train_loss=10.064017295837402
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1667: train_loss=10.065021514892578
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1668: train_loss=10.063294410705566
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1669: train_loss=10.065706253051758
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1670: train_loss=10.06468391418457
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1671: train_loss=10.064377784729004
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1672: train_loss=10.06457233428955
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1673: train_loss=10.062713623046875
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1674: train_loss=10.062682151794434
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1675: train_loss=10.066023826599121
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1676: train_loss=10.06431770324707
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1677: train_loss=10.06573486328125
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1678: train_loss=10.065081596374512
INFO - 04/15/25 16:33:17 - 0:01:41 - Epoch 1679: train_loss=10.06502628326416
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1680: train_loss=10.063863754272461
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1681: train_loss=10.065047264099121
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1682: train_loss=10.062461853027344
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1683: train_loss=10.065936088562012
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1684: train_loss=10.063567161560059
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1685: train_loss=10.066563606262207
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1686: train_loss=10.066299438476562
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1687: train_loss=10.063286781311035
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1688: train_loss=10.063780784606934
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1689: train_loss=10.063767433166504
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1690: train_loss=10.06236743927002
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1691: train_loss=10.065954208374023
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1692: train_loss=10.065377235412598
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1693: train_loss=10.062456130981445
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1694: train_loss=10.062268257141113
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1695: train_loss=10.064706802368164
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1696: train_loss=10.063925743103027
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1697: train_loss=10.063518524169922
INFO - 04/15/25 16:33:18 - 0:01:41 - Epoch 1698: train_loss=10.063358306884766
INFO - 04/15/25 16:33:18 - 0:01:42 - Epoch 1699: train_loss=10.063176155090332
INFO - 04/15/25 16:33:18 - 0:01:42 - Epoch 1700: train_loss=10.06241226196289
INFO - 04/15/25 16:33:18 - 0:01:42 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:18 - 0:01:42 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:33:18 - 0:01:42 - Epoch 1700: ACC: 0.0, NMI: 0.135284004206812, F1: 0.0, ARI: 0.01357790929712022
INFO - 04/15/25 16:33:18 - 0:01:42 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:18 - 0:01:42 - Epoch 1701: train_loss=10.064453125
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1702: train_loss=10.06420612335205
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1703: train_loss=10.0619478225708
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1704: train_loss=10.061349868774414
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1705: train_loss=10.064897537231445
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1706: train_loss=10.064560890197754
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1707: train_loss=10.061407089233398
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1708: train_loss=10.060904502868652
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1709: train_loss=10.06495475769043
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1710: train_loss=10.064598083496094
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1711: train_loss=10.06100082397461
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1712: train_loss=10.060728073120117
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1713: train_loss=10.064315795898438
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1714: train_loss=10.063570976257324
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1715: train_loss=10.062131881713867
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1716: train_loss=10.062027931213379
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1717: train_loss=10.062946319580078
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1718: train_loss=10.062320709228516
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1719: train_loss=10.062984466552734
INFO - 04/15/25 16:33:19 - 0:01:42 - Epoch 1720: train_loss=10.062682151794434
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1721: train_loss=10.06229019165039
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1722: train_loss=10.061873435974121
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1723: train_loss=10.062987327575684
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1724: train_loss=10.062438011169434
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1725: train_loss=10.062530517578125
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1726: train_loss=10.062273979187012
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1727: train_loss=10.062272071838379
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1728: train_loss=10.061697006225586
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1729: train_loss=10.062994003295898
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1730: train_loss=10.062662124633789
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1731: train_loss=10.061761856079102
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1732: train_loss=10.061437606811523
INFO - 04/15/25 16:33:19 - 0:01:43 - Epoch 1733: train_loss=10.062828063964844
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1734: train_loss=10.062331199645996
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1735: train_loss=10.06210708618164
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1736: train_loss=10.06178092956543
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1737: train_loss=10.062396049499512
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1738: train_loss=10.062009811401367
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1739: train_loss=10.062131881713867
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1740: train_loss=10.06175708770752
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1741: train_loss=10.062333106994629
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1742: train_loss=10.062015533447266
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1743: train_loss=10.061929702758789
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1744: train_loss=10.061501502990723
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1745: train_loss=10.06248950958252
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1746: train_loss=10.062182426452637
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1747: train_loss=10.061636924743652
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1748: train_loss=10.061192512512207
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1749: train_loss=10.062594413757324
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1750: train_loss=10.062263488769531
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1751: train_loss=10.061457633972168
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1752: train_loss=10.061079025268555
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1753: train_loss=10.062573432922363
INFO - 04/15/25 16:33:20 - 0:01:43 - Epoch 1754: train_loss=10.062238693237305
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1755: train_loss=10.061300277709961
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1756: train_loss=10.061005592346191
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1757: train_loss=10.06241512298584
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1758: train_loss=10.061909675598145
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1759: train_loss=10.061655044555664
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1760: train_loss=10.0613431930542
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1761: train_loss=10.061943054199219
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1762: train_loss=10.061570167541504
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1763: train_loss=10.061744689941406
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1764: train_loss=10.06135082244873
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1765: train_loss=10.061905860900879
INFO - 04/15/25 16:33:20 - 0:01:44 - Epoch 1766: train_loss=10.061591148376465
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1767: train_loss=10.061491012573242
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1768: train_loss=10.061136245727539
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1769: train_loss=10.06202220916748
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1770: train_loss=10.061633110046387
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1771: train_loss=10.061396598815918
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1772: train_loss=10.061124801635742
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1773: train_loss=10.061767578125
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1774: train_loss=10.061391830444336
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1775: train_loss=10.061576843261719
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1776: train_loss=10.061238288879395
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1777: train_loss=10.0615816116333
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1778: train_loss=10.061171531677246
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1779: train_loss=10.061694145202637
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1780: train_loss=10.061443328857422
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1781: train_loss=10.061223983764648
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1782: train_loss=10.06082820892334
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1783: train_loss=10.06204605102539
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1784: train_loss=10.06189250946045
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1785: train_loss=10.06070327758789
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1786: train_loss=10.060275077819824
INFO - 04/15/25 16:33:21 - 0:01:44 - Epoch 1787: train_loss=10.062442779541016
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1788: train_loss=10.062243461608887
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1789: train_loss=10.060253143310547
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1790: train_loss=10.059929847717285
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1791: train_loss=10.062675476074219
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1792: train_loss=10.062376976013184
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1793: train_loss=10.060101509094238
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1794: train_loss=10.060015678405762
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1795: train_loss=10.062298774719238
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1796: train_loss=10.061596870422363
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1797: train_loss=10.061429977416992
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1798: train_loss=10.0615234375
INFO - 04/15/25 16:33:21 - 0:01:45 - Epoch 1799: train_loss=10.060497283935547
INFO - 04/15/25 16:33:22 - 0:01:45 - Epoch 1800: train_loss=10.061561584472656
INFO - 04/15/25 16:33:22 - 0:01:45 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:22 - 0:01:45 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:33:22 - 0:01:45 - Epoch 1800: ACC: 0.0, NMI: 0.061878385158194195, F1: 0.0, ARI: 0.0004919801295473123
INFO - 04/15/25 16:33:22 - 0:01:45 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:22 - 0:01:45 - Epoch 1801: train_loss=10.059419631958008
INFO - 04/15/25 16:33:22 - 0:01:45 - Epoch 1802: train_loss=10.061388969421387
INFO - 04/15/25 16:33:22 - 0:01:45 - Epoch 1803: train_loss=10.060194969177246
INFO - 04/15/25 16:33:22 - 0:01:45 - Epoch 1804: train_loss=10.06100082397461
INFO - 04/15/25 16:33:22 - 0:01:45 - Epoch 1805: train_loss=10.059441566467285
INFO - 04/15/25 16:33:22 - 0:01:45 - Epoch 1806: train_loss=10.064435958862305
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1807: train_loss=10.06470775604248
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1808: train_loss=10.060365676879883
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1809: train_loss=10.064441680908203
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1810: train_loss=10.06601333618164
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1811: train_loss=10.062235832214355
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1812: train_loss=10.06310749053955
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1813: train_loss=10.06556510925293
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1814: train_loss=10.062517166137695
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1815: train_loss=10.06216812133789
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1816: train_loss=10.063970565795898
INFO - 04/15/25 16:33:22 - 0:01:46 - Epoch 1817: train_loss=10.060956954956055
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1818: train_loss=10.063275337219238
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1819: train_loss=10.064713478088379
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1820: train_loss=10.061419486999512
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1821: train_loss=10.063024520874023
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1822: train_loss=10.064810752868652
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1823: train_loss=10.062214851379395
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1824: train_loss=10.061859130859375
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1825: train_loss=10.063204765319824
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1826: train_loss=10.061616897583008
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1827: train_loss=10.061301231384277
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1828: train_loss=10.06206226348877
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1829: train_loss=10.061135292053223
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1830: train_loss=10.060916900634766
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1831: train_loss=10.061450004577637
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1832: train_loss=10.059157371520996
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1833: train_loss=10.061843872070312
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1834: train_loss=10.0602445602417
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1835: train_loss=10.06264591217041
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1836: train_loss=10.063044548034668
INFO - 04/15/25 16:33:23 - 0:01:46 - Epoch 1837: train_loss=10.059334754943848
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1838: train_loss=10.063985824584961
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1839: train_loss=10.064079284667969
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1840: train_loss=10.06045913696289
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1841: train_loss=10.062848091125488
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1842: train_loss=10.062798500061035
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1843: train_loss=10.061015129089355
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1844: train_loss=10.062095642089844
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1845: train_loss=10.060604095458984
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1846: train_loss=10.062600135803223
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1847: train_loss=10.062334060668945
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1848: train_loss=10.059998512268066
INFO - 04/15/25 16:33:23 - 0:01:47 - Epoch 1849: train_loss=10.06207275390625
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1850: train_loss=10.0606107711792
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1851: train_loss=10.062902450561523
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1852: train_loss=10.062897682189941
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1853: train_loss=10.060730934143066
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1854: train_loss=10.061849594116211
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1855: train_loss=10.06125545501709
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1856: train_loss=10.061612129211426
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1857: train_loss=10.061446189880371
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1858: train_loss=10.060705184936523
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1859: train_loss=10.060711860656738
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1860: train_loss=10.060323715209961
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1861: train_loss=10.060447692871094
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1862: train_loss=10.060894966125488
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1863: train_loss=10.059465408325195
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1864: train_loss=10.062884330749512
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1865: train_loss=10.06286334991455
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1866: train_loss=10.060345649719238
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1867: train_loss=10.06245231628418
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1868: train_loss=10.062031745910645
INFO - 04/15/25 16:33:24 - 0:01:47 - Epoch 1869: train_loss=10.060564041137695
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1870: train_loss=10.060821533203125
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1871: train_loss=10.06032657623291
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1872: train_loss=10.060681343078613
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1873: train_loss=10.059571266174316
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1874: train_loss=10.060136795043945
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1875: train_loss=10.061009407043457
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1876: train_loss=10.059037208557129
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1877: train_loss=10.0634765625
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1878: train_loss=10.06332778930664
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1879: train_loss=10.060944557189941
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1880: train_loss=10.061677932739258
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1881: train_loss=10.061749458312988
INFO - 04/15/25 16:33:24 - 0:01:48 - Epoch 1882: train_loss=10.060249328613281
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1883: train_loss=10.061614036560059
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1884: train_loss=10.059721946716309
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1885: train_loss=10.062786102294922
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1886: train_loss=10.061738014221191
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1887: train_loss=10.061910629272461
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1888: train_loss=10.060751914978027
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1889: train_loss=10.062712669372559
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1890: train_loss=10.061906814575195
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1891: train_loss=10.06158447265625
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1892: train_loss=10.061445236206055
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1893: train_loss=10.061511039733887
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1894: train_loss=10.060583114624023
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1895: train_loss=10.062620162963867
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1896: train_loss=10.061949729919434
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1897: train_loss=10.06126594543457
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1898: train_loss=10.061058044433594
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1899: train_loss=10.061445236206055
INFO - 04/15/25 16:33:25 - 0:01:48 - Epoch 1900: train_loss=10.060809135437012
INFO - 04/15/25 16:33:25 - 0:01:48 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:25 - 0:01:49 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:33:25 - 0:01:49 - Epoch 1900: ACC: 0.0, NMI: 0.09328657217524061, F1: 0.0, ARI: 0.00202114621381247
INFO - 04/15/25 16:33:25 - 0:01:49 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:25 - 0:01:49 - Epoch 1901: train_loss=10.061967849731445
INFO - 04/15/25 16:33:25 - 0:01:49 - Epoch 1902: train_loss=10.061205863952637
INFO - 04/15/25 16:33:25 - 0:01:49 - Epoch 1903: train_loss=10.061534881591797
INFO - 04/15/25 16:33:25 - 0:01:49 - Epoch 1904: train_loss=10.061234474182129
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1905: train_loss=10.061924934387207
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1906: train_loss=10.061165809631348
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1907: train_loss=10.062189102172852
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1908: train_loss=10.061861038208008
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1909: train_loss=10.061044692993164
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1910: train_loss=10.060545921325684
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1911: train_loss=10.062141418457031
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1912: train_loss=10.060930252075195
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1913: train_loss=10.062716484069824
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1914: train_loss=10.062768936157227
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1915: train_loss=10.060546875
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1916: train_loss=10.060571670532227
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1917: train_loss=10.061698913574219
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1918: train_loss=10.060425758361816
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1919: train_loss=10.063150405883789
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1920: train_loss=10.063133239746094
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1921: train_loss=10.059590339660645
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1922: train_loss=10.059683799743652
INFO - 04/15/25 16:33:26 - 0:01:49 - Epoch 1923: train_loss=10.061837196350098
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1924: train_loss=10.060455322265625
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1925: train_loss=10.062708854675293
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1926: train_loss=10.062520980834961
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1927: train_loss=10.05986499786377
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1928: train_loss=10.060259819030762
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1929: train_loss=10.060415267944336
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1930: train_loss=10.059563636779785
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1931: train_loss=10.059728622436523
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1932: train_loss=10.06009578704834
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1933: train_loss=10.059305191040039
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1934: train_loss=10.059597969055176
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1935: train_loss=10.060197830200195
INFO - 04/15/25 16:33:26 - 0:01:50 - Epoch 1936: train_loss=10.058553695678711
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1937: train_loss=10.0601806640625
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1938: train_loss=10.05906867980957
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1939: train_loss=10.061443328857422
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1940: train_loss=10.0608549118042
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1941: train_loss=10.059844970703125
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1942: train_loss=10.059651374816895
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1943: train_loss=10.060046195983887
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1944: train_loss=10.05946159362793
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1945: train_loss=10.061068534851074
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1946: train_loss=10.060746192932129
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1947: train_loss=10.059732437133789
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1948: train_loss=10.059813499450684
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1949: train_loss=10.059560775756836
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1950: train_loss=10.058842658996582
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1951: train_loss=10.061592102050781
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1952: train_loss=10.061273574829102
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1953: train_loss=10.059332847595215
INFO - 04/15/25 16:33:27 - 0:01:50 - Epoch 1954: train_loss=10.060595512390137
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1955: train_loss=10.058781623840332
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1956: train_loss=10.063103675842285
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1957: train_loss=10.06313419342041
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1958: train_loss=10.058781623840332
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1959: train_loss=10.06347942352295
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1960: train_loss=10.064114570617676
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1961: train_loss=10.060007095336914
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1962: train_loss=10.06337833404541
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1963: train_loss=10.065472602844238
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1964: train_loss=10.062790870666504
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1965: train_loss=10.059804916381836
INFO - 04/15/25 16:33:27 - 0:01:51 - Epoch 1966: train_loss=10.062175750732422
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1967: train_loss=10.060800552368164
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1968: train_loss=10.060765266418457
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1969: train_loss=10.061320304870605
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1970: train_loss=10.058880805969238
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1971: train_loss=10.061257362365723
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1972: train_loss=10.060124397277832
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1973: train_loss=10.060959815979004
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1974: train_loss=10.060876846313477
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1975: train_loss=10.059991836547852
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1976: train_loss=10.060689926147461
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1977: train_loss=10.05998420715332
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1978: train_loss=10.060881614685059
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1979: train_loss=10.06033992767334
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1980: train_loss=10.060614585876465
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1981: train_loss=10.059844970703125
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1982: train_loss=10.06038761138916
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1983: train_loss=10.059557914733887
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1984: train_loss=10.059711456298828
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1985: train_loss=10.06015682220459
INFO - 04/15/25 16:33:28 - 0:01:51 - Epoch 1986: train_loss=10.058538436889648
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1987: train_loss=10.060144424438477
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1988: train_loss=10.05918025970459
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1989: train_loss=10.058513641357422
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1990: train_loss=10.06130599975586
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1991: train_loss=10.059484481811523
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1992: train_loss=10.062644004821777
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1993: train_loss=10.062963485717773
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1994: train_loss=10.059255599975586
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1995: train_loss=10.061714172363281
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1996: train_loss=10.061244010925293
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1997: train_loss=10.060306549072266
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1998: train_loss=10.060327529907227
INFO - 04/15/25 16:33:28 - 0:01:52 - Epoch 1999: train_loss=10.060641288757324
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2000: train_loss=10.059234619140625
INFO - 04/15/25 16:33:29 - 0:01:52 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:29 - 0:01:52 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2000: ACC: 0.0, NMI: 0.18563514424184996, F1: 0.0, ARI: 0.016730214091675164
INFO - 04/15/25 16:33:29 - 0:01:52 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2001: train_loss=10.060101509094238
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2002: train_loss=10.059273719787598
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2003: train_loss=10.059823036193848
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2004: train_loss=10.059590339660645
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2005: train_loss=10.059715270996094
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2006: train_loss=10.059917449951172
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2007: train_loss=10.058810234069824
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2008: train_loss=10.062371253967285
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2009: train_loss=10.062432289123535
INFO - 04/15/25 16:33:29 - 0:01:52 - Epoch 2010: train_loss=10.059773445129395
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2011: train_loss=10.060705184936523
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2012: train_loss=10.061079025268555
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2013: train_loss=10.059941291809082
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2014: train_loss=10.060857772827148
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2015: train_loss=10.06094741821289
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2016: train_loss=10.059439659118652
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2017: train_loss=10.060220718383789
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2018: train_loss=10.06006145477295
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2019: train_loss=10.058810234069824
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2020: train_loss=10.060213088989258
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2021: train_loss=10.05807876586914
INFO - 04/15/25 16:33:29 - 0:01:53 - Epoch 2022: train_loss=10.061429023742676
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2023: train_loss=10.060833930969238
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2024: train_loss=10.059996604919434
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2025: train_loss=10.059564590454102
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2026: train_loss=10.060118675231934
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2027: train_loss=10.059009552001953
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2028: train_loss=10.0601167678833
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2029: train_loss=10.059393882751465
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2030: train_loss=10.059834480285645
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2031: train_loss=10.059309959411621
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2032: train_loss=10.059954643249512
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2033: train_loss=10.059528350830078
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2034: train_loss=10.059621810913086
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2035: train_loss=10.059117317199707
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2036: train_loss=10.059889793395996
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2037: train_loss=10.059489250183105
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2038: train_loss=10.059708595275879
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2039: train_loss=10.059425354003906
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2040: train_loss=10.059288024902344
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2041: train_loss=10.059074401855469
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2042: train_loss=10.059730529785156
INFO - 04/15/25 16:33:30 - 0:01:53 - Epoch 2043: train_loss=10.05917739868164
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2044: train_loss=10.05984878540039
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2045: train_loss=10.05959701538086
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2046: train_loss=10.058839797973633
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2047: train_loss=10.05935287475586
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2048: train_loss=10.05831241607666
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2049: train_loss=10.057907104492188
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2050: train_loss=10.060437202453613
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2051: train_loss=10.05844783782959
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2052: train_loss=10.06247615814209
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2053: train_loss=10.062746047973633
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2054: train_loss=10.058815956115723
INFO - 04/15/25 16:33:30 - 0:01:54 - Epoch 2055: train_loss=10.062261581420898
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2056: train_loss=10.062775611877441
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2057: train_loss=10.060111045837402
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2058: train_loss=10.06043815612793
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2059: train_loss=10.061885833740234
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2060: train_loss=10.05976676940918
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2061: train_loss=10.061135292053223
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2062: train_loss=10.06180477142334
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2063: train_loss=10.059012413024902
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2064: train_loss=10.061403274536133
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2065: train_loss=10.062210083007812
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2066: train_loss=10.05972671508789
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2067: train_loss=10.060382843017578
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2068: train_loss=10.0610990524292
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2069: train_loss=10.059807777404785
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2070: train_loss=10.060068130493164
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2071: train_loss=10.0601806640625
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2072: train_loss=10.059919357299805
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2073: train_loss=10.058929443359375
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2074: train_loss=10.060322761535645
INFO - 04/15/25 16:33:31 - 0:01:54 - Epoch 2075: train_loss=10.059383392333984
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2076: train_loss=10.059805870056152
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2077: train_loss=10.06006908416748
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2078: train_loss=10.058298110961914
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2079: train_loss=10.062737464904785
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2080: train_loss=10.062297821044922
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2081: train_loss=10.060087203979492
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2082: train_loss=10.05996036529541
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2083: train_loss=10.06124210357666
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2084: train_loss=10.059836387634277
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2085: train_loss=10.06100082397461
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2086: train_loss=10.06032943725586
INFO - 04/15/25 16:33:31 - 0:01:55 - Epoch 2087: train_loss=10.060516357421875
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2088: train_loss=10.059329986572266
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2089: train_loss=10.06059455871582
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2090: train_loss=10.05963134765625
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2091: train_loss=10.060830116271973
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2092: train_loss=10.058777809143066
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2093: train_loss=10.061959266662598
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2094: train_loss=10.060563087463379
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2095: train_loss=10.06060791015625
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2096: train_loss=10.06059455871582
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2097: train_loss=10.058653831481934
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2098: train_loss=10.058361053466797
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2099: train_loss=10.059416770935059
INFO - 04/15/25 16:33:32 - 0:01:55 - Epoch 2100: train_loss=10.057855606079102
INFO - 04/15/25 16:33:32 - 0:01:55 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:32 - 0:01:55 - Decoding cost time:  0.130 s
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2100: ACC: 0.0, NMI: 0.24987551530506402, F1: 0.0, ARI: 0.03502245712088976
INFO - 04/15/25 16:33:32 - 0:01:56 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2101: train_loss=10.060611724853516
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2102: train_loss=10.059125900268555
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2103: train_loss=10.059226036071777
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2104: train_loss=10.059103012084961
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2105: train_loss=10.057961463928223
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2106: train_loss=10.056763648986816
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2107: train_loss=10.052767753601074
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2108: train_loss=10.05367660522461
INFO - 04/15/25 16:33:32 - 0:01:56 - Epoch 2109: train_loss=10.047622680664062
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2110: train_loss=10.048222541809082
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2111: train_loss=10.040382385253906
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2112: train_loss=10.041707992553711
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2113: train_loss=10.040555953979492
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2114: train_loss=10.038105010986328
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2115: train_loss=10.0380277633667
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2116: train_loss=10.039161682128906
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2117: train_loss=10.036578178405762
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2118: train_loss=10.04092025756836
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2119: train_loss=10.037860870361328
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2120: train_loss=10.037491798400879
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2121: train_loss=10.03742790222168
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2122: train_loss=10.032715797424316
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2123: train_loss=10.037237167358398
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2124: train_loss=10.03562068939209
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2125: train_loss=10.032763481140137
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2126: train_loss=10.033193588256836
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2127: train_loss=10.03313159942627
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2128: train_loss=10.032354354858398
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2129: train_loss=10.032937049865723
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2130: train_loss=10.042372703552246
INFO - 04/15/25 16:33:33 - 0:01:56 - Epoch 2131: train_loss=10.035897254943848
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2132: train_loss=10.041962623596191
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2133: train_loss=10.03898811340332
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2134: train_loss=10.042326927185059
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2135: train_loss=10.04049301147461
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2136: train_loss=10.037407875061035
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2137: train_loss=10.034439086914062
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2138: train_loss=10.037291526794434
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2139: train_loss=10.033254623413086
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2140: train_loss=10.035066604614258
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2141: train_loss=10.034828186035156
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2142: train_loss=10.033950805664062
INFO - 04/15/25 16:33:33 - 0:01:57 - Epoch 2143: train_loss=10.033065795898438
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2144: train_loss=10.035456657409668
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2145: train_loss=10.034443855285645
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2146: train_loss=10.032191276550293
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2147: train_loss=10.035211563110352
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2148: train_loss=10.032489776611328
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2149: train_loss=10.033504486083984
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2150: train_loss=10.0332612991333
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2151: train_loss=10.03174877166748
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2152: train_loss=10.033257484436035
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2153: train_loss=10.032306671142578
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2154: train_loss=10.032682418823242
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2155: train_loss=10.031978607177734
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2156: train_loss=10.031800270080566
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2157: train_loss=10.031140327453613
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2158: train_loss=10.030767440795898
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2159: train_loss=10.031121253967285
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2160: train_loss=10.030683517456055
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2161: train_loss=10.03133487701416
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2162: train_loss=10.030274391174316
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2163: train_loss=10.03003978729248
INFO - 04/15/25 16:33:34 - 0:01:57 - Epoch 2164: train_loss=10.03049087524414
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2165: train_loss=10.029206275939941
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2166: train_loss=10.031734466552734
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2167: train_loss=10.030311584472656
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2168: train_loss=10.030801773071289
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2169: train_loss=10.030457496643066
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2170: train_loss=10.030898094177246
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2171: train_loss=10.029900550842285
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2172: train_loss=10.030467987060547
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2173: train_loss=10.030119895935059
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2174: train_loss=10.029842376708984
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2175: train_loss=10.029407501220703
INFO - 04/15/25 16:33:34 - 0:01:58 - Epoch 2176: train_loss=10.029315948486328
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2177: train_loss=10.028817176818848
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2178: train_loss=10.030434608459473
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2179: train_loss=10.029623031616211
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2180: train_loss=10.029483795166016
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2181: train_loss=10.029253005981445
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2182: train_loss=10.02925968170166
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2183: train_loss=10.0288667678833
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2184: train_loss=10.028947830200195
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2185: train_loss=10.028621673583984
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2186: train_loss=10.029248237609863
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2187: train_loss=10.028390884399414
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2188: train_loss=10.028942108154297
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2189: train_loss=10.028700828552246
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2190: train_loss=10.028573036193848
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2191: train_loss=10.027996063232422
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2192: train_loss=10.028670310974121
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2193: train_loss=10.027909278869629
INFO - 04/15/25 16:33:35 - 0:01:58 - Epoch 2194: train_loss=10.028780937194824
INFO - 04/15/25 16:33:35 - 0:01:59 - Epoch 2195: train_loss=10.028117179870605
INFO - 04/15/25 16:33:35 - 0:01:59 - Epoch 2196: train_loss=10.028264999389648
INFO - 04/15/25 16:33:35 - 0:01:59 - Epoch 2197: train_loss=10.027786254882812
INFO - 04/15/25 16:33:35 - 0:01:59 - Epoch 2198: train_loss=10.028682708740234
INFO - 04/15/25 16:33:35 - 0:01:59 - Epoch 2199: train_loss=10.027823448181152
INFO - 04/15/25 16:33:35 - 0:01:59 - Epoch 2200: train_loss=10.028435707092285
INFO - 04/15/25 16:33:35 - 0:01:59 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:35 - 0:01:59 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2200: ACC: 0.0, NMI: 0.22684871209833762, F1: 0.0, ARI: 0.031625687026821024
INFO - 04/15/25 16:33:36 - 0:01:59 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2201: train_loss=10.028127670288086
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2202: train_loss=10.028094291687012
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2203: train_loss=10.027636528015137
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2204: train_loss=10.028084754943848
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2205: train_loss=10.027691841125488
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2206: train_loss=10.027978897094727
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2207: train_loss=10.027541160583496
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2208: train_loss=10.027557373046875
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2209: train_loss=10.027213096618652
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2210: train_loss=10.027932167053223
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2211: train_loss=10.02761173248291
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2212: train_loss=10.027121543884277
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2213: train_loss=10.026894569396973
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2214: train_loss=10.02771282196045
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2215: train_loss=10.026973724365234
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2216: train_loss=10.028055191040039
INFO - 04/15/25 16:33:36 - 0:01:59 - Epoch 2217: train_loss=10.027851104736328
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2218: train_loss=10.026586532592773
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2219: train_loss=10.026390075683594
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2220: train_loss=10.027327537536621
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2221: train_loss=10.026971817016602
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2222: train_loss=10.027870178222656
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2223: train_loss=10.02700424194336
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2224: train_loss=10.027042388916016
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2225: train_loss=10.027543067932129
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2226: train_loss=10.025920867919922
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2227: train_loss=10.026535987854004
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2228: train_loss=10.028068542480469
INFO - 04/15/25 16:33:36 - 0:02:00 - Epoch 2229: train_loss=10.025959014892578
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2230: train_loss=10.029425621032715
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2231: train_loss=10.028382301330566
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2232: train_loss=10.028071403503418
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2233: train_loss=10.027853012084961
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2234: train_loss=10.027700424194336
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2235: train_loss=10.027517318725586
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2236: train_loss=10.026989936828613
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2237: train_loss=10.02680492401123
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2238: train_loss=10.02714729309082
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2239: train_loss=10.025745391845703
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2240: train_loss=10.028764724731445
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2241: train_loss=10.026161193847656
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2242: train_loss=10.032281875610352
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2243: train_loss=10.032197952270508
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2244: train_loss=10.027088165283203
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2245: train_loss=10.032272338867188
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2246: train_loss=10.032822608947754
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2247: train_loss=10.028962135314941
INFO - 04/15/25 16:33:37 - 0:02:00 - Epoch 2248: train_loss=10.029210090637207
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2249: train_loss=10.029703140258789
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2250: train_loss=10.02950382232666
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2251: train_loss=10.028321266174316
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2252: train_loss=10.029361724853516
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2253: train_loss=10.02840518951416
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2254: train_loss=10.027414321899414
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2255: train_loss=10.027456283569336
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2256: train_loss=10.028597831726074
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2257: train_loss=10.026721954345703
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2258: train_loss=10.027677536010742
INFO - 04/15/25 16:33:37 - 0:02:01 - Epoch 2259: train_loss=10.02776050567627
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2260: train_loss=10.027216911315918
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2261: train_loss=10.028509140014648
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2262: train_loss=10.027180671691895
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2263: train_loss=10.029928207397461
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2264: train_loss=10.028830528259277
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2265: train_loss=10.027017593383789
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2266: train_loss=10.02839469909668
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2267: train_loss=10.02640151977539
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2268: train_loss=10.027900695800781
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2269: train_loss=10.030092239379883
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2270: train_loss=10.028389930725098
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2271: train_loss=10.030648231506348
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2272: train_loss=10.028048515319824
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2273: train_loss=10.028437614440918
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2274: train_loss=10.027225494384766
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2275: train_loss=10.032984733581543
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2276: train_loss=10.030468940734863
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2277: train_loss=10.027549743652344
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2278: train_loss=10.029065132141113
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2279: train_loss=10.029155731201172
INFO - 04/15/25 16:33:38 - 0:02:01 - Epoch 2280: train_loss=10.027900695800781
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2281: train_loss=10.028650283813477
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2282: train_loss=10.028468132019043
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2283: train_loss=10.027687072753906
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2284: train_loss=10.027920722961426
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2285: train_loss=10.027050018310547
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2286: train_loss=10.027589797973633
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2287: train_loss=10.026816368103027
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2288: train_loss=10.02598762512207
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2289: train_loss=10.028675079345703
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2290: train_loss=10.027840614318848
INFO - 04/15/25 16:33:38 - 0:02:02 - Epoch 2291: train_loss=10.026708602905273
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2292: train_loss=10.02625846862793
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2293: train_loss=10.026717185974121
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2294: train_loss=10.02523136138916
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2295: train_loss=10.02619743347168
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2296: train_loss=10.024543762207031
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2297: train_loss=10.027300834655762
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2298: train_loss=10.026093482971191
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2299: train_loss=10.025411605834961
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2300: train_loss=10.027077674865723
INFO - 04/15/25 16:33:39 - 0:02:02 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:39 - 0:02:02 - Decoding cost time:  0.137 s
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2300: ACC: 0.0, NMI: 0.23760864922118471, F1: 0.0, ARI: 0.0873180863502657
INFO - 04/15/25 16:33:39 - 0:02:02 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:39 - 0:02:02 - Epoch 2301: train_loss=10.026045799255371
INFO - 04/15/25 16:33:39 - 0:02:03 - Epoch 2302: train_loss=10.0255765914917
INFO - 04/15/25 16:33:41 - 0:02:03 - Epoch 2303: train_loss=10.027658462524414
INFO - 04/15/25 16:33:41 - 0:02:04 - Epoch 2304: train_loss=10.026365280151367
INFO - 04/15/25 16:33:41 - 0:02:04 - Epoch 2305: train_loss=10.027193069458008
INFO - 04/15/25 16:33:41 - 0:02:04 - Epoch 2306: train_loss=10.025740623474121
INFO - 04/15/25 16:33:41 - 0:02:04 - Epoch 2307: train_loss=10.027738571166992
INFO - 04/15/25 16:33:41 - 0:02:04 - Epoch 2308: train_loss=10.025973320007324
INFO - 04/15/25 16:33:41 - 0:02:04 - Epoch 2309: train_loss=10.027264595031738
INFO - 04/15/25 16:33:41 - 0:02:04 - Epoch 2310: train_loss=10.02636432647705
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2311: train_loss=10.026700019836426
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2312: train_loss=10.02596664428711
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2313: train_loss=10.026065826416016
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2314: train_loss=10.025591850280762
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2315: train_loss=10.02510929107666
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2316: train_loss=10.025769233703613
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2317: train_loss=10.024317741394043
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2318: train_loss=10.024958610534668
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2319: train_loss=10.025646209716797
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2320: train_loss=10.02393913269043
INFO - 04/15/25 16:33:41 - 0:02:05 - Epoch 2321: train_loss=10.026612281799316
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2322: train_loss=10.024827003479004
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2323: train_loss=10.025912284851074
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2324: train_loss=10.024554252624512
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2325: train_loss=10.025242805480957
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2326: train_loss=10.024056434631348
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2327: train_loss=10.025262832641602
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2328: train_loss=10.024398803710938
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2329: train_loss=10.02497673034668
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2330: train_loss=10.024042129516602
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2331: train_loss=10.025714874267578
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2332: train_loss=10.024978637695312
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2333: train_loss=10.023192405700684
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2334: train_loss=10.023276329040527
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2335: train_loss=10.025666236877441
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2336: train_loss=10.024261474609375
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2337: train_loss=10.02396297454834
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2338: train_loss=10.025425910949707
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2339: train_loss=10.022494316101074
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2340: train_loss=10.02697467803955
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2341: train_loss=10.025908470153809
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2342: train_loss=10.026165962219238
INFO - 04/15/25 16:33:42 - 0:02:05 - Epoch 2343: train_loss=10.024829864501953
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2344: train_loss=10.025627136230469
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2345: train_loss=10.024761199951172
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2346: train_loss=10.025877952575684
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2347: train_loss=10.023578643798828
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2348: train_loss=10.025066375732422
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2349: train_loss=10.024239540100098
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2350: train_loss=10.028310775756836
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2351: train_loss=10.02535343170166
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2352: train_loss=10.025472640991211
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2353: train_loss=10.025477409362793
INFO - 04/15/25 16:33:42 - 0:02:06 - Epoch 2354: train_loss=10.029459953308105
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2355: train_loss=10.026890754699707
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2356: train_loss=10.029214859008789
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2357: train_loss=10.02787971496582
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2358: train_loss=10.030223846435547
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2359: train_loss=10.026288986206055
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2360: train_loss=10.02438735961914
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2361: train_loss=10.016191482543945
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2362: train_loss=10.01498794555664
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2363: train_loss=10.017998695373535
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2364: train_loss=10.065289497375488
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2365: train_loss=10.041398048400879
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2366: train_loss=10.033071517944336
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2367: train_loss=10.021554946899414
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2368: train_loss=10.01990795135498
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2369: train_loss=10.024062156677246
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2370: train_loss=10.017139434814453
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2371: train_loss=10.028116226196289
INFO - 04/15/25 16:33:43 - 0:02:06 - Epoch 2372: train_loss=10.041085243225098
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2373: train_loss=10.019006729125977
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2374: train_loss=10.01754379272461
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2375: train_loss=10.018835067749023
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2376: train_loss=10.019686698913574
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2377: train_loss=10.018101692199707
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2378: train_loss=10.012629508972168
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2379: train_loss=10.012275695800781
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2380: train_loss=10.012337684631348
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2381: train_loss=10.016014099121094
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2382: train_loss=10.011258125305176
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2383: train_loss=10.012042999267578
INFO - 04/15/25 16:33:43 - 0:02:07 - Epoch 2384: train_loss=10.011364936828613
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2385: train_loss=10.012030601501465
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2386: train_loss=10.010147094726562
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2387: train_loss=10.011107444763184
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2388: train_loss=10.008380889892578
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2389: train_loss=10.013755798339844
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2390: train_loss=10.011344909667969
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2391: train_loss=10.006356239318848
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2392: train_loss=10.010112762451172
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2393: train_loss=10.007790565490723
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2394: train_loss=10.008790016174316
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2395: train_loss=10.007757186889648
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2396: train_loss=10.004469871520996
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2397: train_loss=10.010249137878418
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2398: train_loss=10.007203102111816
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2399: train_loss=10.010077476501465
INFO - 04/15/25 16:33:44 - 0:02:07 - Epoch 2400: train_loss=10.008369445800781
INFO - 04/15/25 16:33:44 - 0:02:07 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:44 - 0:02:08 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:33:44 - 0:02:08 - Epoch 2400: ACC: 0.0, NMI: 0.2931793220946171, F1: 0.0, ARI: 0.10219077741328646
INFO - 04/15/25 16:33:44 - 0:02:08 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:44 - 0:02:08 - Epoch 2401: train_loss=10.00802993774414
INFO - 04/15/25 16:33:44 - 0:02:08 - Epoch 2402: train_loss=10.006643295288086
INFO - 04/15/25 16:33:44 - 0:02:08 - Epoch 2403: train_loss=10.008830070495605
INFO - 04/15/25 16:33:44 - 0:02:08 - Epoch 2404: train_loss=10.007402420043945
INFO - 04/15/25 16:33:44 - 0:02:08 - Epoch 2405: train_loss=10.005245208740234
INFO - 04/15/25 16:33:44 - 0:02:08 - Epoch 2406: train_loss=10.005138397216797
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2407: train_loss=10.006468772888184
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2408: train_loss=10.004495620727539
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2409: train_loss=10.006728172302246
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2410: train_loss=10.006370544433594
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2411: train_loss=10.003385543823242
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2412: train_loss=10.002795219421387
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2413: train_loss=10.005087852478027
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2414: train_loss=10.003657341003418
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2415: train_loss=10.004849433898926
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2416: train_loss=10.004095077514648
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2417: train_loss=10.00291919708252
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2418: train_loss=10.00253963470459
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2419: train_loss=10.003944396972656
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2420: train_loss=10.00258731842041
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2421: train_loss=10.00280475616455
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2422: train_loss=10.002581596374512
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2423: train_loss=10.002685546875
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2424: train_loss=10.00124454498291
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2425: train_loss=10.003262519836426
INFO - 04/15/25 16:33:45 - 0:02:08 - Epoch 2426: train_loss=10.002983093261719
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2427: train_loss=10.001855850219727
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2428: train_loss=10.000666618347168
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2429: train_loss=10.002815246582031
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2430: train_loss=10.00183391571045
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2431: train_loss=10.002604484558105
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2432: train_loss=10.001652717590332
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2433: train_loss=10.001028060913086
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2434: train_loss=10.000574111938477
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2435: train_loss=10.002531051635742
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2436: train_loss=10.00139331817627
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2437: train_loss=10.000670433044434
INFO - 04/15/25 16:33:45 - 0:02:09 - Epoch 2438: train_loss=10.000367164611816
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2439: train_loss=10.002044677734375
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2440: train_loss=10.000532150268555
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2441: train_loss=10.001383781433105
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2442: train_loss=10.001140594482422
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2443: train_loss=10.001172065734863
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2444: train_loss=9.999847412109375
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2445: train_loss=10.001587867736816
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2446: train_loss=10.001380920410156
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2447: train_loss=9.999753952026367
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2448: train_loss=9.998335838317871
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2449: train_loss=10.001300811767578
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2450: train_loss=10.000690460205078
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2451: train_loss=9.999740600585938
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2452: train_loss=9.998607635498047
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2453: train_loss=10.00191879272461
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2454: train_loss=10.001334190368652
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2455: train_loss=9.999356269836426
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2456: train_loss=10.002462387084961
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2457: train_loss=9.99886417388916
INFO - 04/15/25 16:33:46 - 0:02:09 - Epoch 2458: train_loss=10.003413200378418
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2459: train_loss=10.002598762512207
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2460: train_loss=9.999984741210938
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2461: train_loss=9.998437881469727
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2462: train_loss=10.001404762268066
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2463: train_loss=10.00011920928955
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2464: train_loss=10.003130912780762
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2465: train_loss=10.000855445861816
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2466: train_loss=9.999486923217773
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2467: train_loss=9.999432563781738
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2468: train_loss=10.002243995666504
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2469: train_loss=10.000115394592285
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2470: train_loss=9.999899864196777
INFO - 04/15/25 16:33:46 - 0:02:10 - Epoch 2471: train_loss=9.999921798706055
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2472: train_loss=10.000386238098145
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2473: train_loss=9.998442649841309
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2474: train_loss=10.000335693359375
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2475: train_loss=9.999634742736816
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2476: train_loss=10.000447273254395
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2477: train_loss=9.999269485473633
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2478: train_loss=9.997916221618652
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2479: train_loss=9.997690200805664
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2480: train_loss=10.000114440917969
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2481: train_loss=9.997800827026367
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2482: train_loss=9.998823165893555
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2483: train_loss=9.999041557312012
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2484: train_loss=9.998194694519043
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2485: train_loss=9.99652099609375
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2486: train_loss=9.999253273010254
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2487: train_loss=9.998848915100098
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2488: train_loss=9.99730110168457
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2489: train_loss=9.995878219604492
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2490: train_loss=9.998924255371094
INFO - 04/15/25 16:33:47 - 0:02:10 - Epoch 2491: train_loss=9.998373985290527
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2492: train_loss=9.99802303314209
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2493: train_loss=9.996685981750488
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2494: train_loss=9.997529983520508
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2495: train_loss=9.996953964233398
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2496: train_loss=9.999215126037598
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2497: train_loss=9.997675895690918
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2498: train_loss=9.996480941772461
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2499: train_loss=9.996105194091797
INFO - 04/15/25 16:33:47 - 0:02:11 - Epoch 2500: train_loss=9.999899864196777
INFO - 04/15/25 16:33:47 - 0:02:11 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:48 - 0:02:11 - Decoding cost time:  0.135 s
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2500: ACC: 0.0, NMI: 0.1906258010292974, F1: 0.0, ARI: 0.04391888242728829
INFO - 04/15/25 16:33:48 - 0:02:11 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2501: train_loss=9.998180389404297
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2502: train_loss=9.996411323547363
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2503: train_loss=9.996533393859863
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2504: train_loss=9.998391151428223
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2505: train_loss=9.996413230895996
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2506: train_loss=9.997040748596191
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2507: train_loss=9.996783256530762
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2508: train_loss=9.998366355895996
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2509: train_loss=9.996561050415039
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2510: train_loss=9.996488571166992
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2511: train_loss=9.996520042419434
INFO - 04/15/25 16:33:48 - 0:02:11 - Epoch 2512: train_loss=9.99804973602295
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2513: train_loss=9.996079444885254
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2514: train_loss=9.996079444885254
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2515: train_loss=9.995597839355469
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2516: train_loss=9.999227523803711
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2517: train_loss=9.997485160827637
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2518: train_loss=9.995623588562012
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2519: train_loss=9.995455741882324
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2520: train_loss=9.999247550964355
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2521: train_loss=9.997450828552246
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2522: train_loss=9.994710922241211
INFO - 04/15/25 16:33:48 - 0:02:12 - Epoch 2523: train_loss=9.995158195495605
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2524: train_loss=9.999237060546875
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2525: train_loss=9.996522903442383
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2526: train_loss=9.996413230895996
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2527: train_loss=9.996979713439941
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2528: train_loss=9.996524810791016
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2529: train_loss=9.993876457214355
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2530: train_loss=9.999141693115234
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2531: train_loss=9.999300956726074
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2532: train_loss=9.994304656982422
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2533: train_loss=10.000041961669922
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2534: train_loss=9.994790077209473
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2535: train_loss=10.000397682189941
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2536: train_loss=9.999686241149902
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2537: train_loss=9.999183654785156
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2538: train_loss=9.996647834777832
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2539: train_loss=9.99924373626709
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2540: train_loss=9.996781349182129
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2541: train_loss=10.000432014465332
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2542: train_loss=9.998321533203125
INFO - 04/15/25 16:33:49 - 0:02:12 - Epoch 2543: train_loss=9.999337196350098
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2544: train_loss=9.997385025024414
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2545: train_loss=10.000056266784668
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2546: train_loss=9.999185562133789
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2547: train_loss=9.996115684509277
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2548: train_loss=9.99575138092041
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2549: train_loss=9.99813175201416
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2550: train_loss=9.996106147766113
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2551: train_loss=9.998825073242188
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2552: train_loss=9.997697830200195
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2553: train_loss=9.997011184692383
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2554: train_loss=9.996212005615234
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2555: train_loss=9.996337890625
INFO - 04/15/25 16:33:49 - 0:02:13 - Epoch 2556: train_loss=9.995139122009277
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2557: train_loss=9.998218536376953
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2558: train_loss=9.996949195861816
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2559: train_loss=9.99571418762207
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2560: train_loss=9.995277404785156
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2561: train_loss=9.997238159179688
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2562: train_loss=9.99508285522461
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2563: train_loss=9.99666976928711
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2564: train_loss=9.996171951293945
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2565: train_loss=9.995794296264648
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2566: train_loss=9.994738578796387
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2567: train_loss=9.995522499084473
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2568: train_loss=9.994009017944336
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2569: train_loss=10.001513481140137
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2570: train_loss=9.99964427947998
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2571: train_loss=9.99517822265625
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2572: train_loss=9.99560260772705
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2573: train_loss=9.995171546936035
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2574: train_loss=9.994240760803223
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2575: train_loss=9.999979019165039
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2576: train_loss=9.995647430419922
INFO - 04/15/25 16:33:50 - 0:02:13 - Epoch 2577: train_loss=9.996650695800781
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2578: train_loss=9.99533748626709
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2579: train_loss=9.997182846069336
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2580: train_loss=9.996562957763672
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2581: train_loss=10.001365661621094
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2582: train_loss=9.99941349029541
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2583: train_loss=9.996729850769043
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2584: train_loss=9.996932983398438
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2585: train_loss=9.99791431427002
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2586: train_loss=10.009992599487305
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2587: train_loss=9.996509552001953
INFO - 04/15/25 16:33:50 - 0:02:14 - Epoch 2588: train_loss=9.998575210571289
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2589: train_loss=9.997180938720703
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2590: train_loss=9.997798919677734
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2591: train_loss=9.997029304504395
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2592: train_loss=9.996305465698242
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2593: train_loss=9.996489524841309
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2594: train_loss=9.997198104858398
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2595: train_loss=9.994786262512207
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2596: train_loss=9.996935844421387
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2597: train_loss=9.996479988098145
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2598: train_loss=9.995478630065918
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2599: train_loss=9.995363235473633
INFO - 04/15/25 16:33:51 - 0:02:14 - Epoch 2600: train_loss=9.994707107543945
INFO - 04/15/25 16:33:51 - 0:02:14 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:51 - 0:02:14 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2600: ACC: 0.0, NMI: 0.21854142114902494, F1: 0.0, ARI: 0.09399677546448959
INFO - 04/15/25 16:33:51 - 0:02:15 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2601: train_loss=9.994829177856445
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2602: train_loss=9.994796752929688
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2603: train_loss=9.99304485321045
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2604: train_loss=9.996187210083008
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2605: train_loss=9.995986938476562
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2606: train_loss=9.993531227111816
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2607: train_loss=9.992810249328613
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2608: train_loss=9.993610382080078
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2609: train_loss=9.993738174438477
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2610: train_loss=9.992782592773438
INFO - 04/15/25 16:33:51 - 0:02:15 - Epoch 2611: train_loss=9.995636940002441
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2612: train_loss=9.991981506347656
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2613: train_loss=9.997590065002441
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2614: train_loss=9.995511054992676
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2615: train_loss=9.995658874511719
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2616: train_loss=9.99417495727539
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2617: train_loss=9.996543884277344
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2618: train_loss=9.995010375976562
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2619: train_loss=9.995391845703125
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2620: train_loss=9.99378776550293
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2621: train_loss=9.996338844299316
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2622: train_loss=9.994176864624023
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2623: train_loss=9.997578620910645
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2624: train_loss=9.99620246887207
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2625: train_loss=9.993865966796875
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2626: train_loss=9.994426727294922
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2627: train_loss=9.995808601379395
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2628: train_loss=9.992820739746094
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2629: train_loss=9.997014045715332
INFO - 04/15/25 16:33:52 - 0:02:15 - Epoch 2630: train_loss=9.995931625366211
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2631: train_loss=9.995687484741211
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2632: train_loss=9.994067192077637
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2633: train_loss=9.995410919189453
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2634: train_loss=9.994264602661133
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2635: train_loss=9.995221138000488
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2636: train_loss=9.993661880493164
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2637: train_loss=9.994290351867676
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2638: train_loss=9.993566513061523
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2639: train_loss=9.99325180053711
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2640: train_loss=9.991796493530273
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2641: train_loss=9.997653007507324
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2642: train_loss=9.996332168579102
INFO - 04/15/25 16:33:52 - 0:02:16 - Epoch 2643: train_loss=9.991793632507324
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2644: train_loss=9.99582576751709
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2645: train_loss=9.99431324005127
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2646: train_loss=9.99402141571045
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2647: train_loss=9.992685317993164
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2648: train_loss=9.990628242492676
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2649: train_loss=9.990039825439453
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2650: train_loss=9.984410285949707
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2651: train_loss=9.976325988769531
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2652: train_loss=9.978056907653809
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2653: train_loss=9.973626136779785
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2654: train_loss=9.977417945861816
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2655: train_loss=9.975569725036621
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2656: train_loss=9.97729778289795
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2657: train_loss=9.97609806060791
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2658: train_loss=9.975875854492188
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2659: train_loss=9.975961685180664
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2660: train_loss=9.975200653076172
INFO - 04/15/25 16:33:53 - 0:02:16 - Epoch 2661: train_loss=9.976789474487305
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2662: train_loss=9.975544929504395
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2663: train_loss=9.975625038146973
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2664: train_loss=9.975362777709961
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2665: train_loss=9.974124908447266
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2666: train_loss=9.97631549835205
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2667: train_loss=9.975624084472656
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2668: train_loss=9.975459098815918
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2669: train_loss=9.973651885986328
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2670: train_loss=9.974660873413086
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2671: train_loss=9.97481918334961
INFO - 04/15/25 16:33:53 - 0:02:17 - Epoch 2672: train_loss=9.972796440124512
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2673: train_loss=9.973774909973145
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2674: train_loss=9.975126266479492
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2675: train_loss=9.971863746643066
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2676: train_loss=9.977166175842285
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2677: train_loss=9.976243019104004
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2678: train_loss=9.975299835205078
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2679: train_loss=9.972833633422852
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2680: train_loss=9.976430892944336
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2681: train_loss=9.974944114685059
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2682: train_loss=9.973978042602539
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2683: train_loss=9.973719596862793
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2684: train_loss=9.973803520202637
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2685: train_loss=9.974981307983398
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2686: train_loss=9.972014427185059
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2687: train_loss=9.973036766052246
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2688: train_loss=9.975605964660645
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2689: train_loss=9.97229290008545
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2690: train_loss=9.97511100769043
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2691: train_loss=9.974969863891602
INFO - 04/15/25 16:33:54 - 0:02:17 - Epoch 2692: train_loss=9.972709655761719
INFO - 04/15/25 16:33:54 - 0:02:18 - Epoch 2693: train_loss=9.975664138793945
INFO - 04/15/25 16:33:54 - 0:02:18 - Epoch 2694: train_loss=9.975628852844238
INFO - 04/15/25 16:33:54 - 0:02:18 - Epoch 2695: train_loss=9.974579811096191
INFO - 04/15/25 16:33:54 - 0:02:18 - Epoch 2696: train_loss=9.973221778869629
INFO - 04/15/25 16:33:54 - 0:02:18 - Epoch 2697: train_loss=9.973906517028809
INFO - 04/15/25 16:33:54 - 0:02:18 - Epoch 2698: train_loss=9.972234725952148
INFO - 04/15/25 16:33:54 - 0:02:18 - Epoch 2699: train_loss=9.976522445678711
INFO - 04/15/25 16:33:54 - 0:02:18 - Epoch 2700: train_loss=9.975057601928711
INFO - 04/15/25 16:33:54 - 0:02:18 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:54 - 0:02:18 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2700: ACC: 0.0, NMI: 0.19573139167373974, F1: 0.0, ARI: 0.06618947366639547
INFO - 04/15/25 16:33:55 - 0:02:18 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2701: train_loss=9.975181579589844
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2702: train_loss=9.973613739013672
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2703: train_loss=9.975973129272461
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2704: train_loss=9.975042343139648
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2705: train_loss=9.974081993103027
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2706: train_loss=9.974254608154297
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2707: train_loss=9.97393798828125
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2708: train_loss=9.97392749786377
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2709: train_loss=9.974456787109375
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2710: train_loss=9.97274112701416
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2711: train_loss=9.977169036865234
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2712: train_loss=9.975622177124023
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2713: train_loss=9.975783348083496
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2714: train_loss=9.973990440368652
INFO - 04/15/25 16:33:55 - 0:02:18 - Epoch 2715: train_loss=9.976621627807617
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2716: train_loss=9.97588062286377
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2717: train_loss=9.974367141723633
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2718: train_loss=9.974235534667969
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2719: train_loss=9.976170539855957
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2720: train_loss=9.973033905029297
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2721: train_loss=9.978046417236328
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2722: train_loss=9.978998184204102
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2723: train_loss=9.973280906677246
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2724: train_loss=9.977619171142578
INFO - 04/15/25 16:33:55 - 0:02:19 - Epoch 2725: train_loss=9.976519584655762
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2726: train_loss=9.975790977478027
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2727: train_loss=9.97580337524414
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2728: train_loss=9.974122047424316
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2729: train_loss=9.975188255310059
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2730: train_loss=9.974578857421875
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2731: train_loss=9.97521686553955
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2732: train_loss=9.973273277282715
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2733: train_loss=9.972222328186035
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2734: train_loss=9.973213195800781
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2735: train_loss=9.974589347839355
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2736: train_loss=9.973544120788574
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2737: train_loss=9.973588943481445
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2738: train_loss=9.973362922668457
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2739: train_loss=9.972126960754395
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2740: train_loss=9.9765625
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2741: train_loss=9.973752975463867
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2742: train_loss=9.97751235961914
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2743: train_loss=9.975173950195312
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2744: train_loss=9.978371620178223
INFO - 04/15/25 16:33:56 - 0:02:19 - Epoch 2745: train_loss=9.978172302246094
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2746: train_loss=9.974157333374023
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2747: train_loss=9.97464370727539
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2748: train_loss=9.976821899414062
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2749: train_loss=9.97503662109375
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2750: train_loss=9.977885246276855
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2751: train_loss=9.976995468139648
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2752: train_loss=9.976689338684082
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2753: train_loss=9.97591495513916
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2754: train_loss=9.977530479431152
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2755: train_loss=9.975959777832031
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2756: train_loss=9.978690147399902
INFO - 04/15/25 16:33:56 - 0:02:20 - Epoch 2757: train_loss=9.978309631347656
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2758: train_loss=9.974912643432617
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2759: train_loss=9.97456169128418
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2760: train_loss=9.977376937866211
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2761: train_loss=9.975266456604004
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2762: train_loss=9.978311538696289
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2763: train_loss=9.97745418548584
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2764: train_loss=9.976011276245117
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2765: train_loss=9.97536849975586
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2766: train_loss=9.97658920288086
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2767: train_loss=9.974828720092773
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2768: train_loss=9.978592872619629
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2769: train_loss=9.978306770324707
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2770: train_loss=9.974509239196777
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2771: train_loss=9.974148750305176
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2772: train_loss=9.977302551269531
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2773: train_loss=9.975384712219238
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2774: train_loss=9.978442192077637
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2775: train_loss=9.978599548339844
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2776: train_loss=9.975136756896973
INFO - 04/15/25 16:33:57 - 0:02:20 - Epoch 2777: train_loss=9.975812911987305
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2778: train_loss=9.977206230163574
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2779: train_loss=9.974154472351074
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2780: train_loss=9.974129676818848
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2781: train_loss=9.957164764404297
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2782: train_loss=9.94925594329834
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2783: train_loss=9.930456161499023
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2784: train_loss=9.925214767456055
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2785: train_loss=9.925004959106445
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2786: train_loss=9.9274320602417
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2787: train_loss=9.915736198425293
INFO - 04/15/25 16:33:57 - 0:02:21 - Epoch 2788: train_loss=9.92595386505127
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2789: train_loss=9.917710304260254
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2790: train_loss=9.904472351074219
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2791: train_loss=9.910369873046875
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2792: train_loss=9.910122871398926
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2793: train_loss=9.913156509399414
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2794: train_loss=9.915384292602539
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2795: train_loss=9.910999298095703
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2796: train_loss=9.91096305847168
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2797: train_loss=9.912640571594238
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2798: train_loss=9.908517837524414
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2799: train_loss=9.909998893737793
INFO - 04/15/25 16:33:58 - 0:02:21 - Epoch 2800: train_loss=9.91118049621582
INFO - 04/15/25 16:33:58 - 0:02:21 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:33:58 - 0:02:21 - Decoding cost time:  0.259 s
INFO - 04/15/25 16:33:58 - 0:02:22 - Epoch 2800: ACC: 0.0, NMI: 0.20245913169050755, F1: 0.0, ARI: 0.050867148666150296
INFO - 04/15/25 16:33:58 - 0:02:22 - -------------------------------------------------------------------------
INFO - 04/15/25 16:33:58 - 0:02:22 - Epoch 2801: train_loss=9.905282020568848
INFO - 04/15/25 16:33:58 - 0:02:22 - Epoch 2802: train_loss=9.912858009338379
INFO - 04/15/25 16:33:58 - 0:02:22 - Epoch 2803: train_loss=9.913156509399414
INFO - 04/15/25 16:33:58 - 0:02:22 - Epoch 2804: train_loss=9.908023834228516
INFO - 04/15/25 16:33:58 - 0:02:22 - Epoch 2805: train_loss=9.90690803527832
INFO - 04/15/25 16:33:58 - 0:02:22 - Epoch 2806: train_loss=9.906659126281738
INFO - 04/15/25 16:33:58 - 0:02:22 - Epoch 2807: train_loss=9.89499282836914
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2808: train_loss=9.896726608276367
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2809: train_loss=9.895613670349121
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2810: train_loss=9.939557075500488
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2811: train_loss=9.9241943359375
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2812: train_loss=9.92548942565918
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2813: train_loss=9.932595252990723
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2814: train_loss=9.939663887023926
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2815: train_loss=9.922378540039062
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2816: train_loss=9.925924301147461
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2817: train_loss=9.96024227142334
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2818: train_loss=9.932441711425781
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2819: train_loss=9.918455123901367
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2820: train_loss=9.913536071777344
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2821: train_loss=9.914702415466309
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2822: train_loss=9.914373397827148
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2823: train_loss=9.913200378417969
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2824: train_loss=9.913317680358887
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2825: train_loss=9.909710884094238
INFO - 04/15/25 16:33:59 - 0:02:22 - Epoch 2826: train_loss=9.913925170898438
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2827: train_loss=9.912760734558105
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2828: train_loss=9.910022735595703
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2829: train_loss=9.90877628326416
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2830: train_loss=9.907578468322754
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2831: train_loss=9.907205581665039
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2832: train_loss=9.90483570098877
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2833: train_loss=9.905556678771973
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2834: train_loss=9.903009414672852
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2835: train_loss=9.902555465698242
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2836: train_loss=9.902057647705078
INFO - 04/15/25 16:33:59 - 0:02:23 - Epoch 2837: train_loss=9.90068531036377
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2838: train_loss=9.900809288024902
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2839: train_loss=9.900012969970703
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2840: train_loss=9.89864444732666
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2841: train_loss=9.897939682006836
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2842: train_loss=9.897320747375488
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2843: train_loss=9.896656036376953
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2844: train_loss=9.894972801208496
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2845: train_loss=9.896442413330078
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2846: train_loss=9.894957542419434
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2847: train_loss=9.89690113067627
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2848: train_loss=9.89277458190918
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2849: train_loss=9.89411449432373
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2850: train_loss=9.893852233886719
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2851: train_loss=9.893867492675781
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2852: train_loss=9.893239974975586
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2853: train_loss=9.8927640914917
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2854: train_loss=9.892701148986816
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2855: train_loss=9.891355514526367
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2856: train_loss=9.891684532165527
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2857: train_loss=9.890326499938965
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2858: train_loss=9.890412330627441
INFO - 04/15/25 16:34:00 - 0:02:23 - Epoch 2859: train_loss=9.889482498168945
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2860: train_loss=9.889037132263184
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2861: train_loss=9.88875675201416
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2862: train_loss=9.887462615966797
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2863: train_loss=9.889116287231445
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2864: train_loss=9.88802719116211
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2865: train_loss=9.887045860290527
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2866: train_loss=9.88711166381836
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2867: train_loss=9.886042594909668
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2868: train_loss=9.884429931640625
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2869: train_loss=9.886717796325684
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2870: train_loss=9.884657859802246
INFO - 04/15/25 16:34:00 - 0:02:24 - Epoch 2871: train_loss=9.885534286499023
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2872: train_loss=9.885132789611816
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2873: train_loss=9.8828706741333
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2874: train_loss=9.884007453918457
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2875: train_loss=9.88222599029541
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2876: train_loss=9.882709503173828
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2877: train_loss=9.881026268005371
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2878: train_loss=9.879667282104492
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2879: train_loss=9.88311767578125
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2880: train_loss=9.879372596740723
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2881: train_loss=9.883355140686035
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2882: train_loss=9.880268096923828
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2883: train_loss=9.883404731750488
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2884: train_loss=9.881370544433594
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2885: train_loss=9.881793022155762
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2886: train_loss=9.880158424377441
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2887: train_loss=9.880846977233887
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2888: train_loss=9.87929916381836
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2889: train_loss=9.880448341369629
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2890: train_loss=9.879654884338379
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2891: train_loss=9.877902030944824
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2892: train_loss=9.877374649047852
INFO - 04/15/25 16:34:01 - 0:02:24 - Epoch 2893: train_loss=9.87873363494873
INFO - 04/15/25 16:34:01 - 0:02:25 - Epoch 2894: train_loss=9.877274513244629
INFO - 04/15/25 16:34:01 - 0:02:25 - Epoch 2895: train_loss=9.879318237304688
INFO - 04/15/25 16:34:01 - 0:02:25 - Epoch 2896: train_loss=9.87820816040039
INFO - 04/15/25 16:34:01 - 0:02:25 - Epoch 2897: train_loss=9.878399848937988
INFO - 04/15/25 16:34:01 - 0:02:25 - Epoch 2898: train_loss=9.877318382263184
INFO - 04/15/25 16:34:01 - 0:02:25 - Epoch 2899: train_loss=9.878156661987305
INFO - 04/15/25 16:34:01 - 0:02:25 - Epoch 2900: train_loss=9.877511978149414
INFO - 04/15/25 16:34:01 - 0:02:25 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:01 - 0:02:25 - Decoding cost time:  0.124 s
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2900: ACC: 0.0, NMI: 0.15641769217130425, F1: 0.0, ARI: 0.014087202133507715
INFO - 04/15/25 16:34:02 - 0:02:25 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2901: train_loss=9.87841796875
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2902: train_loss=9.877010345458984
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2903: train_loss=9.877470970153809
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2904: train_loss=9.876676559448242
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2905: train_loss=9.876448631286621
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2906: train_loss=9.875575065612793
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2907: train_loss=9.87537956237793
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2908: train_loss=9.874772071838379
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2909: train_loss=9.874177932739258
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2910: train_loss=9.87298583984375
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2911: train_loss=9.87556266784668
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2912: train_loss=9.873751640319824
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2913: train_loss=9.875795364379883
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2914: train_loss=9.875158309936523
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2915: train_loss=9.874146461486816
INFO - 04/15/25 16:34:02 - 0:02:25 - Epoch 2916: train_loss=9.873969078063965
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2917: train_loss=9.871842384338379
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2918: train_loss=9.874873161315918
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2919: train_loss=9.874601364135742
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2920: train_loss=9.867788314819336
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2921: train_loss=9.86954116821289
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2922: train_loss=9.862385749816895
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2923: train_loss=9.858073234558105
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2924: train_loss=9.857915878295898
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2925: train_loss=9.853179931640625
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2926: train_loss=9.857585906982422
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2927: train_loss=9.85477352142334
INFO - 04/15/25 16:34:02 - 0:02:26 - Epoch 2928: train_loss=9.854785919189453
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2929: train_loss=9.850844383239746
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2930: train_loss=9.847129821777344
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2931: train_loss=9.849401473999023
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2932: train_loss=9.842453956604004
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2933: train_loss=9.806500434875488
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2934: train_loss=9.807957649230957
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2935: train_loss=9.806838989257812
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2936: train_loss=9.805062294006348
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2937: train_loss=9.803288459777832
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2938: train_loss=9.803001403808594
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2939: train_loss=9.802237510681152
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2940: train_loss=9.80166244506836
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2941: train_loss=9.811829566955566
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2942: train_loss=9.803984642028809
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2943: train_loss=9.799896240234375
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2944: train_loss=9.799704551696777
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2945: train_loss=9.797027587890625
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2946: train_loss=9.79686164855957
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2947: train_loss=9.792448997497559
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2948: train_loss=9.794844627380371
INFO - 04/15/25 16:34:03 - 0:02:26 - Epoch 2949: train_loss=9.805214881896973
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2950: train_loss=9.793597221374512
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2951: train_loss=9.7974214553833
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2952: train_loss=9.797666549682617
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2953: train_loss=9.797161102294922
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2954: train_loss=9.803446769714355
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2955: train_loss=9.80528450012207
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2956: train_loss=9.79936408996582
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2957: train_loss=9.798794746398926
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2958: train_loss=9.79743480682373
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2959: train_loss=9.795771598815918
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2960: train_loss=9.795632362365723
INFO - 04/15/25 16:34:03 - 0:02:27 - Epoch 2961: train_loss=9.793339729309082
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2962: train_loss=9.795184135437012
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2963: train_loss=9.791537284851074
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2964: train_loss=9.793000221252441
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2965: train_loss=9.79078197479248
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2966: train_loss=9.79154109954834
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2967: train_loss=9.790151596069336
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2968: train_loss=9.789349555969238
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2969: train_loss=9.788524627685547
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2970: train_loss=9.787626266479492
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2971: train_loss=9.786412239074707
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2972: train_loss=9.785776138305664
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2973: train_loss=9.786417007446289
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2974: train_loss=9.786362648010254
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2975: train_loss=9.785150527954102
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2976: train_loss=9.78454303741455
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2977: train_loss=9.784112930297852
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2978: train_loss=9.783353805541992
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2979: train_loss=9.783299446105957
INFO - 04/15/25 16:34:04 - 0:02:27 - Epoch 2980: train_loss=9.784163475036621
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2981: train_loss=9.780824661254883
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2982: train_loss=9.770984649658203
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2983: train_loss=9.781396865844727
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2984: train_loss=9.778044700622559
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2985: train_loss=9.775138854980469
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2986: train_loss=9.780961990356445
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2987: train_loss=9.781882286071777
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2988: train_loss=9.783731460571289
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2989: train_loss=9.778223037719727
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2990: train_loss=9.769719123840332
INFO - 04/15/25 16:34:04 - 0:02:28 - Epoch 2991: train_loss=9.768278121948242
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 2992: train_loss=9.764918327331543
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 2993: train_loss=9.768930435180664
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 2994: train_loss=9.765117645263672
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 2995: train_loss=9.763137817382812
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 2996: train_loss=9.764336585998535
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 2997: train_loss=9.763218879699707
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 2998: train_loss=9.762948989868164
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 2999: train_loss=9.761255264282227
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 3000: train_loss=9.761664390563965
INFO - 04/15/25 16:34:05 - 0:02:28 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:05 - 0:02:28 - Decoding cost time:  0.130 s
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 3000: ACC: 0.0, NMI: 0.1349491813159806, F1: 0.0, ARI: 0.020026540098550087
INFO - 04/15/25 16:34:05 - 0:02:28 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 3001: train_loss=9.761622428894043
INFO - 04/15/25 16:34:05 - 0:02:28 - Epoch 3002: train_loss=9.760257720947266
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3003: train_loss=9.758597373962402
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3004: train_loss=9.761422157287598
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3005: train_loss=9.758508682250977
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3006: train_loss=9.758773803710938
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3007: train_loss=9.759454727172852
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3008: train_loss=9.756382942199707
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3009: train_loss=9.76114559173584
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3010: train_loss=9.758698463439941
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3011: train_loss=9.759283065795898
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3012: train_loss=9.757447242736816
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3013: train_loss=9.759078025817871
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3014: train_loss=9.758658409118652
INFO - 04/15/25 16:34:05 - 0:02:29 - Epoch 3015: train_loss=9.755999565124512
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3016: train_loss=9.749567031860352
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3017: train_loss=9.756999015808105
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3018: train_loss=9.735840797424316
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3019: train_loss=9.734512329101562
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3020: train_loss=9.738883018493652
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3021: train_loss=9.73546314239502
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3022: train_loss=9.735392570495605
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3023: train_loss=9.734213829040527
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3024: train_loss=9.734932899475098
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3025: train_loss=9.734105110168457
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3026: train_loss=9.732053756713867
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3027: train_loss=9.731364250183105
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3028: train_loss=9.730899810791016
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3029: train_loss=9.727641105651855
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3030: train_loss=9.712238311767578
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3031: train_loss=9.75789737701416
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3032: train_loss=9.85735034942627
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3033: train_loss=9.947328567504883
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3034: train_loss=9.899019241333008
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3035: train_loss=9.910237312316895
INFO - 04/15/25 16:34:06 - 0:02:29 - Epoch 3036: train_loss=9.940388679504395
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3037: train_loss=9.898433685302734
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3038: train_loss=9.893869400024414
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3039: train_loss=9.897212982177734
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3040: train_loss=9.874529838562012
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3041: train_loss=9.874101638793945
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3042: train_loss=9.866374015808105
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3043: train_loss=9.865238189697266
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3044: train_loss=9.864579200744629
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3045: train_loss=9.860428810119629
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3046: train_loss=9.853717803955078
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3047: train_loss=9.850932121276855
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3048: train_loss=9.846056938171387
INFO - 04/15/25 16:34:06 - 0:02:30 - Epoch 3049: train_loss=9.842179298400879
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3050: train_loss=9.840171813964844
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3051: train_loss=9.838232040405273
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3052: train_loss=9.83536434173584
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3053: train_loss=9.832780838012695
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3054: train_loss=9.828868865966797
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3055: train_loss=9.827046394348145
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3056: train_loss=9.824289321899414
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3057: train_loss=9.822566986083984
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3058: train_loss=9.820250511169434
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3059: train_loss=9.817802429199219
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3060: train_loss=9.814546585083008
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3061: train_loss=9.813075065612793
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3062: train_loss=9.81275749206543
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3063: train_loss=9.809560775756836
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3064: train_loss=9.806514739990234
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3065: train_loss=9.805773735046387
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3066: train_loss=9.809870719909668
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3067: train_loss=9.802484512329102
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3068: train_loss=9.80273151397705
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3069: train_loss=9.802895545959473
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3070: train_loss=9.801382064819336
INFO - 04/15/25 16:34:07 - 0:02:30 - Epoch 3071: train_loss=9.799529075622559
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3072: train_loss=9.801190376281738
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3073: train_loss=9.79580020904541
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3074: train_loss=9.796801567077637
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3075: train_loss=9.793105125427246
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3076: train_loss=9.793265342712402
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3077: train_loss=9.791714668273926
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3078: train_loss=9.789743423461914
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3079: train_loss=9.790243148803711
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3080: train_loss=9.786735534667969
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3081: train_loss=9.78664493560791
INFO - 04/15/25 16:34:07 - 0:02:31 - Epoch 3082: train_loss=9.784552574157715
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3083: train_loss=9.784021377563477
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3084: train_loss=9.78197956085205
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3085: train_loss=9.780957221984863
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3086: train_loss=9.780264854431152
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3087: train_loss=9.778943061828613
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3088: train_loss=9.776252746582031
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3089: train_loss=9.78090763092041
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3090: train_loss=9.77664852142334
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3091: train_loss=9.779122352600098
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3092: train_loss=9.777449607849121
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3093: train_loss=9.77371597290039
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3094: train_loss=9.775032997131348
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3095: train_loss=9.773043632507324
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3096: train_loss=9.77255916595459
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3097: train_loss=9.771738052368164
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3098: train_loss=9.770133972167969
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3099: train_loss=9.769757270812988
INFO - 04/15/25 16:34:08 - 0:02:31 - Epoch 3100: train_loss=9.769917488098145
INFO - 04/15/25 16:34:08 - 0:02:31 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:08 - 0:02:31 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:34:08 - 0:02:32 - Epoch 3100: ACC: 0.0, NMI: 0.2230650142883767, F1: 0.0, ARI: 0.02768508097220753
INFO - 04/15/25 16:34:08 - 0:02:32 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:08 - 0:02:32 - Epoch 3101: train_loss=9.770108222961426
INFO - 04/15/25 16:34:08 - 0:02:32 - Epoch 3102: train_loss=9.767104148864746
INFO - 04/15/25 16:34:08 - 0:02:32 - Epoch 3103: train_loss=9.767523765563965
INFO - 04/15/25 16:34:08 - 0:02:32 - Epoch 3104: train_loss=9.767756462097168
INFO - 04/15/25 16:34:08 - 0:02:32 - Epoch 3105: train_loss=9.765454292297363
INFO - 04/15/25 16:34:08 - 0:02:32 - Epoch 3106: train_loss=9.767573356628418
INFO - 04/15/25 16:34:08 - 0:02:32 - Epoch 3107: train_loss=9.76494312286377
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3108: train_loss=9.76596736907959
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3109: train_loss=9.76582145690918
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3110: train_loss=9.762431144714355
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3111: train_loss=9.765013694763184
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3112: train_loss=9.761499404907227
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3113: train_loss=9.76777172088623
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3114: train_loss=9.767685890197754
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3115: train_loss=9.760141372680664
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3116: train_loss=9.765313148498535
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3117: train_loss=9.7666015625
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3118: train_loss=9.761462211608887
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3119: train_loss=9.760086059570312
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3120: train_loss=9.760212898254395
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3121: train_loss=9.759812355041504
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3122: train_loss=9.75680160522461
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3123: train_loss=9.755884170532227
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3124: train_loss=9.756721496582031
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3125: train_loss=9.753314971923828
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3126: train_loss=9.757152557373047
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3127: train_loss=9.758391380310059
INFO - 04/15/25 16:34:09 - 0:02:32 - Epoch 3128: train_loss=9.752016067504883
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3129: train_loss=9.756397247314453
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3130: train_loss=9.756564140319824
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3131: train_loss=9.754138946533203
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3132: train_loss=9.750445365905762
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3133: train_loss=9.754443168640137
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3134: train_loss=9.754595756530762
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3135: train_loss=9.74963092803955
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3136: train_loss=9.748579978942871
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3137: train_loss=9.748617172241211
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3138: train_loss=9.747268676757812
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3139: train_loss=9.745746612548828
INFO - 04/15/25 16:34:09 - 0:02:33 - Epoch 3140: train_loss=9.747319221496582
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3141: train_loss=9.746333122253418
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3142: train_loss=9.746572494506836
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3143: train_loss=9.746397972106934
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3144: train_loss=9.744327545166016
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3145: train_loss=9.749969482421875
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3146: train_loss=9.747964859008789
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3147: train_loss=9.746932029724121
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3148: train_loss=9.74517822265625
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3149: train_loss=9.745552062988281
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3150: train_loss=9.727734565734863
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3151: train_loss=9.711502075195312
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3152: train_loss=9.712672233581543
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3153: train_loss=9.715051651000977
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3154: train_loss=9.7127685546875
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3155: train_loss=9.717182159423828
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3156: train_loss=9.717230796813965
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3157: train_loss=9.719802856445312
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3158: train_loss=9.716703414916992
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3159: train_loss=9.717098236083984
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3160: train_loss=9.7162504196167
INFO - 04/15/25 16:34:10 - 0:02:33 - Epoch 3161: train_loss=9.714981079101562
INFO - 04/15/25 16:34:10 - 0:02:34 - Epoch 3162: train_loss=9.715238571166992
INFO - 04/15/25 16:34:10 - 0:02:34 - Epoch 3163: train_loss=9.716535568237305
INFO - 04/15/25 16:34:10 - 0:02:34 - Epoch 3164: train_loss=9.710918426513672
INFO - 04/15/25 16:34:10 - 0:02:34 - Epoch 3165: train_loss=9.713712692260742
INFO - 04/15/25 16:34:10 - 0:02:34 - Epoch 3166: train_loss=9.714500427246094
INFO - 04/15/25 16:34:10 - 0:02:34 - Epoch 3167: train_loss=9.70876407623291
INFO - 04/15/25 16:34:10 - 0:02:34 - Epoch 3168: train_loss=9.712427139282227
INFO - 04/15/25 16:34:10 - 0:02:34 - Epoch 3169: train_loss=9.710214614868164
INFO - 04/15/25 16:34:11 - 0:02:34 - Epoch 3170: train_loss=9.708740234375
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3171: train_loss=9.707944869995117
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3172: train_loss=9.707530975341797
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3173: train_loss=9.706664085388184
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3174: train_loss=9.703768730163574
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3175: train_loss=9.706382751464844
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3176: train_loss=9.702913284301758
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3177: train_loss=9.706221580505371
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3178: train_loss=9.705228805541992
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3179: train_loss=9.701651573181152
INFO - 04/15/25 16:34:11 - 0:02:35 - Epoch 3180: train_loss=9.70215892791748
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3181: train_loss=9.702319145202637
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3182: train_loss=9.699851989746094
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3183: train_loss=9.700396537780762
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3184: train_loss=9.69971752166748
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3185: train_loss=9.697710037231445
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3186: train_loss=9.700952529907227
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3187: train_loss=9.698739051818848
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3188: train_loss=9.70002555847168
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3189: train_loss=9.699336051940918
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3190: train_loss=9.69957447052002
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3191: train_loss=9.6972017288208
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3192: train_loss=9.70181941986084
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3193: train_loss=9.697623252868652
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3194: train_loss=9.699356079101562
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3195: train_loss=9.69662094116211
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3196: train_loss=9.701024055480957
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3197: train_loss=9.700366020202637
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3198: train_loss=9.694981575012207
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3199: train_loss=9.69556713104248
INFO - 04/15/25 16:34:12 - 0:02:35 - Epoch 3200: train_loss=9.697830200195312
INFO - 04/15/25 16:34:12 - 0:02:35 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:12 - 0:02:36 - Decoding cost time:  0.124 s
INFO - 04/15/25 16:34:12 - 0:02:36 - Epoch 3200: ACC: 0.0, NMI: 0.28360977920919855, F1: 0.0, ARI: 0.060511002311822035
INFO - 04/15/25 16:34:12 - 0:02:36 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:12 - 0:02:36 - Epoch 3201: train_loss=9.695592880249023
INFO - 04/15/25 16:34:12 - 0:02:36 - Epoch 3202: train_loss=9.700586318969727
INFO - 04/15/25 16:34:12 - 0:02:36 - Epoch 3203: train_loss=9.697823524475098
INFO - 04/15/25 16:34:12 - 0:02:36 - Epoch 3204: train_loss=9.696244239807129
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3205: train_loss=9.695259094238281
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3206: train_loss=9.696022987365723
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3207: train_loss=9.694733619689941
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3208: train_loss=9.695481300354004
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3209: train_loss=9.694558143615723
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3210: train_loss=9.694941520690918
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3211: train_loss=9.69317626953125
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3212: train_loss=9.696420669555664
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3213: train_loss=9.696096420288086
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3214: train_loss=9.690775871276855
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3215: train_loss=9.692207336425781
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3216: train_loss=9.692919731140137
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3217: train_loss=9.689438819885254
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3218: train_loss=9.694414138793945
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3219: train_loss=9.693055152893066
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3220: train_loss=9.692463874816895
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3221: train_loss=9.690849304199219
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3222: train_loss=9.692647933959961
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3223: train_loss=9.690807342529297
INFO - 04/15/25 16:34:13 - 0:02:36 - Epoch 3224: train_loss=9.692045211791992
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3225: train_loss=9.691040992736816
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3226: train_loss=9.692227363586426
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3227: train_loss=9.689569473266602
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3228: train_loss=9.691032409667969
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3229: train_loss=9.688516616821289
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3230: train_loss=9.681878089904785
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3231: train_loss=9.6903715133667
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3232: train_loss=9.68015193939209
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3233: train_loss=9.686799049377441
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3234: train_loss=9.692605972290039
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3235: train_loss=9.688843727111816
INFO - 04/15/25 16:34:13 - 0:02:37 - Epoch 3236: train_loss=9.68896198272705
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3237: train_loss=9.68971061706543
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3238: train_loss=9.68825626373291
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3239: train_loss=9.690293312072754
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3240: train_loss=9.6881103515625
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3241: train_loss=9.69310188293457
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3242: train_loss=9.69154167175293
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3243: train_loss=9.690224647521973
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3244: train_loss=9.689542770385742
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3245: train_loss=9.69106674194336
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3246: train_loss=9.686613082885742
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3247: train_loss=9.69074535369873
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3248: train_loss=9.689844131469727
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3249: train_loss=9.688904762268066
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3250: train_loss=9.685372352600098
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3251: train_loss=9.691694259643555
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3252: train_loss=9.691328048706055
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3253: train_loss=9.685763359069824
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3254: train_loss=9.688007354736328
INFO - 04/15/25 16:34:14 - 0:02:37 - Epoch 3255: train_loss=9.686737060546875
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3256: train_loss=9.685929298400879
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3257: train_loss=9.68565845489502
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3258: train_loss=9.68601131439209
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3259: train_loss=9.68386173248291
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3260: train_loss=9.686667442321777
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3261: train_loss=9.685912132263184
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3262: train_loss=9.682940483093262
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3263: train_loss=9.685419082641602
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3264: train_loss=9.683601379394531
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3265: train_loss=9.684026718139648
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3266: train_loss=9.684475898742676
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3267: train_loss=9.681231498718262
INFO - 04/15/25 16:34:14 - 0:02:38 - Epoch 3268: train_loss=9.683928489685059
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3269: train_loss=9.684866905212402
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3270: train_loss=9.680030822753906
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3271: train_loss=9.685193061828613
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3272: train_loss=9.678114891052246
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3273: train_loss=9.685786247253418
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3274: train_loss=9.682588577270508
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3275: train_loss=9.684623718261719
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3276: train_loss=9.681045532226562
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3277: train_loss=9.687453269958496
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3278: train_loss=9.68755054473877
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3279: train_loss=9.682823181152344
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3280: train_loss=9.683954238891602
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3281: train_loss=9.686371803283691
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3282: train_loss=9.687849998474121
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3283: train_loss=9.703619956970215
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3284: train_loss=9.695979118347168
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3285: train_loss=9.691235542297363
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3286: train_loss=9.694228172302246
INFO - 04/15/25 16:34:15 - 0:02:38 - Epoch 3287: train_loss=9.69320011138916
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3288: train_loss=9.692851066589355
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3289: train_loss=9.689030647277832
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3290: train_loss=9.695043563842773
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3291: train_loss=9.687609672546387
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3292: train_loss=9.688157081604004
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3293: train_loss=9.688309669494629
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3294: train_loss=9.685053825378418
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3295: train_loss=9.685949325561523
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3296: train_loss=9.684762001037598
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3297: train_loss=9.684038162231445
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3298: train_loss=9.683883666992188
INFO - 04/15/25 16:34:15 - 0:02:39 - Epoch 3299: train_loss=9.682828903198242
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3300: train_loss=9.686310768127441
INFO - 04/15/25 16:34:16 - 0:02:39 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:16 - 0:02:39 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3300: ACC: 0.0, NMI: 0.0893416290800326, F1: 0.0, ARI: 0.0036679866204526275
INFO - 04/15/25 16:34:16 - 0:02:39 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3301: train_loss=9.683835983276367
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3302: train_loss=9.683500289916992
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3303: train_loss=9.680156707763672
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3304: train_loss=9.680416107177734
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3305: train_loss=9.678030014038086
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3306: train_loss=9.675446510314941
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3307: train_loss=9.674565315246582
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3308: train_loss=9.675070762634277
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3309: train_loss=9.677353858947754
INFO - 04/15/25 16:34:16 - 0:02:39 - Epoch 3310: train_loss=9.67226791381836
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3311: train_loss=9.672759056091309
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3312: train_loss=9.673857688903809
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3313: train_loss=9.670784950256348
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3314: train_loss=9.669700622558594
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3315: train_loss=9.671833038330078
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3316: train_loss=9.67519474029541
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3317: train_loss=9.670860290527344
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3318: train_loss=9.668200492858887
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3319: train_loss=9.670114517211914
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3320: train_loss=9.66279125213623
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3321: train_loss=9.649526596069336
INFO - 04/15/25 16:34:16 - 0:02:40 - Epoch 3322: train_loss=9.636202812194824
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3323: train_loss=9.638693809509277
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3324: train_loss=9.643945693969727
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3325: train_loss=9.648946762084961
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3326: train_loss=9.654516220092773
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3327: train_loss=9.656004905700684
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3328: train_loss=9.64913558959961
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3329: train_loss=9.636661529541016
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3330: train_loss=9.647074699401855
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3331: train_loss=9.656185150146484
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3332: train_loss=9.65128231048584
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3333: train_loss=9.640583038330078
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3334: train_loss=9.644986152648926
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3335: train_loss=9.651469230651855
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3336: train_loss=9.647343635559082
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3337: train_loss=9.637469291687012
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3338: train_loss=9.644837379455566
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3339: train_loss=9.64387321472168
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3340: train_loss=9.637934684753418
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3341: train_loss=9.639371871948242
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3342: train_loss=9.645760536193848
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3343: train_loss=9.629822731018066
INFO - 04/15/25 16:34:17 - 0:02:40 - Epoch 3344: train_loss=9.633193969726562
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3345: train_loss=9.639718055725098
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3346: train_loss=9.64008617401123
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3347: train_loss=9.63624095916748
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3348: train_loss=9.630444526672363
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3349: train_loss=9.631630897521973
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3350: train_loss=9.633458137512207
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3351: train_loss=9.632347106933594
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3352: train_loss=9.64294719696045
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3353: train_loss=9.640607833862305
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3354: train_loss=9.635374069213867
INFO - 04/15/25 16:34:17 - 0:02:41 - Epoch 3355: train_loss=9.636577606201172
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3356: train_loss=9.63764762878418
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3357: train_loss=9.635007858276367
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3358: train_loss=9.632729530334473
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3359: train_loss=9.632707595825195
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3360: train_loss=9.630363464355469
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3361: train_loss=9.630753517150879
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3362: train_loss=9.626631736755371
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3363: train_loss=9.630331993103027
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3364: train_loss=9.634892463684082
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3365: train_loss=9.63169002532959
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3366: train_loss=9.627333641052246
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3367: train_loss=9.623753547668457
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3368: train_loss=9.628865242004395
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3369: train_loss=9.626970291137695
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3370: train_loss=9.623130798339844
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3371: train_loss=9.623245239257812
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3372: train_loss=9.622940063476562
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3373: train_loss=9.621040344238281
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3374: train_loss=9.620532035827637
INFO - 04/15/25 16:34:18 - 0:02:41 - Epoch 3375: train_loss=9.622233390808105
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3376: train_loss=9.619868278503418
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3377: train_loss=9.619758605957031
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3378: train_loss=9.617091178894043
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3379: train_loss=9.618781089782715
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3380: train_loss=9.635812759399414
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3381: train_loss=9.649442672729492
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3382: train_loss=9.640117645263672
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3383: train_loss=9.635009765625
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3384: train_loss=9.62559700012207
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3385: train_loss=9.633371353149414
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3386: train_loss=9.635149002075195
INFO - 04/15/25 16:34:18 - 0:02:42 - Epoch 3387: train_loss=9.631418228149414
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3388: train_loss=9.629923820495605
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3389: train_loss=9.62720775604248
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3390: train_loss=9.634111404418945
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3391: train_loss=9.625418663024902
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3392: train_loss=9.63526439666748
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3393: train_loss=9.626764297485352
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3394: train_loss=9.634490013122559
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3395: train_loss=9.635147094726562
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3396: train_loss=9.626153945922852
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3397: train_loss=9.62868881225586
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3398: train_loss=9.632594108581543
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3399: train_loss=9.627150535583496
INFO - 04/15/25 16:34:19 - 0:02:42 - Epoch 3400: train_loss=9.629721641540527
INFO - 04/15/25 16:34:19 - 0:02:42 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:19 - 0:02:42 - Decoding cost time:  0.133 s
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3400: ACC: 0.0, NMI: 0.12952247973029016, F1: 0.0, ARI: 0.018133040974654104
INFO - 04/15/25 16:34:19 - 0:02:43 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3401: train_loss=9.629857063293457
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3402: train_loss=9.624760627746582
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3403: train_loss=9.62774658203125
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3404: train_loss=9.623851776123047
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3405: train_loss=9.625565528869629
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3406: train_loss=9.625828742980957
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3407: train_loss=9.622637748718262
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3408: train_loss=9.62435531616211
INFO - 04/15/25 16:34:19 - 0:02:43 - Epoch 3409: train_loss=9.622435569763184
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3410: train_loss=9.620920181274414
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3411: train_loss=9.621088027954102
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3412: train_loss=9.619532585144043
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3413: train_loss=9.61927318572998
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3414: train_loss=9.617362022399902
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3415: train_loss=9.616928100585938
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3416: train_loss=9.614137649536133
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3417: train_loss=9.61690616607666
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3418: train_loss=9.614590644836426
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3419: train_loss=9.613553047180176
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3420: train_loss=9.613641738891602
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3421: train_loss=9.610492706298828
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3422: train_loss=9.615669250488281
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3423: train_loss=9.61323356628418
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3424: train_loss=9.612403869628906
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3425: train_loss=9.611579895019531
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3426: train_loss=9.61147689819336
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3427: train_loss=9.608803749084473
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3428: train_loss=9.612726211547852
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3429: train_loss=9.609148979187012
INFO - 04/15/25 16:34:20 - 0:02:43 - Epoch 3430: train_loss=9.614238739013672
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3431: train_loss=9.613964080810547
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3432: train_loss=9.60936164855957
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3433: train_loss=9.610466003417969
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3434: train_loss=9.608765602111816
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3435: train_loss=9.609004020690918
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3436: train_loss=9.601984977722168
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3437: train_loss=9.609622955322266
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3438: train_loss=9.616924285888672
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3439: train_loss=9.616830825805664
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3440: train_loss=9.603507041931152
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3441: train_loss=9.594653129577637
INFO - 04/15/25 16:34:20 - 0:02:44 - Epoch 3442: train_loss=9.591821670532227
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3443: train_loss=9.578490257263184
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3444: train_loss=9.585579872131348
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3445: train_loss=9.574173927307129
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3446: train_loss=9.575479507446289
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3447: train_loss=9.574934005737305
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3448: train_loss=9.573415756225586
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3449: train_loss=9.57082462310791
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3450: train_loss=9.568859100341797
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3451: train_loss=9.57446575164795
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3452: train_loss=9.568909645080566
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3453: train_loss=9.576019287109375
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3454: train_loss=9.572906494140625
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3455: train_loss=9.570480346679688
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3456: train_loss=9.570268630981445
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3457: train_loss=9.57237720489502
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3458: train_loss=9.568815231323242
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3459: train_loss=9.569889068603516
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3460: train_loss=9.567272186279297
INFO - 04/15/25 16:34:21 - 0:02:44 - Epoch 3461: train_loss=9.568662643432617
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3462: train_loss=9.566869735717773
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3463: train_loss=9.566558837890625
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3464: train_loss=9.564977645874023
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3465: train_loss=9.566040992736816
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3466: train_loss=9.563690185546875
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3467: train_loss=9.566317558288574
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3468: train_loss=9.565003395080566
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3469: train_loss=9.564312934875488
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3470: train_loss=9.56273365020752
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3471: train_loss=9.565399169921875
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3472: train_loss=9.563924789428711
INFO - 04/15/25 16:34:21 - 0:02:45 - Epoch 3473: train_loss=9.563318252563477
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3474: train_loss=9.562690734863281
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3475: train_loss=9.562583923339844
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3476: train_loss=9.561272621154785
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3477: train_loss=9.56277084350586
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3478: train_loss=9.560860633850098
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3479: train_loss=9.555061340332031
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3480: train_loss=9.563693046569824
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3481: train_loss=9.559316635131836
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3482: train_loss=9.558793067932129
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3483: train_loss=9.562250137329102
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3484: train_loss=9.559090614318848
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3485: train_loss=9.566081047058105
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3486: train_loss=9.566997528076172
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3487: train_loss=9.55730152130127
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3488: train_loss=9.564140319824219
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3489: train_loss=9.533326148986816
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3490: train_loss=9.529043197631836
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3491: train_loss=9.547390937805176
INFO - 04/15/25 16:34:22 - 0:02:45 - Epoch 3492: train_loss=9.545010566711426
INFO - 04/15/25 16:34:22 - 0:02:46 - Epoch 3493: train_loss=9.542499542236328
INFO - 04/15/25 16:34:22 - 0:02:46 - Epoch 3494: train_loss=9.528549194335938
INFO - 04/15/25 16:34:22 - 0:02:46 - Epoch 3495: train_loss=9.522051811218262
INFO - 04/15/25 16:34:22 - 0:02:46 - Epoch 3496: train_loss=9.505716323852539
INFO - 04/15/25 16:34:22 - 0:02:46 - Epoch 3497: train_loss=9.50365924835205
INFO - 04/15/25 16:34:22 - 0:02:46 - Epoch 3498: train_loss=9.497908592224121
INFO - 04/15/25 16:34:22 - 0:02:46 - Epoch 3499: train_loss=9.495660781860352
INFO - 04/15/25 16:34:22 - 0:02:46 - Epoch 3500: train_loss=9.492830276489258
INFO - 04/15/25 16:34:22 - 0:02:46 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:22 - 0:02:46 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3500: ACC: 0.0, NMI: 0.163301051691413, F1: 0.0, ARI: 0.012615228783132731
INFO - 04/15/25 16:34:23 - 0:02:46 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3501: train_loss=9.502031326293945
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3502: train_loss=9.491546630859375
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3503: train_loss=9.499134063720703
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3504: train_loss=9.497184753417969
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3505: train_loss=9.507216453552246
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3506: train_loss=9.497692108154297
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3507: train_loss=9.505295753479004
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3508: train_loss=9.509024620056152
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3509: train_loss=9.521531105041504
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3510: train_loss=9.518177032470703
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3511: train_loss=9.51127815246582
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3512: train_loss=9.49945068359375
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3513: train_loss=9.51246452331543
INFO - 04/15/25 16:34:23 - 0:02:46 - Epoch 3514: train_loss=9.538738250732422
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3515: train_loss=9.604527473449707
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3516: train_loss=9.64535903930664
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3517: train_loss=9.65888786315918
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3518: train_loss=9.561445236206055
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3519: train_loss=9.54045295715332
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3520: train_loss=9.522340774536133
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3521: train_loss=9.5430908203125
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3522: train_loss=9.556100845336914
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3523: train_loss=9.546073913574219
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3524: train_loss=9.538481712341309
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3525: train_loss=9.530000686645508
INFO - 04/15/25 16:34:23 - 0:02:47 - Epoch 3526: train_loss=9.525062561035156
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3527: train_loss=9.5189790725708
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3528: train_loss=9.517717361450195
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3529: train_loss=9.51605224609375
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3530: train_loss=9.511613845825195
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3531: train_loss=9.509215354919434
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3532: train_loss=9.511112213134766
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3533: train_loss=9.502111434936523
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3534: train_loss=9.49907398223877
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3535: train_loss=9.499364852905273
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3536: train_loss=9.494063377380371
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3537: train_loss=9.498692512512207
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3538: train_loss=9.498025894165039
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3539: train_loss=9.494684219360352
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3540: train_loss=9.49238109588623
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3541: train_loss=9.492467880249023
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3542: train_loss=9.48886489868164
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3543: train_loss=9.4808349609375
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3544: train_loss=9.473710060119629
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3545: train_loss=9.47822093963623
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3546: train_loss=9.47213363647461
INFO - 04/15/25 16:34:24 - 0:02:47 - Epoch 3547: train_loss=9.468292236328125
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3548: train_loss=9.46462345123291
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3549: train_loss=9.465643882751465
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3550: train_loss=9.45898723602295
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3551: train_loss=9.457524299621582
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3552: train_loss=9.459304809570312
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3553: train_loss=9.459918975830078
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3554: train_loss=9.457354545593262
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3555: train_loss=9.454292297363281
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3556: train_loss=9.459157943725586
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3557: train_loss=9.45549201965332
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3558: train_loss=9.454153060913086
INFO - 04/15/25 16:34:24 - 0:02:48 - Epoch 3559: train_loss=9.452189445495605
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3560: train_loss=9.448264122009277
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3561: train_loss=9.451765060424805
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3562: train_loss=9.453393936157227
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3563: train_loss=9.450324058532715
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3564: train_loss=9.448100090026855
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3565: train_loss=9.449004173278809
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3566: train_loss=9.445267677307129
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3567: train_loss=9.446535110473633
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3568: train_loss=9.44330883026123
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3569: train_loss=9.447049140930176
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3570: train_loss=9.446441650390625
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3571: train_loss=9.439122200012207
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3572: train_loss=9.442342758178711
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3573: train_loss=9.440247535705566
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3574: train_loss=9.437433242797852
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3575: train_loss=9.43698501586914
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3576: train_loss=9.434233665466309
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3577: train_loss=9.434737205505371
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3578: train_loss=9.435632705688477
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3579: train_loss=9.434139251708984
INFO - 04/15/25 16:34:25 - 0:02:48 - Epoch 3580: train_loss=9.435354232788086
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3581: train_loss=9.434981346130371
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3582: train_loss=9.43375015258789
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3583: train_loss=9.434579849243164
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3584: train_loss=9.430879592895508
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3585: train_loss=9.433618545532227
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3586: train_loss=9.432047843933105
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3587: train_loss=9.429842948913574
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3588: train_loss=9.428911209106445
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3589: train_loss=9.429222106933594
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3590: train_loss=9.426201820373535
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3591: train_loss=9.429986953735352
INFO - 04/15/25 16:34:25 - 0:02:49 - Epoch 3592: train_loss=9.42851734161377
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3593: train_loss=9.427669525146484
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3594: train_loss=9.42723274230957
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3595: train_loss=9.42292308807373
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3596: train_loss=9.429276466369629
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3597: train_loss=9.426813125610352
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3598: train_loss=9.424751281738281
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3599: train_loss=9.424501419067383
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3600: train_loss=9.425292015075684
INFO - 04/15/25 16:34:26 - 0:02:49 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:26 - 0:02:49 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3600: ACC: 0.0, NMI: 0.17143064377517594, F1: 0.0, ARI: 0.014540209754476546
INFO - 04/15/25 16:34:26 - 0:02:49 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3601: train_loss=9.4232816696167
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3602: train_loss=9.424556732177734
INFO - 04/15/25 16:34:26 - 0:02:49 - Epoch 3603: train_loss=9.422637939453125
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3604: train_loss=9.42369270324707
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3605: train_loss=9.424032211303711
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3606: train_loss=9.423850059509277
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3607: train_loss=9.422375679016113
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3608: train_loss=9.428682327270508
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3609: train_loss=9.423774719238281
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3610: train_loss=9.421513557434082
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3611: train_loss=9.420005798339844
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3612: train_loss=9.42386245727539
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3613: train_loss=9.419601440429688
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3614: train_loss=9.421321868896484
INFO - 04/15/25 16:34:26 - 0:02:50 - Epoch 3615: train_loss=9.418705940246582
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3616: train_loss=9.421066284179688
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3617: train_loss=9.417985916137695
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3618: train_loss=9.416682243347168
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3619: train_loss=9.418939590454102
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3620: train_loss=9.417086601257324
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3621: train_loss=9.41533088684082
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3622: train_loss=9.41724681854248
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3623: train_loss=9.415265083312988
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3624: train_loss=9.415711402893066
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3625: train_loss=9.412599563598633
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3626: train_loss=9.424725532531738
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3627: train_loss=9.418194770812988
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3628: train_loss=9.41979694366455
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3629: train_loss=9.418456077575684
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3630: train_loss=9.416106224060059
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3631: train_loss=9.411641120910645
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3632: train_loss=9.414413452148438
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3633: train_loss=9.412236213684082
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3634: train_loss=9.415837287902832
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3635: train_loss=9.413633346557617
INFO - 04/15/25 16:34:27 - 0:02:50 - Epoch 3636: train_loss=9.410818099975586
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3637: train_loss=9.418416023254395
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3638: train_loss=9.417458534240723
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3639: train_loss=9.412281036376953
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3640: train_loss=9.41057014465332
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3641: train_loss=9.410184860229492
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3642: train_loss=9.408653259277344
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3643: train_loss=9.405291557312012
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3644: train_loss=9.413427352905273
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3645: train_loss=9.412976264953613
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3646: train_loss=9.412254333496094
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3647: train_loss=9.419236183166504
INFO - 04/15/25 16:34:27 - 0:02:51 - Epoch 3648: train_loss=9.421375274658203
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3649: train_loss=9.413459777832031
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3650: train_loss=9.41303539276123
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3651: train_loss=9.414589881896973
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3652: train_loss=9.415581703186035
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3653: train_loss=9.412140846252441
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3654: train_loss=9.411171913146973
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3655: train_loss=9.414241790771484
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3656: train_loss=9.411065101623535
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3657: train_loss=9.41401195526123
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3658: train_loss=9.41252613067627
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3659: train_loss=9.412317276000977
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3660: train_loss=9.409268379211426
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3661: train_loss=9.413288116455078
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3662: train_loss=9.41471004486084
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3663: train_loss=9.414957046508789
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3664: train_loss=9.433835983276367
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3665: train_loss=9.426192283630371
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3666: train_loss=9.429004669189453
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3667: train_loss=9.40953540802002
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3668: train_loss=9.399964332580566
INFO - 04/15/25 16:34:28 - 0:02:51 - Epoch 3669: train_loss=9.421157836914062
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3670: train_loss=9.41828727722168
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3671: train_loss=9.433497428894043
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3672: train_loss=9.449000358581543
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3673: train_loss=9.426218032836914
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3674: train_loss=9.441055297851562
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3675: train_loss=9.439620018005371
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3676: train_loss=9.434158325195312
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3677: train_loss=9.4228515625
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3678: train_loss=9.434019088745117
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3679: train_loss=9.454663276672363
INFO - 04/15/25 16:34:28 - 0:02:52 - Epoch 3680: train_loss=9.440045356750488
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3681: train_loss=9.440903663635254
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3682: train_loss=9.435481071472168
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3683: train_loss=9.440879821777344
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3684: train_loss=9.435428619384766
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3685: train_loss=9.434618949890137
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3686: train_loss=9.435096740722656
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3687: train_loss=9.432107925415039
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3688: train_loss=9.417000770568848
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3689: train_loss=9.4244384765625
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3690: train_loss=9.420063972473145
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3691: train_loss=9.4110746383667
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3692: train_loss=9.412550926208496
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3693: train_loss=9.410571098327637
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3694: train_loss=9.403926849365234
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3695: train_loss=9.40229320526123
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3696: train_loss=9.389345169067383
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3697: train_loss=9.38631534576416
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3698: train_loss=9.381697654724121
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3699: train_loss=9.377152442932129
INFO - 04/15/25 16:34:29 - 0:02:52 - Epoch 3700: train_loss=9.370979309082031
INFO - 04/15/25 16:34:29 - 0:02:52 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:29 - 0:02:53 - Decoding cost time:  0.252 s
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3700: ACC: 0.0, NMI: 0.18732445248446652, F1: 0.0, ARI: 0.023410347309651615
INFO - 04/15/25 16:34:30 - 0:02:53 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3701: train_loss=9.387910842895508
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3702: train_loss=9.353778839111328
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3703: train_loss=9.37347412109375
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3704: train_loss=9.355306625366211
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3705: train_loss=9.368165016174316
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3706: train_loss=9.369444847106934
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3707: train_loss=9.363823890686035
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3708: train_loss=9.367225646972656
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3709: train_loss=9.363454818725586
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3710: train_loss=9.373563766479492
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3711: train_loss=9.359130859375
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3712: train_loss=9.356178283691406
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3713: train_loss=9.356221199035645
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3714: train_loss=9.358245849609375
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3715: train_loss=9.350922584533691
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3716: train_loss=9.358612060546875
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3717: train_loss=9.332921981811523
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3718: train_loss=9.330206871032715
INFO - 04/15/25 16:34:30 - 0:02:53 - Epoch 3719: train_loss=9.330134391784668
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3720: train_loss=9.32785701751709
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3721: train_loss=9.334854125976562
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3722: train_loss=9.32758903503418
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3723: train_loss=9.328597068786621
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3724: train_loss=9.322521209716797
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3725: train_loss=9.328384399414062
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3726: train_loss=9.315666198730469
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3727: train_loss=9.329133033752441
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3728: train_loss=9.321476936340332
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3729: train_loss=9.316314697265625
INFO - 04/15/25 16:34:30 - 0:02:54 - Epoch 3730: train_loss=9.320323944091797
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3731: train_loss=9.32543659210205
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3732: train_loss=9.318344116210938
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3733: train_loss=9.32317066192627
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3734: train_loss=9.321524620056152
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3735: train_loss=9.322781562805176
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3736: train_loss=9.320569038391113
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3737: train_loss=9.319966316223145
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3738: train_loss=9.31662654876709
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3739: train_loss=9.32241439819336
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3740: train_loss=9.317241668701172
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3741: train_loss=9.319343566894531
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3742: train_loss=9.317183494567871
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3743: train_loss=9.318990707397461
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3744: train_loss=9.31633186340332
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3745: train_loss=9.315671920776367
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3746: train_loss=9.313352584838867
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3747: train_loss=9.307748794555664
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3748: train_loss=9.315372467041016
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3749: train_loss=9.307435989379883
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3750: train_loss=9.30451774597168
INFO - 04/15/25 16:34:31 - 0:02:54 - Epoch 3751: train_loss=9.309621810913086
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3752: train_loss=9.308773040771484
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3753: train_loss=9.312416076660156
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3754: train_loss=9.311159133911133
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3755: train_loss=9.314603805541992
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3756: train_loss=9.299015998840332
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3757: train_loss=9.312530517578125
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3758: train_loss=9.311483383178711
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3759: train_loss=9.320479393005371
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3760: train_loss=9.314014434814453
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3761: train_loss=9.321818351745605
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3762: train_loss=9.31581974029541
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3763: train_loss=9.306051254272461
INFO - 04/15/25 16:34:31 - 0:02:55 - Epoch 3764: train_loss=9.316365242004395
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3765: train_loss=9.309021949768066
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3766: train_loss=9.307280540466309
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3767: train_loss=9.309152603149414
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3768: train_loss=9.311910629272461
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3769: train_loss=9.309821128845215
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3770: train_loss=9.315442085266113
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3771: train_loss=9.295293807983398
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3772: train_loss=9.29734992980957
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3773: train_loss=9.30173397064209
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3774: train_loss=9.290180206298828
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3775: train_loss=9.264751434326172
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3776: train_loss=9.26335334777832
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3777: train_loss=9.260705947875977
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3778: train_loss=9.259988784790039
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3779: train_loss=9.257343292236328
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3780: train_loss=9.259835243225098
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3781: train_loss=9.2522554397583
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3782: train_loss=9.254627227783203
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3783: train_loss=9.256569862365723
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3784: train_loss=9.253538131713867
INFO - 04/15/25 16:34:32 - 0:02:55 - Epoch 3785: train_loss=9.252784729003906
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3786: train_loss=9.221735000610352
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3787: train_loss=9.231327056884766
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3788: train_loss=9.204089164733887
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3789: train_loss=9.198145866394043
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3790: train_loss=9.204864501953125
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3791: train_loss=9.198262214660645
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3792: train_loss=9.18993854522705
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3793: train_loss=9.19372844696045
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3794: train_loss=9.190255165100098
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3795: train_loss=9.20201301574707
INFO - 04/15/25 16:34:32 - 0:02:56 - Epoch 3796: train_loss=9.187756538391113
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3797: train_loss=9.197908401489258
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3798: train_loss=9.201602935791016
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3799: train_loss=9.20125675201416
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3800: train_loss=9.193685531616211
INFO - 04/15/25 16:34:33 - 0:02:56 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:33 - 0:02:56 - Decoding cost time:  0.131 s
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3800: ACC: 0.0, NMI: 0.24238665681472843, F1: 0.0, ARI: 0.06713250140941217
INFO - 04/15/25 16:34:33 - 0:02:56 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3801: train_loss=9.194900512695312
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3802: train_loss=9.19118595123291
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3803: train_loss=9.184378623962402
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3804: train_loss=9.189815521240234
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3805: train_loss=9.195722579956055
INFO - 04/15/25 16:34:33 - 0:02:56 - Epoch 3806: train_loss=9.190962791442871
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3807: train_loss=9.196268081665039
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3808: train_loss=9.194825172424316
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3809: train_loss=9.186859130859375
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3810: train_loss=9.18671989440918
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3811: train_loss=9.188004493713379
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3812: train_loss=9.180590629577637
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3813: train_loss=9.188325881958008
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3814: train_loss=9.187506675720215
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3815: train_loss=9.182526588439941
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3816: train_loss=9.182226181030273
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3817: train_loss=9.182117462158203
INFO - 04/15/25 16:34:33 - 0:02:57 - Epoch 3818: train_loss=9.178601264953613
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3819: train_loss=9.177326202392578
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3820: train_loss=9.180749893188477
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3821: train_loss=9.188862800598145
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3822: train_loss=9.179962158203125
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3823: train_loss=9.178752899169922
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3824: train_loss=9.174275398254395
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3825: train_loss=9.181756973266602
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3826: train_loss=9.174606323242188
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3827: train_loss=9.174371719360352
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3828: train_loss=9.168582916259766
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3829: train_loss=9.170271873474121
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3830: train_loss=9.172714233398438
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3831: train_loss=9.174823760986328
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3832: train_loss=9.172685623168945
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3833: train_loss=9.169660568237305
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3834: train_loss=9.173486709594727
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3835: train_loss=9.176668167114258
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3836: train_loss=9.173977851867676
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3837: train_loss=9.178380966186523
INFO - 04/15/25 16:34:34 - 0:02:57 - Epoch 3838: train_loss=9.17151165008545
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3839: train_loss=9.173073768615723
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3840: train_loss=9.172595024108887
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3841: train_loss=9.164298057556152
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3842: train_loss=9.174302101135254
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3843: train_loss=9.166409492492676
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3844: train_loss=9.175662994384766
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3845: train_loss=9.17652416229248
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3846: train_loss=9.178325653076172
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3847: train_loss=9.178146362304688
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3848: train_loss=9.173823356628418
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3849: train_loss=9.194952964782715
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3850: train_loss=9.175973892211914
INFO - 04/15/25 16:34:34 - 0:02:58 - Epoch 3851: train_loss=9.174684524536133
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3852: train_loss=9.178935050964355
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3853: train_loss=9.17111587524414
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3854: train_loss=9.178919792175293
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3855: train_loss=9.18646240234375
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3856: train_loss=9.18462085723877
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3857: train_loss=9.175639152526855
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3858: train_loss=9.183138847351074
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3859: train_loss=9.1757230758667
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3860: train_loss=9.180293083190918
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3861: train_loss=9.186308860778809
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3862: train_loss=9.175475120544434
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3863: train_loss=9.168021202087402
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3864: train_loss=9.155372619628906
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3865: train_loss=9.162883758544922
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3866: train_loss=9.177801132202148
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3867: train_loss=9.142370223999023
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3868: train_loss=9.128411293029785
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3869: train_loss=9.131678581237793
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3870: train_loss=9.12132453918457
INFO - 04/15/25 16:34:35 - 0:02:58 - Epoch 3871: train_loss=9.129894256591797
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3872: train_loss=9.118654251098633
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3873: train_loss=9.131928443908691
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3874: train_loss=9.13221549987793
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3875: train_loss=9.125696182250977
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3876: train_loss=9.137044906616211
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3877: train_loss=9.128615379333496
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3878: train_loss=9.119837760925293
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3879: train_loss=9.132984161376953
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3880: train_loss=9.151849746704102
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3881: train_loss=9.131282806396484
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3882: train_loss=9.136941909790039
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3883: train_loss=9.140424728393555
INFO - 04/15/25 16:34:35 - 0:02:59 - Epoch 3884: train_loss=9.14048957824707
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3885: train_loss=9.133347511291504
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3886: train_loss=9.124250411987305
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3887: train_loss=9.149431228637695
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3888: train_loss=9.148863792419434
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3889: train_loss=9.150371551513672
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3890: train_loss=9.143059730529785
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3891: train_loss=9.16459846496582
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3892: train_loss=9.144828796386719
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3893: train_loss=9.147539138793945
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3894: train_loss=9.144436836242676
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3895: train_loss=9.146315574645996
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3896: train_loss=9.151217460632324
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3897: train_loss=9.147765159606934
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3898: train_loss=9.142436981201172
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3899: train_loss=9.169073104858398
INFO - 04/15/25 16:34:36 - 0:02:59 - Epoch 3900: train_loss=9.177788734436035
INFO - 04/15/25 16:34:36 - 0:02:59 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:36 - 0:02:59 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:34:36 - 0:03:00 - Epoch 3900: ACC: 0.0, NMI: 0.1881973444521369, F1: 0.0, ARI: 0.07453364709966817
INFO - 04/15/25 16:34:36 - 0:03:00 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:36 - 0:03:00 - Epoch 3901: train_loss=9.222067832946777
INFO - 04/15/25 16:34:36 - 0:03:00 - Epoch 3902: train_loss=9.193523406982422
INFO - 04/15/25 16:34:36 - 0:03:00 - Epoch 3903: train_loss=9.185480117797852
INFO - 04/15/25 16:34:36 - 0:03:00 - Epoch 3904: train_loss=9.193120956420898
INFO - 04/15/25 16:34:36 - 0:03:00 - Epoch 3905: train_loss=9.200392723083496
INFO - 04/15/25 16:34:36 - 0:03:00 - Epoch 3906: train_loss=9.194804191589355
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3907: train_loss=9.174589157104492
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3908: train_loss=9.205192565917969
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3909: train_loss=9.201091766357422
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3910: train_loss=9.225260734558105
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3911: train_loss=9.201835632324219
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3912: train_loss=9.19800090789795
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3913: train_loss=9.224788665771484
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3914: train_loss=9.181142807006836
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3915: train_loss=9.212772369384766
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3916: train_loss=9.196409225463867
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3917: train_loss=9.225101470947266
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3918: train_loss=9.204071998596191
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3919: train_loss=9.218179702758789
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3920: train_loss=9.238460540771484
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3921: train_loss=9.233942031860352
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3922: train_loss=9.242491722106934
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3923: train_loss=9.253314971923828
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3924: train_loss=9.316438674926758
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3925: train_loss=9.270048141479492
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3926: train_loss=9.24592399597168
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3927: train_loss=9.278510093688965
INFO - 04/15/25 16:34:37 - 0:03:00 - Epoch 3928: train_loss=9.268186569213867
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3929: train_loss=9.248770713806152
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3930: train_loss=9.238595962524414
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3931: train_loss=9.255351066589355
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3932: train_loss=9.263442039489746
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3933: train_loss=9.227392196655273
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3934: train_loss=9.242772102355957
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3935: train_loss=9.219229698181152
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3936: train_loss=9.232231140136719
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3937: train_loss=9.202805519104004
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3938: train_loss=9.17625617980957
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3939: train_loss=9.141700744628906
INFO - 04/15/25 16:34:37 - 0:03:01 - Epoch 3940: train_loss=9.110259056091309
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3941: train_loss=9.125524520874023
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3942: train_loss=9.108993530273438
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3943: train_loss=9.061299324035645
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3944: train_loss=9.053378105163574
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3945: train_loss=9.032490730285645
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3946: train_loss=9.003880500793457
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3947: train_loss=8.994913101196289
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3948: train_loss=8.990999221801758
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3949: train_loss=9.011383056640625
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3950: train_loss=8.960617065429688
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3951: train_loss=8.987495422363281
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3952: train_loss=8.976357460021973
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3953: train_loss=8.97638988494873
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3954: train_loss=8.938087463378906
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3955: train_loss=8.937093734741211
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3956: train_loss=8.921428680419922
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3957: train_loss=8.946743965148926
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3958: train_loss=8.953137397766113
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3959: train_loss=8.962518692016602
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3960: train_loss=8.930269241333008
INFO - 04/15/25 16:34:38 - 0:03:01 - Epoch 3961: train_loss=8.897262573242188
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3962: train_loss=8.907883644104004
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3963: train_loss=8.904671669006348
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3964: train_loss=8.90007495880127
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3965: train_loss=8.917945861816406
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3966: train_loss=8.912454605102539
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3967: train_loss=8.90092945098877
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3968: train_loss=8.903234481811523
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3969: train_loss=8.893383979797363
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3970: train_loss=8.901168823242188
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3971: train_loss=8.916329383850098
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3972: train_loss=8.964158058166504
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3973: train_loss=8.940688133239746
INFO - 04/15/25 16:34:38 - 0:03:02 - Epoch 3974: train_loss=8.91413402557373
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3975: train_loss=8.888815879821777
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3976: train_loss=8.885601043701172
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3977: train_loss=8.885763168334961
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3978: train_loss=8.895556449890137
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3979: train_loss=8.929924011230469
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3980: train_loss=8.887627601623535
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3981: train_loss=8.849684715270996
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3982: train_loss=8.860081672668457
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3983: train_loss=8.862854957580566
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3984: train_loss=8.870165824890137
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3985: train_loss=8.895219802856445
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3986: train_loss=8.881217002868652
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3987: train_loss=8.899765014648438
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3988: train_loss=8.86138916015625
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3989: train_loss=8.870010375976562
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3990: train_loss=8.84921646118164
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3991: train_loss=8.85092544555664
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3992: train_loss=8.852093696594238
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3993: train_loss=8.866300582885742
INFO - 04/15/25 16:34:39 - 0:03:02 - Epoch 3994: train_loss=8.848761558532715
INFO - 04/15/25 16:34:39 - 0:03:03 - Epoch 3995: train_loss=8.847746849060059
INFO - 04/15/25 16:34:39 - 0:03:03 - Epoch 3996: train_loss=8.856148719787598
INFO - 04/15/25 16:34:39 - 0:03:03 - Epoch 3997: train_loss=8.855011940002441
INFO - 04/15/25 16:34:39 - 0:03:03 - Epoch 3998: train_loss=8.864375114440918
INFO - 04/15/25 16:34:39 - 0:03:03 - Epoch 3999: train_loss=8.859682083129883
INFO - 04/15/25 16:34:39 - 0:03:03 - Epoch 4000: train_loss=8.843064308166504
INFO - 04/15/25 16:34:39 - 0:03:03 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:39 - 0:03:03 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4000: ACC: 0.0, NMI: 0.314329065998441, F1: 0.0, ARI: 0.16230832555376856
INFO - 04/15/25 16:34:40 - 0:03:03 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4001: train_loss=8.844536781311035
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4002: train_loss=8.859512329101562
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4003: train_loss=8.853614807128906
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4004: train_loss=8.831072807312012
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4005: train_loss=8.829649925231934
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4006: train_loss=8.81242847442627
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4007: train_loss=8.836433410644531
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4008: train_loss=8.840721130371094
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4009: train_loss=8.814542770385742
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4010: train_loss=8.794763565063477
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4011: train_loss=8.816967964172363
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4012: train_loss=8.79651927947998
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4013: train_loss=8.779980659484863
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4014: train_loss=8.78503131866455
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4015: train_loss=8.77441120147705
INFO - 04/15/25 16:34:40 - 0:03:03 - Epoch 4016: train_loss=8.797306060791016
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4017: train_loss=8.778656959533691
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4018: train_loss=8.777043342590332
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4019: train_loss=8.813380241394043
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4020: train_loss=8.781038284301758
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4021: train_loss=8.816882133483887
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4022: train_loss=8.795178413391113
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4023: train_loss=8.935766220092773
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4024: train_loss=8.997235298156738
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4025: train_loss=8.99989128112793
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4026: train_loss=9.001948356628418
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4027: train_loss=8.98498249053955
INFO - 04/15/25 16:34:40 - 0:03:04 - Epoch 4028: train_loss=8.950403213500977
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4029: train_loss=8.927599906921387
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4030: train_loss=8.896428108215332
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4031: train_loss=8.952398300170898
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4032: train_loss=8.88715648651123
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4033: train_loss=8.876031875610352
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4034: train_loss=8.85727310180664
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4035: train_loss=8.851122856140137
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4036: train_loss=8.868889808654785
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4037: train_loss=8.859904289245605
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4038: train_loss=8.86862564086914
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4039: train_loss=8.892470359802246
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4040: train_loss=8.861170768737793
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4041: train_loss=8.83277416229248
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4042: train_loss=8.825352668762207
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4043: train_loss=8.817867279052734
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4044: train_loss=8.808645248413086
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4045: train_loss=8.798105239868164
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4046: train_loss=8.810832977294922
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4047: train_loss=8.807611465454102
INFO - 04/15/25 16:34:41 - 0:03:04 - Epoch 4048: train_loss=8.812122344970703
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4049: train_loss=8.807523727416992
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4050: train_loss=8.849079132080078
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4051: train_loss=8.7791109085083
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4052: train_loss=8.785168647766113
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4053: train_loss=8.819244384765625
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4054: train_loss=8.83337116241455
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4055: train_loss=8.815099716186523
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4056: train_loss=8.7816162109375
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4057: train_loss=8.778637886047363
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4058: train_loss=8.766592025756836
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4059: train_loss=8.767756462097168
INFO - 04/15/25 16:34:41 - 0:03:05 - Epoch 4060: train_loss=8.761486053466797
INFO - 04/15/25 16:34:42 - 0:03:05 - Epoch 4061: train_loss=8.788966178894043
INFO - 04/15/25 16:34:42 - 0:03:05 - Epoch 4062: train_loss=8.760886192321777
INFO - 04/15/25 16:34:42 - 0:03:05 - Epoch 4063: train_loss=8.763284683227539
INFO - 04/15/25 16:34:44 - 0:03:05 - Epoch 4064: train_loss=8.753329277038574
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4065: train_loss=8.799806594848633
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4066: train_loss=8.755661964416504
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4067: train_loss=8.7479829788208
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4068: train_loss=8.758223533630371
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4069: train_loss=8.738505363464355
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4070: train_loss=8.794177055358887
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4071: train_loss=8.739028930664062
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4072: train_loss=8.72419261932373
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4073: train_loss=8.734530448913574
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4074: train_loss=8.724228858947754
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4075: train_loss=8.726442337036133
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4076: train_loss=8.71405029296875
INFO - 04/15/25 16:34:44 - 0:03:07 - Epoch 4077: train_loss=8.717443466186523
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4078: train_loss=8.700960159301758
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4079: train_loss=8.702559471130371
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4080: train_loss=8.704032897949219
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4081: train_loss=8.698957443237305
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4082: train_loss=8.743066787719727
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4083: train_loss=8.68764877319336
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4084: train_loss=8.698565483093262
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4085: train_loss=8.699554443359375
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4086: train_loss=8.723641395568848
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4087: train_loss=8.696248054504395
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4088: train_loss=8.667671203613281
INFO - 04/15/25 16:34:44 - 0:03:08 - Epoch 4089: train_loss=8.675163269042969
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4090: train_loss=8.648694038391113
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4091: train_loss=8.632960319519043
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4092: train_loss=8.608648300170898
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4093: train_loss=8.623032569885254
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4094: train_loss=8.601618766784668
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4095: train_loss=8.59002685546875
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4096: train_loss=8.600076675415039
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4097: train_loss=8.569011688232422
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4098: train_loss=8.517197608947754
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4099: train_loss=8.472394943237305
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4100: train_loss=8.459810256958008
INFO - 04/15/25 16:34:45 - 0:03:08 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:45 - 0:03:08 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4100: ACC: 0.0, NMI: 0.3183339650137658, F1: 0.0, ARI: 0.16436389378983102
INFO - 04/15/25 16:34:45 - 0:03:08 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:45 - 0:03:08 - Epoch 4101: train_loss=8.436676979064941
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4102: train_loss=8.462058067321777
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4103: train_loss=8.490363121032715
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4104: train_loss=8.510217666625977
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4105: train_loss=8.487839698791504
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4106: train_loss=8.44126033782959
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4107: train_loss=8.463489532470703
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4108: train_loss=8.467357635498047
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4109: train_loss=8.433832168579102
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4110: train_loss=8.43044376373291
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4111: train_loss=8.439445495605469
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4112: train_loss=8.423819541931152
INFO - 04/15/25 16:34:45 - 0:03:09 - Epoch 4113: train_loss=8.405653953552246
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4114: train_loss=8.407709121704102
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4115: train_loss=8.391382217407227
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4116: train_loss=8.403451919555664
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4117: train_loss=8.401004791259766
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4118: train_loss=8.39504337310791
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4119: train_loss=8.374279022216797
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4120: train_loss=8.35517406463623
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4121: train_loss=8.35411262512207
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4122: train_loss=8.331178665161133
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4123: train_loss=8.34522819519043
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4124: train_loss=8.381470680236816
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4125: train_loss=8.3371000289917
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4126: train_loss=8.333250999450684
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4127: train_loss=8.323083877563477
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4128: train_loss=8.320637702941895
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4129: train_loss=8.34611988067627
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4130: train_loss=8.303020477294922
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4131: train_loss=8.353909492492676
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4132: train_loss=8.308744430541992
INFO - 04/15/25 16:34:46 - 0:03:09 - Epoch 4133: train_loss=8.303888320922852
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4134: train_loss=8.309221267700195
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4135: train_loss=8.320564270019531
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4136: train_loss=8.340481758117676
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4137: train_loss=8.304659843444824
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4138: train_loss=8.328163146972656
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4139: train_loss=8.313071250915527
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4140: train_loss=8.308534622192383
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4141: train_loss=8.29687213897705
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4142: train_loss=8.315476417541504
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4143: train_loss=8.300448417663574
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4144: train_loss=8.293584823608398
INFO - 04/15/25 16:34:46 - 0:03:10 - Epoch 4145: train_loss=8.26522445678711
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4146: train_loss=8.282896041870117
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4147: train_loss=8.252222061157227
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4148: train_loss=8.271946907043457
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4149: train_loss=8.23958683013916
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4150: train_loss=8.236964225769043
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4151: train_loss=8.24885368347168
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4152: train_loss=8.215001106262207
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4153: train_loss=8.213985443115234
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4154: train_loss=8.150300979614258
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4155: train_loss=8.230031967163086
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4156: train_loss=8.199381828308105
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4157: train_loss=8.154950141906738
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4158: train_loss=8.116854667663574
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4159: train_loss=8.107895851135254
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4160: train_loss=8.10977554321289
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4161: train_loss=8.110211372375488
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4162: train_loss=8.083503723144531
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4163: train_loss=8.092284202575684
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4164: train_loss=8.09145736694336
INFO - 04/15/25 16:34:47 - 0:03:10 - Epoch 4165: train_loss=8.060698509216309
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4166: train_loss=8.080923080444336
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4167: train_loss=8.067544937133789
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4168: train_loss=8.055852890014648
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4169: train_loss=8.121413230895996
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4170: train_loss=8.119897842407227
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4171: train_loss=8.09277629852295
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4172: train_loss=8.095270156860352
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4173: train_loss=8.067936897277832
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4174: train_loss=8.080342292785645
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4175: train_loss=8.085984230041504
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4176: train_loss=8.088714599609375
INFO - 04/15/25 16:34:47 - 0:03:11 - Epoch 4177: train_loss=8.062548637390137
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4178: train_loss=8.074633598327637
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4179: train_loss=8.117838859558105
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4180: train_loss=8.0717191696167
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4181: train_loss=8.066182136535645
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4182: train_loss=8.048383712768555
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4183: train_loss=8.068150520324707
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4184: train_loss=8.091120719909668
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4185: train_loss=8.065750122070312
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4186: train_loss=8.0562744140625
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4187: train_loss=8.068660736083984
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4188: train_loss=8.071985244750977
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4189: train_loss=8.115546226501465
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4190: train_loss=8.063720703125
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4191: train_loss=8.053434371948242
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4192: train_loss=8.065347671508789
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4193: train_loss=8.042016983032227
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4194: train_loss=8.118755340576172
INFO - 04/15/25 16:34:48 - 0:03:11 - Epoch 4195: train_loss=8.053775787353516
INFO - 04/15/25 16:34:48 - 0:03:12 - Epoch 4196: train_loss=8.047983169555664
INFO - 04/15/25 16:34:48 - 0:03:12 - Epoch 4197: train_loss=8.044983863830566
INFO - 04/15/25 16:34:48 - 0:03:12 - Epoch 4198: train_loss=8.07345199584961
INFO - 04/15/25 16:34:48 - 0:03:12 - Epoch 4199: train_loss=8.046342849731445
INFO - 04/15/25 16:34:48 - 0:03:12 - Epoch 4200: train_loss=8.049989700317383
INFO - 04/15/25 16:34:48 - 0:03:12 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:48 - 0:03:12 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4200: ACC: 0.0, NMI: 0.3333490760387528, F1: 0.0, ARI: 0.15918097962071726
INFO - 04/15/25 16:34:49 - 0:03:12 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4201: train_loss=8.043010711669922
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4202: train_loss=8.058934211730957
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4203: train_loss=8.046699523925781
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4204: train_loss=8.046385765075684
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4205: train_loss=8.036031723022461
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4206: train_loss=8.069334030151367
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4207: train_loss=8.050870895385742
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4208: train_loss=8.05395793914795
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4209: train_loss=8.061599731445312
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4210: train_loss=8.042794227600098
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4211: train_loss=8.057416915893555
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4212: train_loss=8.058120727539062
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4213: train_loss=8.040392875671387
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4214: train_loss=8.060882568359375
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4215: train_loss=8.043370246887207
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4216: train_loss=8.055105209350586
INFO - 04/15/25 16:34:49 - 0:03:12 - Epoch 4217: train_loss=8.05048942565918
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4218: train_loss=8.04702377319336
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4219: train_loss=8.076982498168945
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4220: train_loss=8.026655197143555
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4221: train_loss=8.03195571899414
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4222: train_loss=8.0380859375
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4223: train_loss=8.074831008911133
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4224: train_loss=8.031338691711426
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4225: train_loss=8.0297212600708
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4226: train_loss=8.022282600402832
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4227: train_loss=8.021239280700684
INFO - 04/15/25 16:34:49 - 0:03:13 - Epoch 4228: train_loss=8.034125328063965
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4229: train_loss=8.025904655456543
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4230: train_loss=8.04165267944336
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4231: train_loss=8.041568756103516
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4232: train_loss=8.042001724243164
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4233: train_loss=8.035072326660156
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4234: train_loss=8.03015422821045
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4235: train_loss=8.093032836914062
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4236: train_loss=8.046700477600098
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4237: train_loss=8.030075073242188
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4238: train_loss=8.04017448425293
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4239: train_loss=8.040999412536621
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4240: train_loss=8.030994415283203
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4241: train_loss=8.040291786193848
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4242: train_loss=8.083966255187988
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4243: train_loss=8.034417152404785
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4244: train_loss=8.029793739318848
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4245: train_loss=8.034878730773926
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4246: train_loss=8.091084480285645
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4247: train_loss=8.031111717224121
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4248: train_loss=8.036919593811035
INFO - 04/15/25 16:34:50 - 0:03:13 - Epoch 4249: train_loss=8.037972450256348
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4250: train_loss=8.031599998474121
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4251: train_loss=8.026117324829102
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4252: train_loss=8.049463272094727
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4253: train_loss=8.078478813171387
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4254: train_loss=8.031163215637207
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4255: train_loss=8.051874160766602
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4256: train_loss=8.021589279174805
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4257: train_loss=8.039454460144043
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4258: train_loss=8.04357624053955
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4259: train_loss=8.025229454040527
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4260: train_loss=8.026813507080078
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4261: train_loss=8.040359497070312
INFO - 04/15/25 16:34:50 - 0:03:14 - Epoch 4262: train_loss=8.056230545043945
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4263: train_loss=8.036361694335938
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4264: train_loss=8.021985054016113
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4265: train_loss=8.036419868469238
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4266: train_loss=8.017427444458008
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4267: train_loss=8.030899047851562
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4268: train_loss=8.020526885986328
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4269: train_loss=8.013387680053711
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4270: train_loss=8.045231819152832
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4271: train_loss=8.029274940490723
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4272: train_loss=8.025714874267578
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4273: train_loss=8.016136169433594
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4274: train_loss=8.02880573272705
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4275: train_loss=8.027762413024902
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4276: train_loss=8.051324844360352
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4277: train_loss=8.09988021850586
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4278: train_loss=8.042734146118164
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4279: train_loss=8.036174774169922
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4280: train_loss=8.02932071685791
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4281: train_loss=8.020318031311035
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4282: train_loss=8.073348045349121
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4283: train_loss=8.09992504119873
INFO - 04/15/25 16:34:51 - 0:03:14 - Epoch 4284: train_loss=8.298748970031738
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4285: train_loss=8.314080238342285
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4286: train_loss=8.273421287536621
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4287: train_loss=8.250779151916504
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4288: train_loss=8.25867748260498
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4289: train_loss=8.297938346862793
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4290: train_loss=8.286279678344727
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4291: train_loss=8.298994064331055
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4292: train_loss=8.26533031463623
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4293: train_loss=8.262210845947266
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4294: train_loss=8.2992525100708
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4295: train_loss=8.258139610290527
INFO - 04/15/25 16:34:51 - 0:03:15 - Epoch 4296: train_loss=8.294791221618652
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4297: train_loss=8.23486614227295
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4298: train_loss=8.253192901611328
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4299: train_loss=8.290735244750977
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4300: train_loss=8.267104148864746
INFO - 04/15/25 16:34:52 - 0:03:15 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:52 - 0:03:15 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4300: ACC: 0.0, NMI: 0.28291996600938746, F1: 0.0, ARI: 0.11818585753734392
INFO - 04/15/25 16:34:52 - 0:03:15 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4301: train_loss=8.25210952758789
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4302: train_loss=8.269194602966309
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4303: train_loss=8.281288146972656
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4304: train_loss=8.245180130004883
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4305: train_loss=8.252222061157227
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4306: train_loss=8.242510795593262
INFO - 04/15/25 16:34:52 - 0:03:15 - Epoch 4307: train_loss=8.258748054504395
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4308: train_loss=8.234058380126953
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4309: train_loss=8.225062370300293
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4310: train_loss=8.223416328430176
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4311: train_loss=8.21076774597168
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4312: train_loss=8.238876342773438
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4313: train_loss=8.201154708862305
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4314: train_loss=8.250066757202148
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4315: train_loss=8.214179039001465
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4316: train_loss=8.208038330078125
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4317: train_loss=8.199624061584473
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4318: train_loss=8.205775260925293
INFO - 04/15/25 16:34:52 - 0:03:16 - Epoch 4319: train_loss=8.245009422302246
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4320: train_loss=8.234773635864258
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4321: train_loss=8.208878517150879
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4322: train_loss=8.219949722290039
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4323: train_loss=8.198148727416992
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4324: train_loss=8.230445861816406
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4325: train_loss=8.22213077545166
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4326: train_loss=8.21931266784668
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4327: train_loss=8.233694076538086
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4328: train_loss=8.19676685333252
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4329: train_loss=8.205728530883789
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4330: train_loss=8.198585510253906
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4331: train_loss=8.199289321899414
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4332: train_loss=8.199024200439453
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4333: train_loss=8.198040962219238
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4334: train_loss=8.19791316986084
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4335: train_loss=8.20055103302002
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4336: train_loss=8.203490257263184
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4337: train_loss=8.202173233032227
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4338: train_loss=8.178865432739258
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4339: train_loss=8.182982444763184
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4340: train_loss=8.189497947692871
INFO - 04/15/25 16:34:53 - 0:03:16 - Epoch 4341: train_loss=8.182445526123047
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4342: train_loss=8.194588661193848
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4343: train_loss=8.237214088439941
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4344: train_loss=8.175260543823242
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4345: train_loss=8.16907024383545
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4346: train_loss=8.18433666229248
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4347: train_loss=8.226557731628418
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4348: train_loss=8.174498558044434
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4349: train_loss=8.195510864257812
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4350: train_loss=8.178915023803711
INFO - 04/15/25 16:34:53 - 0:03:17 - Epoch 4351: train_loss=8.17817497253418
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4352: train_loss=8.170832633972168
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4353: train_loss=8.178154945373535
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4354: train_loss=8.170716285705566
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4355: train_loss=8.173528671264648
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4356: train_loss=8.1721830368042
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4357: train_loss=8.166654586791992
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4358: train_loss=8.175088882446289
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4359: train_loss=8.186521530151367
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4360: train_loss=8.17967700958252
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4361: train_loss=8.162938117980957
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4362: train_loss=8.175174713134766
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4363: train_loss=8.160711288452148
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4364: train_loss=8.151673316955566
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4365: train_loss=8.17628002166748
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4366: train_loss=8.16068172454834
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4367: train_loss=8.211160659790039
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4368: train_loss=8.15755558013916
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4369: train_loss=8.158577919006348
INFO - 04/15/25 16:34:54 - 0:03:17 - Epoch 4370: train_loss=8.207212448120117
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4371: train_loss=8.17400074005127
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4372: train_loss=8.15743350982666
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4373: train_loss=8.168131828308105
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4374: train_loss=8.169341087341309
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4375: train_loss=8.15778923034668
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4376: train_loss=8.16430950164795
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4377: train_loss=8.169900894165039
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4378: train_loss=8.16975212097168
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4379: train_loss=8.16678524017334
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4380: train_loss=8.176749229431152
INFO - 04/15/25 16:34:54 - 0:03:18 - Epoch 4381: train_loss=8.16174602508545
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4382: train_loss=8.154092788696289
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4383: train_loss=8.163521766662598
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4384: train_loss=8.169322967529297
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4385: train_loss=8.186973571777344
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4386: train_loss=8.150710105895996
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4387: train_loss=8.157669067382812
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4388: train_loss=8.159224510192871
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4389: train_loss=8.155867576599121
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4390: train_loss=8.163871765136719
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4391: train_loss=8.159622192382812
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4392: train_loss=8.212153434753418
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4393: train_loss=8.164764404296875
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4394: train_loss=8.160152435302734
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4395: train_loss=8.195093154907227
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4396: train_loss=8.167490005493164
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4397: train_loss=8.150338172912598
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4398: train_loss=8.15549087524414
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4399: train_loss=8.196866035461426
INFO - 04/15/25 16:34:55 - 0:03:18 - Epoch 4400: train_loss=8.149402618408203
INFO - 04/15/25 16:34:55 - 0:03:18 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:55 - 0:03:19 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:34:55 - 0:03:19 - Epoch 4400: ACC: 0.0, NMI: 0.2970945020088449, F1: 0.0, ARI: 0.15643897715661295
INFO - 04/15/25 16:34:55 - 0:03:19 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:55 - 0:03:19 - Epoch 4401: train_loss=8.187475204467773
INFO - 04/15/25 16:34:55 - 0:03:19 - Epoch 4402: train_loss=8.155749320983887
INFO - 04/15/25 16:34:55 - 0:03:19 - Epoch 4403: train_loss=8.150069236755371
INFO - 04/15/25 16:34:55 - 0:03:19 - Epoch 4404: train_loss=8.148992538452148
INFO - 04/15/25 16:34:55 - 0:03:19 - Epoch 4405: train_loss=8.155205726623535
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4406: train_loss=8.155739784240723
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4407: train_loss=8.148674011230469
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4408: train_loss=8.147017478942871
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4409: train_loss=8.153227806091309
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4410: train_loss=8.146475791931152
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4411: train_loss=8.156963348388672
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4412: train_loss=8.164872169494629
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4413: train_loss=8.146394729614258
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4414: train_loss=8.168635368347168
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4415: train_loss=8.150422096252441
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4416: train_loss=8.146416664123535
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4417: train_loss=8.144311904907227
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4418: train_loss=8.151549339294434
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4419: train_loss=8.150961875915527
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4420: train_loss=8.154427528381348
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4421: train_loss=8.176172256469727
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4422: train_loss=8.15850830078125
INFO - 04/15/25 16:34:56 - 0:03:19 - Epoch 4423: train_loss=8.199856758117676
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4424: train_loss=8.154788970947266
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4425: train_loss=8.166173934936523
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4426: train_loss=8.174674987792969
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4427: train_loss=8.155099868774414
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4428: train_loss=8.159370422363281
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4429: train_loss=8.182190895080566
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4430: train_loss=8.19909381866455
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4431: train_loss=8.205615997314453
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4432: train_loss=8.16490364074707
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4433: train_loss=8.193970680236816
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4434: train_loss=8.183221817016602
INFO - 04/15/25 16:34:56 - 0:03:20 - Epoch 4435: train_loss=8.210749626159668
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4436: train_loss=8.16447639465332
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4437: train_loss=8.179410934448242
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4438: train_loss=8.161314010620117
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4439: train_loss=8.173760414123535
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4440: train_loss=8.15258502960205
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4441: train_loss=8.160447120666504
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4442: train_loss=8.166489601135254
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4443: train_loss=8.180996894836426
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4444: train_loss=8.179049491882324
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4445: train_loss=8.168903350830078
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4446: train_loss=8.225327491760254
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4447: train_loss=8.266730308532715
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4448: train_loss=8.285503387451172
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4449: train_loss=8.310999870300293
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4450: train_loss=8.238524436950684
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4451: train_loss=8.248889923095703
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4452: train_loss=8.235611915588379
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4453: train_loss=8.282562255859375
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4454: train_loss=8.237749099731445
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4455: train_loss=8.252832412719727
INFO - 04/15/25 16:34:57 - 0:03:20 - Epoch 4456: train_loss=8.250666618347168
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4457: train_loss=8.236788749694824
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4458: train_loss=8.242606163024902
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4459: train_loss=8.23239517211914
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4460: train_loss=8.233820915222168
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4461: train_loss=8.279521942138672
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4462: train_loss=8.243707656860352
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4463: train_loss=8.24384880065918
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4464: train_loss=8.23351001739502
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4465: train_loss=8.243192672729492
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4466: train_loss=8.2760591506958
INFO - 04/15/25 16:34:57 - 0:03:21 - Epoch 4467: train_loss=8.243464469909668
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4468: train_loss=8.238871574401855
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4469: train_loss=8.258182525634766
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4470: train_loss=8.255487442016602
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4471: train_loss=8.23386001586914
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4472: train_loss=8.255656242370605
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4473: train_loss=8.229917526245117
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4474: train_loss=8.245808601379395
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4475: train_loss=8.23157787322998
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4476: train_loss=8.236729621887207
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4477: train_loss=8.227940559387207
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4478: train_loss=8.230220794677734
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4479: train_loss=8.22298526763916
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4480: train_loss=8.231342315673828
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4481: train_loss=8.228001594543457
INFO - 04/15/25 16:34:58 - 0:03:21 - Epoch 4482: train_loss=8.225452423095703
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4483: train_loss=8.227086067199707
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4484: train_loss=8.225346565246582
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4485: train_loss=8.22640609741211
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4486: train_loss=8.224228858947754
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4487: train_loss=8.232492446899414
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4488: train_loss=8.226180076599121
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4489: train_loss=8.235701560974121
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4490: train_loss=8.225231170654297
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4491: train_loss=8.2235746383667
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4492: train_loss=8.227968215942383
INFO - 04/15/25 16:34:58 - 0:03:22 - Epoch 4493: train_loss=8.223252296447754
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4494: train_loss=8.230857849121094
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4495: train_loss=8.229166030883789
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4496: train_loss=8.232123374938965
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4497: train_loss=8.234232902526855
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4498: train_loss=8.239084243774414
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4499: train_loss=8.224428176879883
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4500: train_loss=8.22799015045166
INFO - 04/15/25 16:34:59 - 0:03:22 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:34:59 - 0:03:22 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4500: ACC: 0.0, NMI: 0.35362183895125826, F1: 0.0, ARI: 0.21781022458028185
INFO - 04/15/25 16:34:59 - 0:03:22 - -------------------------------------------------------------------------
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4501: train_loss=8.230581283569336
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4502: train_loss=8.220812797546387
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4503: train_loss=8.233095169067383
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4504: train_loss=8.22054386138916
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4505: train_loss=8.22640609741211
INFO - 04/15/25 16:34:59 - 0:03:22 - Epoch 4506: train_loss=8.225040435791016
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4507: train_loss=8.233846664428711
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4508: train_loss=8.22890853881836
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4509: train_loss=8.220417022705078
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4510: train_loss=8.218741416931152
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4511: train_loss=8.218576431274414
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4512: train_loss=8.246613502502441
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4513: train_loss=8.2208251953125
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4514: train_loss=8.225835800170898
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4515: train_loss=8.219581604003906
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4516: train_loss=8.22514820098877
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4517: train_loss=8.244270324707031
INFO - 04/15/25 16:34:59 - 0:03:23 - Epoch 4518: train_loss=8.228560447692871
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4519: train_loss=8.237519264221191
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4520: train_loss=8.227070808410645
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4521: train_loss=8.219210624694824
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4522: train_loss=8.23896312713623
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4523: train_loss=8.267587661743164
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4524: train_loss=8.217432975769043
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4525: train_loss=8.262022972106934
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4526: train_loss=8.23502254486084
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4527: train_loss=8.226686477661133
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4528: train_loss=8.215843200683594
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4529: train_loss=8.260781288146973
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4530: train_loss=8.215858459472656
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4531: train_loss=8.223904609680176
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4532: train_loss=8.268316268920898
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4533: train_loss=8.224212646484375
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4534: train_loss=8.229281425476074
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4535: train_loss=8.239151000976562
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4536: train_loss=8.250173568725586
INFO - 04/15/25 16:35:00 - 0:03:23 - Epoch 4537: train_loss=8.236869812011719
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4538: train_loss=8.27064323425293
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4539: train_loss=8.222972869873047
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4540: train_loss=8.268095970153809
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4541: train_loss=8.222179412841797
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4542: train_loss=8.231124877929688
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4543: train_loss=8.223575592041016
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4544: train_loss=8.241613388061523
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4545: train_loss=8.229557037353516
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4546: train_loss=8.224115371704102
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4547: train_loss=8.222036361694336
INFO - 04/15/25 16:35:00 - 0:03:24 - Epoch 4548: train_loss=8.231501579284668
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4549: train_loss=8.22864055633545
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4550: train_loss=8.220292091369629
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4551: train_loss=8.219230651855469
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4552: train_loss=8.21689510345459
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4553: train_loss=8.228020668029785
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4554: train_loss=8.218093872070312
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4555: train_loss=8.217063903808594
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4556: train_loss=8.217179298400879
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4557: train_loss=8.216058731079102
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4558: train_loss=8.22045612335205
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4559: train_loss=8.23324966430664
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4560: train_loss=8.219779014587402
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4561: train_loss=8.214818954467773
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4562: train_loss=8.241788864135742
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4563: train_loss=8.21495532989502
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4564: train_loss=8.231945037841797
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4565: train_loss=8.21360969543457
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4566: train_loss=8.214475631713867
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4567: train_loss=8.259263038635254
INFO - 04/15/25 16:35:01 - 0:03:24 - Epoch 4568: train_loss=8.213130950927734
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4569: train_loss=8.221814155578613
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4570: train_loss=8.212044715881348
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4571: train_loss=8.212593078613281
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4572: train_loss=8.257455825805664
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4573: train_loss=8.224872589111328
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4574: train_loss=8.215718269348145
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4575: train_loss=8.2138090133667
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4576: train_loss=8.214154243469238
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4577: train_loss=8.213041305541992
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4578: train_loss=8.230804443359375
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4579: train_loss=8.225131034851074
INFO - 04/15/25 16:35:01 - 0:03:25 - Epoch 4580: train_loss=8.212518692016602
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4581: train_loss=8.220328330993652
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4582: train_loss=8.221302032470703
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4583: train_loss=8.210902214050293
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4584: train_loss=8.209599494934082
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4585: train_loss=8.220621109008789
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4586: train_loss=8.216548919677734
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4587: train_loss=8.206402778625488
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4588: train_loss=8.209239959716797
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4589: train_loss=8.267130851745605
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4590: train_loss=8.224995613098145
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4591: train_loss=8.22921371459961
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4592: train_loss=8.220843315124512
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4593: train_loss=8.29128360748291
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4594: train_loss=8.252551078796387
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4595: train_loss=8.246217727661133
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4596: train_loss=8.252964973449707
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4597: train_loss=8.245582580566406
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4598: train_loss=8.238363265991211
INFO - 04/15/25 16:35:02 - 0:03:25 - Epoch 4599: train_loss=8.247624397277832
INFO - 04/15/25 16:35:02 - 0:03:26 - Epoch 4600: train_loss=8.249482154846191
INFO - 04/15/25 16:35:02 - 0:03:26 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:35:02 - 0:03:26 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4600: ACC: 0.0, NMI: 0.20074629715513587, F1: 0.0, ARI: 0.0343769486649915
INFO - 04/15/25 16:35:03 - 0:03:26 - -------------------------------------------------------------------------
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4601: train_loss=8.234675407409668
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4602: train_loss=8.235100746154785
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4603: train_loss=8.280760765075684
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4604: train_loss=8.233566284179688
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4605: train_loss=8.234477996826172
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4606: train_loss=8.281540870666504
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4607: train_loss=8.244282722473145
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4608: train_loss=8.275766372680664
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4609: train_loss=8.231728553771973
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4610: train_loss=8.276837348937988
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4611: train_loss=8.252071380615234
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4612: train_loss=8.231680870056152
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4613: train_loss=8.231697082519531
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4614: train_loss=8.231321334838867
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4615: train_loss=8.254850387573242
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4616: train_loss=8.226805686950684
INFO - 04/15/25 16:35:03 - 0:03:26 - Epoch 4617: train_loss=8.235711097717285
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4618: train_loss=8.230703353881836
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4619: train_loss=8.22961139678955
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4620: train_loss=8.26915454864502
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4621: train_loss=8.227991104125977
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4622: train_loss=8.261240005493164
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4623: train_loss=8.216744422912598
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4624: train_loss=8.217464447021484
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4625: train_loss=8.215614318847656
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4626: train_loss=8.21784496307373
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4627: train_loss=8.26506519317627
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4628: train_loss=8.225664138793945
INFO - 04/15/25 16:35:03 - 0:03:27 - Epoch 4629: train_loss=8.23183536529541
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4630: train_loss=8.21672248840332
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4631: train_loss=8.270724296569824
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4632: train_loss=8.236894607543945
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4633: train_loss=8.261289596557617
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4634: train_loss=8.230161666870117
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4635: train_loss=8.228483200073242
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4636: train_loss=8.22684383392334
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4637: train_loss=8.22508716583252
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4638: train_loss=8.222173690795898
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4639: train_loss=8.221769332885742
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4640: train_loss=8.231572151184082
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4641: train_loss=8.217292785644531
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4642: train_loss=8.252090454101562
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4643: train_loss=8.215542793273926
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4644: train_loss=8.21937084197998
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4645: train_loss=8.223315238952637
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4646: train_loss=8.21211051940918
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4647: train_loss=8.209210395812988
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4648: train_loss=8.224921226501465
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4649: train_loss=8.234066009521484
INFO - 04/15/25 16:35:04 - 0:03:27 - Epoch 4650: train_loss=8.203238487243652
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4651: train_loss=8.210434913635254
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4652: train_loss=8.209848403930664
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4653: train_loss=8.23286247253418
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4654: train_loss=8.208962440490723
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4655: train_loss=8.212390899658203
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4656: train_loss=8.209721565246582
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4657: train_loss=8.253067016601562
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4658: train_loss=8.25192928314209
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4659: train_loss=8.207802772521973
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4660: train_loss=8.213407516479492
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4661: train_loss=8.219626426696777
INFO - 04/15/25 16:35:04 - 0:03:28 - Epoch 4662: train_loss=8.210179328918457
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4663: train_loss=8.249239921569824
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4664: train_loss=8.206926345825195
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4665: train_loss=8.215292930603027
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4666: train_loss=8.206888198852539
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4667: train_loss=8.224165916442871
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4668: train_loss=8.199089050292969
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4669: train_loss=8.206076622009277
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4670: train_loss=8.205034255981445
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4671: train_loss=8.207056045532227
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4672: train_loss=8.217135429382324
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4673: train_loss=8.252809524536133
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4674: train_loss=8.239859580993652
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4675: train_loss=8.252889633178711
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4676: train_loss=8.193530082702637
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4677: train_loss=8.191908836364746
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4678: train_loss=8.187399864196777
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4679: train_loss=8.173005104064941
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4680: train_loss=8.171916961669922
INFO - 04/15/25 16:35:05 - 0:03:28 - Epoch 4681: train_loss=8.184351921081543
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4682: train_loss=8.21057415008545
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4683: train_loss=8.216081619262695
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4684: train_loss=8.200533866882324
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4685: train_loss=8.195121765136719
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4686: train_loss=8.20130729675293
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4687: train_loss=8.228524208068848
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4688: train_loss=8.193188667297363
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4689: train_loss=8.229337692260742
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4690: train_loss=8.226689338684082
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4691: train_loss=8.186837196350098
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4692: train_loss=8.193583488464355
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4693: train_loss=8.178394317626953
INFO - 04/15/25 16:35:05 - 0:03:29 - Epoch 4694: train_loss=8.179832458496094
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4695: train_loss=8.189878463745117
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4696: train_loss=8.198684692382812
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4697: train_loss=8.174169540405273
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4698: train_loss=8.176131248474121
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4699: train_loss=8.196645736694336
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4700: train_loss=8.174324035644531
INFO - 04/15/25 16:35:06 - 0:03:29 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:35:06 - 0:03:29 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4700: ACC: 0.0, NMI: 0.16011449502107472, F1: 0.0, ARI: 0.01848438049525502
INFO - 04/15/25 16:35:06 - 0:03:29 - -------------------------------------------------------------------------
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4701: train_loss=8.175609588623047
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4702: train_loss=8.179649353027344
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4703: train_loss=8.170303344726562
INFO - 04/15/25 16:35:06 - 0:03:29 - Epoch 4704: train_loss=8.186017036437988
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4705: train_loss=8.170743942260742
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4706: train_loss=8.170244216918945
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4707: train_loss=8.163881301879883
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4708: train_loss=8.201868057250977
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4709: train_loss=8.163396835327148
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4710: train_loss=8.162473678588867
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4711: train_loss=8.200716018676758
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4712: train_loss=8.16363525390625
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4713: train_loss=8.1693696975708
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4714: train_loss=8.180673599243164
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4715: train_loss=8.160947799682617
INFO - 04/15/25 16:35:06 - 0:03:30 - Epoch 4716: train_loss=8.159825325012207
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4717: train_loss=8.198380470275879
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4718: train_loss=8.159322738647461
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4719: train_loss=8.188356399536133
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4720: train_loss=8.202183723449707
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4721: train_loss=8.158053398132324
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4722: train_loss=8.157242774963379
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4723: train_loss=8.161697387695312
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4724: train_loss=8.157160758972168
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4725: train_loss=8.155677795410156
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4726: train_loss=8.15212631225586
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4727: train_loss=8.153459548950195
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4728: train_loss=8.152981758117676
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4729: train_loss=8.15468978881836
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4730: train_loss=8.147696495056152
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4731: train_loss=8.152787208557129
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4732: train_loss=8.146126747131348
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4733: train_loss=8.147993087768555
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4734: train_loss=8.143648147583008
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4735: train_loss=8.12710952758789
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4736: train_loss=8.16419506072998
INFO - 04/15/25 16:35:07 - 0:03:30 - Epoch 4737: train_loss=8.114323616027832
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4738: train_loss=8.122716903686523
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4739: train_loss=8.110607147216797
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4740: train_loss=8.116832733154297
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4741: train_loss=8.106657028198242
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4742: train_loss=8.10213565826416
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4743: train_loss=8.103109359741211
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4744: train_loss=8.102877616882324
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4745: train_loss=8.092364311218262
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4746: train_loss=8.103399276733398
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4747: train_loss=8.098054885864258
INFO - 04/15/25 16:35:07 - 0:03:31 - Epoch 4748: train_loss=8.100329399108887
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4749: train_loss=8.094502449035645
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4750: train_loss=8.089143753051758
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4751: train_loss=8.092329025268555
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4752: train_loss=8.090089797973633
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4753: train_loss=8.096043586730957
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4754: train_loss=8.084036827087402
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4755: train_loss=8.08184814453125
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4756: train_loss=8.0802001953125
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4757: train_loss=8.07778263092041
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4758: train_loss=8.120837211608887
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4759: train_loss=8.073392868041992
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4760: train_loss=8.080870628356934
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4761: train_loss=8.072623252868652
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4762: train_loss=8.104829788208008
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4763: train_loss=8.064750671386719
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4764: train_loss=8.074789047241211
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4765: train_loss=8.065511703491211
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4766: train_loss=8.062336921691895
INFO - 04/15/25 16:35:08 - 0:03:31 - Epoch 4767: train_loss=8.0596342086792
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4768: train_loss=8.059056282043457
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4769: train_loss=8.063179016113281
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4770: train_loss=8.056139945983887
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4771: train_loss=8.05498218536377
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4772: train_loss=8.061257362365723
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4773: train_loss=8.05141830444336
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4774: train_loss=8.049273490905762
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4775: train_loss=8.068400382995605
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4776: train_loss=8.0971097946167
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4777: train_loss=8.152287483215332
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4778: train_loss=8.154640197753906
INFO - 04/15/25 16:35:08 - 0:03:32 - Epoch 4779: train_loss=8.151586532592773
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4780: train_loss=8.151494979858398
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4781: train_loss=8.140274047851562
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4782: train_loss=8.156853675842285
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4783: train_loss=8.13658332824707
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4784: train_loss=8.141693115234375
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4785: train_loss=8.140727996826172
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4786: train_loss=8.12228012084961
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4787: train_loss=8.129727363586426
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4788: train_loss=8.121919631958008
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4789: train_loss=8.118005752563477
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4790: train_loss=8.111886978149414
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4791: train_loss=8.112983703613281
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4792: train_loss=8.105926513671875
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4793: train_loss=8.106871604919434
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4794: train_loss=8.106376647949219
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4795: train_loss=8.102211952209473
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4796: train_loss=8.099814414978027
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4797: train_loss=8.09648323059082
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4798: train_loss=8.096395492553711
INFO - 04/15/25 16:35:09 - 0:03:32 - Epoch 4799: train_loss=8.098196983337402
INFO - 04/15/25 16:35:09 - 0:03:33 - Epoch 4800: train_loss=8.090286254882812
INFO - 04/15/25 16:35:09 - 0:03:33 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:35:09 - 0:03:33 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:35:09 - 0:03:33 - Epoch 4800: ACC: 0.0, NMI: 0.1889809689101727, F1: 0.0, ARI: 0.03691053932343282
INFO - 04/15/25 16:35:09 - 0:03:33 - -------------------------------------------------------------------------
INFO - 04/15/25 16:35:09 - 0:03:33 - Epoch 4801: train_loss=8.088308334350586
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4802: train_loss=8.092243194580078
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4803: train_loss=8.089157104492188
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4804: train_loss=8.081048011779785
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4805: train_loss=8.080970764160156
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4806: train_loss=8.11902141571045
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4807: train_loss=8.067220687866211
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4808: train_loss=8.089761734008789
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4809: train_loss=8.08047866821289
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4810: train_loss=8.094398498535156
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4811: train_loss=8.147953987121582
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4812: train_loss=8.154088973999023
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4813: train_loss=8.128304481506348
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4814: train_loss=8.100278854370117
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4815: train_loss=8.104361534118652
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4816: train_loss=8.098796844482422
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4817: train_loss=8.103243827819824
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4818: train_loss=8.094341278076172
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4819: train_loss=8.113141059875488
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4820: train_loss=8.1068115234375
INFO - 04/15/25 16:35:10 - 0:03:33 - Epoch 4821: train_loss=8.106231689453125
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4822: train_loss=8.109033584594727
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4823: train_loss=8.104178428649902
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4824: train_loss=8.108171463012695
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4825: train_loss=8.114851951599121
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4826: train_loss=8.108413696289062
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4827: train_loss=8.101383209228516
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4828: train_loss=8.089492797851562
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4829: train_loss=8.08221435546875
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4830: train_loss=8.08220100402832
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4831: train_loss=8.079916000366211
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4832: train_loss=8.07924747467041
INFO - 04/15/25 16:35:10 - 0:03:34 - Epoch 4833: train_loss=8.080245971679688
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4834: train_loss=8.086142539978027
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4835: train_loss=8.082980155944824
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4836: train_loss=8.08254337310791
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4837: train_loss=8.110244750976562
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4838: train_loss=8.078293800354004
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4839: train_loss=8.075593948364258
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4840: train_loss=8.113490104675293
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4841: train_loss=8.074210166931152
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4842: train_loss=8.073408126831055
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4843: train_loss=8.118569374084473
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4844: train_loss=8.071157455444336
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4845: train_loss=8.067648887634277
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4846: train_loss=8.070853233337402
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4847: train_loss=8.071182250976562
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4848: train_loss=8.069711685180664
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4849: train_loss=8.067416191101074
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4850: train_loss=8.066597938537598
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4851: train_loss=8.065505027770996
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4852: train_loss=8.06065845489502
INFO - 04/15/25 16:35:11 - 0:03:34 - Epoch 4853: train_loss=8.058822631835938
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4854: train_loss=8.060949325561523
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4855: train_loss=8.058089256286621
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4856: train_loss=8.056512832641602
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4857: train_loss=8.093393325805664
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4858: train_loss=8.056901931762695
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4859: train_loss=8.070059776306152
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4860: train_loss=8.053582191467285
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4861: train_loss=8.0577974319458
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4862: train_loss=8.059308052062988
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4863: train_loss=8.055338859558105
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4864: train_loss=8.053110122680664
INFO - 04/15/25 16:35:11 - 0:03:35 - Epoch 4865: train_loss=8.052300453186035
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4866: train_loss=8.0477876663208
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4867: train_loss=8.052690505981445
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4868: train_loss=8.044145584106445
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4869: train_loss=8.047500610351562
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4870: train_loss=8.04265308380127
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4871: train_loss=8.044439315795898
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4872: train_loss=8.056645393371582
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4873: train_loss=8.03884506225586
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4874: train_loss=8.040690422058105
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4875: train_loss=8.039422988891602
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4876: train_loss=8.038666725158691
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4877: train_loss=8.030989646911621
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4878: train_loss=8.032959938049316
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4879: train_loss=8.030261039733887
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4880: train_loss=8.02955436706543
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4881: train_loss=8.02871036529541
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4882: train_loss=8.034869194030762
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4883: train_loss=8.033523559570312
INFO - 04/15/25 16:35:12 - 0:03:35 - Epoch 4884: train_loss=8.028800964355469
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4885: train_loss=8.039535522460938
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4886: train_loss=8.03452205657959
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4887: train_loss=8.07393741607666
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4888: train_loss=8.074896812438965
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4889: train_loss=8.039578437805176
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4890: train_loss=8.0756254196167
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4891: train_loss=8.047614097595215
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4892: train_loss=8.037140846252441
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4893: train_loss=8.035223007202148
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4894: train_loss=8.030059814453125
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4895: train_loss=8.028372764587402
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4896: train_loss=8.033363342285156
INFO - 04/15/25 16:35:12 - 0:03:36 - Epoch 4897: train_loss=8.032492637634277
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4898: train_loss=8.03164291381836
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4899: train_loss=8.028371810913086
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4900: train_loss=8.031003952026367
INFO - 04/15/25 16:35:13 - 0:03:36 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:35:13 - 0:03:36 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4900: ACC: 0.0, NMI: 0.025079583715970168, F1: 0.0, ARI: 0.00016755285673276764
INFO - 04/15/25 16:35:13 - 0:03:36 - -------------------------------------------------------------------------
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4901: train_loss=8.022671699523926
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4902: train_loss=8.01725959777832
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4903: train_loss=8.019160270690918
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4904: train_loss=8.017535209655762
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4905: train_loss=8.012618064880371
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4906: train_loss=8.010985374450684
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4907: train_loss=8.014057159423828
INFO - 04/15/25 16:35:13 - 0:03:36 - Epoch 4908: train_loss=8.025564193725586
INFO - 04/15/25 16:35:13 - 0:03:37 - Epoch 4909: train_loss=8.015871047973633
INFO - 04/15/25 16:35:13 - 0:03:37 - Epoch 4910: train_loss=8.010558128356934
INFO - 04/15/25 16:35:13 - 0:03:37 - Epoch 4911: train_loss=8.006815910339355
INFO - 04/15/25 16:35:13 - 0:03:37 - Epoch 4912: train_loss=8.009371757507324
INFO - 04/15/25 16:35:13 - 0:03:37 - Epoch 4913: train_loss=8.018320083618164
INFO - 04/15/25 16:35:13 - 0:03:37 - Epoch 4914: train_loss=8.008610725402832
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4915: train_loss=8.012345314025879
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4916: train_loss=8.011605262756348
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4917: train_loss=8.021465301513672
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4918: train_loss=8.008454322814941
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4919: train_loss=8.010194778442383
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4920: train_loss=8.031888008117676
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4921: train_loss=8.028257369995117
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4922: train_loss=8.11026668548584
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4923: train_loss=8.066424369812012
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4924: train_loss=8.03376293182373
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4925: train_loss=8.035089492797852
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4926: train_loss=8.03954029083252
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4927: train_loss=8.031907081604004
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4928: train_loss=8.004976272583008
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4929: train_loss=8.007720947265625
INFO - 04/15/25 16:35:14 - 0:03:37 - Epoch 4930: train_loss=8.027437210083008
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4931: train_loss=8.034028053283691
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4932: train_loss=8.013246536254883
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4933: train_loss=8.017446517944336
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4934: train_loss=8.001837730407715
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4935: train_loss=8.001208305358887
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4936: train_loss=8.008821487426758
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4937: train_loss=8.004402160644531
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4938: train_loss=7.993211269378662
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4939: train_loss=8.01161003112793
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4940: train_loss=8.00404167175293
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4941: train_loss=7.989073753356934
INFO - 04/15/25 16:35:14 - 0:03:38 - Epoch 4942: train_loss=8.033129692077637
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4943: train_loss=8.00000286102295
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4944: train_loss=8.004008293151855
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4945: train_loss=7.995275497436523
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4946: train_loss=8.003466606140137
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4947: train_loss=7.9929518699646
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4948: train_loss=8.002283096313477
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4949: train_loss=7.995808124542236
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4950: train_loss=7.998890399932861
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4951: train_loss=7.986703872680664
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4952: train_loss=7.9830002784729
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4953: train_loss=7.991665840148926
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4954: train_loss=7.9871296882629395
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4955: train_loss=7.994498252868652
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4956: train_loss=8.004050254821777
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4957: train_loss=8.002760887145996
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4958: train_loss=7.994384765625
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4959: train_loss=7.995819091796875
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4960: train_loss=7.994795799255371
INFO - 04/15/25 16:35:15 - 0:03:38 - Epoch 4961: train_loss=8.037983894348145
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4962: train_loss=8.04172420501709
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4963: train_loss=8.051369667053223
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4964: train_loss=8.048718452453613
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4965: train_loss=8.084285736083984
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4966: train_loss=8.037508964538574
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4967: train_loss=8.03110122680664
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4968: train_loss=8.02774429321289
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4969: train_loss=8.038020133972168
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4970: train_loss=8.03038215637207
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4971: train_loss=8.04963493347168
INFO - 04/15/25 16:35:15 - 0:03:39 - Epoch 4972: train_loss=8.028360366821289
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4973: train_loss=8.03458309173584
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4974: train_loss=8.024457931518555
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4975: train_loss=8.018060684204102
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4976: train_loss=8.018095016479492
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4977: train_loss=8.033916473388672
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4978: train_loss=8.013815879821777
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4979: train_loss=8.010809898376465
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4980: train_loss=8.004279136657715
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4981: train_loss=8.016236305236816
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4982: train_loss=8.013626098632812
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4983: train_loss=8.015715599060059
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4984: train_loss=8.000807762145996
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4985: train_loss=8.000126838684082
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4986: train_loss=7.999243259429932
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4987: train_loss=8.012811660766602
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4988: train_loss=7.998147487640381
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4989: train_loss=7.991360664367676
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4990: train_loss=7.994326114654541
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4991: train_loss=7.989719390869141
INFO - 04/15/25 16:35:16 - 0:03:39 - Epoch 4992: train_loss=7.9886298179626465
INFO - 04/15/25 16:35:16 - 0:03:40 - Epoch 4993: train_loss=8.003263473510742
INFO - 04/15/25 16:35:16 - 0:03:40 - Epoch 4994: train_loss=7.985577583312988
INFO - 04/15/25 16:35:16 - 0:03:40 - Epoch 4995: train_loss=7.9892683029174805
INFO - 04/15/25 16:35:16 - 0:03:40 - Epoch 4996: train_loss=7.989223957061768
INFO - 04/15/25 16:35:16 - 0:03:40 - Epoch 4997: train_loss=8.00113582611084
INFO - 04/15/25 16:35:16 - 0:03:40 - Epoch 4998: train_loss=7.988438606262207
INFO - 04/15/25 16:35:16 - 0:03:40 - Epoch 4999: train_loss=7.983886241912842
INFO - 04/15/25 16:35:16 - 0:03:40 - Epoch 5000: train_loss=7.997227668762207
INFO - 04/15/25 16:35:16 - 0:03:40 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:35:16 - 0:03:40 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:35:17 - 0:03:40 - Epoch 5000: ACC: 0.0, NMI: 0.08888474447747327, F1: 0.0, ARI: 0.01279034540395151
INFO - 04/15/25 16:35:17 - 0:03:40 - -------------------------------------------------------------------------
INFO - 04/15/25 16:35:17 - 0:03:40 - ------------------Loading best model-------------------
INFO - 04/15/25 16:35:34 - 0:03:57 - Best Results according to nmi: ACC: 0.0, NMI: 0.3924143953842758, F1: 0.0, ARI: 0.14548203542856403 
                                     
INFO - 04/15/25 16:35:34 - 0:03:57 - Best Results according to ari: ACC: 0.0, NMI: 0.35362183895125826, F1: 0.0, ARI: 0.21781022458028185 
                                     
INFO - 04/15/25 16:35:34 - 0:03:57 - 
                                     train iters 1
INFO - 04/15/25 16:35:34 - 0:03:57 - Epoch 1: train_loss=5.826819896697998
INFO - 04/15/25 16:35:34 - 0:03:57 - Epoch 2: train_loss=2.975944995880127
INFO - 04/15/25 16:35:34 - 0:03:57 - Epoch 3: train_loss=2.195671319961548
INFO - 04/15/25 16:35:34 - 0:03:57 - Epoch 4: train_loss=1.5578856468200684
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 5: train_loss=1.2048580646514893
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 6: train_loss=1.0484821796417236
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 7: train_loss=0.8970422744750977
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 8: train_loss=0.7569106817245483
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 9: train_loss=0.6507264375686646
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 10: train_loss=0.5841561555862427
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 11: train_loss=0.5645053386688232
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 12: train_loss=0.5296318531036377
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 13: train_loss=0.46559926867485046
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 14: train_loss=0.4180997610092163
INFO - 04/15/25 16:35:34 - 0:03:58 - Epoch 15: train_loss=0.4167238473892212
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 16: train_loss=0.4167224168777466
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 17: train_loss=0.3965109884738922
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 18: train_loss=0.36520326137542725
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 19: train_loss=0.34261438250541687
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 20: train_loss=0.3393925726413727
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 21: train_loss=0.34451326727867126
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 22: train_loss=0.34128624200820923
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 23: train_loss=0.3231384754180908
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 24: train_loss=0.29840365052223206
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 25: train_loss=0.30675187706947327
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 26: train_loss=0.3154345750808716
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 27: train_loss=0.306433767080307
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 28: train_loss=0.28920674324035645
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 29: train_loss=0.28443849086761475
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 30: train_loss=0.2909071445465088
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 31: train_loss=0.2879307270050049
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 32: train_loss=0.2800533175468445
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 33: train_loss=0.2750333845615387
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 34: train_loss=0.27357369661331177
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 35: train_loss=0.27415233850479126
INFO - 04/15/25 16:35:35 - 0:03:58 - Epoch 36: train_loss=0.2714477479457855
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 37: train_loss=0.26599472761154175
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 38: train_loss=0.265756756067276
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 39: train_loss=0.2656553387641907
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 40: train_loss=0.2621282637119293
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 41: train_loss=0.2608259916305542
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 42: train_loss=0.25732117891311646
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 43: train_loss=0.2588444650173187
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 44: train_loss=0.25875064730644226
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 45: train_loss=0.2530580163002014
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 46: train_loss=0.26136133074760437
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 47: train_loss=0.2588503062725067
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 48: train_loss=0.2550796866416931
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 49: train_loss=0.25778570771217346
INFO - 04/15/25 16:35:35 - 0:03:59 - Epoch 50: train_loss=0.25417912006378174
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 51: train_loss=0.25419509410858154
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 52: train_loss=0.252501904964447
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 53: train_loss=0.25009602308273315
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 54: train_loss=0.24722324311733246
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 55: train_loss=0.25351211428642273
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 56: train_loss=0.24659329652786255
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 57: train_loss=0.2500474154949188
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 58: train_loss=0.2475910782814026
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 59: train_loss=0.24462275207042694
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 60: train_loss=0.24864371120929718
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 61: train_loss=0.24310366809368134
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 62: train_loss=0.24607796967029572
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 63: train_loss=0.24217595160007477
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 64: train_loss=0.2398672252893448
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 65: train_loss=0.24228435754776
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 66: train_loss=0.2416156679391861
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 67: train_loss=0.23618391156196594
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 68: train_loss=0.24307481944561005
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 69: train_loss=0.2394266128540039
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 70: train_loss=0.23875528573989868
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 71: train_loss=0.23887161910533905
INFO - 04/15/25 16:35:36 - 0:03:59 - Epoch 72: train_loss=0.2368345409631729
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 73: train_loss=0.2349795699119568
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 74: train_loss=0.23907223343849182
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 75: train_loss=0.233731210231781
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 76: train_loss=0.2363867312669754
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 77: train_loss=0.23547907173633575
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 78: train_loss=0.23215222358703613
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 79: train_loss=0.23495374619960785
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 80: train_loss=0.23300139605998993
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 81: train_loss=0.23049277067184448
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 82: train_loss=0.23415783047676086
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 83: train_loss=0.23044687509536743
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 84: train_loss=0.23293638229370117
INFO - 04/15/25 16:35:36 - 0:04:00 - Epoch 85: train_loss=0.22917529940605164
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 86: train_loss=0.23189347982406616
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 87: train_loss=0.22613966464996338
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 88: train_loss=0.22948908805847168
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 89: train_loss=0.22649140655994415
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 90: train_loss=0.22953583300113678
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 91: train_loss=0.2263733595609665
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 92: train_loss=0.23145022988319397
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 93: train_loss=0.22738203406333923
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 94: train_loss=0.22626017034053802
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 95: train_loss=0.2297855019569397
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 96: train_loss=0.2247743457555771
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 97: train_loss=0.22976362705230713
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 98: train_loss=0.22408488392829895
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 99: train_loss=0.23260222375392914
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 100: train_loss=0.23028536140918732
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 101: train_loss=0.22671756148338318
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 102: train_loss=0.22766712307929993
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 103: train_loss=0.22554190456867218
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 104: train_loss=0.22367040812969208
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 105: train_loss=0.22820469737052917
INFO - 04/15/25 16:35:37 - 0:04:00 - Epoch 106: train_loss=0.2229604721069336
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 107: train_loss=0.22944368422031403
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 108: train_loss=0.22884978353977203
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 109: train_loss=0.22253908216953278
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 110: train_loss=0.22867760062217712
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 111: train_loss=0.2229728400707245
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 112: train_loss=0.2297641783952713
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 113: train_loss=0.22382418811321259
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 114: train_loss=0.2316197007894516
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 115: train_loss=0.22638964653015137
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 116: train_loss=0.2293066829442978
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 117: train_loss=0.22834613919258118
INFO - 04/15/25 16:35:37 - 0:04:01 - Epoch 118: train_loss=0.22513702511787415
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 119: train_loss=0.22216588258743286
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 120: train_loss=0.22820450365543365
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 121: train_loss=0.22313542664051056
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 122: train_loss=0.22812971472740173
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 123: train_loss=0.22727246582508087
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 124: train_loss=0.2207840383052826
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 125: train_loss=0.21973620355129242
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 126: train_loss=0.22472582757472992
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 127: train_loss=0.2209070920944214
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 128: train_loss=0.22466817498207092
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 129: train_loss=0.22412125766277313
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 130: train_loss=0.21819669008255005
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 131: train_loss=0.21628019213676453
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 132: train_loss=0.2238769829273224
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 133: train_loss=0.22096329927444458
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 134: train_loss=0.2199939787387848
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 135: train_loss=0.2185257226228714
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 136: train_loss=0.2203371673822403
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 137: train_loss=0.21814900636672974
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 138: train_loss=0.2196349799633026
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 139: train_loss=0.21789409220218658
INFO - 04/15/25 16:35:38 - 0:04:01 - Epoch 140: train_loss=0.2184804379940033
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 141: train_loss=0.21688571572303772
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 142: train_loss=0.2180747091770172
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 143: train_loss=0.21589377522468567
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 144: train_loss=0.2185594141483307
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 145: train_loss=0.21747495234012604
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 146: train_loss=0.21483080089092255
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 147: train_loss=0.21279782056808472
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 148: train_loss=0.21906661987304688
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 149: train_loss=0.21765664219856262
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 150: train_loss=0.21279041469097137
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 151: train_loss=0.21133971214294434
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 152: train_loss=0.21783728897571564
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 153: train_loss=0.216167151927948
INFO - 04/15/25 16:35:38 - 0:04:02 - Epoch 154: train_loss=0.2124093919992447
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 155: train_loss=0.21099728345870972
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 156: train_loss=0.2163638323545456
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 157: train_loss=0.2148871272802353
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 158: train_loss=0.21161730587482452
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 159: train_loss=0.21014340221881866
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 160: train_loss=0.21536509692668915
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 161: train_loss=0.21395109593868256
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 162: train_loss=0.210675448179245
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 163: train_loss=0.20941585302352905
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 164: train_loss=0.21439342200756073
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 165: train_loss=0.21294838190078735
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 166: train_loss=0.20976996421813965
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 167: train_loss=0.20942632853984833
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 168: train_loss=0.21360737085342407
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 169: train_loss=0.21150748431682587
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 170: train_loss=0.2089434564113617
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 171: train_loss=0.21239016950130463
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 172: train_loss=0.20824211835861206
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 173: train_loss=0.20665952563285828
INFO - 04/15/25 16:35:39 - 0:04:02 - Epoch 174: train_loss=0.21201618015766144
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 175: train_loss=0.2069455236196518
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 176: train_loss=0.21102415025234222
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 177: train_loss=0.20861460268497467
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 178: train_loss=0.211507186293602
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 179: train_loss=0.21111351251602173
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 180: train_loss=0.20563827455043793
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 181: train_loss=0.20950213074684143
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 182: train_loss=0.20823165774345398
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 183: train_loss=0.20484711229801178
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 184: train_loss=0.2089339643716812
INFO - 04/15/25 16:35:39 - 0:04:03 - Epoch 185: train_loss=0.20445223152637482
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 186: train_loss=0.21222274005413055
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 187: train_loss=0.21118846535682678
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 188: train_loss=0.20438003540039062
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 189: train_loss=0.2079167664051056
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 190: train_loss=0.20511843264102936
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 191: train_loss=0.205562561750412
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 192: train_loss=0.20698758959770203
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 193: train_loss=0.20297062397003174
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 194: train_loss=0.20880186557769775
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 195: train_loss=0.2035670429468155
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 196: train_loss=0.20978115499019623
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 197: train_loss=0.20919162034988403
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 198: train_loss=0.202498197555542
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 199: train_loss=0.20531408488750458
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 200: train_loss=0.20717114210128784
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 201: train_loss=0.20270732045173645
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 202: train_loss=0.2056080847978592
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 203: train_loss=0.203007772564888
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 204: train_loss=0.2099854201078415
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 205: train_loss=0.20880144834518433
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 206: train_loss=0.20412321388721466
INFO - 04/15/25 16:35:40 - 0:04:03 - Epoch 207: train_loss=0.21087345480918884
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 208: train_loss=0.2040814906358719
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 209: train_loss=0.21672354638576508
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 210: train_loss=0.21747148036956787
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 211: train_loss=0.2071162462234497
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 212: train_loss=0.20914305746555328
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 213: train_loss=0.2120177000761032
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 214: train_loss=0.2062821388244629
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 215: train_loss=0.21199418604373932
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 216: train_loss=0.21394912898540497
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 217: train_loss=0.20276470482349396
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 218: train_loss=0.20904654264450073
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 219: train_loss=0.21011297404766083
INFO - 04/15/25 16:35:40 - 0:04:04 - Epoch 220: train_loss=0.20125991106033325
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 221: train_loss=0.21363778412342072
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 222: train_loss=0.21488946676254272
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 223: train_loss=0.20333552360534668
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 224: train_loss=0.20831117033958435
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 225: train_loss=0.21185611188411713
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 226: train_loss=0.20433974266052246
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 227: train_loss=0.20727086067199707
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 228: train_loss=0.21119442582130432
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 229: train_loss=0.20234562456607819
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 230: train_loss=0.20625784993171692
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 231: train_loss=0.2101936638355255
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 232: train_loss=0.20279991626739502
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 233: train_loss=0.20609557628631592
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 234: train_loss=0.20951959490776062
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 235: train_loss=0.20330235362052917
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 236: train_loss=0.20215360820293427
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 237: train_loss=0.2055835723876953
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 238: train_loss=0.19796262681484222
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 239: train_loss=0.20844587683677673
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 240: train_loss=0.209672212600708
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 241: train_loss=0.20596130192279816
INFO - 04/15/25 16:35:41 - 0:04:04 - Epoch 242: train_loss=0.1984604299068451
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 243: train_loss=0.20368671417236328
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 244: train_loss=0.20018339157104492
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 245: train_loss=0.20046424865722656
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 246: train_loss=0.2007848471403122
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 247: train_loss=0.19768978655338287
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 248: train_loss=0.1989327371120453
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 249: train_loss=0.2026563286781311
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 250: train_loss=0.19845670461654663
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 251: train_loss=0.19972464442253113
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 252: train_loss=0.20151139795780182
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 253: train_loss=0.1979379802942276
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 254: train_loss=0.20388361811637878
INFO - 04/15/25 16:35:41 - 0:04:05 - Epoch 255: train_loss=0.20006011426448822
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 256: train_loss=0.20415377616882324
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 257: train_loss=0.1963210552930832
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 258: train_loss=0.2079528570175171
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 259: train_loss=0.2037535309791565
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 260: train_loss=0.2057368904352188
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 261: train_loss=0.20498493313789368
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 262: train_loss=0.2014237493276596
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 263: train_loss=0.20176443457603455
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 264: train_loss=0.20143206417560577
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 265: train_loss=0.1986362338066101
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 266: train_loss=0.2035731077194214
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 267: train_loss=0.19900356233119965
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 268: train_loss=0.2057667374610901
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 269: train_loss=0.20353245735168457
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 270: train_loss=0.20244839787483215
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 271: train_loss=0.2021860033273697
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 272: train_loss=0.20095036923885345
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 273: train_loss=0.19992610812187195
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 274: train_loss=0.2015569657087326
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 275: train_loss=0.198140949010849
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 276: train_loss=0.20384332537651062
INFO - 04/15/25 16:35:42 - 0:04:05 - Epoch 277: train_loss=0.20055682957172394
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 278: train_loss=0.2036939561367035
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 279: train_loss=0.20256055891513824
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 280: train_loss=0.2004614770412445
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 281: train_loss=0.20062373578548431
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 282: train_loss=0.1995721161365509
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 283: train_loss=0.19821664690971375
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 284: train_loss=0.20121045410633087
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 285: train_loss=0.19705258309841156
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 286: train_loss=0.20435689389705658
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 287: train_loss=0.20222042500972748
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 288: train_loss=0.20018908381462097
INFO - 04/15/25 16:35:42 - 0:04:06 - Epoch 289: train_loss=0.2010057270526886
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 290: train_loss=0.19762152433395386
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 291: train_loss=0.2002238631248474
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 292: train_loss=0.19715948402881622
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 293: train_loss=0.19865447282791138
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 294: train_loss=0.19644717872142792
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 295: train_loss=0.20286820828914642
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 296: train_loss=0.20012155175209045
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 297: train_loss=0.20118916034698486
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 298: train_loss=0.2011892944574356
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 299: train_loss=0.197334423661232
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 300: train_loss=0.20274248719215393
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 301: train_loss=0.1946708858013153
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 302: train_loss=0.21507656574249268
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 303: train_loss=0.21762433648109436
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 304: train_loss=0.1975080668926239
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 305: train_loss=0.21757899224758148
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 306: train_loss=0.22523805499076843
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 307: train_loss=0.21320205926895142
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 308: train_loss=0.2059904932975769
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 309: train_loss=0.2103368639945984
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 310: train_loss=0.21119707822799683
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 311: train_loss=0.20772048830986023
INFO - 04/15/25 16:35:43 - 0:04:06 - Epoch 312: train_loss=0.19954028725624084
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 313: train_loss=0.20893265306949615
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 314: train_loss=0.20459003746509552
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 315: train_loss=0.19987015426158905
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 316: train_loss=0.2020551711320877
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 317: train_loss=0.19554153084754944
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 318: train_loss=0.19548247754573822
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 319: train_loss=0.19750025868415833
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 320: train_loss=0.195090189576149
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 321: train_loss=0.19569669663906097
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 322: train_loss=0.19547459483146667
INFO - 04/15/25 16:35:43 - 0:04:07 - Epoch 323: train_loss=0.1968662440776825
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 324: train_loss=0.19214068353176117
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 325: train_loss=0.20532381534576416
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 326: train_loss=0.20554102957248688
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 327: train_loss=0.19554999470710754
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 328: train_loss=0.20280586183071136
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 329: train_loss=0.20501478016376495
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 330: train_loss=0.1915794461965561
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 331: train_loss=0.21241188049316406
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 332: train_loss=0.21982914209365845
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 333: train_loss=0.20970198512077332
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 334: train_loss=0.1973269134759903
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 335: train_loss=0.20596924424171448
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 336: train_loss=0.20904511213302612
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 337: train_loss=0.19953861832618713
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 338: train_loss=0.20144374668598175
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 339: train_loss=0.20703613758087158
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 340: train_loss=0.1980406790971756
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 341: train_loss=0.20082011818885803
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 342: train_loss=0.20445516705513
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 343: train_loss=0.19836269319057465
INFO - 04/15/25 16:35:44 - 0:04:07 - Epoch 344: train_loss=0.19770044088363647
INFO - 04/15/25 16:35:45 - 0:04:07 - Epoch 345: train_loss=0.20083531737327576
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 346: train_loss=0.19589382410049438
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 347: train_loss=0.19883936643600464
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 348: train_loss=0.1992482841014862
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 349: train_loss=0.19543151557445526
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 350: train_loss=0.19584660232067108
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 351: train_loss=0.19650886952877045
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 352: train_loss=0.19315508008003235
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 353: train_loss=0.19466949999332428
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 354: train_loss=0.19375216960906982
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 355: train_loss=0.1934484839439392
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 356: train_loss=0.19212289154529572
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 357: train_loss=0.19469700753688812
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 358: train_loss=0.19264927506446838
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 359: train_loss=0.19414879381656647
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 360: train_loss=0.19263237714767456
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 361: train_loss=0.1949910670518875
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 362: train_loss=0.1933903992176056
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 363: train_loss=0.19459736347198486
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 364: train_loss=0.19384165108203888
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 365: train_loss=0.19312137365341187
INFO - 04/15/25 16:35:45 - 0:04:08 - Epoch 366: train_loss=0.19271036982536316
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 367: train_loss=0.1938542127609253
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 368: train_loss=0.19215773046016693
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 369: train_loss=0.1945824921131134
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 370: train_loss=0.19413164258003235
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 371: train_loss=0.19170893728733063
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 372: train_loss=0.19220885634422302
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 373: train_loss=0.19301477074623108
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 374: train_loss=0.19095905125141144
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 375: train_loss=0.19283482432365417
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 376: train_loss=0.19060394167900085
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 377: train_loss=0.1948319375514984
INFO - 04/15/25 16:35:45 - 0:04:09 - Epoch 378: train_loss=0.1933082640171051
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 379: train_loss=0.19242706894874573
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 380: train_loss=0.19357286393642426
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 381: train_loss=0.1908106952905655
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 382: train_loss=0.19211357831954956
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 383: train_loss=0.19151262938976288
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 384: train_loss=0.19360876083374023
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 385: train_loss=0.19165639579296112
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 386: train_loss=0.19276003539562225
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 387: train_loss=0.19254745543003082
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 388: train_loss=0.19063423573970795
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 389: train_loss=0.19050511717796326
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 390: train_loss=0.19629624485969543
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 391: train_loss=0.19207175076007843
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 392: train_loss=0.19615916907787323
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 393: train_loss=0.19451510906219482
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 394: train_loss=0.19342344999313354
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 395: train_loss=0.19603009521961212
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 396: train_loss=0.19376760721206665
INFO - 04/15/25 16:35:46 - 0:04:09 - Epoch 397: train_loss=0.19590359926223755
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 398: train_loss=0.19420218467712402
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 399: train_loss=0.19526228308677673
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 400: train_loss=0.19283117353916168
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 401: train_loss=0.1944623738527298
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 402: train_loss=0.1915762722492218
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 403: train_loss=0.19552046060562134
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 404: train_loss=0.19180509448051453
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 405: train_loss=0.19554707407951355
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 406: train_loss=0.1932007521390915
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 407: train_loss=0.1932603120803833
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 408: train_loss=0.19461026787757874
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 409: train_loss=0.19226861000061035
INFO - 04/15/25 16:35:46 - 0:04:10 - Epoch 410: train_loss=0.19594508409500122
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 411: train_loss=0.1945130079984665
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 412: train_loss=0.19455865025520325
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 413: train_loss=0.19304272532463074
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 414: train_loss=0.19409963488578796
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 415: train_loss=0.19162939488887787
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 416: train_loss=0.19524690508842468
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 417: train_loss=0.19120670855045319
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 418: train_loss=0.19850300252437592
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 419: train_loss=0.19573548436164856
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 420: train_loss=0.19721800088882446
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 421: train_loss=0.19556522369384766
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 422: train_loss=0.19635525345802307
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 423: train_loss=0.19608791172504425
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 424: train_loss=0.19305136799812317
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 425: train_loss=0.19367875158786774
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 426: train_loss=0.1919366717338562
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 427: train_loss=0.19373157620429993
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 428: train_loss=0.19036716222763062
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 429: train_loss=0.19388753175735474
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 430: train_loss=0.19099628925323486
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 431: train_loss=0.19152143597602844
INFO - 04/15/25 16:35:47 - 0:04:10 - Epoch 432: train_loss=0.19235330820083618
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 433: train_loss=0.1906084567308426
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 434: train_loss=0.19121168553829193
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 435: train_loss=0.19049276411533356
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 436: train_loss=0.19258075952529907
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 437: train_loss=0.1886739581823349
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 438: train_loss=0.19180016219615936
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 439: train_loss=0.19250912964344025
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 440: train_loss=0.18648473918437958
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 441: train_loss=0.20585112273693085
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 442: train_loss=0.2074437439441681
INFO - 04/15/25 16:35:47 - 0:04:11 - Epoch 443: train_loss=0.19406427443027496
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 444: train_loss=0.20266124606132507
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 445: train_loss=0.20335069298744202
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 446: train_loss=0.1979609876871109
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 447: train_loss=0.20062610507011414
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 448: train_loss=0.19310715794563293
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 449: train_loss=0.2019491344690323
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 450: train_loss=0.20452448725700378
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 451: train_loss=0.19130919873714447
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 452: train_loss=0.20397263765335083
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 453: train_loss=0.20888152718544006
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 454: train_loss=0.1991811841726303
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 455: train_loss=0.19903211295604706
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 456: train_loss=0.20140668749809265
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 457: train_loss=0.1962166279554367
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 458: train_loss=0.19939152896404266
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 459: train_loss=0.1974179744720459
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 460: train_loss=0.19281810522079468
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 461: train_loss=0.1970158964395523
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 462: train_loss=0.19260013103485107
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 463: train_loss=0.19538435339927673
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 464: train_loss=0.19600531458854675
INFO - 04/15/25 16:35:48 - 0:04:11 - Epoch 465: train_loss=0.19121535122394562
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 466: train_loss=0.19183434545993805
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 467: train_loss=0.19295340776443481
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 468: train_loss=0.1907057762145996
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 469: train_loss=0.194189190864563
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 470: train_loss=0.1932946890592575
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 471: train_loss=0.19234046339988708
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 472: train_loss=0.19082918763160706
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 473: train_loss=0.1942223459482193
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 474: train_loss=0.19311517477035522
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 475: train_loss=0.19109734892845154
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 476: train_loss=0.1912844479084015
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 477: train_loss=0.19073697924613953
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 478: train_loss=0.18979400396347046
INFO - 04/15/25 16:35:48 - 0:04:12 - Epoch 479: train_loss=0.19136719405651093
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 480: train_loss=0.18829183280467987
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 481: train_loss=0.1960647851228714
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 482: train_loss=0.19511200487613678
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 483: train_loss=0.19000600278377533
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 484: train_loss=0.1907743215560913
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 485: train_loss=0.19073346257209778
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 486: train_loss=0.1895500123500824
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 487: train_loss=0.19034987688064575
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 488: train_loss=0.1890791654586792
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 489: train_loss=0.19087250530719757
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 490: train_loss=0.18812619149684906
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 491: train_loss=0.19250740110874176
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 492: train_loss=0.1898832619190216
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 493: train_loss=0.19266647100448608
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 494: train_loss=0.19163882732391357
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 495: train_loss=0.19046510756015778
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 496: train_loss=0.19130490720272064
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 497: train_loss=0.18826977908611298
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 498: train_loss=0.193523570895195
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 499: train_loss=0.1900603324174881
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 500: train_loss=0.19485819339752197
INFO - 04/15/25 16:35:49 - 0:04:12 - Epoch 501: train_loss=0.19503998756408691
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 502: train_loss=0.18923501670360565
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 503: train_loss=0.19289517402648926
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 504: train_loss=0.1903677135705948
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 505: train_loss=0.19300523400306702
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 506: train_loss=0.19299806654453278
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 507: train_loss=0.1887984573841095
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 508: train_loss=0.1890116184949875
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 509: train_loss=0.18916067481040955
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 510: train_loss=0.18908214569091797
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 511: train_loss=0.18751320242881775
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 512: train_loss=0.18881571292877197
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 513: train_loss=0.1876586526632309
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 514: train_loss=0.18822364509105682
INFO - 04/15/25 16:35:49 - 0:04:13 - Epoch 515: train_loss=0.1882132738828659
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 516: train_loss=0.18638280034065247
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 517: train_loss=0.1900443285703659
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 518: train_loss=0.18777930736541748
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 519: train_loss=0.18828538060188293
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 520: train_loss=0.185332790017128
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 521: train_loss=0.1950395703315735
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 522: train_loss=0.19146934151649475
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 523: train_loss=0.19379131495952606
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 524: train_loss=0.19381453096866608
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 525: train_loss=0.19138047099113464
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 526: train_loss=0.19124631583690643
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 527: train_loss=0.1914728581905365
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 528: train_loss=0.18958692252635956
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 529: train_loss=0.18921221792697906
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 530: train_loss=0.19100064039230347
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 531: train_loss=0.18857412040233612
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 532: train_loss=0.19135335087776184
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 533: train_loss=0.1897662878036499
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 534: train_loss=0.18979810178279877
INFO - 04/15/25 16:35:50 - 0:04:13 - Epoch 535: train_loss=0.1902158409357071
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 536: train_loss=0.18761523067951202
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 537: train_loss=0.19238759577274323
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 538: train_loss=0.18833570182323456
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 539: train_loss=0.19642449915409088
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 540: train_loss=0.19694733619689941
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 541: train_loss=0.18675446510314941
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 542: train_loss=0.1939578354358673
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 543: train_loss=0.1921241730451584
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 544: train_loss=0.18922658264636993
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 545: train_loss=0.19054508209228516
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 546: train_loss=0.1875489205121994
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 547: train_loss=0.1903364360332489
INFO - 04/15/25 16:35:50 - 0:04:14 - Epoch 548: train_loss=0.18731532990932465
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 549: train_loss=0.19106218218803406
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 550: train_loss=0.18898552656173706
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 551: train_loss=0.19133694469928741
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 552: train_loss=0.19119754433631897
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 553: train_loss=0.18776635825634003
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 554: train_loss=0.18788745999336243
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 555: train_loss=0.1890198141336441
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 556: train_loss=0.18682627379894257
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 557: train_loss=0.19114121794700623
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 558: train_loss=0.18959112465381622
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 559: train_loss=0.18926836550235748
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 560: train_loss=0.1896207481622696
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 561: train_loss=0.1871902197599411
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 562: train_loss=0.18995629251003265
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 563: train_loss=0.18569593131542206
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 564: train_loss=0.19401149451732635
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 565: train_loss=0.1922234147787094
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 566: train_loss=0.18902897834777832
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 567: train_loss=0.18989478051662445
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 568: train_loss=0.18787167966365814
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 569: train_loss=0.18842729926109314
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 570: train_loss=0.1879449188709259
INFO - 04/15/25 16:35:51 - 0:04:14 - Epoch 571: train_loss=0.18523280322551727
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 572: train_loss=0.19573096930980682
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 573: train_loss=0.19430729746818542
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 574: train_loss=0.18817633390426636
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 575: train_loss=0.1885698288679123
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 576: train_loss=0.19064509868621826
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 577: train_loss=0.18801560997962952
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 578: train_loss=0.19258688390254974
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 579: train_loss=0.19117838144302368
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 580: train_loss=0.19036629796028137
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 581: train_loss=0.1898263841867447
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 582: train_loss=0.19034650921821594
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 583: train_loss=0.18879660964012146
INFO - 04/15/25 16:35:51 - 0:04:15 - Epoch 584: train_loss=0.19012951850891113
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 585: train_loss=0.18863296508789062
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 586: train_loss=0.18940554559230804
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 587: train_loss=0.18854260444641113
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 588: train_loss=0.1879441887140274
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 589: train_loss=0.18914003670215607
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 590: train_loss=0.18615663051605225
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 591: train_loss=0.19050629436969757
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 592: train_loss=0.18639813363552094
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 593: train_loss=0.19293391704559326
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 594: train_loss=0.1906629055738449
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 595: train_loss=0.19088725745677948
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 596: train_loss=0.19063109159469604
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 597: train_loss=0.18944521248340607
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 598: train_loss=0.1890093982219696
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 599: train_loss=0.18925201892852783
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 600: train_loss=0.1880434900522232
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 601: train_loss=0.1887904554605484
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 602: train_loss=0.18778657913208008
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 603: train_loss=0.18712273240089417
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 604: train_loss=0.18899399042129517
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 605: train_loss=0.18548136949539185
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 606: train_loss=0.19154715538024902
INFO - 04/15/25 16:35:52 - 0:04:15 - Epoch 607: train_loss=0.1881352961063385
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 608: train_loss=0.19287528097629547
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 609: train_loss=0.19222119450569153
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 610: train_loss=0.18848329782485962
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 611: train_loss=0.1892070174217224
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 612: train_loss=0.18850383162498474
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 613: train_loss=0.1875423789024353
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 614: train_loss=0.1886439323425293
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 615: train_loss=0.18708863854408264
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 616: train_loss=0.1880350410938263
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 617: train_loss=0.1870357245206833
INFO - 04/15/25 16:35:52 - 0:04:16 - Epoch 618: train_loss=0.18724173307418823
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 619: train_loss=0.18611156940460205
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 620: train_loss=0.18934600055217743
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 621: train_loss=0.18546880781650543
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 622: train_loss=0.19548718631267548
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 623: train_loss=0.19669383764266968
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 624: train_loss=0.18370293080806732
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 625: train_loss=0.20156048238277435
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 626: train_loss=0.20751726627349854
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 627: train_loss=0.19944778084754944
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 628: train_loss=0.18660181760787964
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 629: train_loss=0.1956857293844223
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 630: train_loss=0.19562074542045593
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 631: train_loss=0.18770083785057068
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 632: train_loss=0.1939084231853485
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 633: train_loss=0.19503343105316162
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 634: train_loss=0.18878401815891266
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 635: train_loss=0.1920272558927536
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 636: train_loss=0.19088108837604523
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 637: train_loss=0.19071759283542633
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 638: train_loss=0.19011090695858002
INFO - 04/15/25 16:35:53 - 0:04:16 - Epoch 639: train_loss=0.18757785856723785
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 640: train_loss=0.18973229825496674
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 641: train_loss=0.18545611202716827
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 642: train_loss=0.1921825259923935
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 643: train_loss=0.19277839362621307
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 644: train_loss=0.1832188218832016
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 645: train_loss=0.1910400688648224
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 646: train_loss=0.19131974875926971
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 647: train_loss=0.18728460371494293
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 648: train_loss=0.1886909157037735
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 649: train_loss=0.19043229520320892
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 650: train_loss=0.18792285025119781
INFO - 04/15/25 16:35:53 - 0:04:17 - Epoch 651: train_loss=0.18794885277748108
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 652: train_loss=0.19001981616020203
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 653: train_loss=0.18639907240867615
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 654: train_loss=0.19186913967132568
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 655: train_loss=0.19138836860656738
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 656: train_loss=0.191875621676445
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 657: train_loss=0.18529926240444183
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 658: train_loss=0.19636128842830658
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 659: train_loss=0.19598963856697083
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 660: train_loss=0.1919296532869339
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 661: train_loss=0.19039525091648102
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 662: train_loss=0.19289550185203552
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 663: train_loss=0.19304139912128448
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 664: train_loss=0.18962465226650238
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 665: train_loss=0.18815618753433228
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 666: train_loss=0.19285058975219727
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 667: train_loss=0.19224078953266144
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 668: train_loss=0.19000574946403503
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 669: train_loss=0.1873961091041565
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 670: train_loss=0.19410300254821777
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 671: train_loss=0.19143514335155487
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 672: train_loss=0.19200243055820465
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 673: train_loss=0.19118632376194
INFO - 04/15/25 16:35:54 - 0:04:17 - Epoch 674: train_loss=0.19079828262329102
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 675: train_loss=0.19044820964336395
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 676: train_loss=0.18972530961036682
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 677: train_loss=0.18773840367794037
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 678: train_loss=0.1937030553817749
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 679: train_loss=0.19248643517494202
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 680: train_loss=0.189081072807312
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 681: train_loss=0.18865670263767242
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 682: train_loss=0.19122160971164703
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 683: train_loss=0.1893390715122223
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 684: train_loss=0.19198088347911835
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 685: train_loss=0.19129271805286407
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 686: train_loss=0.18862828612327576
INFO - 04/15/25 16:35:54 - 0:04:18 - Epoch 687: train_loss=0.18771082162857056
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 688: train_loss=0.19199608266353607
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 689: train_loss=0.1905284970998764
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 690: train_loss=0.18978048861026764
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 691: train_loss=0.1893835812807083
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 692: train_loss=0.18949675559997559
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 693: train_loss=0.18784335255622864
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 694: train_loss=0.19213685393333435
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 695: train_loss=0.191742941737175
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 696: train_loss=0.1868421882390976
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 697: train_loss=0.1855240762233734
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 698: train_loss=0.1934782862663269
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 699: train_loss=0.1926819235086441
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 700: train_loss=0.18588769435882568
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 701: train_loss=0.18518748879432678
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 702: train_loss=0.1925966590642929
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 703: train_loss=0.1912008374929428
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 704: train_loss=0.187477707862854
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 705: train_loss=0.18708358705043793
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 706: train_loss=0.19037318229675293
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 707: train_loss=0.18898673355579376
INFO - 04/15/25 16:35:55 - 0:04:18 - Epoch 708: train_loss=0.1891859620809555
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 709: train_loss=0.18856795132160187
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 710: train_loss=0.1889883577823639
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 711: train_loss=0.18814422190189362
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 712: train_loss=0.18926213681697845
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 713: train_loss=0.18815138936042786
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 714: train_loss=0.1894206404685974
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 715: train_loss=0.18882203102111816
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 716: train_loss=0.18802769482135773
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 717: train_loss=0.186900794506073
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 718: train_loss=0.18999475240707397
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 719: train_loss=0.1891632229089737
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 720: train_loss=0.18748874962329865
INFO - 04/15/25 16:35:55 - 0:04:19 - Epoch 721: train_loss=0.18678224086761475
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 722: train_loss=0.18936002254486084
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 723: train_loss=0.18821042776107788
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 724: train_loss=0.18826839327812195
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 725: train_loss=0.1875711977481842
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 726: train_loss=0.18849799036979675
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 727: train_loss=0.18769846856594086
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 728: train_loss=0.18811146914958954
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 729: train_loss=0.18708853423595428
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 730: train_loss=0.18888220191001892
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 731: train_loss=0.1883818805217743
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 732: train_loss=0.1868976354598999
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 733: train_loss=0.18580438196659088
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 734: train_loss=0.1898566037416458
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 735: train_loss=0.1894008219242096
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 736: train_loss=0.18558183312416077
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 737: train_loss=0.184600368142128
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 738: train_loss=0.19056101143360138
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 739: train_loss=0.1898573935031891
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 740: train_loss=0.18503670394420624
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 741: train_loss=0.1844409704208374
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 742: train_loss=0.189812570810318
INFO - 04/15/25 16:35:56 - 0:04:19 - Epoch 743: train_loss=0.1886766254901886
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 744: train_loss=0.18628500401973724
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 745: train_loss=0.18590885400772095
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 746: train_loss=0.18813976645469666
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 747: train_loss=0.18716615438461304
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 748: train_loss=0.18728579580783844
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 749: train_loss=0.18673719465732574
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 750: train_loss=0.18708616495132446
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 751: train_loss=0.1863580048084259
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 752: train_loss=0.187419131398201
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 753: train_loss=0.18662132322788239
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 754: train_loss=0.18716323375701904
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 755: train_loss=0.18657684326171875
INFO - 04/15/25 16:35:56 - 0:04:20 - Epoch 756: train_loss=0.18680289387702942
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 757: train_loss=0.18592259287834167
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 758: train_loss=0.18754735589027405
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 759: train_loss=0.18696998059749603
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 760: train_loss=0.1861611306667328
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 761: train_loss=0.18534019589424133
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 762: train_loss=0.18789705634117126
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 763: train_loss=0.1873258799314499
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 764: train_loss=0.18558603525161743
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 765: train_loss=0.18488718569278717
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 766: train_loss=0.18803077936172485
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 767: train_loss=0.1874222755432129
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 768: train_loss=0.18526211380958557
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 769: train_loss=0.18454135954380035
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 770: train_loss=0.1881633996963501
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 771: train_loss=0.18758195638656616
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 772: train_loss=0.18482257425785065
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 773: train_loss=0.18415305018424988
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 774: train_loss=0.18830211460590363
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 775: train_loss=0.18769624829292297
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 776: train_loss=0.18457558751106262
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 777: train_loss=0.18407173454761505
INFO - 04/15/25 16:35:57 - 0:04:20 - Epoch 778: train_loss=0.18807239830493927
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 779: train_loss=0.18728572130203247
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 780: train_loss=0.18503138422966003
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 781: train_loss=0.1852363795042038
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 782: train_loss=0.18592771887779236
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 783: train_loss=0.18412065505981445
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 784: train_loss=0.18871717154979706
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 785: train_loss=0.18885312974452972
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 786: train_loss=0.182830810546875
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 787: train_loss=0.18921008706092834
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 788: train_loss=0.18249018490314484
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 789: train_loss=0.19975487887859344
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 790: train_loss=0.20318779349327087
INFO - 04/15/25 16:35:57 - 0:04:21 - Epoch 791: train_loss=0.19110862910747528
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 792: train_loss=0.19609412550926208
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 793: train_loss=0.2026503086090088
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 794: train_loss=0.1949702352285385
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 795: train_loss=0.19146639108657837
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 796: train_loss=0.19524334371089935
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 797: train_loss=0.19056063890457153
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 798: train_loss=0.19264154136180878
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 799: train_loss=0.19101741909980774
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 800: train_loss=0.19005252420902252
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 801: train_loss=0.1912863701581955
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 802: train_loss=0.18502406775951385
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 803: train_loss=0.1905054897069931
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 804: train_loss=0.18637758493423462
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 805: train_loss=0.19200673699378967
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 806: train_loss=0.19236093759536743
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 807: train_loss=0.18398825824260712
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 808: train_loss=0.1883193999528885
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 809: train_loss=0.18534201383590698
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 810: train_loss=0.18798300623893738
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 811: train_loss=0.18681550025939941
INFO - 04/15/25 16:35:58 - 0:04:21 - Epoch 812: train_loss=0.18681257963180542
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 813: train_loss=0.18640539050102234
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 814: train_loss=0.18610626459121704
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 815: train_loss=0.1861198991537094
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 816: train_loss=0.1847478747367859
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 817: train_loss=0.18856064975261688
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 818: train_loss=0.18738791346549988
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 819: train_loss=0.1866081804037094
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 820: train_loss=0.18627840280532837
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 821: train_loss=0.18669134378433228
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 822: train_loss=0.18542611598968506
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 823: train_loss=0.18737906217575073
INFO - 04/15/25 16:35:58 - 0:04:22 - Epoch 824: train_loss=0.1855189949274063
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 825: train_loss=0.18798589706420898
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 826: train_loss=0.1861608922481537
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 827: train_loss=0.1881435364484787
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 828: train_loss=0.18673571944236755
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 829: train_loss=0.1881427764892578
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 830: train_loss=0.18690285086631775
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 831: train_loss=0.18798187375068665
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 832: train_loss=0.18729335069656372
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 833: train_loss=0.18686600029468536
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 834: train_loss=0.18617403507232666
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 835: train_loss=0.18750117719173431
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 836: train_loss=0.1868070662021637
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 837: train_loss=0.18671193718910217
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 838: train_loss=0.18588054180145264
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 839: train_loss=0.1876918077468872
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 840: train_loss=0.1870548576116562
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 841: train_loss=0.18639805912971497
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 842: train_loss=0.18555423617362976
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 843: train_loss=0.18793249130249023
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 844: train_loss=0.18711483478546143
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 845: train_loss=0.18648871779441833
INFO - 04/15/25 16:35:59 - 0:04:22 - Epoch 846: train_loss=0.18580076098442078
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 847: train_loss=0.18745209276676178
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 848: train_loss=0.1866047978401184
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 849: train_loss=0.18670015037059784
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 850: train_loss=0.18603934347629547
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 851: train_loss=0.1870446354150772
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 852: train_loss=0.18636441230773926
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 853: train_loss=0.18652017414569855
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 854: train_loss=0.1857433021068573
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 855: train_loss=0.1871929168701172
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 856: train_loss=0.18659670650959015
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 857: train_loss=0.18594016134738922
INFO - 04/15/25 16:35:59 - 0:04:23 - Epoch 858: train_loss=0.1850990504026413
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 859: train_loss=0.18766652047634125
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 860: train_loss=0.1871107518672943
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 861: train_loss=0.18528252840042114
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 862: train_loss=0.18452191352844238
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 863: train_loss=0.1878894865512848
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 864: train_loss=0.1871783435344696
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 865: train_loss=0.18524816632270813
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 866: train_loss=0.1846195012331009
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 867: train_loss=0.18748356401920319
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 868: train_loss=0.18664366006851196
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 869: train_loss=0.18562987446784973
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 870: train_loss=0.18504969775676727
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 871: train_loss=0.18685242533683777
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 872: train_loss=0.18613049387931824
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 873: train_loss=0.18591943383216858
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 874: train_loss=0.18529419600963593
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 875: train_loss=0.1866116225719452
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 876: train_loss=0.18601490557193756
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 877: train_loss=0.18575501441955566
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 878: train_loss=0.18504607677459717
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 879: train_loss=0.18675775825977325
INFO - 04/15/25 16:36:00 - 0:04:23 - Epoch 880: train_loss=0.18620555102825165
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 881: train_loss=0.18538795411586761
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 882: train_loss=0.18462011218070984
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 883: train_loss=0.1870315819978714
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 884: train_loss=0.1864786148071289
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 885: train_loss=0.1849515438079834
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 886: train_loss=0.18422816693782806
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 887: train_loss=0.1872403770685196
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 888: train_loss=0.18668191134929657
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 889: train_loss=0.1846514344215393
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 890: train_loss=0.18402118980884552
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 891: train_loss=0.18720434606075287
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 892: train_loss=0.1865074634552002
INFO - 04/15/25 16:36:00 - 0:04:24 - Epoch 893: train_loss=0.18479646742343903
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 894: train_loss=0.18424589931964874
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 895: train_loss=0.18677563965320587
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 896: train_loss=0.18604806065559387
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 897: train_loss=0.1851285845041275
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 898: train_loss=0.18459515273571014
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 899: train_loss=0.18628816306591034
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 900: train_loss=0.18558409810066223
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 901: train_loss=0.18545641005039215
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 902: train_loss=0.18489085137844086
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 903: train_loss=0.18594728410243988
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 904: train_loss=0.18536151945590973
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 905: train_loss=0.18547038733959198
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 906: train_loss=0.1847931295633316
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 907: train_loss=0.18593765795230865
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 908: train_loss=0.18538808822631836
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 909: train_loss=0.18524177372455597
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 910: train_loss=0.18459400534629822
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 911: train_loss=0.18603026866912842
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 912: train_loss=0.1854349672794342
INFO - 04/15/25 16:36:01 - 0:04:24 - Epoch 913: train_loss=0.1851068139076233
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 914: train_loss=0.18449901044368744
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 915: train_loss=0.18588951230049133
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 916: train_loss=0.18520714342594147
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 917: train_loss=0.18528370559215546
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 918: train_loss=0.18469423055648804
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 919: train_loss=0.18557783961296082
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 920: train_loss=0.1849338263273239
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 921: train_loss=0.18531735241413116
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 922: train_loss=0.18473589420318604
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 923: train_loss=0.18550175428390503
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 924: train_loss=0.18495836853981018
INFO - 04/15/25 16:36:01 - 0:04:25 - Epoch 925: train_loss=0.18508067727088928
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 926: train_loss=0.18443338572978973
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 927: train_loss=0.18561266362667084
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 928: train_loss=0.18503467738628387
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 929: train_loss=0.18493632972240448
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 930: train_loss=0.18432053923606873
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 931: train_loss=0.18554000556468964
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 932: train_loss=0.18493199348449707
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 933: train_loss=0.1849517822265625
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 934: train_loss=0.1844177395105362
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 935: train_loss=0.18528302013874054
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 936: train_loss=0.1846681386232376
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 937: train_loss=0.18511371314525604
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 938: train_loss=0.1845889836549759
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 939: train_loss=0.18497735261917114
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 940: train_loss=0.18440108001232147
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 941: train_loss=0.18518415093421936
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 942: train_loss=0.18463820219039917
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 943: train_loss=0.1848852038383484
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 944: train_loss=0.1843561977148056
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 945: train_loss=0.18510831892490387
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 946: train_loss=0.18451452255249023
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 947: train_loss=0.1849011331796646
INFO - 04/15/25 16:36:02 - 0:04:25 - Epoch 948: train_loss=0.18431971967220306
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 949: train_loss=0.18502578139305115
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 950: train_loss=0.18452845513820648
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 951: train_loss=0.18475128710269928
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 952: train_loss=0.18420729041099548
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 953: train_loss=0.1850416660308838
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 954: train_loss=0.18449437618255615
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 955: train_loss=0.1845966875553131
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 956: train_loss=0.18394362926483154
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 957: train_loss=0.18936578929424286
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 958: train_loss=0.18641133606433868
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 959: train_loss=0.18658897280693054
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 960: train_loss=0.1874634474515915
INFO - 04/15/25 16:36:02 - 0:04:26 - Epoch 961: train_loss=0.18545836210250854
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 962: train_loss=0.18699638545513153
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 963: train_loss=0.18696971237659454
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 964: train_loss=0.1840435415506363
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 965: train_loss=0.19053716957569122
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 966: train_loss=0.18849141895771027
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 967: train_loss=0.18747515976428986
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 968: train_loss=0.1872275173664093
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 969: train_loss=0.18773773312568665
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 970: train_loss=0.18498140573501587
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 971: train_loss=0.1887720674276352
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 972: train_loss=0.1845235973596573
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 973: train_loss=0.1910628080368042
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 974: train_loss=0.1882198005914688
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 975: train_loss=0.19034363329410553
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 976: train_loss=0.19007880985736847
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 977: train_loss=0.18657410144805908
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 978: train_loss=0.1866133213043213
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 979: train_loss=0.18806958198547363
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 980: train_loss=0.18629565834999084
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 981: train_loss=0.18957608938217163
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 982: train_loss=0.18860357999801636
INFO - 04/15/25 16:36:03 - 0:04:26 - Epoch 983: train_loss=0.1876259595155716
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 984: train_loss=0.18689008057117462
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 985: train_loss=0.18854117393493652
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 986: train_loss=0.18717721104621887
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 987: train_loss=0.18851767480373383
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 988: train_loss=0.1879524439573288
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 989: train_loss=0.1869538426399231
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 990: train_loss=0.18603430688381195
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 991: train_loss=0.18872475624084473
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 992: train_loss=0.18738919496536255
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 993: train_loss=0.18788424134254456
INFO - 04/15/25 16:36:03 - 0:04:27 - Epoch 994: train_loss=0.18735046684741974
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 995: train_loss=0.1871054619550705
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 996: train_loss=0.18618731200695038
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 997: train_loss=0.18837237358093262
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 998: train_loss=0.1874280422925949
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 999: train_loss=0.18710674345493317
INFO - 04/15/25 16:36:04 - 0:04:27 - --------------------------Training Start-------------------------
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 1: train_loss=10.109613418579102
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 2: train_loss=10.224530220031738
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 3: train_loss=10.201655387878418
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 4: train_loss=10.148700714111328
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 5: train_loss=10.100454330444336
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 6: train_loss=10.119267463684082
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 7: train_loss=10.129229545593262
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 8: train_loss=10.12324333190918
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 9: train_loss=10.105012893676758
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 10: train_loss=10.084420204162598
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 11: train_loss=10.089723587036133
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 12: train_loss=10.096381187438965
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 13: train_loss=10.094593048095703
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 14: train_loss=10.087074279785156
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 15: train_loss=10.081477165222168
INFO - 04/15/25 16:36:04 - 0:04:27 - Epoch 16: train_loss=10.083285331726074
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 17: train_loss=10.083334922790527
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 18: train_loss=10.07888126373291
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 19: train_loss=10.075182914733887
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 20: train_loss=10.076828002929688
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 21: train_loss=10.076735496520996
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 22: train_loss=10.074176788330078
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 23: train_loss=10.071625709533691
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 24: train_loss=10.070239067077637
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 25: train_loss=10.069632530212402
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 26: train_loss=10.070634841918945
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 27: train_loss=10.070024490356445
INFO - 04/15/25 16:36:04 - 0:04:28 - Epoch 28: train_loss=10.06734848022461
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 29: train_loss=10.067907333374023
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 30: train_loss=10.069620132446289
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 31: train_loss=10.067561149597168
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 32: train_loss=10.068286895751953
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 33: train_loss=10.066947937011719
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 34: train_loss=10.064573287963867
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 35: train_loss=10.066736221313477
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 36: train_loss=10.066666603088379
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 37: train_loss=10.065953254699707
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 38: train_loss=10.06787395477295
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 39: train_loss=10.065972328186035
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 40: train_loss=10.066415786743164
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 41: train_loss=10.065194129943848
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 42: train_loss=10.063785552978516
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 43: train_loss=10.066288948059082
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 44: train_loss=10.064422607421875
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 45: train_loss=10.062735557556152
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 46: train_loss=10.065816879272461
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 47: train_loss=10.06674861907959
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 48: train_loss=10.062589645385742
INFO - 04/15/25 16:36:05 - 0:04:28 - Epoch 49: train_loss=10.06775188446045
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 50: train_loss=10.06314468383789
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 51: train_loss=10.067442893981934
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 52: train_loss=10.063836097717285
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 53: train_loss=10.064183235168457
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 54: train_loss=10.066340446472168
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 55: train_loss=10.063760757446289
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 56: train_loss=10.067072868347168
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 57: train_loss=10.06295108795166
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 58: train_loss=10.06800365447998
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 59: train_loss=10.06535530090332
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 60: train_loss=10.067167282104492
INFO - 04/15/25 16:36:05 - 0:04:29 - Epoch 61: train_loss=10.06711483001709
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 62: train_loss=10.06460189819336
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 63: train_loss=10.066500663757324
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 64: train_loss=10.063618659973145
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 65: train_loss=10.068861961364746
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 66: train_loss=10.066655158996582
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 67: train_loss=10.067316055297852
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 68: train_loss=10.067437171936035
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 69: train_loss=10.064526557922363
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 70: train_loss=10.064576148986816
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 71: train_loss=10.065221786499023
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 72: train_loss=10.064167022705078
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 73: train_loss=10.064988136291504
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 74: train_loss=10.064170837402344
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 75: train_loss=10.063942909240723
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 76: train_loss=10.064101219177246
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 77: train_loss=10.06358528137207
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 78: train_loss=10.062198638916016
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 79: train_loss=10.066301345825195
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 80: train_loss=10.062507629394531
INFO - 04/15/25 16:36:06 - 0:04:29 - Epoch 81: train_loss=10.071181297302246
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 82: train_loss=10.072365760803223
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 83: train_loss=10.061895370483398
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 84: train_loss=10.076213836669922
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 85: train_loss=10.081194877624512
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 86: train_loss=10.074241638183594
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 87: train_loss=10.064046859741211
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 88: train_loss=10.073237419128418
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 89: train_loss=10.074252128601074
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 90: train_loss=10.066365242004395
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 91: train_loss=10.070000648498535
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 92: train_loss=10.073853492736816
INFO - 04/15/25 16:36:06 - 0:04:30 - Epoch 93: train_loss=10.068452835083008
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 94: train_loss=10.066609382629395
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 95: train_loss=10.070001602172852
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 96: train_loss=10.064388275146484
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 97: train_loss=10.069249153137207
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 98: train_loss=10.071763038635254
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 99: train_loss=10.065226554870605
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 100: train_loss=10.06865119934082
INFO - 04/15/25 16:36:07 - 0:04:30 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:07 - 0:04:30 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:36:07 - 0:04:30 - ------------------Saving best model-------------------
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 100: ACC: 0.0, NMI: 0.2007426675878734, F1: 0.0, ARI: 0.01819378221789749
INFO - 04/15/25 16:36:07 - 0:04:30 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 101: train_loss=10.072003364562988
INFO - 04/15/25 16:36:07 - 0:04:30 - Epoch 102: train_loss=10.066255569458008
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 103: train_loss=10.066912651062012
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 104: train_loss=10.069984436035156
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 105: train_loss=10.065009117126465
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 106: train_loss=10.06749439239502
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 107: train_loss=10.069779396057129
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 108: train_loss=10.064645767211914
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 109: train_loss=10.068114280700684
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 110: train_loss=10.070143699645996
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 111: train_loss=10.065460205078125
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 112: train_loss=10.066829681396484
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 113: train_loss=10.06873607635498
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 114: train_loss=10.064361572265625
INFO - 04/15/25 16:36:07 - 0:04:31 - Epoch 115: train_loss=10.067235946655273
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 116: train_loss=10.068464279174805
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 117: train_loss=10.064116477966309
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 118: train_loss=10.067838668823242
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 119: train_loss=10.068497657775879
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 120: train_loss=10.065217971801758
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 121: train_loss=10.066585540771484
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 122: train_loss=10.06688404083252
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 123: train_loss=10.064373016357422
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 124: train_loss=10.066947937011719
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 125: train_loss=10.065476417541504
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 126: train_loss=10.065518379211426
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 127: train_loss=10.066584587097168
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 128: train_loss=10.063920974731445
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 129: train_loss=10.068808555603027
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 130: train_loss=10.068450927734375
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 131: train_loss=10.06768798828125
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 132: train_loss=10.062773704528809
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 133: train_loss=10.072117805480957
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 134: train_loss=10.068683624267578
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 135: train_loss=10.068469047546387
INFO - 04/15/25 16:36:08 - 0:04:31 - Epoch 136: train_loss=10.069162368774414
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 137: train_loss=10.064759254455566
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 138: train_loss=10.063714981079102
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 139: train_loss=10.069681167602539
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 140: train_loss=10.06801986694336
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 141: train_loss=10.065969467163086
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 142: train_loss=10.065861701965332
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 143: train_loss=10.066081047058105
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 144: train_loss=10.06441593170166
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 145: train_loss=10.068217277526855
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 146: train_loss=10.067718505859375
INFO - 04/15/25 16:36:08 - 0:04:32 - Epoch 147: train_loss=10.06357479095459
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 148: train_loss=10.062833786010742
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 149: train_loss=10.067806243896484
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 150: train_loss=10.066875457763672
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 151: train_loss=10.063911437988281
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 152: train_loss=10.06382942199707
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 153: train_loss=10.065526962280273
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 154: train_loss=10.064081192016602
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 155: train_loss=10.066082000732422
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 156: train_loss=10.06578540802002
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 157: train_loss=10.063337326049805
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 158: train_loss=10.06338119506836
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 159: train_loss=10.06466007232666
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 160: train_loss=10.062981605529785
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 161: train_loss=10.06661319732666
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 162: train_loss=10.066598892211914
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 163: train_loss=10.061854362487793
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 164: train_loss=10.067032814025879
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 165: train_loss=10.061223030090332
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 166: train_loss=10.074429512023926
INFO - 04/15/25 16:36:09 - 0:04:32 - Epoch 167: train_loss=10.076204299926758
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 168: train_loss=10.066216468811035
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 169: train_loss=10.072169303894043
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 170: train_loss=10.075488090515137
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 171: train_loss=10.069808959960938
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 172: train_loss=10.069271087646484
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 173: train_loss=10.069452285766602
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 174: train_loss=10.069625854492188
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 175: train_loss=10.06825065612793
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 176: train_loss=10.0653715133667
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 177: train_loss=10.068303108215332
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 178: train_loss=10.064728736877441
INFO - 04/15/25 16:36:09 - 0:04:33 - Epoch 179: train_loss=10.067390441894531
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 180: train_loss=10.068209648132324
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 181: train_loss=10.062804222106934
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 182: train_loss=10.066387176513672
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 183: train_loss=10.066316604614258
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 184: train_loss=10.06233024597168
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 185: train_loss=10.067220687866211
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 186: train_loss=10.066219329833984
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 187: train_loss=10.062583923339844
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 188: train_loss=10.063673973083496
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 189: train_loss=10.062346458435059
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 190: train_loss=10.063188552856445
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 191: train_loss=10.062628746032715
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 192: train_loss=10.063359260559082
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 193: train_loss=10.060803413391113
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 194: train_loss=10.06799030303955
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 195: train_loss=10.068236351013184
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 196: train_loss=10.062823295593262
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 197: train_loss=10.066254615783691
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 198: train_loss=10.067432403564453
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 199: train_loss=10.06258487701416
INFO - 04/15/25 16:36:10 - 0:04:33 - Epoch 200: train_loss=10.066036224365234
INFO - 04/15/25 16:36:10 - 0:04:33 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:10 - 0:04:34 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:36:10 - 0:04:34 - ------------------Saving best model-------------------
INFO - 04/15/25 16:36:13 - 0:04:36 - Epoch 200: ACC: 0.0, NMI: 0.2821829147371353, F1: 0.0, ARI: 0.04608685123393526
INFO - 04/15/25 16:36:13 - 0:04:36 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:13 - 0:04:36 - Epoch 201: train_loss=10.068062782287598
INFO - 04/15/25 16:36:13 - 0:04:36 - Epoch 202: train_loss=10.063009262084961
INFO - 04/15/25 16:36:13 - 0:04:36 - Epoch 203: train_loss=10.066394805908203
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 204: train_loss=10.069186210632324
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 205: train_loss=10.064543724060059
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 206: train_loss=10.064352035522461
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 207: train_loss=10.066651344299316
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 208: train_loss=10.064091682434082
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 209: train_loss=10.063380241394043
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 210: train_loss=10.064599990844727
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 211: train_loss=10.062309265136719
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 212: train_loss=10.064372062683105
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 213: train_loss=10.063583374023438
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 214: train_loss=10.06321907043457
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 215: train_loss=10.062941551208496
INFO - 04/15/25 16:36:13 - 0:04:37 - Epoch 216: train_loss=10.062649726867676
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 217: train_loss=10.062261581420898
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 218: train_loss=10.062765121459961
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 219: train_loss=10.062701225280762
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 220: train_loss=10.06019401550293
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 221: train_loss=10.06579875946045
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 222: train_loss=10.064976692199707
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 223: train_loss=10.063838005065918
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 224: train_loss=10.06314754486084
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 225: train_loss=10.063522338867188
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 226: train_loss=10.063020706176758
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 227: train_loss=10.06303596496582
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 228: train_loss=10.061015129089355
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 229: train_loss=10.065433502197266
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 230: train_loss=10.062976837158203
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 231: train_loss=10.06539535522461
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 232: train_loss=10.064558029174805
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 233: train_loss=10.064081192016602
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 234: train_loss=10.064053535461426
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 235: train_loss=10.06270980834961
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 236: train_loss=10.064308166503906
INFO - 04/15/25 16:36:14 - 0:04:37 - Epoch 237: train_loss=10.061470031738281
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 238: train_loss=10.06522274017334
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 239: train_loss=10.0615816116333
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 240: train_loss=10.065823554992676
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 241: train_loss=10.061833381652832
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 242: train_loss=10.067652702331543
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 243: train_loss=10.064958572387695
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 244: train_loss=10.06675910949707
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 245: train_loss=10.066397666931152
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 246: train_loss=10.064040184020996
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 247: train_loss=10.063711166381836
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 248: train_loss=10.065155982971191
INFO - 04/15/25 16:36:14 - 0:04:38 - Epoch 249: train_loss=10.062448501586914
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 250: train_loss=10.06678295135498
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 251: train_loss=10.064292907714844
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 252: train_loss=10.066728591918945
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 253: train_loss=10.066863059997559
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 254: train_loss=10.061941146850586
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 255: train_loss=10.063345909118652
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 256: train_loss=10.062304496765137
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 257: train_loss=10.062665939331055
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 258: train_loss=10.061378479003906
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 259: train_loss=10.06336784362793
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 260: train_loss=10.06091022491455
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 261: train_loss=10.064821243286133
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 262: train_loss=10.062710762023926
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 263: train_loss=10.064759254455566
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 264: train_loss=10.064852714538574
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 265: train_loss=10.060994148254395
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 266: train_loss=10.062593460083008
INFO - 04/15/25 16:36:15 - 0:04:38 - Epoch 267: train_loss=10.060782432556152
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 268: train_loss=10.060586929321289
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 269: train_loss=10.063149452209473
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 270: train_loss=10.059671401977539
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 271: train_loss=10.066617012023926
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 272: train_loss=10.06542682647705
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 273: train_loss=10.061980247497559
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 274: train_loss=10.062886238098145
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 275: train_loss=10.061643600463867
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 276: train_loss=10.061424255371094
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 277: train_loss=10.063069343566895
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 278: train_loss=10.06063175201416
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 279: train_loss=10.067076683044434
INFO - 04/15/25 16:36:15 - 0:04:39 - Epoch 280: train_loss=10.067208290100098
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 281: train_loss=10.059616088867188
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 282: train_loss=10.06482219696045
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 283: train_loss=10.062331199645996
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 284: train_loss=10.064688682556152
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 285: train_loss=10.063867568969727
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 286: train_loss=10.063057899475098
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 287: train_loss=10.063179016113281
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 288: train_loss=10.061542510986328
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 289: train_loss=10.06229019165039
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 290: train_loss=10.060234069824219
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 291: train_loss=10.063450813293457
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 292: train_loss=10.06053638458252
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 293: train_loss=10.064894676208496
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 294: train_loss=10.062480926513672
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 295: train_loss=10.064872741699219
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 296: train_loss=10.06375503540039
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 297: train_loss=10.0637788772583
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 298: train_loss=10.062976837158203
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 299: train_loss=10.062310218811035
INFO - 04/15/25 16:36:16 - 0:04:39 - Epoch 300: train_loss=10.061976432800293
INFO - 04/15/25 16:36:16 - 0:04:39 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:16 - 0:04:40 - Decoding cost time:  0.124 s
INFO - 04/15/25 16:36:16 - 0:04:40 - Epoch 300: ACC: 0.0, NMI: 0.2121432844509949, F1: 0.0, ARI: 0.03793267217629328
INFO - 04/15/25 16:36:16 - 0:04:40 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:16 - 0:04:40 - Epoch 301: train_loss=10.061893463134766
INFO - 04/15/25 16:36:16 - 0:04:40 - Epoch 302: train_loss=10.061704635620117
INFO - 04/15/25 16:36:16 - 0:04:40 - Epoch 303: train_loss=10.062299728393555
INFO - 04/15/25 16:36:16 - 0:04:40 - Epoch 304: train_loss=10.059504508972168
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 305: train_loss=10.067676544189453
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 306: train_loss=10.065950393676758
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 307: train_loss=10.06302261352539
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 308: train_loss=10.063369750976562
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 309: train_loss=10.062735557556152
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 310: train_loss=10.062888145446777
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 311: train_loss=10.06137466430664
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 312: train_loss=10.064046859741211
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 313: train_loss=10.061433792114258
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 314: train_loss=10.066129684448242
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 315: train_loss=10.064630508422852
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 316: train_loss=10.063315391540527
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 317: train_loss=10.063096046447754
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 318: train_loss=10.06309700012207
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 319: train_loss=10.061890602111816
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 320: train_loss=10.063323020935059
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 321: train_loss=10.061660766601562
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 322: train_loss=10.062798500061035
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 323: train_loss=10.06159496307373
INFO - 04/15/25 16:36:17 - 0:04:40 - Epoch 324: train_loss=10.062361717224121
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 325: train_loss=10.061373710632324
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 326: train_loss=10.061074256896973
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 327: train_loss=10.062214851379395
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 328: train_loss=10.05905532836914
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 329: train_loss=10.065970420837402
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 330: train_loss=10.063862800598145
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 331: train_loss=10.063139915466309
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 332: train_loss=10.062828063964844
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 333: train_loss=10.0629301071167
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 334: train_loss=10.062012672424316
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 335: train_loss=10.063135147094727
INFO - 04/15/25 16:36:17 - 0:04:41 - Epoch 336: train_loss=10.062150001525879
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 337: train_loss=10.062615394592285
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 338: train_loss=10.061655044555664
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 339: train_loss=10.063043594360352
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 340: train_loss=10.061644554138184
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 341: train_loss=10.063311576843262
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 342: train_loss=10.062407493591309
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 343: train_loss=10.061863899230957
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 344: train_loss=10.060972213745117
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 345: train_loss=10.06334114074707
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 346: train_loss=10.062004089355469
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 347: train_loss=10.062336921691895
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 348: train_loss=10.061367988586426
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 349: train_loss=10.062920570373535
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 350: train_loss=10.061349868774414
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 351: train_loss=10.062871932983398
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 352: train_loss=10.061655044555664
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 353: train_loss=10.06242847442627
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 354: train_loss=10.06153678894043
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 355: train_loss=10.063068389892578
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 356: train_loss=10.061760902404785
INFO - 04/15/25 16:36:18 - 0:04:41 - Epoch 357: train_loss=10.062369346618652
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 358: train_loss=10.061283111572266
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 359: train_loss=10.062559127807617
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 360: train_loss=10.060924530029297
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 361: train_loss=10.062856674194336
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 362: train_loss=10.062129974365234
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 363: train_loss=10.061026573181152
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 364: train_loss=10.060224533081055
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 365: train_loss=10.062067985534668
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 366: train_loss=10.060748100280762
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 367: train_loss=10.061835289001465
INFO - 04/15/25 16:36:18 - 0:04:42 - Epoch 368: train_loss=10.061047554016113
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 369: train_loss=10.060920715332031
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 370: train_loss=10.060362815856934
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 371: train_loss=10.060578346252441
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 372: train_loss=10.059361457824707
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 373: train_loss=10.061935424804688
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 374: train_loss=10.060897827148438
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 375: train_loss=10.060470581054688
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 376: train_loss=10.05950927734375
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 377: train_loss=10.061694145202637
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 378: train_loss=10.060822486877441
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 379: train_loss=10.060129165649414
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 380: train_loss=10.059247016906738
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 381: train_loss=10.06093692779541
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 382: train_loss=10.05993366241455
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 383: train_loss=10.05997371673584
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 384: train_loss=10.05897045135498
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 385: train_loss=10.06120491027832
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 386: train_loss=10.060126304626465
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 387: train_loss=10.05958080291748
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 388: train_loss=10.058858871459961
INFO - 04/15/25 16:36:19 - 0:04:42 - Epoch 389: train_loss=10.060341835021973
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 390: train_loss=10.059345245361328
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 391: train_loss=10.059782981872559
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 392: train_loss=10.058950424194336
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 393: train_loss=10.059089660644531
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 394: train_loss=10.058361053466797
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 395: train_loss=10.059643745422363
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 396: train_loss=10.058688163757324
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 397: train_loss=10.059332847595215
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 398: train_loss=10.058784484863281
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 399: train_loss=10.058198928833008
INFO - 04/15/25 16:36:19 - 0:04:43 - Epoch 400: train_loss=10.057343482971191
INFO - 04/15/25 16:36:19 - 0:04:43 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:20 - 0:04:43 - Decoding cost time:  0.133 s
INFO - 04/15/25 16:36:20 - 0:04:43 - ------------------Saving best model-------------------
INFO - 04/15/25 16:36:21 - 0:04:44 - Epoch 400: ACC: 0.0, NMI: 0.3417415192445756, F1: 0.0, ARI: 0.19579488403594228
INFO - 04/15/25 16:36:21 - 0:04:44 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:21 - 0:04:44 - Epoch 401: train_loss=10.059785842895508
INFO - 04/15/25 16:36:21 - 0:04:44 - Epoch 402: train_loss=10.059115409851074
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 403: train_loss=10.057398796081543
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 404: train_loss=10.05656909942627
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 405: train_loss=10.059863090515137
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 406: train_loss=10.059146881103516
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 407: train_loss=10.056714057922363
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 408: train_loss=10.055939674377441
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 409: train_loss=10.059669494628906
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 410: train_loss=10.058942794799805
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 411: train_loss=10.056230545043945
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 412: train_loss=10.055502891540527
INFO - 04/15/25 16:36:21 - 0:04:45 - Epoch 413: train_loss=10.059056282043457
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 414: train_loss=10.058390617370605
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 415: train_loss=10.05625057220459
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 416: train_loss=10.055534362792969
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 417: train_loss=10.058242797851562
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 418: train_loss=10.057462692260742
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 419: train_loss=10.056356430053711
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 420: train_loss=10.055760383605957
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 421: train_loss=10.057475090026855
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 422: train_loss=10.056879043579102
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 423: train_loss=10.055866241455078
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 424: train_loss=10.055118560791016
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 425: train_loss=10.057389259338379
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 426: train_loss=10.056832313537598
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 427: train_loss=10.055590629577637
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 428: train_loss=10.054980278015137
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 429: train_loss=10.056827545166016
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 430: train_loss=10.05588150024414
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 431: train_loss=10.056007385253906
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 432: train_loss=10.055541038513184
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 433: train_loss=10.055195808410645
INFO - 04/15/25 16:36:22 - 0:04:45 - Epoch 434: train_loss=10.054454803466797
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 435: train_loss=10.056900978088379
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 436: train_loss=10.055985450744629
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 437: train_loss=10.054869651794434
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 438: train_loss=10.054747581481934
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 439: train_loss=10.055346488952637
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 440: train_loss=10.053818702697754
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 441: train_loss=10.056962966918945
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 442: train_loss=10.056435585021973
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 443: train_loss=10.053841590881348
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 444: train_loss=10.054739952087402
INFO - 04/15/25 16:36:22 - 0:04:46 - Epoch 445: train_loss=10.05463981628418
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 446: train_loss=10.055397033691406
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 447: train_loss=10.055885314941406
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 448: train_loss=10.054938316345215
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 449: train_loss=10.053506851196289
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 450: train_loss=10.055035591125488
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 451: train_loss=10.055489540100098
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 452: train_loss=10.055804252624512
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 453: train_loss=10.052971839904785
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 454: train_loss=10.057842254638672
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 455: train_loss=10.054046630859375
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 456: train_loss=10.060275077819824
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 457: train_loss=10.060091972351074
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 458: train_loss=10.055502891540527
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 459: train_loss=10.058262825012207
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 460: train_loss=10.058368682861328
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 461: train_loss=10.052423477172852
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 462: train_loss=10.057077407836914
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 463: train_loss=10.054609298706055
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 464: train_loss=10.056221961975098
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 465: train_loss=10.056041717529297
INFO - 04/15/25 16:36:23 - 0:04:46 - Epoch 466: train_loss=10.053120613098145
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 467: train_loss=10.055102348327637
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 468: train_loss=10.052018165588379
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 469: train_loss=10.055435180664062
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 470: train_loss=10.052555084228516
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 471: train_loss=10.053008079528809
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 472: train_loss=10.054309844970703
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 473: train_loss=10.051433563232422
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 474: train_loss=10.053340911865234
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 475: train_loss=10.054163932800293
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 476: train_loss=10.051312446594238
INFO - 04/15/25 16:36:23 - 0:04:47 - Epoch 477: train_loss=10.0560941696167
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 478: train_loss=10.055129051208496
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 479: train_loss=10.055015563964844
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 480: train_loss=10.051980018615723
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 481: train_loss=10.057830810546875
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 482: train_loss=10.056692123413086
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 483: train_loss=10.054505348205566
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 484: train_loss=10.054182052612305
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 485: train_loss=10.053561210632324
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 486: train_loss=10.052528381347656
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 487: train_loss=10.054190635681152
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 488: train_loss=10.051279067993164
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 489: train_loss=10.055543899536133
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 490: train_loss=10.053595542907715
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 491: train_loss=10.0540771484375
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 492: train_loss=10.053288459777832
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 493: train_loss=10.052352905273438
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 494: train_loss=10.051104545593262
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 495: train_loss=10.05479907989502
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 496: train_loss=10.052895545959473
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 497: train_loss=10.054439544677734
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 498: train_loss=10.052976608276367
INFO - 04/15/25 16:36:24 - 0:04:47 - Epoch 499: train_loss=10.052103996276855
INFO - 04/15/25 16:36:24 - 0:04:48 - Epoch 500: train_loss=10.051321983337402
INFO - 04/15/25 16:36:24 - 0:04:48 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:24 - 0:04:48 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:36:24 - 0:04:48 - ------------------Saving best model-------------------
INFO - 04/15/25 16:36:25 - 0:04:49 - Epoch 500: ACC: 0.0, NMI: 0.3753505191488844, F1: 0.0, ARI: 0.239362217941912
INFO - 04/15/25 16:36:25 - 0:04:49 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:25 - 0:04:49 - Epoch 501: train_loss=10.054929733276367
INFO - 04/15/25 16:36:25 - 0:04:49 - Epoch 502: train_loss=10.052801132202148
INFO - 04/15/25 16:36:25 - 0:04:49 - Epoch 503: train_loss=10.052987098693848
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 504: train_loss=10.052725791931152
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 505: train_loss=10.050969123840332
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 506: train_loss=10.050661087036133
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 507: train_loss=10.05261516571045
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 508: train_loss=10.050699234008789
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 509: train_loss=10.051868438720703
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 510: train_loss=10.050738334655762
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 511: train_loss=10.050949096679688
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 512: train_loss=10.049626350402832
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 513: train_loss=10.052616119384766
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 514: train_loss=10.051430702209473
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 515: train_loss=10.051714897155762
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 516: train_loss=10.050704002380371
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 517: train_loss=10.05185317993164
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 518: train_loss=10.051126480102539
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 519: train_loss=10.051412582397461
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 520: train_loss=10.051750183105469
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 521: train_loss=10.050922393798828
INFO - 04/15/25 16:36:26 - 0:04:49 - Epoch 522: train_loss=10.049372673034668
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 523: train_loss=10.052776336669922
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 524: train_loss=10.05055046081543
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 525: train_loss=10.052255630493164
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 526: train_loss=10.0515718460083
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 527: train_loss=10.04967975616455
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 528: train_loss=10.049528121948242
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 529: train_loss=10.049084663391113
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 530: train_loss=10.048038482666016
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 531: train_loss=10.051465034484863
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 532: train_loss=10.048885345458984
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 533: train_loss=10.052488327026367
INFO - 04/15/25 16:36:26 - 0:04:50 - Epoch 534: train_loss=10.050957679748535
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 535: train_loss=10.04922866821289
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 536: train_loss=10.05127239227295
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 537: train_loss=10.048354148864746
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 538: train_loss=10.05285358428955
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 539: train_loss=10.052760124206543
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 540: train_loss=10.047704696655273
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 541: train_loss=10.050817489624023
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 542: train_loss=10.0495023727417
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 543: train_loss=10.047683715820312
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 544: train_loss=10.047002792358398
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 545: train_loss=10.052793502807617
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 546: train_loss=10.05008602142334
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 547: train_loss=10.050716400146484
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 548: train_loss=10.052496910095215
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 549: train_loss=10.049314498901367
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 550: train_loss=10.051087379455566
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 551: train_loss=10.051063537597656
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 552: train_loss=10.047667503356934
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 553: train_loss=10.054021835327148
INFO - 04/15/25 16:36:27 - 0:04:50 - Epoch 554: train_loss=10.05329418182373
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 555: train_loss=10.052095413208008
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 556: train_loss=10.048297882080078
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 557: train_loss=10.05335521697998
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 558: train_loss=10.048858642578125
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 559: train_loss=10.052831649780273
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 560: train_loss=10.052102088928223
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 561: train_loss=10.049578666687012
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 562: train_loss=10.05073070526123
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 563: train_loss=10.04834270477295
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 564: train_loss=10.05005931854248
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 565: train_loss=10.04699993133545
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 566: train_loss=10.050667762756348
INFO - 04/15/25 16:36:27 - 0:04:51 - Epoch 567: train_loss=10.048249244689941
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 568: train_loss=10.047359466552734
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 569: train_loss=10.047199249267578
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 570: train_loss=10.041163444519043
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 571: train_loss=10.03890323638916
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 572: train_loss=10.027608871459961
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 573: train_loss=10.02391242980957
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 574: train_loss=10.018498420715332
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 575: train_loss=10.01957893371582
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 576: train_loss=10.014854431152344
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 577: train_loss=10.01492691040039
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 578: train_loss=10.013006210327148
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 579: train_loss=10.013162612915039
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 580: train_loss=10.010083198547363
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 581: train_loss=10.014679908752441
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 582: train_loss=10.010904312133789
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 583: train_loss=10.014557838439941
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 584: train_loss=10.012303352355957
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 585: train_loss=10.014338493347168
INFO - 04/15/25 16:36:28 - 0:04:51 - Epoch 586: train_loss=10.011533737182617
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 587: train_loss=10.01404094696045
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 588: train_loss=10.010555267333984
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 589: train_loss=10.014996528625488
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 590: train_loss=10.012351989746094
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 591: train_loss=10.01379108428955
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 592: train_loss=10.01315689086914
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 593: train_loss=10.011850357055664
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 594: train_loss=10.01062297821045
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 595: train_loss=10.012577056884766
INFO - 04/15/25 16:36:28 - 0:04:52 - Epoch 596: train_loss=10.0106201171875
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 597: train_loss=10.012321472167969
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 598: train_loss=10.011362075805664
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 599: train_loss=10.010465621948242
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 600: train_loss=10.009539604187012
INFO - 04/15/25 16:36:29 - 0:04:52 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:29 - 0:04:52 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 600: ACC: 0.0, NMI: 0.2682300395654108, F1: 0.0, ARI: 0.1255727596419673
INFO - 04/15/25 16:36:29 - 0:04:52 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 601: train_loss=10.011391639709473
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 602: train_loss=10.008904457092285
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 603: train_loss=10.011945724487305
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 604: train_loss=10.00969409942627
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 605: train_loss=10.01209831237793
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 606: train_loss=10.010391235351562
INFO - 04/15/25 16:36:29 - 0:04:52 - Epoch 607: train_loss=10.00984001159668
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 608: train_loss=10.00894832611084
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 609: train_loss=10.010135650634766
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 610: train_loss=10.007608413696289
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 611: train_loss=10.009963989257812
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 612: train_loss=10.008597373962402
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 613: train_loss=10.00887680053711
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 614: train_loss=10.006843566894531
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 615: train_loss=10.007089614868164
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 616: train_loss=10.004463195800781
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 617: train_loss=10.006869316101074
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 618: train_loss=10.00396728515625
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 619: train_loss=9.996148109436035
INFO - 04/15/25 16:36:29 - 0:04:53 - Epoch 620: train_loss=9.998141288757324
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 621: train_loss=10.009814262390137
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 622: train_loss=10.033199310302734
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 623: train_loss=10.027301788330078
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 624: train_loss=10.016999244689941
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 625: train_loss=10.016072273254395
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 626: train_loss=10.0172119140625
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 627: train_loss=10.01281452178955
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 628: train_loss=10.008809089660645
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 629: train_loss=10.012603759765625
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 630: train_loss=10.009607315063477
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 631: train_loss=10.011312484741211
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 632: train_loss=10.008429527282715
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 633: train_loss=10.010743141174316
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 634: train_loss=10.006053924560547
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 635: train_loss=10.009896278381348
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 636: train_loss=10.007505416870117
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 637: train_loss=10.009588241577148
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 638: train_loss=10.008089065551758
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 639: train_loss=10.006783485412598
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 640: train_loss=10.008729934692383
INFO - 04/15/25 16:36:30 - 0:04:53 - Epoch 641: train_loss=10.003917694091797
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 642: train_loss=10.013915061950684
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 643: train_loss=10.013713836669922
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 644: train_loss=10.003538131713867
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 645: train_loss=10.009978294372559
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 646: train_loss=10.010475158691406
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 647: train_loss=10.003229141235352
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 648: train_loss=10.008245468139648
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 649: train_loss=10.009572982788086
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 650: train_loss=10.000999450683594
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 651: train_loss=10.007367134094238
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 652: train_loss=10.008702278137207
INFO - 04/15/25 16:36:30 - 0:04:54 - Epoch 653: train_loss=10.00089168548584
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 654: train_loss=9.991171836853027
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 655: train_loss=9.989969253540039
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 656: train_loss=9.973641395568848
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 657: train_loss=9.967597007751465
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 658: train_loss=9.963172912597656
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 659: train_loss=9.960156440734863
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 660: train_loss=9.961051940917969
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 661: train_loss=9.959126472473145
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 662: train_loss=9.9598388671875
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 663: train_loss=9.959343910217285
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 664: train_loss=9.95698356628418
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 665: train_loss=9.961195945739746
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 666: train_loss=9.957599639892578
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 667: train_loss=9.95948314666748
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 668: train_loss=9.957508087158203
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 669: train_loss=9.959213256835938
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 670: train_loss=9.954910278320312
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 671: train_loss=9.960999488830566
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 672: train_loss=9.956400871276855
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 673: train_loss=9.96004581451416
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 674: train_loss=9.956878662109375
INFO - 04/15/25 16:36:31 - 0:04:54 - Epoch 675: train_loss=9.95814037322998
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 676: train_loss=9.955180168151855
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 677: train_loss=9.959166526794434
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 678: train_loss=9.956829071044922
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 679: train_loss=9.956273078918457
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 680: train_loss=9.955223083496094
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 681: train_loss=9.954216003417969
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 682: train_loss=9.951301574707031
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 683: train_loss=9.949939727783203
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 684: train_loss=9.941926002502441
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 685: train_loss=9.935027122497559
INFO - 04/15/25 16:36:31 - 0:04:55 - Epoch 686: train_loss=9.925002098083496
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 687: train_loss=9.923027992248535
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 688: train_loss=9.895365715026855
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 689: train_loss=9.887408256530762
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 690: train_loss=9.884986877441406
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 691: train_loss=9.88957691192627
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 692: train_loss=9.885841369628906
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 693: train_loss=9.888816833496094
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 694: train_loss=9.888246536254883
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 695: train_loss=9.884599685668945
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 696: train_loss=9.884196281433105
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 697: train_loss=9.889065742492676
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 698: train_loss=9.884239196777344
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 699: train_loss=9.885053634643555
INFO - 04/15/25 16:36:32 - 0:04:55 - Epoch 700: train_loss=9.88149356842041
INFO - 04/15/25 16:36:32 - 0:04:55 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:32 - 0:04:55 - Decoding cost time:  0.124 s
INFO - 04/15/25 16:36:32 - 0:04:56 - ------------------Saving best model-------------------
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 700: ACC: 0.0, NMI: 0.4235576517141658, F1: 0.0, ARI: 0.2449387865820954
INFO - 04/15/25 16:36:33 - 0:04:56 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 701: train_loss=9.891006469726562
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 702: train_loss=9.888778686523438
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 703: train_loss=9.885700225830078
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 704: train_loss=9.887190818786621
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 705: train_loss=9.883532524108887
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 706: train_loss=9.890544891357422
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 707: train_loss=9.886788368225098
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 708: train_loss=9.88722038269043
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 709: train_loss=9.886937141418457
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 710: train_loss=9.882038116455078
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 711: train_loss=9.894407272338867
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 712: train_loss=9.891629219055176
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 713: train_loss=9.887630462646484
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 714: train_loss=9.885655403137207
INFO - 04/15/25 16:36:33 - 0:04:56 - Epoch 715: train_loss=9.888472557067871
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 716: train_loss=9.883170127868652
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 717: train_loss=9.888535499572754
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 718: train_loss=9.883197784423828
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 719: train_loss=9.870528221130371
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 720: train_loss=9.868471145629883
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 721: train_loss=9.879778861999512
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 722: train_loss=9.868603706359863
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 723: train_loss=9.875332832336426
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 724: train_loss=9.877480506896973
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 725: train_loss=9.861366271972656
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 726: train_loss=9.871110916137695
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 727: train_loss=9.859620094299316
INFO - 04/15/25 16:36:33 - 0:04:57 - Epoch 728: train_loss=9.849379539489746
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 729: train_loss=9.84775447845459
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 730: train_loss=9.847996711730957
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 731: train_loss=9.843161582946777
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 732: train_loss=9.846195220947266
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 733: train_loss=9.845269203186035
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 734: train_loss=9.842757225036621
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 735: train_loss=9.839241027832031
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 736: train_loss=9.841358184814453
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 737: train_loss=9.840970039367676
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 738: train_loss=9.846153259277344
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 739: train_loss=9.841352462768555
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 740: train_loss=9.840272903442383
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 741: train_loss=9.868490219116211
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 742: train_loss=9.84267807006836
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 743: train_loss=9.842146873474121
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 744: train_loss=9.838930130004883
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 745: train_loss=9.844134330749512
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 746: train_loss=9.840249061584473
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 747: train_loss=9.843591690063477
INFO - 04/15/25 16:36:34 - 0:04:57 - Epoch 748: train_loss=9.841184616088867
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 749: train_loss=9.84519100189209
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 750: train_loss=9.839479446411133
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 751: train_loss=9.845101356506348
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 752: train_loss=9.8416748046875
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 753: train_loss=9.834006309509277
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 754: train_loss=9.824986457824707
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 755: train_loss=9.808113098144531
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 756: train_loss=9.773242950439453
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 757: train_loss=9.77080249786377
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 758: train_loss=9.768750190734863
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 759: train_loss=9.769314765930176
INFO - 04/15/25 16:36:34 - 0:04:58 - Epoch 760: train_loss=9.764724731445312
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 761: train_loss=9.774937629699707
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 762: train_loss=9.77343463897705
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 763: train_loss=9.765236854553223
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 764: train_loss=9.773621559143066
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 765: train_loss=9.768800735473633
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 766: train_loss=9.773486137390137
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 767: train_loss=9.770100593566895
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 768: train_loss=9.772197723388672
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 769: train_loss=9.768567085266113
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 770: train_loss=9.765202522277832
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 771: train_loss=9.77587604522705
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 772: train_loss=9.766443252563477
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 773: train_loss=9.775581359863281
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 774: train_loss=9.771354675292969
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 775: train_loss=9.774078369140625
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 776: train_loss=9.768543243408203
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 777: train_loss=9.774389266967773
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 778: train_loss=9.769063949584961
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 779: train_loss=9.774466514587402
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 780: train_loss=9.76920223236084
INFO - 04/15/25 16:36:35 - 0:04:58 - Epoch 781: train_loss=9.772784233093262
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 782: train_loss=9.767537117004395
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 783: train_loss=9.779169082641602
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 784: train_loss=9.771488189697266
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 785: train_loss=9.778504371643066
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 786: train_loss=9.771799087524414
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 787: train_loss=9.775702476501465
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 788: train_loss=9.771699905395508
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 789: train_loss=9.773051261901855
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 790: train_loss=9.770814895629883
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 791: train_loss=9.772207260131836
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 792: train_loss=9.769250869750977
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 793: train_loss=9.769720077514648
INFO - 04/15/25 16:36:35 - 0:04:59 - Epoch 794: train_loss=9.76750373840332
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 795: train_loss=9.770231246948242
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 796: train_loss=9.768189430236816
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 797: train_loss=9.767186164855957
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 798: train_loss=9.764981269836426
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 799: train_loss=9.768242835998535
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 800: train_loss=9.766826629638672
INFO - 04/15/25 16:36:36 - 0:04:59 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:36 - 0:04:59 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 800: ACC: 0.0, NMI: 0.37407599071708214, F1: 0.0, ARI: 0.1730327371797264
INFO - 04/15/25 16:36:36 - 0:04:59 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 801: train_loss=9.763826370239258
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 802: train_loss=9.762188911437988
INFO - 04/15/25 16:36:36 - 0:04:59 - Epoch 803: train_loss=9.767316818237305
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 804: train_loss=9.766149520874023
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 805: train_loss=9.762386322021484
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 806: train_loss=9.760528564453125
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 807: train_loss=9.766044616699219
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 808: train_loss=9.764472007751465
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 809: train_loss=9.76185417175293
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 810: train_loss=9.760916709899902
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 811: train_loss=9.763373374938965
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 812: train_loss=9.761651992797852
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 813: train_loss=9.763821601867676
INFO - 04/15/25 16:36:36 - 0:05:00 - Epoch 814: train_loss=9.761375427246094
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 815: train_loss=9.764405250549316
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 816: train_loss=9.763129234313965
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 817: train_loss=9.76124095916748
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 818: train_loss=9.76066780090332
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 819: train_loss=9.762845993041992
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 820: train_loss=9.761110305786133
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 821: train_loss=9.763516426086426
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 822: train_loss=9.76274299621582
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 823: train_loss=9.760647773742676
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 824: train_loss=9.759796142578125
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 825: train_loss=9.762724876403809
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 826: train_loss=9.761240005493164
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 827: train_loss=9.761545181274414
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 828: train_loss=9.760891914367676
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 829: train_loss=9.760380744934082
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 830: train_loss=9.759182929992676
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 831: train_loss=9.762043952941895
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 832: train_loss=9.761249542236328
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 833: train_loss=9.759100914001465
INFO - 04/15/25 16:36:37 - 0:05:00 - Epoch 834: train_loss=9.758010864257812
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 835: train_loss=9.762166023254395
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 836: train_loss=9.761197090148926
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 837: train_loss=9.758145332336426
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 838: train_loss=9.757301330566406
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 839: train_loss=9.76149845123291
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 840: train_loss=9.760225296020508
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 841: train_loss=9.758719444274902
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 842: train_loss=9.75816535949707
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 843: train_loss=9.759628295898438
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 844: train_loss=9.758265495300293
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 845: train_loss=9.760181427001953
INFO - 04/15/25 16:36:37 - 0:05:01 - Epoch 846: train_loss=9.759331703186035
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 847: train_loss=9.758142471313477
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 848: train_loss=9.757709503173828
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 849: train_loss=9.758078575134277
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 850: train_loss=9.75646686553955
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 851: train_loss=9.759834289550781
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 852: train_loss=9.758208274841309
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 853: train_loss=9.757627487182617
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 854: train_loss=9.756914138793945
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 855: train_loss=9.757011413574219
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 856: train_loss=9.755127906799316
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 857: train_loss=9.758939743041992
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 858: train_loss=9.757933616638184
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 859: train_loss=9.754300117492676
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 860: train_loss=9.753223419189453
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 861: train_loss=9.758373260498047
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 862: train_loss=9.756139755249023
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 863: train_loss=9.755837440490723
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 864: train_loss=9.754844665527344
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 865: train_loss=9.75222396850586
INFO - 04/15/25 16:36:38 - 0:05:01 - Epoch 866: train_loss=9.752978324890137
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 867: train_loss=9.757871627807617
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 868: train_loss=9.752269744873047
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 869: train_loss=9.7621488571167
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 870: train_loss=9.758825302124023
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 871: train_loss=9.757020950317383
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 872: train_loss=9.755622863769531
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 873: train_loss=9.75385570526123
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 874: train_loss=9.759220123291016
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 875: train_loss=9.754416465759277
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 876: train_loss=9.753807067871094
INFO - 04/15/25 16:36:38 - 0:05:02 - Epoch 877: train_loss=9.752227783203125
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 878: train_loss=9.74788761138916
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 879: train_loss=9.747540473937988
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 880: train_loss=9.742366790771484
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 881: train_loss=9.738276481628418
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 882: train_loss=9.726943016052246
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 883: train_loss=9.722249984741211
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 884: train_loss=9.716730117797852
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 885: train_loss=9.760852813720703
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 886: train_loss=9.815412521362305
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 887: train_loss=9.769158363342285
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 888: train_loss=9.748818397521973
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 889: train_loss=9.770135879516602
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 890: train_loss=9.74619197845459
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 891: train_loss=9.759711265563965
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 892: train_loss=9.718883514404297
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 893: train_loss=9.75361442565918
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 894: train_loss=9.7073974609375
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 895: train_loss=9.699604034423828
INFO - 04/15/25 16:36:39 - 0:05:02 - Epoch 896: train_loss=9.687511444091797
INFO - 04/15/25 16:36:39 - 0:05:03 - Epoch 897: train_loss=9.667126655578613
INFO - 04/15/25 16:36:39 - 0:05:03 - Epoch 898: train_loss=9.668357849121094
INFO - 04/15/25 16:36:39 - 0:05:03 - Epoch 899: train_loss=9.660870552062988
INFO - 04/15/25 16:36:39 - 0:05:03 - Epoch 900: train_loss=9.653922080993652
INFO - 04/15/25 16:36:39 - 0:05:03 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:39 - 0:05:03 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 900: ACC: 0.0, NMI: 0.37075087414274577, F1: 0.0, ARI: 0.18626611350891825
INFO - 04/15/25 16:36:40 - 0:05:03 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 901: train_loss=9.654206275939941
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 902: train_loss=9.669890403747559
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 903: train_loss=9.666755676269531
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 904: train_loss=9.653230667114258
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 905: train_loss=9.660843849182129
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 906: train_loss=9.63833236694336
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 907: train_loss=9.640247344970703
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 908: train_loss=9.636655807495117
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 909: train_loss=9.638578414916992
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 910: train_loss=9.630669593811035
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 911: train_loss=9.638671875
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 912: train_loss=9.63504695892334
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 913: train_loss=9.625645637512207
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 914: train_loss=9.629791259765625
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 915: train_loss=9.622380256652832
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 916: train_loss=9.623064994812012
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 917: train_loss=9.616138458251953
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 918: train_loss=9.612068176269531
INFO - 04/15/25 16:36:40 - 0:05:03 - Epoch 919: train_loss=9.611979484558105
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 920: train_loss=9.606427192687988
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 921: train_loss=9.6126708984375
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 922: train_loss=9.607038497924805
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 923: train_loss=9.603114128112793
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 924: train_loss=9.614175796508789
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 925: train_loss=9.606852531433105
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 926: train_loss=9.613480567932129
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 927: train_loss=9.610551834106445
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 928: train_loss=9.607118606567383
INFO - 04/15/25 16:36:40 - 0:05:04 - Epoch 929: train_loss=9.604940414428711
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 930: train_loss=9.611209869384766
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 931: train_loss=9.605158805847168
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 932: train_loss=9.615629196166992
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 933: train_loss=9.61306381225586
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 934: train_loss=9.611289978027344
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 935: train_loss=9.609901428222656
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 936: train_loss=9.608299255371094
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 937: train_loss=9.604012489318848
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 938: train_loss=9.614531517028809
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 939: train_loss=9.61231803894043
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 940: train_loss=9.603714942932129
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 941: train_loss=9.604148864746094
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 942: train_loss=9.602712631225586
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 943: train_loss=9.600257873535156
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 944: train_loss=9.602195739746094
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 945: train_loss=9.597840309143066
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 946: train_loss=9.60253620147705
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 947: train_loss=9.598773002624512
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 948: train_loss=9.5980224609375
INFO - 04/15/25 16:36:41 - 0:05:04 - Epoch 949: train_loss=9.595292091369629
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 950: train_loss=9.59422779083252
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 951: train_loss=9.593122482299805
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 952: train_loss=9.591824531555176
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 953: train_loss=9.58806324005127
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 954: train_loss=9.595962524414062
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 955: train_loss=9.592626571655273
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 956: train_loss=9.587557792663574
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 957: train_loss=9.591923713684082
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 958: train_loss=9.586689949035645
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 959: train_loss=9.587611198425293
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 960: train_loss=9.584007263183594
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 961: train_loss=9.588263511657715
INFO - 04/15/25 16:36:41 - 0:05:05 - Epoch 962: train_loss=9.58564567565918
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 963: train_loss=9.58909797668457
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 964: train_loss=9.586854934692383
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 965: train_loss=9.592425346374512
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 966: train_loss=9.58336067199707
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 967: train_loss=9.57020092010498
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 968: train_loss=9.560676574707031
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 969: train_loss=9.545780181884766
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 970: train_loss=9.50395393371582
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 971: train_loss=9.495397567749023
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 972: train_loss=9.480351448059082
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 973: train_loss=9.465272903442383
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 974: train_loss=9.440213203430176
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 975: train_loss=9.422170639038086
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 976: train_loss=9.412064552307129
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 977: train_loss=9.415724754333496
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 978: train_loss=9.417976379394531
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 979: train_loss=9.419665336608887
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 980: train_loss=9.421626091003418
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 981: train_loss=9.4205904006958
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 982: train_loss=9.413414001464844
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 983: train_loss=9.417130470275879
INFO - 04/15/25 16:36:42 - 0:05:05 - Epoch 984: train_loss=9.422042846679688
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 985: train_loss=9.41824722290039
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 986: train_loss=9.423178672790527
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 987: train_loss=9.411286354064941
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 988: train_loss=9.416232109069824
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 989: train_loss=9.411737442016602
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 990: train_loss=9.40932846069336
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 991: train_loss=9.408191680908203
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 992: train_loss=9.409255027770996
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 993: train_loss=9.406166076660156
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 994: train_loss=9.403429985046387
INFO - 04/15/25 16:36:42 - 0:05:06 - Epoch 995: train_loss=9.416505813598633
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 996: train_loss=9.398699760437012
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 997: train_loss=9.411168098449707
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 998: train_loss=9.433563232421875
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 999: train_loss=9.42991828918457
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 1000: train_loss=9.423624038696289
INFO - 04/15/25 16:36:43 - 0:05:06 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:43 - 0:05:06 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 1000: ACC: 0.0, NMI: 0.3661153990409277, F1: 0.0, ARI: 0.13543301081555548
INFO - 04/15/25 16:36:43 - 0:05:06 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 1001: train_loss=9.424029350280762
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 1002: train_loss=9.409536361694336
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 1003: train_loss=9.42026138305664
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 1004: train_loss=9.3972806930542
INFO - 04/15/25 16:36:43 - 0:05:06 - Epoch 1005: train_loss=9.417388916015625
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1006: train_loss=9.388652801513672
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1007: train_loss=9.454134941101074
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1008: train_loss=9.4308500289917
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1009: train_loss=9.398266792297363
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1010: train_loss=9.409469604492188
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1011: train_loss=9.393404006958008
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1012: train_loss=9.390738487243652
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1013: train_loss=9.392094612121582
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1014: train_loss=9.401729583740234
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1015: train_loss=9.388176918029785
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1016: train_loss=9.39719009399414
INFO - 04/15/25 16:36:43 - 0:05:07 - Epoch 1017: train_loss=9.39260482788086
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1018: train_loss=9.392486572265625
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1019: train_loss=9.393537521362305
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1020: train_loss=9.390564918518066
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1021: train_loss=9.39276123046875
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1022: train_loss=9.38930892944336
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1023: train_loss=9.388684272766113
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1024: train_loss=9.391531944274902
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1025: train_loss=9.396717071533203
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1026: train_loss=9.390674591064453
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1027: train_loss=9.401618003845215
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1028: train_loss=9.394152641296387
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1029: train_loss=9.396943092346191
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1030: train_loss=9.390256881713867
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1031: train_loss=9.397429466247559
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1032: train_loss=9.393769264221191
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1033: train_loss=9.391471862792969
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1034: train_loss=9.38464069366455
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1035: train_loss=9.38122272491455
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1036: train_loss=9.400355339050293
INFO - 04/15/25 16:36:44 - 0:05:07 - Epoch 1037: train_loss=9.39414119720459
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1038: train_loss=9.388304710388184
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1039: train_loss=9.382533073425293
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1040: train_loss=9.38173770904541
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1041: train_loss=9.395736694335938
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1042: train_loss=9.392190933227539
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1043: train_loss=9.378103256225586
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1044: train_loss=9.347362518310547
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1045: train_loss=9.36901569366455
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1046: train_loss=9.36745548248291
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1047: train_loss=9.374470710754395
INFO - 04/15/25 16:36:44 - 0:05:08 - Epoch 1048: train_loss=9.340758323669434
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1049: train_loss=9.372640609741211
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1050: train_loss=9.347597122192383
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1051: train_loss=9.323843002319336
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1052: train_loss=9.289477348327637
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1053: train_loss=9.26845645904541
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1054: train_loss=9.217625617980957
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1055: train_loss=9.156523704528809
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1056: train_loss=9.084991455078125
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1057: train_loss=8.88555908203125
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1058: train_loss=8.737162590026855
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1059: train_loss=8.620680809020996
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1060: train_loss=8.592324256896973
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1061: train_loss=8.522073745727539
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1062: train_loss=8.571486473083496
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1063: train_loss=8.475920677185059
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1064: train_loss=8.51941967010498
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1065: train_loss=8.544486045837402
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1066: train_loss=8.6563720703125
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1067: train_loss=8.526243209838867
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1068: train_loss=8.539475440979004
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1069: train_loss=8.537280082702637
INFO - 04/15/25 16:36:45 - 0:05:08 - Epoch 1070: train_loss=8.542556762695312
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1071: train_loss=8.537203788757324
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1072: train_loss=8.528063774108887
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1073: train_loss=8.515236854553223
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1074: train_loss=8.508350372314453
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1075: train_loss=8.51032829284668
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1076: train_loss=8.510575294494629
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1077: train_loss=8.50759506225586
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1078: train_loss=8.498026847839355
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1079: train_loss=8.493758201599121
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1080: train_loss=8.493194580078125
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1081: train_loss=8.495063781738281
INFO - 04/15/25 16:36:45 - 0:05:09 - Epoch 1082: train_loss=8.488521575927734
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1083: train_loss=8.485552787780762
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1084: train_loss=8.485578536987305
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1085: train_loss=8.483190536499023
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1086: train_loss=8.480363845825195
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1087: train_loss=8.47805404663086
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1088: train_loss=8.4750337600708
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1089: train_loss=8.475770950317383
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1090: train_loss=8.473148345947266
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1091: train_loss=8.470832824707031
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1092: train_loss=8.467439651489258
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1093: train_loss=8.470091819763184
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1094: train_loss=8.453509330749512
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1095: train_loss=8.465097427368164
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1096: train_loss=8.463479042053223
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1097: train_loss=8.46198844909668
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1098: train_loss=8.461443901062012
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1099: train_loss=8.461918830871582
INFO - 04/15/25 16:36:46 - 0:05:09 - Epoch 1100: train_loss=8.461336135864258
INFO - 04/15/25 16:36:46 - 0:05:09 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:46 - 0:05:10 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:36:46 - 0:05:10 - ------------------Saving best model-------------------
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1100: ACC: 0.0, NMI: 0.4322312036619708, F1: 0.0, ARI: 0.21475074769918198
INFO - 04/15/25 16:36:47 - 0:05:10 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1101: train_loss=8.462481498718262
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1102: train_loss=8.460356712341309
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1103: train_loss=8.455402374267578
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1104: train_loss=8.465757369995117
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1105: train_loss=8.45865535736084
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1106: train_loss=8.46401596069336
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1107: train_loss=8.461104393005371
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1108: train_loss=8.456007957458496
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1109: train_loss=8.454140663146973
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1110: train_loss=8.461699485778809
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1111: train_loss=8.440513610839844
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1112: train_loss=8.453632354736328
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1113: train_loss=8.45785140991211
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1114: train_loss=8.459110260009766
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1115: train_loss=8.436494827270508
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1116: train_loss=8.458269119262695
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1117: train_loss=8.459465026855469
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1118: train_loss=8.451736450195312
INFO - 04/15/25 16:36:47 - 0:05:10 - Epoch 1119: train_loss=8.461129188537598
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1120: train_loss=8.455436706542969
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1121: train_loss=8.453378677368164
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1122: train_loss=8.460007667541504
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1123: train_loss=8.451410293579102
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1124: train_loss=8.45729923248291
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1125: train_loss=8.455562591552734
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1126: train_loss=8.451513290405273
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1127: train_loss=8.457329750061035
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1128: train_loss=8.452686309814453
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1129: train_loss=8.464329719543457
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1130: train_loss=8.494427680969238
INFO - 04/15/25 16:36:47 - 0:05:11 - Epoch 1131: train_loss=8.466964721679688
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1132: train_loss=8.464444160461426
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1133: train_loss=8.46776008605957
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1134: train_loss=8.461345672607422
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1135: train_loss=8.468690872192383
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1136: train_loss=8.470800399780273
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1137: train_loss=8.455381393432617
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1138: train_loss=8.46580696105957
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1139: train_loss=8.463249206542969
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1140: train_loss=8.461329460144043
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1141: train_loss=8.456437110900879
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1142: train_loss=8.455467224121094
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1143: train_loss=8.455471992492676
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1144: train_loss=8.45395278930664
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1145: train_loss=8.446743965148926
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1146: train_loss=8.453479766845703
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1147: train_loss=8.446120262145996
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1148: train_loss=8.446470260620117
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1149: train_loss=8.449593544006348
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1150: train_loss=8.44648551940918
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1151: train_loss=8.444074630737305
INFO - 04/15/25 16:36:48 - 0:05:11 - Epoch 1152: train_loss=8.444941520690918
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1153: train_loss=8.442358016967773
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1154: train_loss=8.4445161819458
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1155: train_loss=8.446822166442871
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1156: train_loss=8.440569877624512
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1157: train_loss=8.446499824523926
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1158: train_loss=8.443206787109375
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1159: train_loss=8.44180679321289
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1160: train_loss=8.444087982177734
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1161: train_loss=8.442809104919434
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1162: train_loss=8.440831184387207
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1163: train_loss=8.438515663146973
INFO - 04/15/25 16:36:48 - 0:05:12 - Epoch 1164: train_loss=8.438397407531738
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1165: train_loss=8.438754081726074
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1166: train_loss=8.440696716308594
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1167: train_loss=8.438752174377441
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1168: train_loss=8.448890686035156
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1169: train_loss=8.440780639648438
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1170: train_loss=8.455022811889648
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1171: train_loss=8.44959545135498
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1172: train_loss=8.449115753173828
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1173: train_loss=8.446627616882324
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1174: train_loss=8.450714111328125
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1175: train_loss=8.445789337158203
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1176: train_loss=8.450515747070312
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1177: train_loss=8.447796821594238
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1178: train_loss=8.448029518127441
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1179: train_loss=8.444411277770996
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1180: train_loss=8.450112342834473
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1181: train_loss=8.447728157043457
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1182: train_loss=8.446861267089844
INFO - 04/15/25 16:36:49 - 0:05:12 - Epoch 1183: train_loss=8.44377613067627
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1184: train_loss=8.448760032653809
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1185: train_loss=8.444830894470215
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1186: train_loss=8.449077606201172
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1187: train_loss=8.448284149169922
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1188: train_loss=8.439994812011719
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1189: train_loss=8.44055461883545
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1190: train_loss=8.448991775512695
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1191: train_loss=8.447078704833984
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1192: train_loss=8.437515258789062
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1193: train_loss=8.440107345581055
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1194: train_loss=8.439023971557617
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1195: train_loss=8.436861991882324
INFO - 04/15/25 16:36:49 - 0:05:13 - Epoch 1196: train_loss=8.440402030944824
INFO - 04/15/25 16:36:50 - 0:05:13 - Epoch 1197: train_loss=8.435591697692871
INFO - 04/15/25 16:36:50 - 0:05:13 - Epoch 1198: train_loss=8.446775436401367
INFO - 04/15/25 16:36:50 - 0:05:13 - Epoch 1199: train_loss=8.446383476257324
INFO - 04/15/25 16:36:50 - 0:05:13 - Epoch 1200: train_loss=8.43503475189209
INFO - 04/15/25 16:36:50 - 0:05:13 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:36:50 - 0:05:13 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:36:50 - 0:05:13 - ------------------Saving best model-------------------
INFO - 04/15/25 16:36:56 - 0:05:19 - Epoch 1200: ACC: 0.0, NMI: 0.4967336357584623, F1: 0.0, ARI: 0.3331653149608203
INFO - 04/15/25 16:36:56 - 0:05:19 - -------------------------------------------------------------------------
INFO - 04/15/25 16:36:56 - 0:05:19 - Epoch 1201: train_loss=8.443796157836914
INFO - 04/15/25 16:36:56 - 0:05:19 - Epoch 1202: train_loss=8.442813873291016
INFO - 04/15/25 16:36:56 - 0:05:19 - Epoch 1203: train_loss=8.436640739440918
INFO - 04/15/25 16:36:56 - 0:05:19 - Epoch 1204: train_loss=8.439433097839355
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1205: train_loss=8.438400268554688
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1206: train_loss=8.438873291015625
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1207: train_loss=8.43687629699707
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1208: train_loss=8.439004898071289
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1209: train_loss=8.437211990356445
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1210: train_loss=8.435365676879883
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1211: train_loss=8.434616088867188
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1212: train_loss=8.435686111450195
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1213: train_loss=8.432670593261719
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1214: train_loss=8.43781566619873
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1215: train_loss=8.435832023620605
INFO - 04/15/25 16:36:56 - 0:05:20 - Epoch 1216: train_loss=8.434093475341797
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1217: train_loss=8.434993743896484
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1218: train_loss=8.433162689208984
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1219: train_loss=8.430676460266113
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1220: train_loss=8.438965797424316
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1221: train_loss=8.435023307800293
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1222: train_loss=8.439762115478516
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1223: train_loss=8.438589096069336
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1224: train_loss=8.438813209533691
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1225: train_loss=8.444655418395996
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1226: train_loss=8.425541877746582
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1227: train_loss=8.457916259765625
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1228: train_loss=8.449912071228027
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1229: train_loss=8.448872566223145
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1230: train_loss=8.443757057189941
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1231: train_loss=8.446683883666992
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1232: train_loss=8.448129653930664
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1233: train_loss=8.445545196533203
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1234: train_loss=8.451231956481934
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1235: train_loss=8.444559097290039
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1236: train_loss=8.452384948730469
INFO - 04/15/25 16:36:57 - 0:05:20 - Epoch 1237: train_loss=8.449172019958496
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1238: train_loss=8.445270538330078
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1239: train_loss=8.44361400604248
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1240: train_loss=8.446426391601562
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1241: train_loss=8.445029258728027
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1242: train_loss=8.437992095947266
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1243: train_loss=8.438859939575195
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1244: train_loss=8.442787170410156
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1245: train_loss=8.440085411071777
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1246: train_loss=8.439997673034668
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1247: train_loss=8.43943977355957
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1248: train_loss=8.436677932739258
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1249: train_loss=8.435354232788086
INFO - 04/15/25 16:36:57 - 0:05:21 - Epoch 1250: train_loss=8.438441276550293
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1251: train_loss=8.436470031738281
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1252: train_loss=8.436543464660645
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1253: train_loss=8.43588638305664
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1254: train_loss=8.434276580810547
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1255: train_loss=8.435153007507324
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1256: train_loss=8.431902885437012
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1257: train_loss=8.43410587310791
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1258: train_loss=8.430224418640137
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1259: train_loss=8.43482780456543
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1260: train_loss=8.430831909179688
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1261: train_loss=8.43599796295166
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1262: train_loss=8.434621810913086
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1263: train_loss=8.432112693786621
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1264: train_loss=8.429573059082031
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1265: train_loss=8.431175231933594
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1266: train_loss=8.463354110717773
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1267: train_loss=8.430892944335938
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1268: train_loss=8.429327011108398
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1269: train_loss=8.443818092346191
INFO - 04/15/25 16:36:58 - 0:05:21 - Epoch 1270: train_loss=8.499265670776367
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1271: train_loss=8.645084381103516
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1272: train_loss=8.605106353759766
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1273: train_loss=8.57503890991211
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1274: train_loss=8.592313766479492
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1275: train_loss=8.548402786254883
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1276: train_loss=8.58735179901123
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1277: train_loss=8.569734573364258
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1278: train_loss=8.530193328857422
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1279: train_loss=8.540456771850586
INFO - 04/15/25 16:36:58 - 0:05:22 - Epoch 1280: train_loss=8.734964370727539
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1281: train_loss=8.529406547546387
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1282: train_loss=8.514616966247559
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1283: train_loss=8.539981842041016
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1284: train_loss=8.622076988220215
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1285: train_loss=8.644611358642578
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1286: train_loss=8.7431001663208
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1287: train_loss=8.592766761779785
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1288: train_loss=8.543140411376953
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1289: train_loss=8.557210922241211
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1290: train_loss=8.663016319274902
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1291: train_loss=8.614028930664062
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1292: train_loss=8.591631889343262
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1293: train_loss=8.587133407592773
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1294: train_loss=8.582671165466309
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1295: train_loss=8.573278427124023
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1296: train_loss=8.567867279052734
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1297: train_loss=8.571837425231934
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1298: train_loss=8.559293746948242
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1299: train_loss=8.582027435302734
INFO - 04/15/25 16:36:59 - 0:05:22 - Epoch 1300: train_loss=8.55809497833252
INFO - 04/15/25 16:36:59 - 0:05:22 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:00 - 0:05:23 - Decoding cost time:  0.446 s
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1300: ACC: 0.0, NMI: 0.41841151929805565, F1: 0.0, ARI: 0.2220793084408848
INFO - 04/15/25 16:37:00 - 0:05:23 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1301: train_loss=8.555841445922852
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1302: train_loss=8.549432754516602
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1303: train_loss=8.53238296508789
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1304: train_loss=8.525093078613281
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1305: train_loss=8.521374702453613
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1306: train_loss=8.596640586853027
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1307: train_loss=8.526766777038574
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1308: train_loss=8.523236274719238
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1309: train_loss=8.67896842956543
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1310: train_loss=8.532011032104492
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1311: train_loss=8.531526565551758
INFO - 04/15/25 16:37:00 - 0:05:23 - Epoch 1312: train_loss=8.542387962341309
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1313: train_loss=8.53929328918457
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1314: train_loss=8.53480339050293
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1315: train_loss=8.534899711608887
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1316: train_loss=8.534122467041016
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1317: train_loss=8.533037185668945
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1318: train_loss=8.536445617675781
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1319: train_loss=8.532989501953125
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1320: train_loss=8.525979995727539
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1321: train_loss=8.532550811767578
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1322: train_loss=8.52450942993164
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1323: train_loss=8.525899887084961
INFO - 04/15/25 16:37:00 - 0:05:24 - Epoch 1324: train_loss=8.522332191467285
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1325: train_loss=8.518172264099121
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1326: train_loss=8.51628589630127
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1327: train_loss=8.515649795532227
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1328: train_loss=8.509692192077637
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1329: train_loss=8.507349014282227
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1330: train_loss=8.518000602722168
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1331: train_loss=8.510841369628906
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1332: train_loss=8.521161079406738
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1333: train_loss=8.507622718811035
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1334: train_loss=8.526177406311035
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1335: train_loss=8.521246910095215
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1336: train_loss=8.51161003112793
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1337: train_loss=8.50862979888916
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1338: train_loss=8.516636848449707
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1339: train_loss=8.510334968566895
INFO - 04/15/25 16:37:01 - 0:05:24 - Epoch 1340: train_loss=8.515710830688477
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1341: train_loss=8.511857032775879
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1342: train_loss=8.509931564331055
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1343: train_loss=8.510143280029297
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1344: train_loss=8.502362251281738
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1345: train_loss=8.497659683227539
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1346: train_loss=8.51125431060791
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1347: train_loss=8.507207870483398
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1348: train_loss=8.49997615814209
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1349: train_loss=8.4986572265625
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1350: train_loss=8.499085426330566
INFO - 04/15/25 16:37:01 - 0:05:25 - Epoch 1351: train_loss=8.49379825592041
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1352: train_loss=8.503678321838379
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1353: train_loss=8.501114845275879
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1354: train_loss=8.492398262023926
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1355: train_loss=8.493606567382812
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1356: train_loss=8.492715835571289
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1357: train_loss=8.489097595214844
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1358: train_loss=8.495037078857422
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1359: train_loss=8.492115020751953
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1360: train_loss=8.492663383483887
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1361: train_loss=8.491369247436523
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1362: train_loss=8.487607955932617
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1363: train_loss=8.486279487609863
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1364: train_loss=8.489355087280273
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1365: train_loss=8.485840797424316
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1366: train_loss=8.489910125732422
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1367: train_loss=8.488632202148438
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1368: train_loss=8.483912467956543
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1369: train_loss=8.474909782409668
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1370: train_loss=8.490257263183594
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1371: train_loss=8.488176345825195
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1372: train_loss=8.481661796569824
INFO - 04/15/25 16:37:02 - 0:05:25 - Epoch 1373: train_loss=8.480450630187988
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1374: train_loss=8.486209869384766
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1375: train_loss=8.482848167419434
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1376: train_loss=8.48552417755127
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1377: train_loss=8.484437942504883
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1378: train_loss=8.480656623840332
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1379: train_loss=8.478490829467773
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1380: train_loss=8.484959602355957
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1381: train_loss=8.48339557647705
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1382: train_loss=8.479673385620117
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1383: train_loss=8.478338241577148
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1384: train_loss=8.483464241027832
INFO - 04/15/25 16:37:02 - 0:05:26 - Epoch 1385: train_loss=8.4808988571167
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1386: train_loss=8.482598304748535
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1387: train_loss=8.481646537780762
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1388: train_loss=8.481138229370117
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1389: train_loss=8.47883415222168
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1390: train_loss=8.4844331741333
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1391: train_loss=8.484504699707031
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1392: train_loss=8.479217529296875
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1393: train_loss=8.479008674621582
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1394: train_loss=8.482522010803223
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1395: train_loss=8.480612754821777
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1396: train_loss=8.482121467590332
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1397: train_loss=8.481287002563477
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1398: train_loss=8.480120658874512
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1399: train_loss=8.478246688842773
INFO - 04/15/25 16:37:03 - 0:05:26 - Epoch 1400: train_loss=8.482200622558594
INFO - 04/15/25 16:37:03 - 0:05:26 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:03 - 0:05:26 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1400: ACC: 0.0, NMI: 0.3762095736161802, F1: 0.0, ARI: 0.150414498016442
INFO - 04/15/25 16:37:03 - 0:05:27 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1401: train_loss=8.480398178100586
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1402: train_loss=8.480152130126953
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1403: train_loss=8.478471755981445
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1404: train_loss=8.480175018310547
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1405: train_loss=8.478187561035156
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1406: train_loss=8.480916976928711
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1407: train_loss=8.479538917541504
INFO - 04/15/25 16:37:03 - 0:05:27 - Epoch 1408: train_loss=8.478395462036133
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1409: train_loss=8.477535247802734
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1410: train_loss=8.479621887207031
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1411: train_loss=8.46539306640625
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1412: train_loss=8.481385231018066
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1413: train_loss=8.479561805725098
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1414: train_loss=8.477718353271484
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1415: train_loss=8.480420112609863
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1416: train_loss=8.4764404296875
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1417: train_loss=8.479900360107422
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1418: train_loss=8.478265762329102
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1419: train_loss=8.477596282958984
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1420: train_loss=8.477227210998535
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1421: train_loss=8.47808837890625
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1422: train_loss=8.475013732910156
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1423: train_loss=8.479660034179688
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1424: train_loss=8.478632926940918
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1425: train_loss=8.475057601928711
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1426: train_loss=8.4793701171875
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1427: train_loss=8.475931167602539
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1428: train_loss=8.480256080627441
INFO - 04/15/25 16:37:04 - 0:05:27 - Epoch 1429: train_loss=8.478352546691895
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1430: train_loss=8.477998733520508
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1431: train_loss=8.478597640991211
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1432: train_loss=8.477469444274902
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1433: train_loss=8.477734565734863
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1434: train_loss=8.476491928100586
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1435: train_loss=8.477091789245605
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1436: train_loss=8.475436210632324
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1437: train_loss=8.473625183105469
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1438: train_loss=8.479841232299805
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1439: train_loss=8.478504180908203
INFO - 04/15/25 16:37:04 - 0:05:28 - Epoch 1440: train_loss=8.4767427444458
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1441: train_loss=8.474156379699707
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1442: train_loss=8.47680950164795
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1443: train_loss=8.472101211547852
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1444: train_loss=8.472214698791504
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1445: train_loss=8.476156234741211
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1446: train_loss=8.472221374511719
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1447: train_loss=8.478615760803223
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1448: train_loss=8.4781494140625
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1449: train_loss=8.475339889526367
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1450: train_loss=8.473265647888184
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1451: train_loss=8.475794792175293
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1452: train_loss=8.473368644714355
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1453: train_loss=8.473384857177734
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1454: train_loss=8.473740577697754
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1455: train_loss=8.471643447875977
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1456: train_loss=8.475876808166504
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1457: train_loss=8.47313117980957
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1458: train_loss=8.477592468261719
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1459: train_loss=8.476912498474121
INFO - 04/15/25 16:37:05 - 0:05:28 - Epoch 1460: train_loss=8.47468376159668
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1461: train_loss=8.475868225097656
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1462: train_loss=8.473332405090332
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1463: train_loss=8.475547790527344
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1464: train_loss=8.473505020141602
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1465: train_loss=8.47745418548584
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1466: train_loss=8.475611686706543
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1467: train_loss=8.475576400756836
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1468: train_loss=8.474681854248047
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1469: train_loss=8.475420951843262
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1470: train_loss=8.473126411437988
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1471: train_loss=8.474645614624023
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1472: train_loss=8.473094940185547
INFO - 04/15/25 16:37:05 - 0:05:29 - Epoch 1473: train_loss=8.472687721252441
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1474: train_loss=8.4730863571167
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1475: train_loss=8.472070693969727
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1476: train_loss=8.473143577575684
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1477: train_loss=8.472203254699707
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1478: train_loss=8.475398063659668
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1479: train_loss=8.470949172973633
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1480: train_loss=8.480012893676758
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1481: train_loss=8.479646682739258
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1482: train_loss=8.47238540649414
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1483: train_loss=8.476751327514648
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1484: train_loss=8.473623275756836
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1485: train_loss=8.474283218383789
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1486: train_loss=8.474264144897461
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1487: train_loss=8.470928192138672
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1488: train_loss=8.472983360290527
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1489: train_loss=8.469709396362305
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1490: train_loss=8.475056648254395
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1491: train_loss=8.474211692810059
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1492: train_loss=8.469013214111328
INFO - 04/15/25 16:37:06 - 0:05:29 - Epoch 1493: train_loss=8.474533081054688
INFO - 04/15/25 16:37:06 - 0:05:30 - Epoch 1494: train_loss=8.4722318649292
INFO - 04/15/25 16:37:06 - 0:05:30 - Epoch 1495: train_loss=8.472624778747559
INFO - 04/15/25 16:37:06 - 0:05:30 - Epoch 1496: train_loss=8.47214126586914
INFO - 04/15/25 16:37:06 - 0:05:30 - Epoch 1497: train_loss=8.45738697052002
INFO - 04/15/25 16:37:06 - 0:05:30 - Epoch 1498: train_loss=8.469403266906738
INFO - 04/15/25 16:37:06 - 0:05:30 - Epoch 1499: train_loss=8.475625991821289
INFO - 04/15/25 16:37:06 - 0:05:30 - Epoch 1500: train_loss=8.476298332214355
INFO - 04/15/25 16:37:06 - 0:05:30 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:06 - 0:05:30 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1500: ACC: 0.0, NMI: 0.4678746978653826, F1: 0.0, ARI: 0.25027653203891104
INFO - 04/15/25 16:37:07 - 0:05:30 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1501: train_loss=8.470369338989258
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1502: train_loss=8.481268882751465
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1503: train_loss=8.476349830627441
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1504: train_loss=8.480513572692871
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1505: train_loss=8.477604866027832
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1506: train_loss=8.478615760803223
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1507: train_loss=8.474720001220703
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1508: train_loss=8.481087684631348
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1509: train_loss=8.477750778198242
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1510: train_loss=8.479257583618164
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1511: train_loss=8.478285789489746
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1512: train_loss=8.475875854492188
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1513: train_loss=8.466768264770508
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1514: train_loss=8.479357719421387
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1515: train_loss=8.475752830505371
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1516: train_loss=8.47636604309082
INFO - 04/15/25 16:37:07 - 0:05:30 - Epoch 1517: train_loss=8.477002143859863
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1518: train_loss=8.475179672241211
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1519: train_loss=8.49312973022461
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1520: train_loss=8.479409217834473
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1521: train_loss=8.478986740112305
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1522: train_loss=8.481367111206055
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1523: train_loss=8.482439041137695
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1524: train_loss=8.491510391235352
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1525: train_loss=8.487922668457031
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1526: train_loss=8.509231567382812
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1527: train_loss=8.480281829833984
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1528: train_loss=8.476771354675293
INFO - 04/15/25 16:37:07 - 0:05:31 - Epoch 1529: train_loss=8.483874320983887
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1530: train_loss=8.489394187927246
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1531: train_loss=8.486120223999023
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1532: train_loss=8.486875534057617
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1533: train_loss=8.47399616241455
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1534: train_loss=8.488784790039062
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1535: train_loss=8.488616943359375
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1536: train_loss=8.476933479309082
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1537: train_loss=8.484508514404297
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1538: train_loss=8.489219665527344
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1539: train_loss=8.482596397399902
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1540: train_loss=8.473186492919922
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1541: train_loss=8.476396560668945
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1542: train_loss=8.476027488708496
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1543: train_loss=8.472689628601074
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1544: train_loss=8.474862098693848
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1545: train_loss=8.472115516662598
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1546: train_loss=8.471693992614746
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1547: train_loss=8.472137451171875
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1548: train_loss=8.470582962036133
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1549: train_loss=8.471487045288086
INFO - 04/15/25 16:37:08 - 0:05:31 - Epoch 1550: train_loss=8.470473289489746
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1551: train_loss=8.47118854522705
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1552: train_loss=8.470002174377441
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1553: train_loss=8.46832275390625
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1554: train_loss=8.471236228942871
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1555: train_loss=8.47004222869873
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1556: train_loss=8.469193458557129
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1557: train_loss=8.46838665008545
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1558: train_loss=8.468368530273438
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1559: train_loss=8.4667329788208
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1560: train_loss=8.468088150024414
INFO - 04/15/25 16:37:08 - 0:05:32 - Epoch 1561: train_loss=8.465652465820312
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1562: train_loss=8.470013618469238
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1563: train_loss=8.468433380126953
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1564: train_loss=8.46700382232666
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1565: train_loss=8.469939231872559
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1566: train_loss=8.467117309570312
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1567: train_loss=8.457794189453125
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1568: train_loss=8.469330787658691
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1569: train_loss=8.464815139770508
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1570: train_loss=8.469541549682617
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1571: train_loss=8.472075462341309
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1572: train_loss=8.475545883178711
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1573: train_loss=8.473823547363281
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1574: train_loss=8.471280097961426
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1575: train_loss=8.475517272949219
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1576: train_loss=8.475932121276855
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1577: train_loss=8.474388122558594
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1578: train_loss=8.474333763122559
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1579: train_loss=8.476383209228516
INFO - 04/15/25 16:37:09 - 0:05:32 - Epoch 1580: train_loss=8.472161293029785
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1581: train_loss=8.45762825012207
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1582: train_loss=8.480149269104004
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1583: train_loss=8.474298477172852
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1584: train_loss=8.476092338562012
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1585: train_loss=8.473678588867188
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1586: train_loss=8.47252082824707
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1587: train_loss=8.468572616577148
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1588: train_loss=8.470110893249512
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1589: train_loss=8.471092224121094
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1590: train_loss=8.475021362304688
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1591: train_loss=8.469819068908691
INFO - 04/15/25 16:37:09 - 0:05:33 - Epoch 1592: train_loss=8.470404624938965
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1593: train_loss=8.470938682556152
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1594: train_loss=8.470161437988281
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1595: train_loss=8.469236373901367
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1596: train_loss=8.45880126953125
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1597: train_loss=8.457269668579102
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1598: train_loss=8.467022895812988
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1599: train_loss=8.457334518432617
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1600: train_loss=8.472451210021973
INFO - 04/15/25 16:37:10 - 0:05:33 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:10 - 0:05:33 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1600: ACC: 0.0, NMI: 0.4695956675647216, F1: 0.0, ARI: 0.2503070788596376
INFO - 04/15/25 16:37:10 - 0:05:33 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1601: train_loss=8.466796875
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1602: train_loss=8.466060638427734
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1603: train_loss=8.476167678833008
INFO - 04/15/25 16:37:10 - 0:05:33 - Epoch 1604: train_loss=8.466402053833008
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1605: train_loss=8.481687545776367
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1606: train_loss=8.47824764251709
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1607: train_loss=8.469586372375488
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1608: train_loss=8.468971252441406
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1609: train_loss=8.47164249420166
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1610: train_loss=8.467432022094727
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1611: train_loss=8.477337837219238
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1612: train_loss=8.475590705871582
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1613: train_loss=8.459294319152832
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1614: train_loss=8.46794605255127
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1615: train_loss=8.4736967086792
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1616: train_loss=8.471013069152832
INFO - 04/15/25 16:37:10 - 0:05:34 - Epoch 1617: train_loss=8.466672897338867
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1618: train_loss=8.465673446655273
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1619: train_loss=8.466784477233887
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1620: train_loss=8.464042663574219
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1621: train_loss=8.467020988464355
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1622: train_loss=8.472354888916016
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1623: train_loss=8.463828086853027
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1624: train_loss=8.462031364440918
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1625: train_loss=8.464042663574219
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1626: train_loss=8.450627326965332
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1627: train_loss=8.448200225830078
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1628: train_loss=8.44451904296875
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1629: train_loss=8.461560249328613
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1630: train_loss=8.458243370056152
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1631: train_loss=8.462615013122559
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1632: train_loss=8.445881843566895
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1633: train_loss=8.458735466003418
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1634: train_loss=8.458189010620117
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1635: train_loss=8.458821296691895
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1636: train_loss=8.660110473632812
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1637: train_loss=8.94197940826416
INFO - 04/15/25 16:37:11 - 0:05:34 - Epoch 1638: train_loss=9.082003593444824
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1639: train_loss=8.869701385498047
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1640: train_loss=8.720145225524902
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1641: train_loss=8.756126403808594
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1642: train_loss=8.6272611618042
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1643: train_loss=8.58728313446045
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1644: train_loss=8.627276420593262
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1645: train_loss=8.641329765319824
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1646: train_loss=8.642141342163086
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1647: train_loss=8.619685173034668
INFO - 04/15/25 16:37:11 - 0:05:35 - Epoch 1648: train_loss=8.569923400878906
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1649: train_loss=8.567587852478027
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1650: train_loss=8.520230293273926
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1651: train_loss=8.563573837280273
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1652: train_loss=8.65046501159668
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1653: train_loss=8.564053535461426
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1654: train_loss=8.545733451843262
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1655: train_loss=8.558573722839355
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1656: train_loss=8.54110336303711
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1657: train_loss=8.518423080444336
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1658: train_loss=8.539230346679688
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1659: train_loss=8.509866714477539
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1660: train_loss=8.517132759094238
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1661: train_loss=8.511544227600098
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1662: train_loss=8.505341529846191
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1663: train_loss=8.484931945800781
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1664: train_loss=8.510907173156738
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1665: train_loss=8.487281799316406
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1666: train_loss=8.496999740600586
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1667: train_loss=8.489569664001465
INFO - 04/15/25 16:37:12 - 0:05:35 - Epoch 1668: train_loss=8.479681015014648
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1669: train_loss=8.452909469604492
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1670: train_loss=8.460894584655762
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1671: train_loss=8.454282760620117
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1672: train_loss=8.45129108428955
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1673: train_loss=8.438336372375488
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1674: train_loss=8.449512481689453
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1675: train_loss=8.441878318786621
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1676: train_loss=8.424513816833496
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1677: train_loss=8.441530227661133
INFO - 04/15/25 16:37:12 - 0:05:36 - Epoch 1678: train_loss=8.456598281860352
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1679: train_loss=8.448382377624512
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1680: train_loss=8.445648193359375
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1681: train_loss=8.432019233703613
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1682: train_loss=8.427342414855957
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1683: train_loss=8.44531536102295
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1684: train_loss=8.4285888671875
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1685: train_loss=8.460304260253906
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1686: train_loss=8.431173324584961
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1687: train_loss=8.43386459350586
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1688: train_loss=8.417716979980469
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1689: train_loss=8.43232536315918
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1690: train_loss=8.40655517578125
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1691: train_loss=8.423877716064453
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1692: train_loss=8.414163589477539
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1693: train_loss=8.419912338256836
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1694: train_loss=8.414331436157227
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1695: train_loss=8.408645629882812
INFO - 04/15/25 16:37:13 - 0:05:36 - Epoch 1696: train_loss=8.409656524658203
INFO - 04/15/25 16:37:13 - 0:05:37 - Epoch 1697: train_loss=8.398442268371582
INFO - 04/15/25 16:37:13 - 0:05:37 - Epoch 1698: train_loss=8.4027099609375
INFO - 04/15/25 16:37:13 - 0:05:37 - Epoch 1699: train_loss=8.396235466003418
INFO - 04/15/25 16:37:13 - 0:05:37 - Epoch 1700: train_loss=8.398725509643555
INFO - 04/15/25 16:37:13 - 0:05:37 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:13 - 0:05:37 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1700: ACC: 0.0, NMI: 0.42946912140721166, F1: 0.0, ARI: 0.25941110216793917
INFO - 04/15/25 16:37:14 - 0:05:37 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1701: train_loss=8.394882202148438
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1702: train_loss=8.393497467041016
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1703: train_loss=8.390251159667969
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1704: train_loss=8.392910957336426
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1705: train_loss=8.38424301147461
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1706: train_loss=8.394116401672363
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1707: train_loss=8.3895845413208
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1708: train_loss=8.385174751281738
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1709: train_loss=8.386359214782715
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1710: train_loss=8.375791549682617
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1711: train_loss=8.377286911010742
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1712: train_loss=8.38671875
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1713: train_loss=8.386214256286621
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1714: train_loss=8.379899978637695
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1715: train_loss=8.381741523742676
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1716: train_loss=8.379120826721191
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1717: train_loss=8.377495765686035
INFO - 04/15/25 16:37:14 - 0:05:37 - Epoch 1718: train_loss=8.375448226928711
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1719: train_loss=8.378511428833008
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1720: train_loss=8.374722480773926
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1721: train_loss=8.379415512084961
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1722: train_loss=8.375055313110352
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1723: train_loss=8.37834644317627
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1724: train_loss=8.376537322998047
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1725: train_loss=8.369376182556152
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1726: train_loss=8.37335205078125
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1727: train_loss=8.374882698059082
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1728: train_loss=8.373108863830566
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1729: train_loss=8.373127937316895
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1730: train_loss=8.369627952575684
INFO - 04/15/25 16:37:14 - 0:05:38 - Epoch 1731: train_loss=8.374544143676758
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1732: train_loss=8.373454093933105
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1733: train_loss=8.364026069641113
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1734: train_loss=8.369097709655762
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1735: train_loss=8.372031211853027
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1736: train_loss=8.37238597869873
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1737: train_loss=8.367534637451172
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1738: train_loss=8.37069320678711
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1739: train_loss=8.373368263244629
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1740: train_loss=8.359776496887207
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1741: train_loss=8.356490135192871
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1742: train_loss=8.361599922180176
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1743: train_loss=8.368734359741211
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1744: train_loss=8.380462646484375
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1745: train_loss=8.406505584716797
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1746: train_loss=8.445137977600098
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1747: train_loss=8.456525802612305
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1748: train_loss=8.444734573364258
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1749: train_loss=8.46676254272461
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1750: train_loss=8.491479873657227
INFO - 04/15/25 16:37:15 - 0:05:38 - Epoch 1751: train_loss=8.486960411071777
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1752: train_loss=8.483521461486816
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1753: train_loss=8.49264144897461
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1754: train_loss=8.532395362854004
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1755: train_loss=8.684989929199219
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1756: train_loss=8.560315132141113
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1757: train_loss=8.551167488098145
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1758: train_loss=8.540260314941406
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1759: train_loss=8.550108909606934
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1760: train_loss=8.54517936706543
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1761: train_loss=8.53954029083252
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1762: train_loss=8.538283348083496
INFO - 04/15/25 16:37:15 - 0:05:39 - Epoch 1763: train_loss=8.514249801635742
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1764: train_loss=8.511103630065918
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1765: train_loss=8.49087142944336
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1766: train_loss=8.48294448852539
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1767: train_loss=8.479433059692383
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1768: train_loss=8.464113235473633
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1769: train_loss=8.459918022155762
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1770: train_loss=8.445136070251465
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1771: train_loss=8.447263717651367
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1772: train_loss=8.430435180664062
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1773: train_loss=8.436650276184082
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1774: train_loss=8.428332328796387
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1775: train_loss=8.40915584564209
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1776: train_loss=8.398696899414062
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1777: train_loss=8.39221477508545
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1778: train_loss=8.393716812133789
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1779: train_loss=8.384697914123535
INFO - 04/15/25 16:37:16 - 0:05:39 - Epoch 1780: train_loss=8.38515853881836
INFO - 04/15/25 16:37:16 - 0:05:40 - Epoch 1781: train_loss=8.383231163024902
INFO - 04/15/25 16:37:16 - 0:05:40 - Epoch 1782: train_loss=8.3790283203125
INFO - 04/15/25 16:37:16 - 0:05:40 - Epoch 1783: train_loss=8.373749732971191
INFO - 04/15/25 16:37:20 - 0:05:40 - Epoch 1784: train_loss=8.381231307983398
INFO - 04/15/25 16:37:20 - 0:05:43 - Epoch 1785: train_loss=8.377755165100098
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1786: train_loss=8.413238525390625
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1787: train_loss=8.406769752502441
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1788: train_loss=8.413664817810059
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1789: train_loss=8.385229110717773
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1790: train_loss=8.389825820922852
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1791: train_loss=8.39879322052002
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1792: train_loss=8.404718399047852
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1793: train_loss=8.390878677368164
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1794: train_loss=8.404196739196777
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1795: train_loss=8.407756805419922
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1796: train_loss=8.395505905151367
INFO - 04/15/25 16:37:20 - 0:05:44 - Epoch 1797: train_loss=8.398319244384766
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1798: train_loss=8.408767700195312
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1799: train_loss=8.392632484436035
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1800: train_loss=8.404159545898438
INFO - 04/15/25 16:37:21 - 0:05:44 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:21 - 0:05:44 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:37:21 - 0:05:44 - ------------------Saving best model-------------------
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1800: ACC: 0.0, NMI: 0.5365984375946476, F1: 0.0, ARI: 0.29650458271194735
INFO - 04/15/25 16:37:21 - 0:05:44 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1801: train_loss=8.391990661621094
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1802: train_loss=8.395853042602539
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1803: train_loss=8.38556957244873
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1804: train_loss=8.387431144714355
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1805: train_loss=8.383681297302246
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1806: train_loss=8.382680892944336
INFO - 04/15/25 16:37:21 - 0:05:44 - Epoch 1807: train_loss=8.382002830505371
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1808: train_loss=8.375640869140625
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1809: train_loss=8.374971389770508
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1810: train_loss=8.376367568969727
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1811: train_loss=8.3654203414917
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1812: train_loss=8.369598388671875
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1813: train_loss=8.370766639709473
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1814: train_loss=8.368163108825684
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1815: train_loss=8.368468284606934
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1816: train_loss=8.36137866973877
INFO - 04/15/25 16:37:21 - 0:05:45 - Epoch 1817: train_loss=8.367545127868652
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1818: train_loss=8.36635684967041
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1819: train_loss=8.367206573486328
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1820: train_loss=8.365575790405273
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1821: train_loss=8.369115829467773
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1822: train_loss=8.366576194763184
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1823: train_loss=8.366543769836426
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1824: train_loss=8.365630149841309
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1825: train_loss=8.370984077453613
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1826: train_loss=8.375309944152832
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1827: train_loss=8.38547420501709
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1828: train_loss=8.372136116027832
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1829: train_loss=8.385746002197266
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1830: train_loss=8.397981643676758
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1831: train_loss=8.375874519348145
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1832: train_loss=8.293451309204102
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1833: train_loss=8.223773956298828
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1834: train_loss=8.174741744995117
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1835: train_loss=8.160375595092773
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1836: train_loss=8.143426895141602
INFO - 04/15/25 16:37:22 - 0:05:45 - Epoch 1837: train_loss=8.138288497924805
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1838: train_loss=8.125046730041504
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1839: train_loss=8.108792304992676
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1840: train_loss=8.096846580505371
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1841: train_loss=8.095975875854492
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1842: train_loss=8.088906288146973
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1843: train_loss=8.088396072387695
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1844: train_loss=8.075926780700684
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1845: train_loss=8.082786560058594
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1846: train_loss=8.076952934265137
INFO - 04/15/25 16:37:22 - 0:05:46 - Epoch 1847: train_loss=8.075465202331543
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1848: train_loss=8.076007843017578
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1849: train_loss=8.075064659118652
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1850: train_loss=8.070318222045898
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1851: train_loss=8.075847625732422
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1852: train_loss=8.07491397857666
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1853: train_loss=8.070795059204102
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1854: train_loss=8.072811126708984
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1855: train_loss=8.06900405883789
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1856: train_loss=8.074260711669922
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1857: train_loss=8.071099281311035
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1858: train_loss=8.065349578857422
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1859: train_loss=8.061861991882324
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1860: train_loss=8.059423446655273
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1861: train_loss=8.053642272949219
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1862: train_loss=8.04788875579834
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1863: train_loss=8.046048164367676
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1864: train_loss=8.048069953918457
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1865: train_loss=8.052071571350098
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1866: train_loss=8.045633316040039
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1867: train_loss=8.049857139587402
INFO - 04/15/25 16:37:23 - 0:05:46 - Epoch 1868: train_loss=8.04704761505127
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1869: train_loss=8.04837417602539
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1870: train_loss=8.048162460327148
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1871: train_loss=8.044032096862793
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1872: train_loss=8.04117202758789
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1873: train_loss=8.063465118408203
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1874: train_loss=8.036617279052734
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1875: train_loss=8.047907829284668
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1876: train_loss=8.048079490661621
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1877: train_loss=8.050646781921387
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1878: train_loss=8.050007820129395
INFO - 04/15/25 16:37:23 - 0:05:47 - Epoch 1879: train_loss=8.042576789855957
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1880: train_loss=8.036499977111816
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1881: train_loss=8.016030311584473
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1882: train_loss=8.015026092529297
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1883: train_loss=8.019075393676758
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1884: train_loss=8.004250526428223
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1885: train_loss=8.003035545349121
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1886: train_loss=7.9994378089904785
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1887: train_loss=7.996767044067383
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1888: train_loss=8.00058364868164
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1889: train_loss=7.994076251983643
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1890: train_loss=7.994035243988037
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1891: train_loss=7.9910054206848145
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1892: train_loss=7.989344596862793
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1893: train_loss=7.989104270935059
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1894: train_loss=7.985668182373047
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1895: train_loss=7.985466957092285
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1896: train_loss=7.985476970672607
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1897: train_loss=7.993457794189453
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1898: train_loss=7.993015289306641
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1899: train_loss=7.987616539001465
INFO - 04/15/25 16:37:24 - 0:05:47 - Epoch 1900: train_loss=7.989750862121582
INFO - 04/15/25 16:37:24 - 0:05:47 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:24 - 0:05:48 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:37:24 - 0:05:48 - Epoch 1900: ACC: 0.0, NMI: 0.5295382338753555, F1: 0.0, ARI: 0.3523730710034316
INFO - 04/15/25 16:37:24 - 0:05:48 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:24 - 0:05:48 - Epoch 1901: train_loss=7.98927640914917
INFO - 04/15/25 16:37:24 - 0:05:48 - Epoch 1902: train_loss=7.984439849853516
INFO - 04/15/25 16:37:24 - 0:05:48 - Epoch 1903: train_loss=8.065814971923828
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1904: train_loss=7.990208148956299
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1905: train_loss=7.996661186218262
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1906: train_loss=7.99718713760376
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1907: train_loss=7.994384288787842
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1908: train_loss=7.991267204284668
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1909: train_loss=7.998125076293945
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1910: train_loss=7.995903015136719
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1911: train_loss=7.995888710021973
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1912: train_loss=7.999908924102783
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1913: train_loss=7.997739315032959
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1914: train_loss=7.994539737701416
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1915: train_loss=8.007594108581543
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1916: train_loss=7.997861862182617
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1917: train_loss=8.004265785217285
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1918: train_loss=8.005280494689941
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1919: train_loss=7.993100166320801
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1920: train_loss=8.002006530761719
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1921: train_loss=8.000712394714355
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1922: train_loss=7.993851184844971
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1923: train_loss=7.994339942932129
INFO - 04/15/25 16:37:25 - 0:05:48 - Epoch 1924: train_loss=7.990462779998779
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1925: train_loss=7.987868309020996
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1926: train_loss=7.986785411834717
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1927: train_loss=7.982134819030762
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1928: train_loss=7.983669281005859
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1929: train_loss=7.981412410736084
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1930: train_loss=7.981912136077881
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1931: train_loss=7.980970859527588
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1932: train_loss=7.9770050048828125
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1933: train_loss=7.979626655578613
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1934: train_loss=7.977593421936035
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1935: train_loss=7.9788970947265625
INFO - 04/15/25 16:37:25 - 0:05:49 - Epoch 1936: train_loss=7.977900505065918
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1937: train_loss=7.983102798461914
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1938: train_loss=7.978910446166992
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1939: train_loss=7.979008197784424
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1940: train_loss=7.976652145385742
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1941: train_loss=7.975150108337402
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1942: train_loss=7.984011650085449
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1943: train_loss=7.975435256958008
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1944: train_loss=7.976459503173828
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1945: train_loss=7.973448753356934
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1946: train_loss=7.970470905303955
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1947: train_loss=7.9498162269592285
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1948: train_loss=7.940881252288818
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1949: train_loss=7.937236309051514
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1950: train_loss=7.930217742919922
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1951: train_loss=7.927999496459961
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1952: train_loss=7.928637504577637
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1953: train_loss=7.923520565032959
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1954: train_loss=7.925862789154053
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1955: train_loss=7.923639297485352
INFO - 04/15/25 16:37:26 - 0:05:49 - Epoch 1956: train_loss=7.923730850219727
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1957: train_loss=7.922092437744141
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1958: train_loss=7.920463562011719
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1959: train_loss=7.909170150756836
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1960: train_loss=7.921768665313721
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1961: train_loss=7.917675971984863
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1962: train_loss=7.921485900878906
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1963: train_loss=7.919766902923584
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1964: train_loss=7.907694339752197
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1965: train_loss=7.910266876220703
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1966: train_loss=7.918242454528809
INFO - 04/15/25 16:37:26 - 0:05:50 - Epoch 1967: train_loss=7.9140944480896
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1968: train_loss=7.911038398742676
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1969: train_loss=7.913136959075928
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1970: train_loss=7.917466163635254
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1971: train_loss=7.917241096496582
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1972: train_loss=7.915264129638672
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1973: train_loss=7.917016506195068
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1974: train_loss=7.914557933807373
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1975: train_loss=7.914825439453125
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1976: train_loss=7.903200626373291
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1977: train_loss=7.918745517730713
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1978: train_loss=7.9180073738098145
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1979: train_loss=7.909969329833984
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1980: train_loss=7.911430358886719
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1981: train_loss=7.911873817443848
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1982: train_loss=7.909135818481445
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1983: train_loss=7.915960788726807
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1984: train_loss=7.916570663452148
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1985: train_loss=7.910134792327881
INFO - 04/15/25 16:37:27 - 0:05:50 - Epoch 1986: train_loss=7.90936803817749
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1987: train_loss=7.909475803375244
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1988: train_loss=7.912094593048096
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1989: train_loss=7.906649112701416
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1990: train_loss=7.911257743835449
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1991: train_loss=7.916168689727783
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1992: train_loss=7.907952785491943
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1993: train_loss=7.912463665008545
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1994: train_loss=7.911561012268066
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1995: train_loss=7.913100242614746
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1996: train_loss=7.912067413330078
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1997: train_loss=7.914379596710205
INFO - 04/15/25 16:37:27 - 0:05:51 - Epoch 1998: train_loss=7.9115705490112305
INFO - 04/15/25 16:37:28 - 0:05:51 - Epoch 1999: train_loss=7.9198079109191895
INFO - 04/15/25 16:37:28 - 0:05:51 - Epoch 2000: train_loss=7.899235248565674
INFO - 04/15/25 16:37:28 - 0:05:51 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:28 - 0:05:51 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:37:28 - 0:05:51 - ------------------Saving best model-------------------
INFO - 04/15/25 16:37:31 - 0:05:55 - Epoch 2000: ACC: 0.0, NMI: 0.539301317549878, F1: 0.0, ARI: 0.35061056553745307
INFO - 04/15/25 16:37:31 - 0:05:55 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:31 - 0:05:55 - Epoch 2001: train_loss=7.904192924499512
INFO - 04/15/25 16:37:31 - 0:05:55 - Epoch 2002: train_loss=7.881537914276123
INFO - 04/15/25 16:37:31 - 0:05:55 - Epoch 2003: train_loss=7.877944469451904
INFO - 04/15/25 16:37:31 - 0:05:55 - Epoch 2004: train_loss=7.894958972930908
INFO - 04/15/25 16:37:31 - 0:05:55 - Epoch 2005: train_loss=7.885484218597412
INFO - 04/15/25 16:37:31 - 0:05:55 - Epoch 2006: train_loss=7.88572883605957
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2007: train_loss=7.881278991699219
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2008: train_loss=7.877791404724121
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2009: train_loss=7.8802714347839355
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2010: train_loss=7.875982284545898
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2011: train_loss=7.881478309631348
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2012: train_loss=7.872339725494385
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2013: train_loss=7.872375011444092
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2014: train_loss=7.883181095123291
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2015: train_loss=7.874159336090088
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2016: train_loss=7.880780220031738
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2017: train_loss=7.888530254364014
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2018: train_loss=7.865336894989014
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2019: train_loss=7.87268590927124
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2020: train_loss=7.874577522277832
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2021: train_loss=7.8720703125
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2022: train_loss=7.856828689575195
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2023: train_loss=7.867410182952881
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2024: train_loss=7.865800380706787
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2025: train_loss=7.866765975952148
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2026: train_loss=7.850664138793945
INFO - 04/15/25 16:37:32 - 0:05:55 - Epoch 2027: train_loss=7.861649513244629
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2028: train_loss=7.8715291023254395
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2029: train_loss=7.861743927001953
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2030: train_loss=7.8557610511779785
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2031: train_loss=7.853559494018555
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2032: train_loss=7.8582329750061035
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2033: train_loss=7.848760604858398
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2034: train_loss=7.8446736335754395
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2035: train_loss=7.846536636352539
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2036: train_loss=7.845207691192627
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2037: train_loss=7.844222545623779
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2038: train_loss=7.846975326538086
INFO - 04/15/25 16:37:32 - 0:05:56 - Epoch 2039: train_loss=7.837915420532227
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2040: train_loss=7.844150066375732
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2041: train_loss=7.847984313964844
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2042: train_loss=7.836266040802002
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2043: train_loss=7.838895320892334
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2044: train_loss=7.83639669418335
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2045: train_loss=7.829346179962158
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2046: train_loss=7.8305182456970215
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2047: train_loss=7.8689799308776855
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2048: train_loss=7.8479766845703125
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2049: train_loss=7.91870641708374
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2050: train_loss=7.860617160797119
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2051: train_loss=7.868485927581787
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2052: train_loss=7.889817714691162
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2053: train_loss=7.8991780281066895
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2054: train_loss=7.93970251083374
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2055: train_loss=7.929093837738037
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2056: train_loss=7.9421515464782715
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2057: train_loss=7.905824661254883
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2058: train_loss=7.923050880432129
INFO - 04/15/25 16:37:33 - 0:05:56 - Epoch 2059: train_loss=7.928656578063965
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2060: train_loss=7.949332237243652
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2061: train_loss=7.935990333557129
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2062: train_loss=7.931894302368164
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2063: train_loss=8.037935256958008
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2064: train_loss=8.055257797241211
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2065: train_loss=8.058564186096191
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2066: train_loss=8.002923965454102
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2067: train_loss=7.968552589416504
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2068: train_loss=7.970134258270264
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2069: train_loss=7.986360549926758
INFO - 04/15/25 16:37:33 - 0:05:57 - Epoch 2070: train_loss=7.993163108825684
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2071: train_loss=8.001096725463867
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2072: train_loss=7.96925163269043
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2073: train_loss=7.976890563964844
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2074: train_loss=7.952142238616943
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2075: train_loss=7.951409816741943
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2076: train_loss=7.956751346588135
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2077: train_loss=7.947197437286377
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2078: train_loss=7.95204496383667
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2079: train_loss=7.951886177062988
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2080: train_loss=7.94409704208374
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2081: train_loss=7.944031715393066
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2082: train_loss=7.937304496765137
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2083: train_loss=7.937802314758301
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2084: train_loss=7.9282660484313965
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2085: train_loss=7.917847633361816
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2086: train_loss=7.912266254425049
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2087: train_loss=7.912564754486084
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2088: train_loss=7.909159183502197
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2089: train_loss=7.906562328338623
INFO - 04/15/25 16:37:34 - 0:05:57 - Epoch 2090: train_loss=7.899499416351318
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2091: train_loss=7.901520252227783
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2092: train_loss=7.8966474533081055
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2093: train_loss=7.896966457366943
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2094: train_loss=7.8941969871521
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2095: train_loss=7.8963189125061035
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2096: train_loss=7.894201278686523
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2097: train_loss=7.8820953369140625
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2098: train_loss=7.893868923187256
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2099: train_loss=7.892027854919434
INFO - 04/15/25 16:37:34 - 0:05:58 - Epoch 2100: train_loss=7.89443302154541
INFO - 04/15/25 16:37:34 - 0:05:58 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:35 - 0:05:58 - Decoding cost time:  0.131 s
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2100: ACC: 0.0, NMI: 0.5025329111458773, F1: 0.0, ARI: 0.2957289529579811
INFO - 04/15/25 16:37:35 - 0:05:58 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2101: train_loss=7.8948540687561035
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2102: train_loss=7.88693904876709
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2103: train_loss=7.898944854736328
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2104: train_loss=7.8920135498046875
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2105: train_loss=7.897092342376709
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2106: train_loss=7.911550998687744
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2107: train_loss=7.904637336730957
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2108: train_loss=7.889493465423584
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2109: train_loss=7.898849964141846
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2110: train_loss=7.903785228729248
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2111: train_loss=7.898310661315918
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2112: train_loss=7.891348361968994
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2113: train_loss=7.89327335357666
INFO - 04/15/25 16:37:35 - 0:05:58 - Epoch 2114: train_loss=7.893284320831299
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2115: train_loss=7.894110679626465
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2116: train_loss=7.893430233001709
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2117: train_loss=7.8949456214904785
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2118: train_loss=7.893485069274902
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2119: train_loss=7.8886494636535645
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2120: train_loss=7.886106491088867
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2121: train_loss=7.8906731605529785
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2122: train_loss=7.886231899261475
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2123: train_loss=7.888203144073486
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2124: train_loss=7.888978004455566
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2125: train_loss=7.884331703186035
INFO - 04/15/25 16:37:35 - 0:05:59 - Epoch 2126: train_loss=7.882577896118164
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2127: train_loss=7.8847336769104
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2128: train_loss=7.882107257843018
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2129: train_loss=7.8835062980651855
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2130: train_loss=7.882980823516846
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2131: train_loss=7.877171516418457
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2132: train_loss=7.876744747161865
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2133: train_loss=7.881995677947998
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2134: train_loss=7.8813090324401855
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2135: train_loss=7.874139308929443
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2136: train_loss=7.875479698181152
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2137: train_loss=7.878731727600098
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2138: train_loss=7.876506805419922
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2139: train_loss=7.874582767486572
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2140: train_loss=7.87600040435791
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2141: train_loss=7.874685764312744
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2142: train_loss=7.875589847564697
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2143: train_loss=7.87516975402832
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2144: train_loss=7.872658729553223
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2145: train_loss=7.869202136993408
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2146: train_loss=7.8724822998046875
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2147: train_loss=7.872541904449463
INFO - 04/15/25 16:37:36 - 0:05:59 - Epoch 2148: train_loss=7.871466636657715
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2149: train_loss=7.879870891571045
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2150: train_loss=7.876204490661621
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2151: train_loss=7.876223564147949
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2152: train_loss=7.875217437744141
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2153: train_loss=7.878986358642578
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2154: train_loss=7.878371715545654
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2155: train_loss=7.867175102233887
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2156: train_loss=7.87177038192749
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2157: train_loss=7.869934558868408
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2158: train_loss=7.871864318847656
INFO - 04/15/25 16:37:36 - 0:06:00 - Epoch 2159: train_loss=7.8748860359191895
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2160: train_loss=7.892109394073486
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2161: train_loss=7.8827009201049805
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2162: train_loss=7.884079933166504
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2163: train_loss=7.888129711151123
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2164: train_loss=7.889944076538086
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2165: train_loss=7.887105941772461
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2166: train_loss=7.892416477203369
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2167: train_loss=7.886592388153076
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2168: train_loss=7.892891883850098
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2169: train_loss=7.8948259353637695
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2170: train_loss=7.885499477386475
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2171: train_loss=7.8897833824157715
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2172: train_loss=7.89036750793457
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2173: train_loss=7.8758158683776855
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2174: train_loss=7.878848075866699
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2175: train_loss=7.877024173736572
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2176: train_loss=7.87019681930542
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2177: train_loss=7.866890907287598
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2178: train_loss=7.860713481903076
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2179: train_loss=7.86204195022583
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2180: train_loss=7.854591369628906
INFO - 04/15/25 16:37:37 - 0:06:00 - Epoch 2181: train_loss=7.85202169418335
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2182: train_loss=7.83604097366333
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2183: train_loss=7.831597805023193
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2184: train_loss=7.829338073730469
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2185: train_loss=7.826335906982422
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2186: train_loss=7.8262810707092285
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2187: train_loss=7.8234477043151855
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2188: train_loss=7.826578617095947
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2189: train_loss=7.812177658081055
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2190: train_loss=7.81980562210083
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2191: train_loss=7.821913719177246
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2192: train_loss=7.829577922821045
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2193: train_loss=7.830408096313477
INFO - 04/15/25 16:37:37 - 0:06:01 - Epoch 2194: train_loss=7.8514227867126465
INFO - 04/15/25 16:37:38 - 0:06:01 - Epoch 2195: train_loss=7.83806037902832
INFO - 04/15/25 16:37:38 - 0:06:01 - Epoch 2196: train_loss=7.810426712036133
INFO - 04/15/25 16:37:38 - 0:06:01 - Epoch 2197: train_loss=7.813023567199707
INFO - 04/15/25 16:37:38 - 0:06:01 - Epoch 2198: train_loss=7.828101634979248
INFO - 04/15/25 16:37:38 - 0:06:01 - Epoch 2199: train_loss=7.8331618309021
INFO - 04/15/25 16:37:38 - 0:06:01 - Epoch 2200: train_loss=7.823125839233398
INFO - 04/15/25 16:37:38 - 0:06:01 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:38 - 0:06:01 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:37:38 - 0:06:01 - ------------------Saving best model-------------------
INFO - 04/15/25 16:37:41 - 0:06:05 - Epoch 2200: ACC: 0.0, NMI: 0.5528308031233881, F1: 0.0, ARI: 0.3702473522701175
INFO - 04/15/25 16:37:41 - 0:06:05 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2201: train_loss=7.815099239349365
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2202: train_loss=7.833629608154297
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2203: train_loss=7.836965084075928
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2204: train_loss=7.828590393066406
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2205: train_loss=7.83305025100708
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2206: train_loss=7.832493305206299
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2207: train_loss=7.842061996459961
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2208: train_loss=7.802829742431641
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2209: train_loss=7.8212738037109375
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2210: train_loss=7.778223037719727
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2211: train_loss=7.817256927490234
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2212: train_loss=7.824073314666748
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2213: train_loss=7.80900239944458
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2214: train_loss=7.80072021484375
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2215: train_loss=7.791060447692871
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2216: train_loss=7.765714645385742
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2217: train_loss=7.756188869476318
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2218: train_loss=7.778469562530518
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2219: train_loss=7.750103950500488
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2220: train_loss=7.746911525726318
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2221: train_loss=7.813843250274658
INFO - 04/15/25 16:37:42 - 0:06:05 - Epoch 2222: train_loss=7.754885673522949
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2223: train_loss=7.754996299743652
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2224: train_loss=7.776689529418945
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2225: train_loss=7.75222635269165
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2226: train_loss=7.748349189758301
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2227: train_loss=7.824521064758301
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2228: train_loss=7.751243591308594
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2229: train_loss=7.742783546447754
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2230: train_loss=7.730626106262207
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2231: train_loss=7.731077194213867
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2232: train_loss=7.719171524047852
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2233: train_loss=7.73041296005249
INFO - 04/15/25 16:37:42 - 0:06:06 - Epoch 2234: train_loss=7.720789432525635
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2235: train_loss=7.714832782745361
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2236: train_loss=7.719196796417236
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2237: train_loss=7.708573818206787
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2238: train_loss=7.71579647064209
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2239: train_loss=7.706452369689941
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2240: train_loss=7.713677406311035
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2241: train_loss=7.72929573059082
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2242: train_loss=7.709031581878662
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2243: train_loss=7.726519584655762
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2244: train_loss=7.708161354064941
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2245: train_loss=7.725545883178711
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2246: train_loss=7.714422225952148
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2247: train_loss=7.725837230682373
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2248: train_loss=7.702826499938965
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2249: train_loss=7.696771144866943
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2250: train_loss=7.68479585647583
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2251: train_loss=7.67092227935791
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2252: train_loss=7.653957366943359
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2253: train_loss=7.652400016784668
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2254: train_loss=7.64145565032959
INFO - 04/15/25 16:37:43 - 0:06:06 - Epoch 2255: train_loss=7.629294395446777
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2256: train_loss=7.600858688354492
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2257: train_loss=7.636702537536621
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2258: train_loss=7.607936859130859
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2259: train_loss=7.598208904266357
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2260: train_loss=7.577224254608154
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2261: train_loss=7.596568584442139
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2262: train_loss=7.582646369934082
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2263: train_loss=7.575145721435547
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2264: train_loss=7.575432300567627
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2265: train_loss=7.573033332824707
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2266: train_loss=7.5449538230896
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2267: train_loss=7.554258346557617
INFO - 04/15/25 16:37:43 - 0:06:07 - Epoch 2268: train_loss=7.542901039123535
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2269: train_loss=7.536859035491943
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2270: train_loss=7.534823894500732
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2271: train_loss=7.519545555114746
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2272: train_loss=7.515798091888428
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2273: train_loss=7.502111434936523
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2274: train_loss=7.49730110168457
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2275: train_loss=7.487163543701172
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2276: train_loss=7.502560615539551
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2277: train_loss=7.500027179718018
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2278: train_loss=7.487741947174072
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2279: train_loss=7.497573375701904
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2280: train_loss=7.498844146728516
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2281: train_loss=7.4883317947387695
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2282: train_loss=7.531881809234619
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2283: train_loss=7.534379005432129
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2284: train_loss=7.624672889709473
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2285: train_loss=7.703782081604004
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2286: train_loss=7.746703147888184
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2287: train_loss=7.677483558654785
INFO - 04/15/25 16:37:44 - 0:06:07 - Epoch 2288: train_loss=7.648984909057617
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2289: train_loss=7.618677139282227
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2290: train_loss=7.604949474334717
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2291: train_loss=7.62103796005249
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2292: train_loss=7.629422187805176
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2293: train_loss=7.617103576660156
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2294: train_loss=7.6305646896362305
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2295: train_loss=7.595913410186768
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2296: train_loss=7.596830368041992
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2297: train_loss=7.59792947769165
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2298: train_loss=7.587040901184082
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2299: train_loss=7.573972225189209
INFO - 04/15/25 16:37:44 - 0:06:08 - Epoch 2300: train_loss=7.566795825958252
INFO - 04/15/25 16:37:44 - 0:06:08 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:45 - 0:06:08 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2300: ACC: 0.0, NMI: 0.49196517856424704, F1: 0.0, ARI: 0.30007350160367413
INFO - 04/15/25 16:37:45 - 0:06:08 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2301: train_loss=7.565178871154785
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2302: train_loss=7.565676689147949
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2303: train_loss=7.571474075317383
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2304: train_loss=7.557137489318848
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2305: train_loss=7.554354667663574
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2306: train_loss=7.554332256317139
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2307: train_loss=7.553921222686768
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2308: train_loss=7.5491251945495605
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2309: train_loss=7.5473737716674805
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2310: train_loss=7.544551372528076
INFO - 04/15/25 16:37:45 - 0:06:08 - Epoch 2311: train_loss=7.544304370880127
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2312: train_loss=7.537974834442139
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2313: train_loss=7.538126468658447
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2314: train_loss=7.536928176879883
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2315: train_loss=7.533263206481934
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2316: train_loss=7.532708644866943
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2317: train_loss=7.5298171043396
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2318: train_loss=7.529026985168457
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2319: train_loss=7.523987293243408
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2320: train_loss=7.526242733001709
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2321: train_loss=7.526613712310791
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2322: train_loss=7.526643753051758
INFO - 04/15/25 16:37:45 - 0:06:09 - Epoch 2323: train_loss=7.521343231201172
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2324: train_loss=7.525553226470947
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2325: train_loss=7.520717620849609
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2326: train_loss=7.521285057067871
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2327: train_loss=7.520262718200684
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2328: train_loss=7.5046515464782715
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2329: train_loss=7.5062689781188965
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2330: train_loss=7.520324230194092
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2331: train_loss=7.500701427459717
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2332: train_loss=7.49963903427124
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2333: train_loss=7.5031633377075195
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2334: train_loss=7.498271942138672
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2335: train_loss=7.495825290679932
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2336: train_loss=7.498149394989014
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2337: train_loss=7.4951910972595215
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2338: train_loss=7.493868827819824
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2339: train_loss=7.494909286499023
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2340: train_loss=7.4944963455200195
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2341: train_loss=7.497035503387451
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2342: train_loss=7.49447774887085
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2343: train_loss=7.498109340667725
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2344: train_loss=7.495047569274902
INFO - 04/15/25 16:37:46 - 0:06:09 - Epoch 2345: train_loss=7.494101047515869
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2346: train_loss=7.496220588684082
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2347: train_loss=7.491700649261475
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2348: train_loss=7.488925457000732
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2349: train_loss=7.476543426513672
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2350: train_loss=7.467385292053223
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2351: train_loss=7.465323448181152
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2352: train_loss=7.460244178771973
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2353: train_loss=7.4569244384765625
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2354: train_loss=7.447701454162598
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2355: train_loss=7.43664026260376
INFO - 04/15/25 16:37:46 - 0:06:10 - Epoch 2356: train_loss=7.436164855957031
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2357: train_loss=7.428997039794922
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2358: train_loss=7.409740447998047
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2359: train_loss=7.414827823638916
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2360: train_loss=7.389082431793213
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2361: train_loss=7.414097785949707
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2362: train_loss=7.4091596603393555
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2363: train_loss=7.396360874176025
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2364: train_loss=7.398935317993164
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2365: train_loss=7.384889125823975
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2366: train_loss=7.37661075592041
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2367: train_loss=7.374520301818848
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2368: train_loss=7.374719619750977
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2369: train_loss=7.36985969543457
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2370: train_loss=7.3745646476745605
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2371: train_loss=7.37817907333374
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2372: train_loss=7.366857528686523
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2373: train_loss=7.3616132736206055
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2374: train_loss=7.356218338012695
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2375: train_loss=7.3514509201049805
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2376: train_loss=7.344381332397461
INFO - 04/15/25 16:37:47 - 0:06:10 - Epoch 2377: train_loss=7.342980861663818
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2378: train_loss=7.335232257843018
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2379: train_loss=7.338403701782227
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2380: train_loss=7.333538055419922
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2381: train_loss=7.329638481140137
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2382: train_loss=7.33042049407959
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2383: train_loss=7.326658725738525
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2384: train_loss=7.31583833694458
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2385: train_loss=7.309257507324219
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2386: train_loss=7.311539649963379
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2387: train_loss=7.3087639808654785
INFO - 04/15/25 16:37:47 - 0:06:11 - Epoch 2388: train_loss=7.298384666442871
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2389: train_loss=7.304698467254639
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2390: train_loss=7.3019633293151855
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2391: train_loss=7.298394203186035
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2392: train_loss=7.287773609161377
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2393: train_loss=7.295897483825684
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2394: train_loss=7.3006815910339355
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2395: train_loss=7.301047325134277
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2396: train_loss=7.304971694946289
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2397: train_loss=7.308177947998047
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2398: train_loss=7.297062397003174
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2399: train_loss=7.297021865844727
INFO - 04/15/25 16:37:48 - 0:06:11 - Epoch 2400: train_loss=7.302033424377441
INFO - 04/15/25 16:37:48 - 0:06:11 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:51 - 0:06:11 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2400: ACC: 0.0, NMI: 0.5146542506143813, F1: 0.0, ARI: 0.35881039851667695
INFO - 04/15/25 16:37:51 - 0:06:14 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2401: train_loss=7.295524597167969
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2402: train_loss=7.287817001342773
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2403: train_loss=7.279181957244873
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2404: train_loss=7.273466110229492
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2405: train_loss=7.271617889404297
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2406: train_loss=7.251534938812256
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2407: train_loss=7.2590861320495605
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2408: train_loss=7.265453815460205
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2409: train_loss=7.264919281005859
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2410: train_loss=7.270841598510742
INFO - 04/15/25 16:37:51 - 0:06:14 - Epoch 2411: train_loss=7.270094394683838
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2412: train_loss=7.246781826019287
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2413: train_loss=7.254040241241455
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2414: train_loss=7.236941814422607
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2415: train_loss=7.241683006286621
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2416: train_loss=7.245172023773193
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2417: train_loss=7.247213840484619
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2418: train_loss=7.248443603515625
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2419: train_loss=7.233447074890137
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2420: train_loss=7.2352824211120605
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2421: train_loss=7.2417755126953125
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2422: train_loss=7.237555980682373
INFO - 04/15/25 16:37:51 - 0:06:15 - Epoch 2423: train_loss=7.231996536254883
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2424: train_loss=7.234412670135498
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2425: train_loss=7.213620662689209
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2426: train_loss=7.2239251136779785
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2427: train_loss=7.211109161376953
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2428: train_loss=7.203906059265137
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2429: train_loss=7.203836441040039
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2430: train_loss=7.209507942199707
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2431: train_loss=7.203871250152588
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2432: train_loss=7.201128005981445
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2433: train_loss=7.200344085693359
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2434: train_loss=7.196948051452637
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2435: train_loss=7.198793888092041
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2436: train_loss=7.19521951675415
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2437: train_loss=7.196252822875977
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2438: train_loss=7.19056510925293
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2439: train_loss=7.189182758331299
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2440: train_loss=7.185445785522461
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2441: train_loss=7.187355995178223
INFO - 04/15/25 16:37:52 - 0:06:15 - Epoch 2442: train_loss=7.19771671295166
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2443: train_loss=7.21323299407959
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2444: train_loss=7.192306041717529
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2445: train_loss=7.194504261016846
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2446: train_loss=7.185734748840332
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2447: train_loss=7.178053379058838
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2448: train_loss=7.176487922668457
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2449: train_loss=7.173427581787109
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2450: train_loss=7.177826881408691
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2451: train_loss=7.1781697273254395
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2452: train_loss=7.175426483154297
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2453: train_loss=7.174642086029053
INFO - 04/15/25 16:37:52 - 0:06:16 - Epoch 2454: train_loss=7.177364349365234
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2455: train_loss=7.171128749847412
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2456: train_loss=7.176239490509033
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2457: train_loss=7.170058250427246
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2458: train_loss=7.1663689613342285
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2459: train_loss=7.173294544219971
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2460: train_loss=7.166933059692383
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2461: train_loss=7.1656365394592285
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2462: train_loss=7.161012172698975
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2463: train_loss=7.1539106369018555
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2464: train_loss=7.162571430206299
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2465: train_loss=7.161975860595703
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2466: train_loss=7.15549373626709
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2467: train_loss=7.139530658721924
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2468: train_loss=7.135097980499268
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2469: train_loss=7.13527774810791
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2470: train_loss=7.129362106323242
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2471: train_loss=7.131278991699219
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2472: train_loss=7.139017105102539
INFO - 04/15/25 16:37:53 - 0:06:16 - Epoch 2473: train_loss=7.128026962280273
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2474: train_loss=7.125956058502197
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2475: train_loss=7.127981662750244
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2476: train_loss=7.126643180847168
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2477: train_loss=7.124031066894531
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2478: train_loss=7.122550964355469
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2479: train_loss=7.123312950134277
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2480: train_loss=7.120373725891113
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2481: train_loss=7.1257500648498535
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2482: train_loss=7.124922275543213
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2483: train_loss=7.127137660980225
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2484: train_loss=7.124873638153076
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2485: train_loss=7.152345657348633
INFO - 04/15/25 16:37:53 - 0:06:17 - Epoch 2486: train_loss=7.160884380340576
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2487: train_loss=7.150709629058838
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2488: train_loss=7.174412727355957
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2489: train_loss=7.179193019866943
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2490: train_loss=7.236000061035156
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2491: train_loss=7.245912075042725
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2492: train_loss=7.2543625831604
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2493: train_loss=7.244401454925537
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2494: train_loss=7.216933727264404
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2495: train_loss=7.230945587158203
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2496: train_loss=7.2492899894714355
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2497: train_loss=7.249907493591309
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2498: train_loss=7.339405059814453
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2499: train_loss=7.28137731552124
INFO - 04/15/25 16:37:54 - 0:06:17 - Epoch 2500: train_loss=7.3803324699401855
INFO - 04/15/25 16:37:54 - 0:06:17 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:54 - 0:06:17 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2500: ACC: 0.0, NMI: 0.5110609208439774, F1: 0.0, ARI: 0.319970291411481
INFO - 04/15/25 16:37:54 - 0:06:18 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2501: train_loss=7.30568265914917
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2502: train_loss=7.253203392028809
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2503: train_loss=7.244593620300293
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2504: train_loss=7.244381427764893
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2505: train_loss=7.266191005706787
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2506: train_loss=7.245062351226807
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2507: train_loss=7.351946830749512
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2508: train_loss=7.282456874847412
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2509: train_loss=7.272718906402588
INFO - 04/15/25 16:37:54 - 0:06:18 - Epoch 2510: train_loss=7.24893856048584
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2511: train_loss=7.2477803230285645
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2512: train_loss=7.24642276763916
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2513: train_loss=7.2259345054626465
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2514: train_loss=7.229514122009277
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2515: train_loss=7.2273430824279785
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2516: train_loss=7.242629051208496
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2517: train_loss=7.234500885009766
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2518: train_loss=7.218916416168213
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2519: train_loss=7.2230610847473145
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2520: train_loss=7.23059606552124
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2521: train_loss=7.235532760620117
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2522: train_loss=7.225183010101318
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2523: train_loss=7.224969387054443
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2524: train_loss=7.233323097229004
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2525: train_loss=7.233394622802734
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2526: train_loss=7.229366779327393
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2527: train_loss=7.225539684295654
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2528: train_loss=7.225444793701172
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2529: train_loss=7.22246789932251
INFO - 04/15/25 16:37:55 - 0:06:18 - Epoch 2530: train_loss=7.222167015075684
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2531: train_loss=7.233895301818848
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2532: train_loss=7.222233772277832
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2533: train_loss=7.22752046585083
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2534: train_loss=7.2247514724731445
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2535: train_loss=7.22330904006958
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2536: train_loss=7.224274158477783
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2537: train_loss=7.220423698425293
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2538: train_loss=7.220219135284424
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2539: train_loss=7.219181060791016
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2540: train_loss=7.216212749481201
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2541: train_loss=7.214852809906006
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2542: train_loss=7.213509559631348
INFO - 04/15/25 16:37:55 - 0:06:19 - Epoch 2543: train_loss=7.2188944816589355
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2544: train_loss=7.220251083374023
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2545: train_loss=7.2051215171813965
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2546: train_loss=7.209549427032471
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2547: train_loss=7.2147908210754395
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2548: train_loss=7.206389427185059
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2549: train_loss=7.205887794494629
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2550: train_loss=7.203181743621826
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2551: train_loss=7.2215166091918945
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2552: train_loss=7.174482345581055
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2553: train_loss=7.192563533782959
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2554: train_loss=7.184056282043457
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2555: train_loss=7.170222282409668
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2556: train_loss=7.171756267547607
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2557: train_loss=7.17476749420166
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2558: train_loss=7.17038106918335
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2559: train_loss=7.166691303253174
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2560: train_loss=7.161849021911621
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2561: train_loss=7.162159442901611
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2562: train_loss=7.157704830169678
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2563: train_loss=7.158121585845947
INFO - 04/15/25 16:37:56 - 0:06:19 - Epoch 2564: train_loss=7.154653549194336
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2565: train_loss=7.15258264541626
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2566: train_loss=7.150417327880859
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2567: train_loss=7.150608062744141
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2568: train_loss=7.1485795974731445
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2569: train_loss=7.148916244506836
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2570: train_loss=7.153244972229004
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2571: train_loss=7.152900218963623
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2572: train_loss=7.151149272918701
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2573: train_loss=7.1506829261779785
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2574: train_loss=7.146737575531006
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2575: train_loss=7.14794397354126
INFO - 04/15/25 16:37:56 - 0:06:20 - Epoch 2576: train_loss=7.146056652069092
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2577: train_loss=7.142181396484375
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2578: train_loss=7.142725944519043
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2579: train_loss=7.140566825866699
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2580: train_loss=7.14039421081543
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2581: train_loss=7.134680271148682
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2582: train_loss=7.135678768157959
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2583: train_loss=7.144536972045898
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2584: train_loss=7.14430570602417
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2585: train_loss=7.143835067749023
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2586: train_loss=7.143195152282715
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2587: train_loss=7.142341613769531
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2588: train_loss=7.137849807739258
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2589: train_loss=7.152811527252197
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2590: train_loss=7.137789726257324
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2591: train_loss=7.136214733123779
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2592: train_loss=7.147064685821533
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2593: train_loss=7.144348621368408
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2594: train_loss=7.144025802612305
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2595: train_loss=7.143808841705322
INFO - 04/15/25 16:37:57 - 0:06:20 - Epoch 2596: train_loss=7.139627456665039
INFO - 04/15/25 16:37:57 - 0:06:21 - Epoch 2597: train_loss=7.1425604820251465
INFO - 04/15/25 16:37:57 - 0:06:21 - Epoch 2598: train_loss=7.140294551849365
INFO - 04/15/25 16:37:57 - 0:06:21 - Epoch 2599: train_loss=7.138757705688477
INFO - 04/15/25 16:37:57 - 0:06:21 - Epoch 2600: train_loss=7.134850978851318
INFO - 04/15/25 16:37:57 - 0:06:21 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:37:57 - 0:06:21 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2600: ACC: 0.0, NMI: 0.4968317470814048, F1: 0.0, ARI: 0.31687895156949797
INFO - 04/15/25 16:37:58 - 0:06:21 - -------------------------------------------------------------------------
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2601: train_loss=7.137855052947998
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2602: train_loss=7.1324687004089355
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2603: train_loss=7.1383748054504395
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2604: train_loss=7.133022785186768
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2605: train_loss=7.1339311599731445
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2606: train_loss=7.1356306076049805
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2607: train_loss=7.131367206573486
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2608: train_loss=7.130158424377441
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2609: train_loss=7.1304450035095215
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2610: train_loss=7.12875509262085
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2611: train_loss=7.129292964935303
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2612: train_loss=7.127742767333984
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2613: train_loss=7.127530097961426
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2614: train_loss=7.1218366622924805
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2615: train_loss=7.115755081176758
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2616: train_loss=7.102015018463135
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2617: train_loss=7.11663293838501
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2618: train_loss=7.114983081817627
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2619: train_loss=7.094447612762451
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2620: train_loss=7.089222431182861
INFO - 04/15/25 16:37:58 - 0:06:21 - Epoch 2621: train_loss=7.092212200164795
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2622: train_loss=7.083775043487549
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2623: train_loss=7.082952499389648
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2624: train_loss=7.070687294006348
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2625: train_loss=7.070306777954102
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2626: train_loss=7.0541558265686035
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2627: train_loss=7.051224231719971
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2628: train_loss=7.040000915527344
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2629: train_loss=7.043819904327393
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2630: train_loss=7.037733554840088
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2631: train_loss=7.032730579376221
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2632: train_loss=7.033923149108887
INFO - 04/15/25 16:37:58 - 0:06:22 - Epoch 2633: train_loss=7.0337958335876465
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2634: train_loss=7.028895378112793
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2635: train_loss=7.035726547241211
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2636: train_loss=7.032530307769775
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2637: train_loss=7.027454376220703
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2638: train_loss=7.028644561767578
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2639: train_loss=7.0294365882873535
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2640: train_loss=7.02681827545166
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2641: train_loss=7.027256488800049
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2642: train_loss=7.023921966552734
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2643: train_loss=7.019753932952881
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2644: train_loss=7.018075942993164
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2645: train_loss=7.019486427307129
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2646: train_loss=7.016758441925049
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2647: train_loss=7.017858505249023
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2648: train_loss=7.014923095703125
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2649: train_loss=7.020909786224365
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2650: train_loss=7.016462326049805
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2651: train_loss=7.0230278968811035
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2652: train_loss=7.014736175537109
INFO - 04/15/25 16:37:59 - 0:06:22 - Epoch 2653: train_loss=7.006733417510986
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2654: train_loss=7.0304646492004395
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2655: train_loss=7.022768497467041
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2656: train_loss=7.013332366943359
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2657: train_loss=7.011137008666992
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2658: train_loss=7.013202667236328
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2659: train_loss=7.013052463531494
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2660: train_loss=7.015069961547852
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2661: train_loss=7.011924743652344
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2662: train_loss=7.013980388641357
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2663: train_loss=7.012502193450928
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2664: train_loss=7.011940956115723
INFO - 04/15/25 16:37:59 - 0:06:23 - Epoch 2665: train_loss=7.010879039764404
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2666: train_loss=7.012857437133789
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2667: train_loss=7.009408950805664
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2668: train_loss=7.008457660675049
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2669: train_loss=7.007495880126953
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2670: train_loss=7.008379936218262
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2671: train_loss=7.007418155670166
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2672: train_loss=7.007695198059082
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2673: train_loss=7.010021686553955
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2674: train_loss=7.009442329406738
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2675: train_loss=7.006626129150391
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2676: train_loss=7.005440711975098
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2677: train_loss=7.005228519439697
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2678: train_loss=7.006235599517822
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2679: train_loss=7.007026672363281
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2680: train_loss=7.004685878753662
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2681: train_loss=7.00715970993042
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2682: train_loss=7.00797176361084
INFO - 04/15/25 16:38:00 - 0:06:23 - Epoch 2683: train_loss=7.004138469696045
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2684: train_loss=7.008596897125244
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2685: train_loss=7.004306793212891
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2686: train_loss=7.005006313323975
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2687: train_loss=7.004831790924072
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2688: train_loss=7.003453254699707
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2689: train_loss=7.004682540893555
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2690: train_loss=7.000489711761475
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2691: train_loss=6.992539405822754
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2692: train_loss=6.992562294006348
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2693: train_loss=6.991010665893555
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2694: train_loss=6.988576412200928
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2695: train_loss=6.987051010131836
INFO - 04/15/25 16:38:00 - 0:06:24 - Epoch 2696: train_loss=6.981832504272461
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2697: train_loss=6.979819297790527
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2698: train_loss=6.97760534286499
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2699: train_loss=6.967182636260986
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2700: train_loss=6.9721550941467285
INFO - 04/15/25 16:38:01 - 0:06:24 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:01 - 0:06:24 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2700: ACC: 0.0, NMI: 0.4903939652485298, F1: 0.0, ARI: 0.3027274558394965
INFO - 04/15/25 16:38:01 - 0:06:24 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2701: train_loss=6.9714884757995605
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2702: train_loss=6.969199180603027
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2703: train_loss=6.970362663269043
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2704: train_loss=6.969083786010742
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2705: train_loss=6.965746879577637
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2706: train_loss=6.966437339782715
INFO - 04/15/25 16:38:01 - 0:06:24 - Epoch 2707: train_loss=6.96595573425293
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2708: train_loss=6.964354038238525
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2709: train_loss=6.963193893432617
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2710: train_loss=6.966392517089844
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2711: train_loss=6.96245002746582
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2712: train_loss=6.962280750274658
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2713: train_loss=6.961053371429443
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2714: train_loss=6.961136817932129
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2715: train_loss=6.9573073387146
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2716: train_loss=6.954761505126953
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2717: train_loss=6.944375991821289
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2718: train_loss=6.959362983703613
INFO - 04/15/25 16:38:01 - 0:06:25 - Epoch 2719: train_loss=6.943499565124512
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2720: train_loss=6.950122833251953
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2721: train_loss=6.951603412628174
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2722: train_loss=6.9379191398620605
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2723: train_loss=6.951618194580078
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2724: train_loss=6.9500250816345215
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2725: train_loss=6.949018478393555
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2726: train_loss=6.948868751525879
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2727: train_loss=6.947644233703613
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2728: train_loss=6.947633266448975
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2729: train_loss=6.946841716766357
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2730: train_loss=6.94525671005249
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2731: train_loss=6.946274280548096
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2732: train_loss=6.944396018981934
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2733: train_loss=6.937772274017334
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2734: train_loss=6.943007946014404
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2735: train_loss=6.935919761657715
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2736: train_loss=6.945786952972412
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2737: train_loss=6.9462809562683105
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2738: train_loss=6.909097194671631
INFO - 04/15/25 16:38:02 - 0:06:25 - Epoch 2739: train_loss=6.944984436035156
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2740: train_loss=6.9425129890441895
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2741: train_loss=6.947558879852295
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2742: train_loss=6.956728458404541
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2743: train_loss=6.956450939178467
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2744: train_loss=6.937002182006836
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2745: train_loss=6.938318729400635
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2746: train_loss=6.941565990447998
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2747: train_loss=6.935957431793213
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2748: train_loss=6.930973529815674
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2749: train_loss=6.936606407165527
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2750: train_loss=6.926876068115234
INFO - 04/15/25 16:38:02 - 0:06:26 - Epoch 2751: train_loss=6.932065010070801
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2752: train_loss=6.930124759674072
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2753: train_loss=6.92605447769165
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2754: train_loss=6.921142578125
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2755: train_loss=6.919712543487549
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2756: train_loss=6.92497444152832
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2757: train_loss=6.923904895782471
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2758: train_loss=6.921432971954346
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2759: train_loss=6.914217472076416
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2760: train_loss=6.909131050109863
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2761: train_loss=6.909588813781738
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2762: train_loss=6.907107830047607
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2763: train_loss=6.905706882476807
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2764: train_loss=6.909909248352051
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2765: train_loss=6.903274059295654
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2766: train_loss=6.907221794128418
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2767: train_loss=6.905396461486816
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2768: train_loss=6.899210453033447
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2769: train_loss=6.900927543640137
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2770: train_loss=6.898746490478516
INFO - 04/15/25 16:38:03 - 0:06:26 - Epoch 2771: train_loss=6.896908283233643
INFO - 04/15/25 16:38:03 - 0:06:27 - Epoch 2772: train_loss=6.899877071380615
INFO - 04/15/25 16:38:03 - 0:06:27 - Epoch 2773: train_loss=6.895948886871338
INFO - 04/15/25 16:38:03 - 0:06:27 - Epoch 2774: train_loss=6.890643119812012
INFO - 04/15/25 16:38:03 - 0:06:27 - Epoch 2775: train_loss=6.892688751220703
INFO - 04/15/25 16:38:03 - 0:06:27 - Epoch 2776: train_loss=6.898624420166016
INFO - 04/15/25 16:38:03 - 0:06:27 - Epoch 2777: train_loss=6.891956329345703
INFO - 04/15/25 16:38:03 - 0:06:27 - Epoch 2778: train_loss=6.894890308380127
INFO - 04/15/25 16:38:05 - 0:06:27 - Epoch 2779: train_loss=6.891795635223389
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2780: train_loss=6.89022159576416
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2781: train_loss=6.891175270080566
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2782: train_loss=6.8894243240356445
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2783: train_loss=6.8917036056518555
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2784: train_loss=6.889564037322998
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2785: train_loss=6.884768009185791
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2786: train_loss=6.886408805847168
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2787: train_loss=6.883111000061035
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2788: train_loss=6.885739803314209
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2789: train_loss=6.884734153747559
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2790: train_loss=6.883646011352539
INFO - 04/15/25 16:38:05 - 0:06:29 - Epoch 2791: train_loss=6.886536598205566
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2792: train_loss=6.884182929992676
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2793: train_loss=6.882858753204346
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2794: train_loss=6.881155490875244
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2795: train_loss=6.883381366729736
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2796: train_loss=6.882998943328857
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2797: train_loss=6.880087852478027
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2798: train_loss=6.882204532623291
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2799: train_loss=6.874688148498535
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2800: train_loss=6.882246494293213
INFO - 04/15/25 16:38:06 - 0:06:29 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:06 - 0:06:29 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2800: ACC: 0.0, NMI: 0.46070652143456037, F1: 0.0, ARI: 0.3035539243876962
INFO - 04/15/25 16:38:06 - 0:06:29 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2801: train_loss=6.883915424346924
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2802: train_loss=6.883293151855469
INFO - 04/15/25 16:38:06 - 0:06:29 - Epoch 2803: train_loss=6.88472843170166
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2804: train_loss=6.881176948547363
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2805: train_loss=6.882429122924805
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2806: train_loss=6.88051176071167
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2807: train_loss=6.881376266479492
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2808: train_loss=6.878577709197998
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2809: train_loss=6.882557392120361
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2810: train_loss=6.882990837097168
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2811: train_loss=6.874321937561035
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2812: train_loss=6.882484436035156
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2813: train_loss=6.87905216217041
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2814: train_loss=6.881582260131836
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2815: train_loss=6.884340763092041
INFO - 04/15/25 16:38:06 - 0:06:30 - Epoch 2816: train_loss=6.888069152832031
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2817: train_loss=6.877601623535156
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2818: train_loss=6.883454322814941
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2819: train_loss=6.8862457275390625
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2820: train_loss=6.878033638000488
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2821: train_loss=6.87094259262085
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2822: train_loss=6.897193431854248
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2823: train_loss=6.894327640533447
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2824: train_loss=6.904539108276367
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2825: train_loss=6.898244857788086
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2826: train_loss=6.904923915863037
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2827: train_loss=6.907285690307617
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2828: train_loss=6.89633321762085
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2829: train_loss=6.934957027435303
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2830: train_loss=6.930910110473633
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2831: train_loss=6.942466735839844
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2832: train_loss=6.931093215942383
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2833: train_loss=6.951030731201172
INFO - 04/15/25 16:38:07 - 0:06:30 - Epoch 2834: train_loss=6.964009761810303
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2835: train_loss=7.0416340827941895
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2836: train_loss=7.064395427703857
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2837: train_loss=7.032170295715332
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2838: train_loss=7.071163654327393
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2839: train_loss=6.982844352722168
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2840: train_loss=6.945046901702881
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2841: train_loss=6.937207221984863
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2842: train_loss=6.926998138427734
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2843: train_loss=6.939721584320068
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2844: train_loss=6.92391300201416
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2845: train_loss=6.920907020568848
INFO - 04/15/25 16:38:07 - 0:06:31 - Epoch 2846: train_loss=6.948816776275635
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2847: train_loss=7.030319690704346
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2848: train_loss=7.042553424835205
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2849: train_loss=7.005514621734619
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2850: train_loss=7.01047945022583
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2851: train_loss=7.093039512634277
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2852: train_loss=7.117045879364014
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2853: train_loss=7.114496231079102
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2854: train_loss=7.08895206451416
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2855: train_loss=7.060687065124512
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2856: train_loss=7.041200637817383
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2857: train_loss=7.0155816078186035
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2858: train_loss=6.971439361572266
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2859: train_loss=6.958393573760986
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2860: train_loss=6.9657511711120605
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2861: train_loss=6.961678504943848
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2862: train_loss=6.943004131317139
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2863: train_loss=6.923790454864502
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2864: train_loss=6.916454792022705
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2865: train_loss=6.91100549697876
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2866: train_loss=6.91025447845459
INFO - 04/15/25 16:38:08 - 0:06:31 - Epoch 2867: train_loss=6.912590980529785
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2868: train_loss=6.904405117034912
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2869: train_loss=6.889705657958984
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2870: train_loss=6.890206813812256
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2871: train_loss=6.884532451629639
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2872: train_loss=6.878127574920654
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2873: train_loss=6.87416410446167
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2874: train_loss=6.8679399490356445
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2875: train_loss=6.865952491760254
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2876: train_loss=6.861320972442627
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2877: train_loss=6.856555461883545
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2878: train_loss=6.853516578674316
INFO - 04/15/25 16:38:08 - 0:06:32 - Epoch 2879: train_loss=6.852676868438721
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2880: train_loss=6.849043846130371
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2881: train_loss=6.848109722137451
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2882: train_loss=6.8458733558654785
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2883: train_loss=6.841620922088623
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2884: train_loss=6.839444637298584
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2885: train_loss=6.839662075042725
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2886: train_loss=6.835928440093994
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2887: train_loss=6.833572864532471
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2888: train_loss=6.831538677215576
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2889: train_loss=6.8295440673828125
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2890: train_loss=6.82590389251709
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2891: train_loss=6.825124263763428
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2892: train_loss=6.821660041809082
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2893: train_loss=6.823131561279297
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2894: train_loss=6.820664405822754
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2895: train_loss=6.819781303405762
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2896: train_loss=6.820178985595703
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2897: train_loss=6.8158369064331055
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2898: train_loss=6.821437835693359
INFO - 04/15/25 16:38:09 - 0:06:32 - Epoch 2899: train_loss=6.816614627838135
INFO - 04/15/25 16:38:09 - 0:06:33 - Epoch 2900: train_loss=6.818638324737549
INFO - 04/15/25 16:38:09 - 0:06:33 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:09 - 0:06:33 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:38:09 - 0:06:33 - Epoch 2900: ACC: 0.0, NMI: 0.5166954585302135, F1: 0.0, ARI: 0.3570140770989979
INFO - 04/15/25 16:38:09 - 0:06:33 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:09 - 0:06:33 - Epoch 2901: train_loss=6.818974494934082
INFO - 04/15/25 16:38:09 - 0:06:33 - Epoch 2902: train_loss=6.811270713806152
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2903: train_loss=6.815791606903076
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2904: train_loss=6.813976287841797
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2905: train_loss=6.807006359100342
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2906: train_loss=6.8066487312316895
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2907: train_loss=6.8040595054626465
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2908: train_loss=6.801614284515381
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2909: train_loss=6.7996625900268555
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2910: train_loss=6.796689033508301
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2911: train_loss=6.795041084289551
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2912: train_loss=6.790421962738037
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2913: train_loss=6.791288375854492
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2914: train_loss=6.788334369659424
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2915: train_loss=6.786525726318359
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2916: train_loss=6.785807132720947
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2917: train_loss=6.783415794372559
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2918: train_loss=6.782011032104492
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2919: train_loss=6.779962062835693
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2920: train_loss=6.777338981628418
INFO - 04/15/25 16:38:10 - 0:06:33 - Epoch 2921: train_loss=6.776320934295654
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2922: train_loss=6.774848937988281
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2923: train_loss=6.774494171142578
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2924: train_loss=6.773384094238281
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2925: train_loss=6.7730607986450195
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2926: train_loss=6.771899700164795
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2927: train_loss=6.773321151733398
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2928: train_loss=6.771897792816162
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2929: train_loss=6.772876262664795
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2930: train_loss=6.772253513336182
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2931: train_loss=6.770535945892334
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2932: train_loss=6.77083158493042
INFO - 04/15/25 16:38:10 - 0:06:34 - Epoch 2933: train_loss=6.770062446594238
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2934: train_loss=6.769083499908447
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2935: train_loss=6.769536972045898
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2936: train_loss=6.768496990203857
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2937: train_loss=6.768258571624756
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2938: train_loss=6.767633438110352
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2939: train_loss=6.768321514129639
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2940: train_loss=6.766898155212402
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2941: train_loss=6.767906665802002
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2942: train_loss=6.767395496368408
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2943: train_loss=6.766788005828857
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2944: train_loss=6.766324996948242
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2945: train_loss=6.765945911407471
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2946: train_loss=6.765891075134277
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2947: train_loss=6.765963077545166
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2948: train_loss=6.764768600463867
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2949: train_loss=6.765540599822998
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2950: train_loss=6.764643669128418
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2951: train_loss=6.765315532684326
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2952: train_loss=6.764481544494629
INFO - 04/15/25 16:38:11 - 0:06:34 - Epoch 2953: train_loss=6.764349460601807
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2954: train_loss=6.7641472816467285
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2955: train_loss=6.765322685241699
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2956: train_loss=6.763260364532471
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2957: train_loss=6.76534366607666
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2958: train_loss=6.7639007568359375
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2959: train_loss=6.763781547546387
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2960: train_loss=6.763671398162842
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2961: train_loss=6.763025283813477
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2962: train_loss=6.762854099273682
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2963: train_loss=6.763698101043701
INFO - 04/15/25 16:38:11 - 0:06:35 - Epoch 2964: train_loss=6.76336669921875
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2965: train_loss=6.762012958526611
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2966: train_loss=6.761739730834961
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2967: train_loss=6.762139797210693
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2968: train_loss=6.761812686920166
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2969: train_loss=6.762142658233643
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2970: train_loss=6.7616119384765625
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2971: train_loss=6.761224746704102
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2972: train_loss=6.760842323303223
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2973: train_loss=6.761648178100586
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2974: train_loss=6.761251926422119
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2975: train_loss=6.761105060577393
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2976: train_loss=6.759952545166016
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2977: train_loss=6.76064920425415
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2978: train_loss=6.760196208953857
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2979: train_loss=6.760533809661865
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2980: train_loss=6.7611894607543945
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2981: train_loss=6.759440898895264
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2982: train_loss=6.758775234222412
INFO - 04/15/25 16:38:12 - 0:06:35 - Epoch 2983: train_loss=6.760945796966553
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2984: train_loss=6.760908603668213
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2985: train_loss=6.758563041687012
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2986: train_loss=6.758140563964844
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2987: train_loss=6.760746002197266
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2988: train_loss=6.760040760040283
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2989: train_loss=6.758674144744873
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2990: train_loss=6.7585272789001465
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2991: train_loss=6.75991678237915
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2992: train_loss=6.758998870849609
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2993: train_loss=6.758991241455078
INFO - 04/15/25 16:38:12 - 0:06:36 - Epoch 2994: train_loss=6.7583537101745605
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 2995: train_loss=6.759303569793701
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 2996: train_loss=6.759006023406982
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 2997: train_loss=6.75830078125
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 2998: train_loss=6.758254051208496
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 2999: train_loss=6.758482456207275
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 3000: train_loss=6.758386611938477
INFO - 04/15/25 16:38:13 - 0:06:36 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:13 - 0:06:36 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 3000: ACC: 0.0, NMI: 0.5071163895634396, F1: 0.0, ARI: 0.3396297377869163
INFO - 04/15/25 16:38:13 - 0:06:36 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 3001: train_loss=6.758983612060547
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 3002: train_loss=6.7578229904174805
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 3003: train_loss=6.757900714874268
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 3004: train_loss=6.757753372192383
INFO - 04/15/25 16:38:13 - 0:06:36 - Epoch 3005: train_loss=6.7582831382751465
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3006: train_loss=6.757504463195801
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3007: train_loss=6.758594512939453
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3008: train_loss=6.758732795715332
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3009: train_loss=6.756777286529541
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3010: train_loss=6.755838871002197
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3011: train_loss=6.759825706481934
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3012: train_loss=6.759973049163818
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3013: train_loss=6.755355358123779
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3014: train_loss=6.761019706726074
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3015: train_loss=6.761629104614258
INFO - 04/15/25 16:38:13 - 0:06:37 - Epoch 3016: train_loss=6.758389472961426
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3017: train_loss=6.757969856262207
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3018: train_loss=6.759454250335693
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3019: train_loss=6.757639408111572
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3020: train_loss=6.757431983947754
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3021: train_loss=6.7589006423950195
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3022: train_loss=6.756722450256348
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3023: train_loss=6.756819248199463
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3024: train_loss=6.757208824157715
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3025: train_loss=6.756654262542725
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3026: train_loss=6.756740093231201
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3027: train_loss=6.756566524505615
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3028: train_loss=6.7553606033325195
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3029: train_loss=6.756027698516846
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3030: train_loss=6.75480318069458
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3031: train_loss=6.755472660064697
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3032: train_loss=6.754889011383057
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3033: train_loss=6.755878925323486
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3034: train_loss=6.75544548034668
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3035: train_loss=6.75532341003418
INFO - 04/15/25 16:38:14 - 0:06:37 - Epoch 3036: train_loss=6.754818916320801
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3037: train_loss=6.755089282989502
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3038: train_loss=6.754806995391846
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3039: train_loss=6.755077362060547
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3040: train_loss=6.754610061645508
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3041: train_loss=6.754549026489258
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3042: train_loss=6.754366397857666
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3043: train_loss=6.75489616394043
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3044: train_loss=6.754612922668457
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3045: train_loss=6.754799842834473
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3046: train_loss=6.754498481750488
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3047: train_loss=6.7546844482421875
INFO - 04/15/25 16:38:14 - 0:06:38 - Epoch 3048: train_loss=6.753998279571533
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3049: train_loss=6.7545599937438965
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3050: train_loss=6.754283905029297
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3051: train_loss=6.754583358764648
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3052: train_loss=6.75398588180542
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3053: train_loss=6.754560470581055
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3054: train_loss=6.7548322677612305
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3055: train_loss=6.753883361816406
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3056: train_loss=6.753759860992432
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3057: train_loss=6.7541351318359375
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3058: train_loss=6.753779411315918
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3059: train_loss=6.754519462585449
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3060: train_loss=6.754095554351807
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3061: train_loss=6.753682613372803
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3062: train_loss=6.753406524658203
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3063: train_loss=6.753320693969727
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3064: train_loss=6.75291109085083
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3065: train_loss=6.753910541534424
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3066: train_loss=6.753524303436279
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3067: train_loss=6.753394603729248
INFO - 04/15/25 16:38:15 - 0:06:38 - Epoch 3068: train_loss=6.753530979156494
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3069: train_loss=6.753440856933594
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3070: train_loss=6.753028392791748
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3071: train_loss=6.752965450286865
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3072: train_loss=6.752896785736084
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3073: train_loss=6.753259181976318
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3074: train_loss=6.752813816070557
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3075: train_loss=6.753594875335693
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3076: train_loss=6.753357410430908
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3077: train_loss=6.752340316772461
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3078: train_loss=6.752350807189941
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3079: train_loss=6.753549098968506
INFO - 04/15/25 16:38:15 - 0:06:39 - Epoch 3080: train_loss=6.753153324127197
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3081: train_loss=6.752596855163574
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3082: train_loss=6.753003120422363
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3083: train_loss=6.7518439292907715
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3084: train_loss=6.753668785095215
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3085: train_loss=6.751922130584717
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3086: train_loss=6.755533218383789
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3087: train_loss=6.75637674331665
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3088: train_loss=6.752264499664307
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3089: train_loss=6.7566986083984375
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3090: train_loss=6.758818626403809
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3091: train_loss=6.756236553192139
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3092: train_loss=6.752374172210693
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3093: train_loss=6.7548956871032715
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3094: train_loss=6.7543044090271
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3095: train_loss=6.752724647521973
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3096: train_loss=6.753514289855957
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3097: train_loss=6.752831935882568
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3098: train_loss=6.753048896789551
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3099: train_loss=6.752488136291504
INFO - 04/15/25 16:38:16 - 0:06:39 - Epoch 3100: train_loss=6.753029823303223
INFO - 04/15/25 16:38:16 - 0:06:39 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:17 - 0:06:40 - Decoding cost time:  0.425 s
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3100: ACC: 0.0, NMI: 0.5157352067710302, F1: 0.0, ARI: 0.3491830138288143
INFO - 04/15/25 16:38:17 - 0:06:40 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3101: train_loss=6.751344680786133
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3102: train_loss=6.752044677734375
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3103: train_loss=6.752145767211914
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3104: train_loss=6.751121997833252
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3105: train_loss=6.753424167633057
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3106: train_loss=6.752546787261963
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3107: train_loss=6.753020763397217
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3108: train_loss=6.752267837524414
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3109: train_loss=6.751857757568359
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3110: train_loss=6.751460552215576
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3111: train_loss=6.751806735992432
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3112: train_loss=6.7511749267578125
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3113: train_loss=6.751950740814209
INFO - 04/15/25 16:38:17 - 0:06:40 - Epoch 3114: train_loss=6.75160026550293
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3115: train_loss=6.7520623207092285
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3116: train_loss=6.75150203704834
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3117: train_loss=6.751719951629639
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3118: train_loss=6.751902103424072
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3119: train_loss=6.752223968505859
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3120: train_loss=6.751179218292236
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3121: train_loss=6.751784801483154
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3122: train_loss=6.751284122467041
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3123: train_loss=6.751965522766113
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3124: train_loss=6.752028942108154
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3125: train_loss=6.751133441925049
INFO - 04/15/25 16:38:17 - 0:06:41 - Epoch 3126: train_loss=6.750904083251953
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3127: train_loss=6.7512335777282715
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3128: train_loss=6.7503509521484375
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3129: train_loss=6.7523956298828125
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3130: train_loss=6.752338409423828
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3131: train_loss=6.750349044799805
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3132: train_loss=6.751306533813477
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3133: train_loss=6.750014781951904
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3134: train_loss=6.751842021942139
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3135: train_loss=6.751456260681152
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3136: train_loss=6.7508416175842285
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3137: train_loss=6.751129150390625
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3138: train_loss=6.750199794769287
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3139: train_loss=6.751253604888916
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3140: train_loss=6.750069618225098
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3141: train_loss=6.752016067504883
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3142: train_loss=6.751543045043945
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3143: train_loss=6.751317501068115
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3144: train_loss=6.751185894012451
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3145: train_loss=6.750773906707764
INFO - 04/15/25 16:38:18 - 0:06:41 - Epoch 3146: train_loss=6.750770568847656
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3147: train_loss=6.7510809898376465
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3148: train_loss=6.750268459320068
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3149: train_loss=6.750834941864014
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3150: train_loss=6.749808311462402
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3151: train_loss=6.752442836761475
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3152: train_loss=6.752184867858887
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3153: train_loss=6.749443054199219
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3154: train_loss=6.751011848449707
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3155: train_loss=6.749334335327148
INFO - 04/15/25 16:38:18 - 0:06:42 - Epoch 3156: train_loss=6.751639366149902
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3157: train_loss=6.7513508796691895
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3158: train_loss=6.7507500648498535
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3159: train_loss=6.750673770904541
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3160: train_loss=6.750398635864258
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3161: train_loss=6.750311851501465
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3162: train_loss=6.749754428863525
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3163: train_loss=6.7511515617370605
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3164: train_loss=6.750476360321045
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3165: train_loss=6.750462532043457
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3166: train_loss=6.750146389007568
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3167: train_loss=6.750316619873047
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3168: train_loss=6.749761581420898
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3169: train_loss=6.749357223510742
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3170: train_loss=6.75078821182251
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3171: train_loss=6.749991416931152
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3172: train_loss=6.750594615936279
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3173: train_loss=6.750844955444336
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3174: train_loss=6.751075744628906
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3175: train_loss=6.750308036804199
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3176: train_loss=6.751060962677002
INFO - 04/15/25 16:38:19 - 0:06:42 - Epoch 3177: train_loss=6.750247478485107
INFO - 04/15/25 16:38:19 - 0:06:43 - Epoch 3178: train_loss=6.751141548156738
INFO - 04/15/25 16:38:19 - 0:06:43 - Epoch 3179: train_loss=6.751091003417969
INFO - 04/15/25 16:38:20 - 0:06:43 - Epoch 3180: train_loss=6.749849796295166
INFO - 04/15/25 16:38:20 - 0:06:44 - Epoch 3181: train_loss=6.749162197113037
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3182: train_loss=6.7509765625
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3183: train_loss=6.750296592712402
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3184: train_loss=6.7504353523254395
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3185: train_loss=6.750396728515625
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3186: train_loss=6.75004768371582
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3187: train_loss=6.749210357666016
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3188: train_loss=6.7507758140563965
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3189: train_loss=6.750476360321045
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3190: train_loss=6.74953556060791
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3191: train_loss=6.749302387237549
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3192: train_loss=6.750226020812988
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3193: train_loss=6.749880313873291
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3194: train_loss=6.749606132507324
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3195: train_loss=6.749288558959961
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3196: train_loss=6.749800682067871
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3197: train_loss=6.749796390533447
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3198: train_loss=6.749814033508301
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3199: train_loss=6.749682903289795
INFO - 04/15/25 16:38:21 - 0:06:44 - Epoch 3200: train_loss=6.7492499351501465
INFO - 04/15/25 16:38:21 - 0:06:44 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:21 - 0:06:45 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:38:21 - 0:06:45 - Epoch 3200: ACC: 0.0, NMI: 0.5201947961575556, F1: 0.0, ARI: 0.3523948405239994
INFO - 04/15/25 16:38:21 - 0:06:45 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:21 - 0:06:45 - Epoch 3201: train_loss=6.7493133544921875
INFO - 04/15/25 16:38:21 - 0:06:45 - Epoch 3202: train_loss=6.750055313110352
INFO - 04/15/25 16:38:21 - 0:06:45 - Epoch 3203: train_loss=6.7497429847717285
INFO - 04/15/25 16:38:21 - 0:06:45 - Epoch 3204: train_loss=6.749946594238281
INFO - 04/15/25 16:38:21 - 0:06:45 - Epoch 3205: train_loss=6.749390602111816
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3206: train_loss=6.749252796173096
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3207: train_loss=6.748536109924316
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3208: train_loss=6.75049352645874
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3209: train_loss=6.7502875328063965
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3210: train_loss=6.748674392700195
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3211: train_loss=6.748259544372559
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3212: train_loss=6.750489234924316
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3213: train_loss=6.750150680541992
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3214: train_loss=6.748593330383301
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3215: train_loss=6.748579502105713
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3216: train_loss=6.749583721160889
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3217: train_loss=6.749536514282227
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3218: train_loss=6.749268531799316
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3219: train_loss=6.748749256134033
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3220: train_loss=6.74951696395874
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3221: train_loss=6.749014854431152
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3222: train_loss=6.748777866363525
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3223: train_loss=6.74843168258667
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3224: train_loss=6.74929141998291
INFO - 04/15/25 16:38:22 - 0:06:45 - Epoch 3225: train_loss=6.749017715454102
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3226: train_loss=6.7484636306762695
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3227: train_loss=6.7485833168029785
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3228: train_loss=6.748906135559082
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3229: train_loss=6.749023914337158
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3230: train_loss=6.748867511749268
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3231: train_loss=6.749153137207031
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3232: train_loss=6.749022960662842
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3233: train_loss=6.749114990234375
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3234: train_loss=6.748571872711182
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3235: train_loss=6.748021125793457
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3236: train_loss=6.749761581420898
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3237: train_loss=6.749278545379639
INFO - 04/15/25 16:38:22 - 0:06:46 - Epoch 3238: train_loss=6.747569561004639
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3239: train_loss=6.747462749481201
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3240: train_loss=6.749630928039551
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3241: train_loss=6.748844146728516
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3242: train_loss=6.74783992767334
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3243: train_loss=6.74747371673584
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3244: train_loss=6.750004291534424
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3245: train_loss=6.748805999755859
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3246: train_loss=6.747753143310547
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3247: train_loss=6.747798442840576
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3248: train_loss=6.748954772949219
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3249: train_loss=6.749017238616943
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3250: train_loss=6.747446060180664
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3251: train_loss=6.746984004974365
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3252: train_loss=6.749373435974121
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3253: train_loss=6.749024868011475
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3254: train_loss=6.746931076049805
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3255: train_loss=6.746384620666504
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3256: train_loss=6.750450611114502
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3257: train_loss=6.748987674713135
INFO - 04/15/25 16:38:23 - 0:06:46 - Epoch 3258: train_loss=6.7477006912231445
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3259: train_loss=6.7481794357299805
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3260: train_loss=6.748286724090576
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3261: train_loss=6.747770309448242
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3262: train_loss=6.748396396636963
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3263: train_loss=6.747765064239502
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3264: train_loss=6.7478814125061035
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3265: train_loss=6.747570991516113
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3266: train_loss=6.748169422149658
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3267: train_loss=6.747361660003662
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3268: train_loss=6.748095512390137
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3269: train_loss=6.7472333908081055
INFO - 04/15/25 16:38:23 - 0:06:47 - Epoch 3270: train_loss=6.748189449310303
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3271: train_loss=6.74783182144165
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3272: train_loss=6.748188495635986
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3273: train_loss=6.74770975112915
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3274: train_loss=6.747354030609131
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3275: train_loss=6.747354507446289
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3276: train_loss=6.747799396514893
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3277: train_loss=6.747823238372803
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3278: train_loss=6.747390270233154
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3279: train_loss=6.7469353675842285
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3280: train_loss=6.748288154602051
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3281: train_loss=6.747296333312988
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3282: train_loss=6.747035503387451
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3283: train_loss=6.747795104980469
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3284: train_loss=6.74737548828125
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3285: train_loss=6.746942520141602
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3286: train_loss=6.748019218444824
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3287: train_loss=6.74811315536499
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3288: train_loss=6.747010707855225
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3289: train_loss=6.746324062347412
INFO - 04/15/25 16:38:24 - 0:06:47 - Epoch 3290: train_loss=6.747694969177246
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3291: train_loss=6.7472100257873535
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3292: train_loss=6.747461795806885
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3293: train_loss=6.746760368347168
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3294: train_loss=6.7475128173828125
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3295: train_loss=6.747058391571045
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3296: train_loss=6.747562885284424
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3297: train_loss=6.747673511505127
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3298: train_loss=6.746671676635742
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3299: train_loss=6.746303081512451
INFO - 04/15/25 16:38:24 - 0:06:48 - Epoch 3300: train_loss=6.747941970825195
INFO - 04/15/25 16:38:24 - 0:06:48 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:25 - 0:06:48 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3300: ACC: 0.0, NMI: 0.5214274394853518, F1: 0.0, ARI: 0.3524996901308039
INFO - 04/15/25 16:38:25 - 0:06:48 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3301: train_loss=6.747989654541016
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3302: train_loss=6.745845317840576
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3303: train_loss=6.745608806610107
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3304: train_loss=6.747440338134766
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3305: train_loss=6.746987342834473
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3306: train_loss=6.746365547180176
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3307: train_loss=6.746163368225098
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3308: train_loss=6.747209548950195
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3309: train_loss=6.746457576751709
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3310: train_loss=6.746992588043213
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3311: train_loss=6.746745586395264
INFO - 04/15/25 16:38:25 - 0:06:48 - Epoch 3312: train_loss=6.746222972869873
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3313: train_loss=6.746164798736572
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3314: train_loss=6.74710750579834
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3315: train_loss=6.746495723724365
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3316: train_loss=6.747162342071533
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3317: train_loss=6.746510028839111
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3318: train_loss=6.746152877807617
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3319: train_loss=6.745474815368652
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3320: train_loss=6.7470927238464355
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3321: train_loss=6.746760845184326
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3322: train_loss=6.745934963226318
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3323: train_loss=6.745579719543457
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3324: train_loss=6.746505260467529
INFO - 04/15/25 16:38:25 - 0:06:49 - Epoch 3325: train_loss=6.746280670166016
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3326: train_loss=6.74666166305542
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3327: train_loss=6.74671745300293
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3328: train_loss=6.745725631713867
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3329: train_loss=6.745156288146973
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3330: train_loss=6.746809482574463
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3331: train_loss=6.7462005615234375
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3332: train_loss=6.746056079864502
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3333: train_loss=6.745673179626465
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3334: train_loss=6.746062755584717
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3335: train_loss=6.745619773864746
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3336: train_loss=6.746371269226074
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3337: train_loss=6.745797634124756
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3338: train_loss=6.745670795440674
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3339: train_loss=6.7453742027282715
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3340: train_loss=6.746328353881836
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3341: train_loss=6.7459516525268555
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3342: train_loss=6.745822906494141
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3343: train_loss=6.745677471160889
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3344: train_loss=6.746128082275391
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3345: train_loss=6.746196746826172
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3346: train_loss=6.7458672523498535
INFO - 04/15/25 16:38:26 - 0:06:49 - Epoch 3347: train_loss=6.745644569396973
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3348: train_loss=6.746105670928955
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3349: train_loss=6.745406627655029
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3350: train_loss=6.745743274688721
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3351: train_loss=6.74516487121582
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3352: train_loss=6.746097087860107
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3353: train_loss=6.745962619781494
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3354: train_loss=6.7448835372924805
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3355: train_loss=6.744295597076416
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3356: train_loss=6.747157573699951
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3357: train_loss=6.746549129486084
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3358: train_loss=6.745011329650879
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3359: train_loss=6.745199203491211
INFO - 04/15/25 16:38:26 - 0:06:50 - Epoch 3360: train_loss=6.745771884918213
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3361: train_loss=6.7448410987854
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3362: train_loss=6.746066093444824
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3363: train_loss=6.745664119720459
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3364: train_loss=6.745893955230713
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3365: train_loss=6.745419979095459
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3366: train_loss=6.745316028594971
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3367: train_loss=6.74508810043335
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3368: train_loss=6.746164321899414
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3369: train_loss=6.745787620544434
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3370: train_loss=6.744597434997559
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3371: train_loss=6.744513511657715
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3372: train_loss=6.7456374168396
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3373: train_loss=6.744361877441406
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3374: train_loss=6.745630741119385
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3375: train_loss=6.745891571044922
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3376: train_loss=6.744457244873047
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3377: train_loss=6.743838310241699
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3378: train_loss=6.745029449462891
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3379: train_loss=6.74430513381958
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3380: train_loss=6.745882034301758
INFO - 04/15/25 16:38:27 - 0:06:50 - Epoch 3381: train_loss=6.745551586151123
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3382: train_loss=6.744131565093994
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3383: train_loss=6.744107723236084
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3384: train_loss=6.744701385498047
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3385: train_loss=6.743569850921631
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3386: train_loss=6.746110916137695
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3387: train_loss=6.745471477508545
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3388: train_loss=6.743738174438477
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3389: train_loss=6.744449615478516
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3390: train_loss=6.74491024017334
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3391: train_loss=6.743487358093262
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3392: train_loss=6.746466636657715
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3393: train_loss=6.746382236480713
INFO - 04/15/25 16:38:27 - 0:06:51 - Epoch 3394: train_loss=6.742452621459961
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3395: train_loss=6.747369289398193
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3396: train_loss=6.747255802154541
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3397: train_loss=6.743998050689697
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3398: train_loss=6.746993541717529
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3399: train_loss=6.748205661773682
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3400: train_loss=6.745944499969482
INFO - 04/15/25 16:38:28 - 0:06:51 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:28 - 0:06:51 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3400: ACC: 0.0, NMI: 0.5229334344280807, F1: 0.0, ARI: 0.3556316630764501
INFO - 04/15/25 16:38:28 - 0:06:51 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3401: train_loss=6.745357990264893
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3402: train_loss=6.746075630187988
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3403: train_loss=6.745222091674805
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3404: train_loss=6.744709491729736
INFO - 04/15/25 16:38:28 - 0:06:51 - Epoch 3405: train_loss=6.74554443359375
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3406: train_loss=6.744969844818115
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3407: train_loss=6.744253158569336
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3408: train_loss=6.744974136352539
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3409: train_loss=6.744009494781494
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3410: train_loss=6.744787693023682
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3411: train_loss=6.744461536407471
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3412: train_loss=6.743464469909668
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3413: train_loss=6.744439601898193
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3414: train_loss=6.743368625640869
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3415: train_loss=6.744803428649902
INFO - 04/15/25 16:38:28 - 0:06:52 - Epoch 3416: train_loss=6.743695259094238
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3417: train_loss=6.744918346405029
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3418: train_loss=6.744626045227051
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3419: train_loss=6.7438859939575195
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3420: train_loss=6.744025707244873
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3421: train_loss=6.743682384490967
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3422: train_loss=6.7435431480407715
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3423: train_loss=6.744357585906982
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3424: train_loss=6.743279457092285
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3425: train_loss=6.744259834289551
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3426: train_loss=6.743804931640625
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3427: train_loss=6.743577480316162
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3428: train_loss=6.743601322174072
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3429: train_loss=6.744890213012695
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3430: train_loss=6.743506908416748
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3431: train_loss=6.74456787109375
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3432: train_loss=6.743721008300781
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3433: train_loss=6.744085311889648
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3434: train_loss=6.74422550201416
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3435: train_loss=6.744198322296143
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3436: train_loss=6.743465423583984
INFO - 04/15/25 16:38:29 - 0:06:52 - Epoch 3437: train_loss=6.744366645812988
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3438: train_loss=6.74374532699585
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3439: train_loss=6.743872165679932
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3440: train_loss=6.743659973144531
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3441: train_loss=6.743910789489746
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3442: train_loss=6.743730545043945
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3443: train_loss=6.743671894073486
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3444: train_loss=6.74320650100708
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3445: train_loss=6.74392032623291
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3446: train_loss=6.743630409240723
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3447: train_loss=6.743649482727051
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3448: train_loss=6.7433180809021
INFO - 04/15/25 16:38:29 - 0:06:53 - Epoch 3449: train_loss=6.743669033050537
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3450: train_loss=6.743224620819092
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3451: train_loss=6.74359130859375
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3452: train_loss=6.743081092834473
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3453: train_loss=6.743842124938965
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3454: train_loss=6.743574142456055
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3455: train_loss=6.742787837982178
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3456: train_loss=6.742821216583252
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3457: train_loss=6.744083404541016
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3458: train_loss=6.743279457092285
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3459: train_loss=6.743052959442139
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3460: train_loss=6.742717742919922
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3461: train_loss=6.743279457092285
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3462: train_loss=6.743216514587402
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3463: train_loss=6.743486404418945
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3464: train_loss=6.742641925811768
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3465: train_loss=6.743066787719727
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3466: train_loss=6.742973804473877
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3467: train_loss=6.743109703063965
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3468: train_loss=6.742711067199707
INFO - 04/15/25 16:38:30 - 0:06:53 - Epoch 3469: train_loss=6.742884635925293
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3470: train_loss=6.742618560791016
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3471: train_loss=6.742665767669678
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3472: train_loss=6.743005752563477
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3473: train_loss=6.743068218231201
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3474: train_loss=6.742661476135254
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3475: train_loss=6.742625713348389
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3476: train_loss=6.742157459259033
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3477: train_loss=6.743099689483643
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3478: train_loss=6.74330997467041
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3479: train_loss=6.742687225341797
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3480: train_loss=6.742098331451416
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3481: train_loss=6.742969036102295
INFO - 04/15/25 16:38:30 - 0:06:54 - Epoch 3482: train_loss=6.742557525634766
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3483: train_loss=6.742387771606445
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3484: train_loss=6.742125511169434
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3485: train_loss=6.742746829986572
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3486: train_loss=6.74294900894165
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3487: train_loss=6.748671054840088
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3488: train_loss=6.742382526397705
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3489: train_loss=6.744711399078369
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3490: train_loss=6.742467880249023
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3491: train_loss=6.742911338806152
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3492: train_loss=6.743915557861328
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3493: train_loss=6.742499351501465
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3494: train_loss=6.742836952209473
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3495: train_loss=6.743122100830078
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3496: train_loss=6.741720199584961
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3497: train_loss=6.743084907531738
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3498: train_loss=6.742755889892578
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3499: train_loss=6.742314338684082
INFO - 04/15/25 16:38:31 - 0:06:54 - Epoch 3500: train_loss=6.741997718811035
INFO - 04/15/25 16:38:31 - 0:06:54 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:31 - 0:06:55 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:38:31 - 0:06:55 - Epoch 3500: ACC: 0.0, NMI: 0.5268117082557767, F1: 0.0, ARI: 0.3611026841615421
INFO - 04/15/25 16:38:31 - 0:06:55 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:31 - 0:06:55 - Epoch 3501: train_loss=6.7425336837768555
INFO - 04/15/25 16:38:31 - 0:06:55 - Epoch 3502: train_loss=6.741855621337891
INFO - 04/15/25 16:38:31 - 0:06:55 - Epoch 3503: train_loss=6.742739677429199
INFO - 04/15/25 16:38:31 - 0:06:55 - Epoch 3504: train_loss=6.742447853088379
INFO - 04/15/25 16:38:31 - 0:06:55 - Epoch 3505: train_loss=6.742254257202148
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3506: train_loss=6.7422943115234375
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3507: train_loss=6.74245023727417
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3508: train_loss=6.742123603820801
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3509: train_loss=6.742799758911133
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3510: train_loss=6.742865085601807
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3511: train_loss=6.741912364959717
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3512: train_loss=6.741704940795898
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3513: train_loss=6.742741107940674
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3514: train_loss=6.742043972015381
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3515: train_loss=6.742252349853516
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3516: train_loss=6.742011070251465
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3517: train_loss=6.742498397827148
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3518: train_loss=6.74249267578125
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3519: train_loss=6.741804122924805
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3520: train_loss=6.741690635681152
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3521: train_loss=6.742122650146484
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3522: train_loss=6.74196720123291
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3523: train_loss=6.742194175720215
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3524: train_loss=6.7418413162231445
INFO - 04/15/25 16:38:32 - 0:06:55 - Epoch 3525: train_loss=6.741837501525879
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3526: train_loss=6.741469383239746
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3527: train_loss=6.7418036460876465
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3528: train_loss=6.741659164428711
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3529: train_loss=6.741724967956543
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3530: train_loss=6.742635250091553
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3531: train_loss=6.741702079772949
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3532: train_loss=6.741476535797119
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3533: train_loss=6.741769313812256
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3534: train_loss=6.74177360534668
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3535: train_loss=6.741733551025391
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3536: train_loss=6.741326808929443
INFO - 04/15/25 16:38:32 - 0:06:56 - Epoch 3537: train_loss=6.7417120933532715
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3538: train_loss=6.74160099029541
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3539: train_loss=6.741209030151367
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3540: train_loss=6.740897178649902
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3541: train_loss=6.741406440734863
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3542: train_loss=6.741455078125
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3543: train_loss=6.741068363189697
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3544: train_loss=6.740907669067383
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3545: train_loss=6.741666793823242
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3546: train_loss=6.741848468780518
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3547: train_loss=6.7407636642456055
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3548: train_loss=6.740855693817139
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3549: train_loss=6.741544246673584
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3550: train_loss=6.740891456604004
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3551: train_loss=6.741249084472656
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3552: train_loss=6.741358757019043
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3553: train_loss=6.740655899047852
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3554: train_loss=6.740820407867432
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3555: train_loss=6.741235256195068
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3556: train_loss=6.741334438323975
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3557: train_loss=6.7408246994018555
INFO - 04/15/25 16:38:33 - 0:06:56 - Epoch 3558: train_loss=6.740708827972412
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3559: train_loss=6.7415313720703125
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3560: train_loss=6.7413835525512695
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3561: train_loss=6.740732192993164
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3562: train_loss=6.740262031555176
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3563: train_loss=6.741239070892334
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3564: train_loss=6.74132776260376
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3565: train_loss=6.7404632568359375
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3566: train_loss=6.7407660484313965
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3567: train_loss=6.7411651611328125
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3568: train_loss=6.741034507751465
INFO - 04/15/25 16:38:33 - 0:06:57 - Epoch 3569: train_loss=6.740332126617432
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3570: train_loss=6.740260124206543
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3571: train_loss=6.741208076477051
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3572: train_loss=6.740945339202881
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3573: train_loss=6.740583896636963
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3574: train_loss=6.740370273590088
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3575: train_loss=6.74061393737793
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3576: train_loss=6.7403059005737305
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3577: train_loss=6.741254806518555
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3578: train_loss=6.740557670593262
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3579: train_loss=6.740632057189941
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3580: train_loss=6.739911079406738
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3581: train_loss=6.741199016571045
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3582: train_loss=6.741381645202637
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3583: train_loss=6.73928165435791
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3584: train_loss=6.739246845245361
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3585: train_loss=6.7413225173950195
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3586: train_loss=6.740623474121094
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3587: train_loss=6.740294456481934
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3588: train_loss=6.740120887756348
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3589: train_loss=6.740590572357178
INFO - 04/15/25 16:38:34 - 0:06:57 - Epoch 3590: train_loss=6.7397003173828125
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3591: train_loss=6.740373134613037
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3592: train_loss=6.739634990692139
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3593: train_loss=6.740856647491455
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3594: train_loss=6.740938663482666
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3595: train_loss=6.740290641784668
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3596: train_loss=6.739744663238525
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3597: train_loss=6.740604877471924
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3598: train_loss=6.740326881408691
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3599: train_loss=6.740144729614258
INFO - 04/15/25 16:38:34 - 0:06:58 - Epoch 3600: train_loss=6.7401862144470215
INFO - 04/15/25 16:38:34 - 0:06:58 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:35 - 0:06:58 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3600: ACC: 0.0, NMI: 0.5268117082557767, F1: 0.0, ARI: 0.3611026841615421
INFO - 04/15/25 16:38:35 - 0:06:58 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3601: train_loss=6.7400221824646
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3602: train_loss=6.739743232727051
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3603: train_loss=6.740266799926758
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3604: train_loss=6.739512920379639
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3605: train_loss=6.740647315979004
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3606: train_loss=6.740037441253662
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3607: train_loss=6.739600658416748
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3608: train_loss=6.739445686340332
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3609: train_loss=6.740466117858887
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3610: train_loss=6.740166187286377
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3611: train_loss=6.739548683166504
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3612: train_loss=6.739267349243164
INFO - 04/15/25 16:38:35 - 0:06:58 - Epoch 3613: train_loss=6.7402520179748535
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3614: train_loss=6.740206718444824
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3615: train_loss=6.7389116287231445
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3616: train_loss=6.7390947341918945
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3617: train_loss=6.740692138671875
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3618: train_loss=6.740421772003174
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3619: train_loss=6.7386980056762695
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3620: train_loss=6.738686561584473
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3621: train_loss=6.739890098571777
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3622: train_loss=6.739225387573242
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3623: train_loss=6.740198135375977
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3624: train_loss=6.740488529205322
INFO - 04/15/25 16:38:35 - 0:06:59 - Epoch 3625: train_loss=6.738547325134277
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3626: train_loss=6.7393670082092285
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3627: train_loss=6.737765789031982
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3628: train_loss=6.7395524978637695
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3629: train_loss=6.738080024719238
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3630: train_loss=6.740128040313721
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3631: train_loss=6.739722728729248
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3632: train_loss=6.738219261169434
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3633: train_loss=6.738977909088135
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3634: train_loss=6.738603115081787
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3635: train_loss=6.7381672859191895
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3636: train_loss=6.739168643951416
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3637: train_loss=6.738260746002197
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3638: train_loss=6.740599155426025
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3639: train_loss=6.740117073059082
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3640: train_loss=6.738810062408447
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3641: train_loss=6.7397966384887695
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3642: train_loss=6.7383952140808105
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3643: train_loss=6.738617897033691
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3644: train_loss=6.739220142364502
INFO - 04/15/25 16:38:36 - 0:06:59 - Epoch 3645: train_loss=6.738461971282959
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3646: train_loss=6.7399797439575195
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3647: train_loss=6.739240646362305
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3648: train_loss=6.738978862762451
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3649: train_loss=6.73872709274292
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3650: train_loss=6.739039421081543
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3651: train_loss=6.738887786865234
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3652: train_loss=6.738198280334473
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3653: train_loss=6.739113807678223
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3654: train_loss=6.738153457641602
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3655: train_loss=6.740279197692871
INFO - 04/15/25 16:38:36 - 0:07:00 - Epoch 3656: train_loss=6.740334987640381
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3657: train_loss=6.738001346588135
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3658: train_loss=6.739416599273682
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3659: train_loss=6.738335609436035
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3660: train_loss=6.740026950836182
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3661: train_loss=6.738448143005371
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3662: train_loss=6.73982048034668
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3663: train_loss=6.739414215087891
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3664: train_loss=6.738914966583252
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3665: train_loss=6.739111423492432
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3666: train_loss=6.738469123840332
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3667: train_loss=6.738975524902344
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3668: train_loss=6.738221168518066
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3669: train_loss=6.738636493682861
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3670: train_loss=6.738646984100342
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3671: train_loss=6.73778772354126
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3672: train_loss=6.737865447998047
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3673: train_loss=6.737032413482666
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3674: train_loss=6.7383952140808105
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3675: train_loss=6.737284183502197
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3676: train_loss=6.738762378692627
INFO - 04/15/25 16:38:37 - 0:07:00 - Epoch 3677: train_loss=6.738880634307861
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3678: train_loss=6.737392902374268
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3679: train_loss=6.73797082901001
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3680: train_loss=6.737264156341553
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3681: train_loss=6.738279342651367
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3682: train_loss=6.73734712600708
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3683: train_loss=6.738646030426025
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3684: train_loss=6.738250255584717
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3685: train_loss=6.737543106079102
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3686: train_loss=6.737363338470459
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3687: train_loss=6.738156318664551
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3688: train_loss=6.736852645874023
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3689: train_loss=6.738165378570557
INFO - 04/15/25 16:38:37 - 0:07:01 - Epoch 3690: train_loss=6.736874580383301
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3691: train_loss=6.738714218139648
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3692: train_loss=6.738297939300537
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3693: train_loss=6.737636089324951
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3694: train_loss=6.737518787384033
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3695: train_loss=6.738120079040527
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3696: train_loss=6.736995697021484
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3697: train_loss=6.738297462463379
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3698: train_loss=6.737397193908691
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3699: train_loss=6.7380900382995605
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3700: train_loss=6.737881660461426
INFO - 04/15/25 16:38:38 - 0:07:01 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:38 - 0:07:01 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3700: ACC: 0.0, NMI: 0.5306827899345428, F1: 0.0, ARI: 0.36373913127143165
INFO - 04/15/25 16:38:38 - 0:07:01 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:38 - 0:07:01 - Epoch 3701: train_loss=6.737884998321533
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3702: train_loss=6.737629413604736
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3703: train_loss=6.737916469573975
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3704: train_loss=6.737656116485596
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3705: train_loss=6.73792839050293
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3706: train_loss=6.73760461807251
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3707: train_loss=6.737663745880127
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3708: train_loss=6.737593173980713
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3709: train_loss=6.7376909255981445
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3710: train_loss=6.737605571746826
INFO - 04/15/25 16:38:38 - 0:07:02 - Epoch 3711: train_loss=6.738799095153809
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3712: train_loss=6.7453532218933105
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3713: train_loss=6.745835304260254
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3714: train_loss=6.743619441986084
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3715: train_loss=6.736927032470703
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3716: train_loss=6.74232292175293
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3717: train_loss=6.744697570800781
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3718: train_loss=6.740703582763672
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3719: train_loss=6.745002269744873
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3720: train_loss=6.777258396148682
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3721: train_loss=6.767703533172607
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3722: train_loss=6.757634162902832
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3723: train_loss=6.75862455368042
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3724: train_loss=6.751758575439453
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3725: train_loss=6.766506671905518
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3726: train_loss=6.747378826141357
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3727: train_loss=6.750818729400635
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3728: train_loss=6.758436679840088
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3729: train_loss=6.755557060241699
INFO - 04/15/25 16:38:39 - 0:07:02 - Epoch 3730: train_loss=6.748219013214111
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3731: train_loss=6.744303226470947
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3732: train_loss=6.740742206573486
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3733: train_loss=6.742194652557373
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3734: train_loss=6.744520664215088
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3735: train_loss=6.743439674377441
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3736: train_loss=6.744720458984375
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3737: train_loss=6.745860576629639
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3738: train_loss=6.7445220947265625
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3739: train_loss=6.744470119476318
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3740: train_loss=6.744218349456787
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3741: train_loss=6.742537498474121
INFO - 04/15/25 16:38:39 - 0:07:03 - Epoch 3742: train_loss=6.743072986602783
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3743: train_loss=6.7417778968811035
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3744: train_loss=6.740803241729736
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3745: train_loss=6.741184234619141
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3746: train_loss=6.740117073059082
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3747: train_loss=6.740601062774658
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3748: train_loss=6.740678787231445
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3749: train_loss=6.739767551422119
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3750: train_loss=6.739711284637451
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3751: train_loss=6.73915433883667
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3752: train_loss=6.739968299865723
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3753: train_loss=6.738891124725342
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3754: train_loss=6.740082263946533
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3755: train_loss=6.738951683044434
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3756: train_loss=6.739872455596924
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3757: train_loss=6.739660263061523
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3758: train_loss=6.739842414855957
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3759: train_loss=6.739595413208008
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3760: train_loss=6.739192962646484
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3761: train_loss=6.739223957061768
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3762: train_loss=6.739479064941406
INFO - 04/15/25 16:38:40 - 0:07:03 - Epoch 3763: train_loss=6.738827228546143
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3764: train_loss=6.739253044128418
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3765: train_loss=6.738351821899414
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3766: train_loss=6.739284038543701
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3767: train_loss=6.738853454589844
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3768: train_loss=6.738051414489746
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3769: train_loss=6.738644599914551
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3770: train_loss=6.738295078277588
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3771: train_loss=6.73766565322876
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3772: train_loss=6.738762855529785
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3773: train_loss=6.738605499267578
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3774: train_loss=6.737887859344482
INFO - 04/15/25 16:38:40 - 0:07:04 - Epoch 3775: train_loss=6.738147258758545
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3776: train_loss=6.738741874694824
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3777: train_loss=6.737905979156494
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3778: train_loss=6.737928867340088
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3779: train_loss=6.738194942474365
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3780: train_loss=6.738163471221924
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3781: train_loss=6.737602233886719
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3782: train_loss=6.738340854644775
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3783: train_loss=6.738360404968262
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3784: train_loss=6.737490653991699
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3785: train_loss=6.737117290496826
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3786: train_loss=6.738334655761719
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3787: train_loss=6.737436294555664
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3788: train_loss=6.738023281097412
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3789: train_loss=6.737588405609131
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3790: train_loss=6.737258434295654
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3791: train_loss=6.736795425415039
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3792: train_loss=6.737852096557617
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3793: train_loss=6.737641334533691
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3794: train_loss=6.737209320068359
INFO - 04/15/25 16:38:41 - 0:07:04 - Epoch 3795: train_loss=6.736815452575684
INFO - 04/15/25 16:38:41 - 0:07:05 - Epoch 3796: train_loss=6.737646102905273
INFO - 04/15/25 16:38:41 - 0:07:05 - Epoch 3797: train_loss=6.737411022186279
INFO - 04/15/25 16:38:41 - 0:07:05 - Epoch 3798: train_loss=6.736853122711182
INFO - 04/15/25 16:38:41 - 0:07:05 - Epoch 3799: train_loss=6.736570835113525
INFO - 04/15/25 16:38:41 - 0:07:05 - Epoch 3800: train_loss=6.737748146057129
INFO - 04/15/25 16:38:41 - 0:07:05 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:41 - 0:07:05 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3800: ACC: 0.0, NMI: 0.5105569618515218, F1: 0.0, ARI: 0.3352525652086331
INFO - 04/15/25 16:38:42 - 0:07:05 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3801: train_loss=6.737716197967529
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3802: train_loss=6.736469268798828
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3803: train_loss=6.736399173736572
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3804: train_loss=6.737307071685791
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3805: train_loss=6.737076282501221
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3806: train_loss=6.736758708953857
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3807: train_loss=6.736090660095215
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3808: train_loss=6.737077236175537
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3809: train_loss=6.736902236938477
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3810: train_loss=6.736871242523193
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3811: train_loss=6.736861705780029
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3812: train_loss=6.736920356750488
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3813: train_loss=6.736625671386719
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3814: train_loss=6.7363386154174805
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3815: train_loss=6.7362141609191895
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3816: train_loss=6.736732006072998
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3817: train_loss=6.736930847167969
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3818: train_loss=6.736485481262207
INFO - 04/15/25 16:38:42 - 0:07:05 - Epoch 3819: train_loss=6.736310005187988
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3820: train_loss=6.73652458190918
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3821: train_loss=6.736408233642578
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3822: train_loss=6.736350059509277
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3823: train_loss=6.736032485961914
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3824: train_loss=6.736608982086182
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3825: train_loss=6.736543655395508
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3826: train_loss=6.736279010772705
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3827: train_loss=6.7364606857299805
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3828: train_loss=6.736211776733398
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3829: train_loss=6.736068248748779
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3830: train_loss=6.736214637756348
INFO - 04/15/25 16:38:42 - 0:07:06 - Epoch 3831: train_loss=6.736363887786865
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3832: train_loss=6.7359771728515625
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3833: train_loss=6.735935688018799
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3834: train_loss=6.736439228057861
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3835: train_loss=6.736109733581543
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3836: train_loss=6.736019134521484
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3837: train_loss=6.735753536224365
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3838: train_loss=6.736473083496094
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3839: train_loss=6.736069202423096
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3840: train_loss=6.735531806945801
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3841: train_loss=6.735343933105469
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3842: train_loss=6.7369384765625
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3843: train_loss=6.736133098602295
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3844: train_loss=6.735135555267334
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3845: train_loss=6.734739780426025
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3846: train_loss=6.737210750579834
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3847: train_loss=6.736252784729004
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3848: train_loss=6.734328269958496
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3849: train_loss=6.734703063964844
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3850: train_loss=6.736570835113525
INFO - 04/15/25 16:38:43 - 0:07:06 - Epoch 3851: train_loss=6.735934257507324
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3852: train_loss=6.7362542152404785
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3853: train_loss=6.736015796661377
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3854: train_loss=6.735579013824463
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3855: train_loss=6.735729694366455
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3856: train_loss=6.734626770019531
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3857: train_loss=6.735487461090088
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3858: train_loss=6.734774589538574
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3859: train_loss=6.734948635101318
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3860: train_loss=6.734460353851318
INFO - 04/15/25 16:38:43 - 0:07:07 - Epoch 3861: train_loss=6.735897064208984
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3862: train_loss=6.734940528869629
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3863: train_loss=6.737159252166748
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3864: train_loss=6.735531330108643
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3865: train_loss=6.736724853515625
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3866: train_loss=6.734817028045654
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3867: train_loss=6.737372875213623
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3868: train_loss=6.735779762268066
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3869: train_loss=6.736825942993164
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3870: train_loss=6.738933563232422
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3871: train_loss=6.750925540924072
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3872: train_loss=6.74137020111084
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3873: train_loss=6.739052772521973
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3874: train_loss=6.739663124084473
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3875: train_loss=6.740755081176758
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3876: train_loss=6.743551731109619
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3877: train_loss=6.740511894226074
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3878: train_loss=6.738916873931885
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3879: train_loss=6.738116264343262
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3880: train_loss=6.737983226776123
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3881: train_loss=6.739124298095703
INFO - 04/15/25 16:38:44 - 0:07:07 - Epoch 3882: train_loss=6.7388691902160645
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3883: train_loss=6.7369065284729
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3884: train_loss=6.744758605957031
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3885: train_loss=6.741106986999512
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3886: train_loss=6.745606899261475
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3887: train_loss=6.742732048034668
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3888: train_loss=6.741437911987305
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3889: train_loss=6.829915523529053
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3890: train_loss=6.740203380584717
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3891: train_loss=6.7367939949035645
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3892: train_loss=6.766925811767578
INFO - 04/15/25 16:38:44 - 0:07:08 - Epoch 3893: train_loss=6.742985725402832
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3894: train_loss=6.78425931930542
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3895: train_loss=6.7835493087768555
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3896: train_loss=6.752589225769043
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3897: train_loss=6.760490894317627
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3898: train_loss=6.763734817504883
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3899: train_loss=6.758428573608398
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3900: train_loss=6.777017593383789
INFO - 04/15/25 16:38:45 - 0:07:08 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:45 - 0:07:08 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3900: ACC: 0.0, NMI: 0.532193608692978, F1: 0.0, ARI: 0.3675347928735334
INFO - 04/15/25 16:38:45 - 0:07:08 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3901: train_loss=6.788553714752197
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3902: train_loss=6.778359889984131
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3903: train_loss=6.763426780700684
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3904: train_loss=6.763916969299316
INFO - 04/15/25 16:38:45 - 0:07:08 - Epoch 3905: train_loss=6.768242359161377
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3906: train_loss=6.762988090515137
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3907: train_loss=6.753318786621094
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3908: train_loss=6.767465591430664
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3909: train_loss=6.761629581451416
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3910: train_loss=6.760515213012695
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3911: train_loss=6.763907432556152
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3912: train_loss=6.761059761047363
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3913: train_loss=6.762021064758301
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3914: train_loss=6.761979103088379
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3915: train_loss=6.75885534286499
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3916: train_loss=6.75924825668335
INFO - 04/15/25 16:38:45 - 0:07:09 - Epoch 3917: train_loss=6.757882118225098
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3918: train_loss=6.75356388092041
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3919: train_loss=6.756686687469482
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3920: train_loss=6.755477428436279
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3921: train_loss=6.752118110656738
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3922: train_loss=6.75253963470459
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3923: train_loss=6.751855850219727
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3924: train_loss=6.752866268157959
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3925: train_loss=6.749642372131348
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3926: train_loss=6.751758575439453
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3927: train_loss=6.751416206359863
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3928: train_loss=6.749622344970703
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3929: train_loss=6.748704433441162
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3930: train_loss=6.749983787536621
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3931: train_loss=6.749999046325684
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3932: train_loss=6.748414039611816
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3933: train_loss=6.746500492095947
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3934: train_loss=6.7494587898254395
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3935: train_loss=6.746247291564941
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3936: train_loss=6.751615047454834
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3937: train_loss=6.7498884201049805
INFO - 04/15/25 16:38:46 - 0:07:09 - Epoch 3938: train_loss=6.749253273010254
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3939: train_loss=6.750009059906006
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3940: train_loss=6.743156433105469
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3941: train_loss=6.743149757385254
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3942: train_loss=6.745916366577148
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3943: train_loss=6.7434983253479
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3944: train_loss=6.740762710571289
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3945: train_loss=6.750097274780273
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3946: train_loss=6.743971824645996
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3947: train_loss=6.74337100982666
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3948: train_loss=6.7426676750183105
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3949: train_loss=6.737553596496582
INFO - 04/15/25 16:38:46 - 0:07:10 - Epoch 3950: train_loss=6.7421555519104
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3951: train_loss=6.745365619659424
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3952: train_loss=6.744137287139893
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3953: train_loss=6.739996433258057
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3954: train_loss=6.739010334014893
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3955: train_loss=6.740797519683838
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3956: train_loss=6.740881443023682
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3957: train_loss=6.739181041717529
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3958: train_loss=6.7378435134887695
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3959: train_loss=6.73900032043457
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3960: train_loss=6.7387566566467285
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3961: train_loss=6.737350940704346
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3962: train_loss=6.738064289093018
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3963: train_loss=6.737183570861816
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3964: train_loss=6.737210750579834
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3965: train_loss=6.736656188964844
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3966: train_loss=6.737185955047607
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3967: train_loss=6.736579418182373
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3968: train_loss=6.736544132232666
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3969: train_loss=6.7359418869018555
INFO - 04/15/25 16:38:47 - 0:07:10 - Epoch 3970: train_loss=6.736352920532227
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3971: train_loss=6.735867500305176
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3972: train_loss=6.735909461975098
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3973: train_loss=6.73560905456543
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3974: train_loss=6.735494613647461
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3975: train_loss=6.735644340515137
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3976: train_loss=6.73550271987915
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3977: train_loss=6.7358598709106445
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3978: train_loss=6.735119819641113
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3979: train_loss=6.735481262207031
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3980: train_loss=6.735045433044434
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3981: train_loss=6.735067367553711
INFO - 04/15/25 16:38:47 - 0:07:11 - Epoch 3982: train_loss=6.73512077331543
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3983: train_loss=6.734445571899414
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3984: train_loss=6.735715866088867
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3985: train_loss=6.7346038818359375
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3986: train_loss=6.735902309417725
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3987: train_loss=6.735557556152344
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3988: train_loss=6.735150337219238
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3989: train_loss=6.734958648681641
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3990: train_loss=6.735503673553467
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3991: train_loss=6.735086917877197
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3992: train_loss=6.735093593597412
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3993: train_loss=6.735268592834473
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3994: train_loss=6.7343668937683105
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3995: train_loss=6.7342705726623535
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3996: train_loss=6.734906196594238
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3997: train_loss=6.734070777893066
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3998: train_loss=6.735694408416748
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 3999: train_loss=6.735137462615967
INFO - 04/15/25 16:38:48 - 0:07:11 - Epoch 4000: train_loss=6.73434591293335
INFO - 04/15/25 16:38:48 - 0:07:11 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:48 - 0:07:12 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:38:48 - 0:07:12 - Epoch 4000: ACC: 0.0, NMI: 0.5336707446221612, F1: 0.0, ARI: 0.3562408171935874
INFO - 04/15/25 16:38:48 - 0:07:12 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:48 - 0:07:12 - Epoch 4001: train_loss=6.734170913696289
INFO - 04/15/25 16:38:48 - 0:07:12 - Epoch 4002: train_loss=6.734609603881836
INFO - 04/15/25 16:38:48 - 0:07:12 - Epoch 4003: train_loss=6.734073162078857
INFO - 04/15/25 16:38:48 - 0:07:12 - Epoch 4004: train_loss=6.7348175048828125
INFO - 04/15/25 16:38:48 - 0:07:12 - Epoch 4005: train_loss=6.734378814697266
INFO - 04/15/25 16:38:48 - 0:07:12 - Epoch 4006: train_loss=6.734391212463379
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4007: train_loss=6.734074592590332
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4008: train_loss=6.734329700469971
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4009: train_loss=6.733781814575195
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4010: train_loss=6.734175682067871
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4011: train_loss=6.733920097351074
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4012: train_loss=6.734130382537842
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4013: train_loss=6.733708381652832
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4014: train_loss=6.733996391296387
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4015: train_loss=6.733602046966553
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4016: train_loss=6.734109401702881
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4017: train_loss=6.734145641326904
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4018: train_loss=6.733786106109619
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4019: train_loss=6.733795166015625
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4020: train_loss=6.733450412750244
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4021: train_loss=6.73336124420166
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4022: train_loss=6.737504959106445
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4023: train_loss=6.740022659301758
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4024: train_loss=6.7343058586120605
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4025: train_loss=6.734315395355225
INFO - 04/15/25 16:38:49 - 0:07:12 - Epoch 4026: train_loss=6.7351603507995605
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4027: train_loss=6.734527111053467
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4028: train_loss=6.735703945159912
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4029: train_loss=6.735591888427734
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4030: train_loss=6.736264228820801
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4031: train_loss=6.734757900238037
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4032: train_loss=6.73588752746582
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4033: train_loss=6.734803676605225
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4034: train_loss=6.7340474128723145
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4035: train_loss=6.733684062957764
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4036: train_loss=6.73414421081543
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4037: train_loss=6.734221458435059
INFO - 04/15/25 16:38:49 - 0:07:13 - Epoch 4038: train_loss=6.73419189453125
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4039: train_loss=6.7339277267456055
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4040: train_loss=6.733811855316162
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4041: train_loss=6.733641147613525
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4042: train_loss=6.733504295349121
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4043: train_loss=6.733181953430176
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4044: train_loss=6.73394775390625
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4045: train_loss=6.733071327209473
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4046: train_loss=6.733795166015625
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4047: train_loss=6.7336554527282715
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4048: train_loss=6.732968807220459
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4049: train_loss=6.733211517333984
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4050: train_loss=6.7332048416137695
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4051: train_loss=6.732894420623779
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4052: train_loss=6.7343950271606445
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4053: train_loss=6.734155654907227
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4054: train_loss=6.732450008392334
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4055: train_loss=6.732204437255859
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4056: train_loss=6.7337422370910645
INFO - 04/15/25 16:38:50 - 0:07:13 - Epoch 4057: train_loss=6.732969284057617
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4058: train_loss=6.734322547912598
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4059: train_loss=6.734169006347656
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4060: train_loss=6.732457160949707
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4061: train_loss=6.733041286468506
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4062: train_loss=6.732116222381592
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4063: train_loss=6.732989311218262
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4064: train_loss=6.732084274291992
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4065: train_loss=6.733490467071533
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4066: train_loss=6.732426643371582
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4067: train_loss=6.732421875
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4068: train_loss=6.732420921325684
INFO - 04/15/25 16:38:50 - 0:07:14 - Epoch 4069: train_loss=6.7321648597717285
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4070: train_loss=6.7319512367248535
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4071: train_loss=6.732007026672363
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4072: train_loss=6.73213529586792
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4073: train_loss=6.731963157653809
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4074: train_loss=6.7317891120910645
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4075: train_loss=6.732954025268555
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4076: train_loss=6.732437610626221
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4077: train_loss=6.731629848480225
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4078: train_loss=6.731265544891357
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4079: train_loss=6.732491493225098
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4080: train_loss=6.731656551361084
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4081: train_loss=6.73254919052124
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4082: train_loss=6.7318010330200195
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4083: train_loss=6.732690811157227
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4084: train_loss=6.732311725616455
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4085: train_loss=6.7317399978637695
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4086: train_loss=6.73136568069458
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4087: train_loss=6.732079982757568
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4088: train_loss=6.73191499710083
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4089: train_loss=6.731556415557861
INFO - 04/15/25 16:38:51 - 0:07:14 - Epoch 4090: train_loss=6.731569290161133
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4091: train_loss=6.732131004333496
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4092: train_loss=6.731525421142578
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4093: train_loss=6.732463359832764
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4094: train_loss=6.732468605041504
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4095: train_loss=6.730437755584717
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4096: train_loss=6.732771396636963
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4097: train_loss=6.730907917022705
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4098: train_loss=6.734344959259033
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4099: train_loss=6.734787464141846
INFO - 04/15/25 16:38:51 - 0:07:15 - Epoch 4100: train_loss=6.732097625732422
INFO - 04/15/25 16:38:51 - 0:07:15 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:52 - 0:07:15 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4100: ACC: 0.0, NMI: 0.5337883603970061, F1: 0.0, ARI: 0.3564661444696207
INFO - 04/15/25 16:38:52 - 0:07:15 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4101: train_loss=6.733521938323975
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4102: train_loss=6.734337329864502
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4103: train_loss=6.732911109924316
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4104: train_loss=6.732742786407471
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4105: train_loss=6.732863426208496
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4106: train_loss=6.732385158538818
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4107: train_loss=6.7320451736450195
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4108: train_loss=6.7327680587768555
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4109: train_loss=6.731784343719482
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4110: train_loss=6.731809139251709
INFO - 04/15/25 16:38:52 - 0:07:15 - Epoch 4111: train_loss=6.731661319732666
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4112: train_loss=6.731062412261963
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4113: train_loss=6.73126220703125
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4114: train_loss=6.730485439300537
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4115: train_loss=6.731619834899902
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4116: train_loss=6.730543613433838
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4117: train_loss=6.732504844665527
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4118: train_loss=6.7324419021606445
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4119: train_loss=6.731472492218018
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4120: train_loss=6.731908321380615
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4121: train_loss=6.731503486633301
INFO - 04/15/25 16:38:52 - 0:07:16 - Epoch 4122: train_loss=6.7307820320129395
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4123: train_loss=6.731235980987549
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4124: train_loss=6.730238437652588
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4125: train_loss=6.732039928436279
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4126: train_loss=6.731148719787598
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4127: train_loss=6.731751441955566
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4128: train_loss=6.731454372406006
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4129: train_loss=6.731688976287842
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4130: train_loss=6.730915546417236
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4131: train_loss=6.731937408447266
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4132: train_loss=6.732513904571533
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4133: train_loss=6.730769634246826
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4134: train_loss=6.731107234954834
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4135: train_loss=6.731549263000488
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4136: train_loss=6.730757713317871
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4137: train_loss=6.731183052062988
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4138: train_loss=6.7304158210754395
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4139: train_loss=6.731179237365723
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4140: train_loss=6.730920314788818
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4141: train_loss=6.731134414672852
INFO - 04/15/25 16:38:53 - 0:07:16 - Epoch 4142: train_loss=6.730987071990967
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4143: train_loss=6.7309417724609375
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4144: train_loss=6.730770587921143
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4145: train_loss=6.7308149337768555
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4146: train_loss=6.730643272399902
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4147: train_loss=6.731569766998291
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4148: train_loss=6.731020450592041
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4149: train_loss=6.730902671813965
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4150: train_loss=6.7309770584106445
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4151: train_loss=6.730643272399902
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4152: train_loss=6.730315685272217
INFO - 04/15/25 16:38:53 - 0:07:17 - Epoch 4153: train_loss=6.7306389808654785
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4154: train_loss=6.730757713317871
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4155: train_loss=6.730772495269775
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4156: train_loss=6.730696678161621
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4157: train_loss=6.730762958526611
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4158: train_loss=6.730436325073242
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4159: train_loss=6.730698108673096
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4160: train_loss=6.730299949645996
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4161: train_loss=6.730760097503662
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4162: train_loss=6.730456352233887
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4163: train_loss=6.730390548706055
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4164: train_loss=6.730001449584961
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4165: train_loss=6.730323314666748
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4166: train_loss=6.729918956756592
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4167: train_loss=6.7303385734558105
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4168: train_loss=6.7302165031433105
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4169: train_loss=6.729985237121582
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4170: train_loss=6.729349613189697
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4171: train_loss=6.7312726974487305
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4172: train_loss=6.730565071105957
INFO - 04/15/25 16:38:54 - 0:07:17 - Epoch 4173: train_loss=6.73024845123291
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4174: train_loss=6.730043411254883
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4175: train_loss=6.7308831214904785
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4176: train_loss=6.729950904846191
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4177: train_loss=6.730412006378174
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4178: train_loss=6.729704856872559
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4179: train_loss=6.731008529663086
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4180: train_loss=6.730189323425293
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4181: train_loss=6.729823112487793
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4182: train_loss=6.729682922363281
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4183: train_loss=6.730485439300537
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4184: train_loss=6.729948997497559
INFO - 04/15/25 16:38:54 - 0:07:18 - Epoch 4185: train_loss=6.730119228363037
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4186: train_loss=6.729813575744629
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4187: train_loss=6.729598045349121
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4188: train_loss=6.729561805725098
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4189: train_loss=6.729786396026611
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4190: train_loss=6.729856014251709
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4191: train_loss=6.729787349700928
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4192: train_loss=6.7293901443481445
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4193: train_loss=6.730299472808838
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4194: train_loss=6.7296552658081055
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4195: train_loss=6.729583263397217
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4196: train_loss=6.729215145111084
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4197: train_loss=6.729471683502197
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4198: train_loss=6.729360103607178
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4199: train_loss=6.730459690093994
INFO - 04/15/25 16:38:55 - 0:07:18 - Epoch 4200: train_loss=6.729852676391602
INFO - 04/15/25 16:38:55 - 0:07:18 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:55 - 0:07:18 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:38:55 - 0:07:19 - Epoch 4200: ACC: 0.0, NMI: 0.5237608654063868, F1: 0.0, ARI: 0.35276218716595603
INFO - 04/15/25 16:38:55 - 0:07:19 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:55 - 0:07:19 - Epoch 4201: train_loss=6.729493618011475
INFO - 04/15/25 16:38:55 - 0:07:19 - Epoch 4202: train_loss=6.729257583618164
INFO - 04/15/25 16:38:55 - 0:07:19 - Epoch 4203: train_loss=6.730251789093018
INFO - 04/15/25 16:38:55 - 0:07:19 - Epoch 4204: train_loss=6.729730606079102
INFO - 04/15/25 16:38:55 - 0:07:19 - Epoch 4205: train_loss=6.728853702545166
INFO - 04/15/25 16:38:55 - 0:07:19 - Epoch 4206: train_loss=6.728703498840332
INFO - 04/15/25 16:38:55 - 0:07:19 - Epoch 4207: train_loss=6.731094837188721
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4208: train_loss=6.7303290367126465
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4209: train_loss=6.729251384735107
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4210: train_loss=6.729879856109619
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4211: train_loss=6.729921340942383
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4212: train_loss=6.728944778442383
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4213: train_loss=6.730571746826172
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4214: train_loss=6.7301411628723145
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4215: train_loss=6.7291669845581055
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4216: train_loss=6.7297043800354
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4217: train_loss=6.728823184967041
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4218: train_loss=6.7289204597473145
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4219: train_loss=6.729274272918701
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4220: train_loss=6.728603363037109
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4221: train_loss=6.730462074279785
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4222: train_loss=6.730044364929199
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4223: train_loss=6.7284417152404785
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4224: train_loss=6.729189872741699
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4225: train_loss=6.728631019592285
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4226: train_loss=6.729839324951172
INFO - 04/15/25 16:38:56 - 0:07:19 - Epoch 4227: train_loss=6.728851318359375
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4228: train_loss=6.729587078094482
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4229: train_loss=6.729740142822266
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4230: train_loss=6.728985786437988
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4231: train_loss=6.729593753814697
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4232: train_loss=6.7284369468688965
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4233: train_loss=6.730726718902588
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4234: train_loss=6.7321977615356445
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4235: train_loss=6.729269027709961
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4236: train_loss=6.730111598968506
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4237: train_loss=6.730299949645996
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4238: train_loss=6.730072975158691
INFO - 04/15/25 16:38:56 - 0:07:20 - Epoch 4239: train_loss=6.729451656341553
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4240: train_loss=6.729190826416016
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4241: train_loss=6.729036331176758
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4242: train_loss=6.7286601066589355
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4243: train_loss=6.729438781738281
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4244: train_loss=6.729245662689209
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4245: train_loss=6.730525970458984
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4246: train_loss=6.736104965209961
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4247: train_loss=6.729238510131836
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4248: train_loss=6.730201244354248
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4249: train_loss=6.729620456695557
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4250: train_loss=6.7299604415893555
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4251: train_loss=6.7289204597473145
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4252: train_loss=6.730165958404541
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4253: train_loss=6.729930400848389
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4254: train_loss=6.730133533477783
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4255: train_loss=6.729552745819092
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4256: train_loss=6.729456901550293
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4257: train_loss=6.72986364364624
INFO - 04/15/25 16:38:57 - 0:07:20 - Epoch 4258: train_loss=6.729105472564697
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4259: train_loss=6.729599475860596
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4260: train_loss=6.72909688949585
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4261: train_loss=6.7290191650390625
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4262: train_loss=6.7288408279418945
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4263: train_loss=6.7284040451049805
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4264: train_loss=6.728957176208496
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4265: train_loss=6.728553295135498
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4266: train_loss=6.729802131652832
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4267: train_loss=6.728793144226074
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4268: train_loss=6.72974967956543
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4269: train_loss=6.7288031578063965
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4270: train_loss=6.7299041748046875
INFO - 04/15/25 16:38:57 - 0:07:21 - Epoch 4271: train_loss=6.729822158813477
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4272: train_loss=6.728957176208496
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4273: train_loss=6.7290239334106445
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4274: train_loss=6.728916645050049
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4275: train_loss=6.728054046630859
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4276: train_loss=6.729662895202637
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4277: train_loss=6.729616165161133
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4278: train_loss=6.728537559509277
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4279: train_loss=6.72838020324707
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4280: train_loss=6.730082988739014
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4281: train_loss=6.728882312774658
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4282: train_loss=6.729124069213867
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4283: train_loss=6.729031085968018
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4284: train_loss=6.728851318359375
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4285: train_loss=6.728092193603516
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4286: train_loss=6.729544162750244
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4287: train_loss=6.728790760040283
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4288: train_loss=6.728971481323242
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4289: train_loss=6.728518962860107
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4290: train_loss=6.728801727294922
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4291: train_loss=6.728710651397705
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4292: train_loss=6.729061603546143
INFO - 04/15/25 16:38:58 - 0:07:21 - Epoch 4293: train_loss=6.728673458099365
INFO - 04/15/25 16:38:58 - 0:07:22 - Epoch 4294: train_loss=6.72796630859375
INFO - 04/15/25 16:38:58 - 0:07:22 - Epoch 4295: train_loss=6.7276997566223145
INFO - 04/15/25 16:38:58 - 0:07:22 - Epoch 4296: train_loss=6.729227542877197
INFO - 04/15/25 16:38:58 - 0:07:22 - Epoch 4297: train_loss=6.728935241699219
INFO - 04/15/25 16:38:58 - 0:07:22 - Epoch 4298: train_loss=6.728338718414307
INFO - 04/15/25 16:38:58 - 0:07:22 - Epoch 4299: train_loss=6.72834587097168
INFO - 04/15/25 16:38:58 - 0:07:22 - Epoch 4300: train_loss=6.728465557098389
INFO - 04/15/25 16:38:58 - 0:07:22 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:38:58 - 0:07:22 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:38:59 - 0:07:22 - ------------------Saving best model-------------------
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4300: ACC: 0.0, NMI: 0.5598036620142851, F1: 0.0, ARI: 0.3885561016796039
INFO - 04/15/25 16:38:59 - 0:07:22 - -------------------------------------------------------------------------
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4301: train_loss=6.728035926818848
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4302: train_loss=6.7287917137146
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4303: train_loss=6.72854471206665
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4304: train_loss=6.7278289794921875
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4305: train_loss=6.727726936340332
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4306: train_loss=6.729047775268555
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4307: train_loss=6.728573322296143
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4308: train_loss=6.728548526763916
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4309: train_loss=6.728305816650391
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4310: train_loss=6.7283453941345215
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4311: train_loss=6.727755069732666
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4312: train_loss=6.728411674499512
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4313: train_loss=6.728346824645996
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4314: train_loss=6.729476451873779
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4315: train_loss=6.727481842041016
INFO - 04/15/25 16:38:59 - 0:07:22 - Epoch 4316: train_loss=6.729812145233154
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4317: train_loss=6.729832649230957
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4318: train_loss=6.727869510650635
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4319: train_loss=6.727973461151123
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4320: train_loss=6.728503704071045
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4321: train_loss=6.726985454559326
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4322: train_loss=6.729726791381836
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4323: train_loss=6.731863498687744
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4324: train_loss=6.7263407707214355
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4325: train_loss=6.7297163009643555
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4326: train_loss=6.728764057159424
INFO - 04/15/25 16:38:59 - 0:07:23 - Epoch 4327: train_loss=6.728961944580078
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4328: train_loss=6.728875637054443
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4329: train_loss=6.728145122528076
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4330: train_loss=6.727358818054199
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4331: train_loss=6.728573799133301
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4332: train_loss=6.726991176605225
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4333: train_loss=6.728692531585693
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4334: train_loss=6.728855133056641
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4335: train_loss=6.727189064025879
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4336: train_loss=6.7275471687316895
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4337: train_loss=6.727735996246338
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4338: train_loss=6.726721286773682
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4339: train_loss=6.728233337402344
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4340: train_loss=6.727694034576416
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4341: train_loss=6.728036403656006
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4342: train_loss=6.727710723876953
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4343: train_loss=6.727353096008301
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4344: train_loss=6.727110385894775
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4345: train_loss=6.728683948516846
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4346: train_loss=6.727963447570801
INFO - 04/15/25 16:39:00 - 0:07:23 - Epoch 4347: train_loss=6.727291584014893
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4348: train_loss=6.7272233963012695
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4349: train_loss=6.72762393951416
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4350: train_loss=6.727108478546143
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4351: train_loss=6.728432655334473
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4352: train_loss=6.7284932136535645
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4353: train_loss=6.726380825042725
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4354: train_loss=6.726634502410889
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4355: train_loss=6.727416038513184
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4356: train_loss=6.72629976272583
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4357: train_loss=6.729000568389893
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4358: train_loss=6.729039192199707
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4359: train_loss=6.7265424728393555
INFO - 04/15/25 16:39:00 - 0:07:24 - Epoch 4360: train_loss=6.726996421813965
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4361: train_loss=6.726943492889404
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4362: train_loss=6.7266645431518555
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4363: train_loss=6.727177143096924
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4364: train_loss=6.7264299392700195
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4365: train_loss=6.727780818939209
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4366: train_loss=6.843850135803223
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4367: train_loss=6.813036918640137
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4368: train_loss=6.955050468444824
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4369: train_loss=6.873729228973389
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4370: train_loss=6.862512111663818
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4371: train_loss=6.915391445159912
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4372: train_loss=7.248264789581299
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4373: train_loss=7.123358249664307
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4374: train_loss=7.167449474334717
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4375: train_loss=7.173830986022949
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4376: train_loss=7.195500373840332
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4377: train_loss=7.120537281036377
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4378: train_loss=7.102578639984131
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4379: train_loss=7.054177284240723
INFO - 04/15/25 16:39:01 - 0:07:24 - Epoch 4380: train_loss=7.088216781616211
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4381: train_loss=7.048959255218506
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4382: train_loss=7.036935329437256
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4383: train_loss=7.019128799438477
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4384: train_loss=7.056659698486328
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4385: train_loss=7.036319732666016
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4386: train_loss=7.064317226409912
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4387: train_loss=7.046034812927246
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4388: train_loss=7.091622352600098
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4389: train_loss=7.09390115737915
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4390: train_loss=7.073698043823242
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4391: train_loss=7.037226676940918
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4392: train_loss=7.048983097076416
INFO - 04/15/25 16:39:01 - 0:07:25 - Epoch 4393: train_loss=7.027918815612793
INFO - 04/15/25 16:39:02 - 0:07:25 - Epoch 4394: train_loss=7.0145583152771
INFO - 04/15/25 16:39:02 - 0:07:25 - Epoch 4395: train_loss=7.006594657897949
INFO - 04/15/25 16:39:02 - 0:07:25 - Epoch 4396: train_loss=7.014840126037598
INFO - 04/15/25 16:39:02 - 0:07:25 - Epoch 4397: train_loss=7.003188610076904
INFO - 04/15/25 16:39:02 - 0:07:25 - Epoch 4398: train_loss=6.9997076988220215
INFO - 04/15/25 16:39:02 - 0:07:25 - Epoch 4399: train_loss=6.989489555358887
INFO - 04/15/25 16:39:02 - 0:07:25 - Epoch 4400: train_loss=6.98660945892334
INFO - 04/15/25 16:39:02 - 0:07:25 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:39:02 - 0:07:25 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:39:02 - 0:07:25 - ------------------Saving best model-------------------
INFO - 04/15/25 16:39:03 - 0:07:26 - Epoch 4400: ACC: 0.0, NMI: 0.6317262025260642, F1: 0.0, ARI: 0.48643217877158973
INFO - 04/15/25 16:39:03 - 0:07:26 - -------------------------------------------------------------------------
INFO - 04/15/25 16:39:03 - 0:07:26 - Epoch 4401: train_loss=6.985047817230225
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4402: train_loss=6.985901355743408
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4403: train_loss=6.974818706512451
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4404: train_loss=6.969937324523926
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4405: train_loss=6.972270488739014
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4406: train_loss=6.975861549377441
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4407: train_loss=6.974867820739746
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4408: train_loss=6.968355655670166
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4409: train_loss=6.963754177093506
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4410: train_loss=6.965975761413574
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4411: train_loss=6.96293830871582
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4412: train_loss=6.960908889770508
INFO - 04/15/25 16:39:03 - 0:07:27 - Epoch 4413: train_loss=6.962213516235352
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4414: train_loss=6.960187911987305
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4415: train_loss=6.956484794616699
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4416: train_loss=6.957902431488037
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4417: train_loss=6.955052852630615
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4418: train_loss=6.9561767578125
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4419: train_loss=6.956357479095459
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4420: train_loss=6.952699661254883
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4421: train_loss=6.953834533691406
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4422: train_loss=6.951120853424072
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4423: train_loss=6.9541144371032715
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4424: train_loss=6.953560829162598
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4425: train_loss=6.949800491333008
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4426: train_loss=6.950530052185059
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4427: train_loss=6.949952602386475
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4428: train_loss=6.947624206542969
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4429: train_loss=6.951941967010498
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4430: train_loss=6.949134826660156
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4431: train_loss=6.952496528625488
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4432: train_loss=6.951153755187988
INFO - 04/15/25 16:39:04 - 0:07:27 - Epoch 4433: train_loss=6.94870662689209
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4434: train_loss=6.949150562286377
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4435: train_loss=6.943451404571533
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4436: train_loss=6.944273948669434
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4437: train_loss=6.944565773010254
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4438: train_loss=6.942895412445068
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4439: train_loss=6.940087795257568
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4440: train_loss=6.942594051361084
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4441: train_loss=6.94276762008667
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4442: train_loss=6.940141201019287
INFO - 04/15/25 16:39:04 - 0:07:28 - Epoch 4443: train_loss=6.94000244140625
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4444: train_loss=6.941009998321533
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4445: train_loss=6.939840793609619
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4446: train_loss=6.938536643981934
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4447: train_loss=6.939379692077637
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4448: train_loss=6.938619136810303
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4449: train_loss=6.937870025634766
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4450: train_loss=6.938384056091309
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4451: train_loss=6.937007427215576
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4452: train_loss=6.938236713409424
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4453: train_loss=6.9378437995910645
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4454: train_loss=6.9369587898254395
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4455: train_loss=6.938171863555908
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4456: train_loss=6.9375224113464355
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4457: train_loss=6.937594413757324
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4458: train_loss=6.93594217300415
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4459: train_loss=6.937342166900635
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4460: train_loss=6.935325622558594
INFO - 04/15/25 16:39:05 - 0:07:28 - Epoch 4461: train_loss=6.935464382171631
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4462: train_loss=6.936885833740234
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4463: train_loss=6.934844493865967
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4464: train_loss=6.938166618347168
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4465: train_loss=6.9372076988220215
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4466: train_loss=6.9369940757751465
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4467: train_loss=6.93623685836792
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4468: train_loss=6.936434268951416
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4469: train_loss=6.936618328094482
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4470: train_loss=6.9343671798706055
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4471: train_loss=6.933681488037109
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4472: train_loss=6.935635089874268
INFO - 04/15/25 16:39:05 - 0:07:29 - Epoch 4473: train_loss=6.932709693908691
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4474: train_loss=6.938960075378418
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4475: train_loss=6.939236164093018
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4476: train_loss=6.933176517486572
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4477: train_loss=6.939624309539795
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4478: train_loss=6.9413557052612305
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4479: train_loss=6.936818599700928
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4480: train_loss=6.936880111694336
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4481: train_loss=6.938903331756592
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4482: train_loss=6.935368537902832
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4483: train_loss=6.936551094055176
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4484: train_loss=6.937790393829346
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4485: train_loss=6.933919906616211
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4486: train_loss=6.936654567718506
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4487: train_loss=6.937424182891846
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4488: train_loss=6.933199882507324
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4489: train_loss=6.936456203460693
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4490: train_loss=6.936913013458252
INFO - 04/15/25 16:39:06 - 0:07:29 - Epoch 4491: train_loss=6.932821750640869
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4492: train_loss=6.935876846313477
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4493: train_loss=6.935965538024902
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4494: train_loss=6.9326300621032715
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4495: train_loss=6.934648036956787
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4496: train_loss=6.933646202087402
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4497: train_loss=6.93326997756958
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4498: train_loss=6.933342456817627
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4499: train_loss=6.93170166015625
INFO - 04/15/25 16:39:06 - 0:07:30 - Epoch 4500: train_loss=6.932309627532959
INFO - 04/15/25 16:39:06 - 0:07:30 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:39:07 - 0:07:30 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:39:07 - 0:07:30 - ------------------Saving best model-------------------
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4500: ACC: 0.0, NMI: 0.6323646386519765, F1: 0.0, ARI: 0.4864309247532703
INFO - 04/15/25 16:39:07 - 0:07:30 - -------------------------------------------------------------------------
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4501: train_loss=6.93048095703125
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4502: train_loss=6.930872917175293
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4503: train_loss=6.931375503540039
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4504: train_loss=6.9302144050598145
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4505: train_loss=6.932828426361084
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4506: train_loss=6.9324631690979
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4507: train_loss=6.930922985076904
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4508: train_loss=6.930838584899902
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4509: train_loss=6.93142557144165
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4510: train_loss=6.930301666259766
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4511: train_loss=6.932168960571289
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4512: train_loss=6.931787967681885
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4513: train_loss=6.930197238922119
INFO - 04/15/25 16:39:07 - 0:07:30 - Epoch 4514: train_loss=6.930017471313477
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4515: train_loss=6.930983066558838
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4516: train_loss=6.930294513702393
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4517: train_loss=6.930825233459473
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4518: train_loss=6.930213451385498
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4519: train_loss=6.930961608886719
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4520: train_loss=6.930572509765625
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4521: train_loss=6.9298882484436035
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4522: train_loss=6.9295549392700195
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4523: train_loss=6.930387020111084
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4524: train_loss=6.929755210876465
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4525: train_loss=6.930339813232422
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4526: train_loss=6.929988861083984
INFO - 04/15/25 16:39:07 - 0:07:31 - Epoch 4527: train_loss=6.929479598999023
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4528: train_loss=6.929027080535889
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4529: train_loss=6.930185317993164
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4530: train_loss=6.929726600646973
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4531: train_loss=6.9293060302734375
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4532: train_loss=6.928988456726074
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4533: train_loss=6.929610729217529
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4534: train_loss=6.929126262664795
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4535: train_loss=6.929237365722656
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4536: train_loss=6.928884983062744
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4537: train_loss=6.929165840148926
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4538: train_loss=6.928704261779785
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4539: train_loss=6.929143905639648
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4540: train_loss=6.928779602050781
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4541: train_loss=6.928621768951416
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4542: train_loss=6.92808723449707
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4543: train_loss=6.929296493530273
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4544: train_loss=6.929013252258301
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4545: train_loss=6.9277873039245605
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4546: train_loss=6.927267551422119
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4547: train_loss=6.929531097412109
INFO - 04/15/25 16:39:08 - 0:07:31 - Epoch 4548: train_loss=6.929227352142334
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4549: train_loss=6.927147388458252
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4550: train_loss=6.926721572875977
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4551: train_loss=6.929428577423096
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4552: train_loss=6.9289984703063965
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4553: train_loss=6.926999568939209
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4554: train_loss=6.926738739013672
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4555: train_loss=6.928840637207031
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4556: train_loss=6.928306579589844
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4557: train_loss=6.927218914031982
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4558: train_loss=6.926923751831055
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4559: train_loss=6.928188800811768
INFO - 04/15/25 16:39:08 - 0:07:32 - Epoch 4560: train_loss=6.927696704864502
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4561: train_loss=6.927330017089844
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4562: train_loss=6.926989555358887
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4563: train_loss=6.9276909828186035
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4564: train_loss=6.927318096160889
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4565: train_loss=6.9271321296691895
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4566: train_loss=6.926791667938232
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4567: train_loss=6.927434921264648
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4568: train_loss=6.927063941955566
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4569: train_loss=6.926957130432129
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4570: train_loss=6.9265522956848145
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4571: train_loss=6.927230358123779
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4572: train_loss=6.926895618438721
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4573: train_loss=6.926616668701172
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4574: train_loss=6.926175117492676
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4575: train_loss=6.927252292633057
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4576: train_loss=6.92694616317749
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4577: train_loss=6.926062107086182
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4578: train_loss=6.925607204437256
INFO - 04/15/25 16:39:09 - 0:07:32 - Epoch 4579: train_loss=6.927325248718262
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4580: train_loss=6.9270172119140625
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4581: train_loss=6.925610542297363
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4582: train_loss=6.925236225128174
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4583: train_loss=6.92720890045166
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4584: train_loss=6.926822185516357
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4585: train_loss=6.9254255294799805
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4586: train_loss=6.925105094909668
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4587: train_loss=6.926858425140381
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4588: train_loss=6.92640495300293
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4589: train_loss=6.925530910491943
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4590: train_loss=6.9252448081970215
INFO - 04/15/25 16:39:09 - 0:07:33 - Epoch 4591: train_loss=6.926332473754883
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4592: train_loss=6.925920486450195
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4593: train_loss=6.925582408905029
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4594: train_loss=6.925239562988281
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4595: train_loss=6.92591667175293
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4596: train_loss=6.925553798675537
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4597: train_loss=6.925478458404541
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4598: train_loss=6.925121784210205
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4599: train_loss=6.925742149353027
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4600: train_loss=6.9254374504089355
INFO - 04/15/25 16:39:10 - 0:07:33 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:39:10 - 0:07:33 - Decoding cost time:  0.115 s
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4600: ACC: 0.0, NMI: 0.6323646386519765, F1: 0.0, ARI: 0.4864309247532703
INFO - 04/15/25 16:39:10 - 0:07:33 - -------------------------------------------------------------------------
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4601: train_loss=6.9251298904418945
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4602: train_loss=6.924744606018066
INFO - 04/15/25 16:39:10 - 0:07:33 - Epoch 4603: train_loss=6.925754547119141
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4604: train_loss=6.925441265106201
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4605: train_loss=6.924736976623535
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4606: train_loss=6.924345970153809
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4607: train_loss=6.925703048706055
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4608: train_loss=6.925381660461426
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4609: train_loss=6.924432277679443
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4610: train_loss=6.9240193367004395
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4611: train_loss=6.925750255584717
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4612: train_loss=6.925459384918213
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4613: train_loss=6.923976898193359
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4614: train_loss=6.923615455627441
INFO - 04/15/25 16:39:10 - 0:07:34 - Epoch 4615: train_loss=6.925606727600098
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4616: train_loss=6.925174713134766
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4617: train_loss=6.924083709716797
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4618: train_loss=6.923863410949707
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4619: train_loss=6.925024032592773
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4620: train_loss=6.924635410308838
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4621: train_loss=6.924198150634766
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4622: train_loss=6.9239277839660645
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4623: train_loss=6.9245219230651855
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4624: train_loss=6.924079895019531
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4625: train_loss=6.9244513511657715
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4626: train_loss=6.9242095947265625
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4627: train_loss=6.92392635345459
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4628: train_loss=6.923497200012207
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4629: train_loss=6.924653053283691
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4630: train_loss=6.924396991729736
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4631: train_loss=6.923386096954346
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4632: train_loss=6.922885894775391
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4633: train_loss=6.925027370452881
INFO - 04/15/25 16:39:11 - 0:07:34 - Epoch 4634: train_loss=6.924916744232178
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4635: train_loss=6.922492027282715
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4636: train_loss=6.922024250030518
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4637: train_loss=6.925503253936768
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4638: train_loss=6.925328254699707
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4639: train_loss=6.921754837036133
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4640: train_loss=6.921427249908447
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4641: train_loss=6.924994945526123
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4642: train_loss=6.924108505249023
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4643: train_loss=6.923241138458252
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4644: train_loss=6.923404216766357
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4645: train_loss=6.922863006591797
INFO - 04/15/25 16:39:11 - 0:07:35 - Epoch 4646: train_loss=6.922239303588867
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4647: train_loss=6.924295425415039
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4648: train_loss=6.923916816711426
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4649: train_loss=6.922522068023682
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4650: train_loss=6.9224162101745605
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4651: train_loss=6.923327922821045
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4652: train_loss=6.922565460205078
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4653: train_loss=6.923722743988037
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4654: train_loss=6.923590183258057
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4655: train_loss=6.922234058380127
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4656: train_loss=6.922246932983398
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4657: train_loss=6.922828674316406
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4658: train_loss=6.9219746589660645
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4659: train_loss=6.923748970031738
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4660: train_loss=6.923476219177246
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4661: train_loss=6.922014236450195
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4662: train_loss=6.922191143035889
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4663: train_loss=6.922220230102539
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4664: train_loss=6.921522617340088
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4665: train_loss=6.922844886779785
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4666: train_loss=6.922002792358398
INFO - 04/15/25 16:39:12 - 0:07:35 - Epoch 4667: train_loss=6.922917366027832
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4668: train_loss=6.922717571258545
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4669: train_loss=6.921851634979248
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4670: train_loss=6.921904563903809
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4671: train_loss=6.921730995178223
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4672: train_loss=6.921503067016602
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4673: train_loss=6.921635150909424
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4674: train_loss=6.921197414398193
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4675: train_loss=6.9221296310424805
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4676: train_loss=6.921106338500977
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4677: train_loss=6.923330307006836
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4678: train_loss=6.923550128936768
INFO - 04/15/25 16:39:12 - 0:07:36 - Epoch 4679: train_loss=6.919822692871094
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4680: train_loss=6.921591281890869
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4681: train_loss=6.919755458831787
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4682: train_loss=6.921334743499756
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4683: train_loss=6.919862270355225
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4684: train_loss=6.922375202178955
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4685: train_loss=6.922181606292725
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4686: train_loss=6.920454025268555
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4687: train_loss=6.922006607055664
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4688: train_loss=6.921887397766113
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4689: train_loss=6.920288562774658
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4690: train_loss=6.92137336730957
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4691: train_loss=6.920297145843506
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4692: train_loss=6.921976089477539
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4693: train_loss=6.921863079071045
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4694: train_loss=6.920831203460693
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4695: train_loss=6.921095371246338
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4696: train_loss=6.9210076332092285
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4697: train_loss=6.920477390289307
INFO - 04/15/25 16:39:13 - 0:07:36 - Epoch 4698: train_loss=6.920432090759277
INFO - 04/15/25 16:39:13 - 0:07:37 - Epoch 4699: train_loss=6.92025899887085
INFO - 04/15/25 16:39:13 - 0:07:37 - Epoch 4700: train_loss=6.920692443847656
INFO - 04/15/25 16:39:13 - 0:07:37 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:39:13 - 0:07:37 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:39:13 - 0:07:37 - ------------------Saving best model-------------------
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4700: ACC: 0.0, NMI: 0.6509143249923596, F1: 0.0, ARI: 0.509733027090467
INFO - 04/15/25 16:39:14 - 0:07:37 - -------------------------------------------------------------------------
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4701: train_loss=6.9194440841674805
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4702: train_loss=6.9219865798950195
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4703: train_loss=6.921286582946777
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4704: train_loss=6.920906066894531
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4705: train_loss=6.920823097229004
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4706: train_loss=6.920803070068359
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4707: train_loss=6.920170783996582
INFO - 04/15/25 16:39:14 - 0:07:37 - Epoch 4708: train_loss=6.920754432678223
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4709: train_loss=6.920009136199951
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4710: train_loss=6.920621871948242
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4711: train_loss=6.920224666595459
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4712: train_loss=6.9204182624816895
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4713: train_loss=6.920166492462158
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4714: train_loss=6.920406818389893
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4715: train_loss=6.920112609863281
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4716: train_loss=6.920436859130859
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4717: train_loss=6.92014217376709
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4718: train_loss=6.920340061187744
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4719: train_loss=6.9200286865234375
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4720: train_loss=6.920263290405273
INFO - 04/15/25 16:39:14 - 0:07:38 - Epoch 4721: train_loss=6.920016765594482
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4722: train_loss=6.920048713684082
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4723: train_loss=6.919757843017578
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4724: train_loss=6.920243263244629
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4725: train_loss=6.919997215270996
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4726: train_loss=6.919849395751953
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4727: train_loss=6.919502258300781
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4728: train_loss=6.920258522033691
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4729: train_loss=6.9199910163879395
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4730: train_loss=6.919708251953125
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4731: train_loss=6.919494152069092
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4732: train_loss=6.91990852355957
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4733: train_loss=6.9196858406066895
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4734: train_loss=6.9197163581848145
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4735: train_loss=6.91937780380249
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4736: train_loss=6.919931888580322
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4737: train_loss=6.919816970825195
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4738: train_loss=6.9192214012146
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4739: train_loss=6.918960094451904
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4740: train_loss=6.919927597045898
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4741: train_loss=6.9195380210876465
INFO - 04/15/25 16:39:15 - 0:07:38 - Epoch 4742: train_loss=6.919395923614502
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4743: train_loss=6.91923189163208
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4744: train_loss=6.91939640045166
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4745: train_loss=6.91906213760376
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4746: train_loss=6.919587135314941
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4747: train_loss=6.919352054595947
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4748: train_loss=6.919155120849609
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4749: train_loss=6.91891622543335
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4750: train_loss=6.919318199157715
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4751: train_loss=6.9190449714660645
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4752: train_loss=6.91928768157959
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4753: train_loss=6.919125080108643
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4754: train_loss=6.918933391571045
INFO - 04/15/25 16:39:15 - 0:07:39 - Epoch 4755: train_loss=6.918663501739502
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4756: train_loss=6.9193549156188965
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4757: train_loss=6.919119834899902
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4758: train_loss=6.9186930656433105
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4759: train_loss=6.918481826782227
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4760: train_loss=6.919172286987305
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4761: train_loss=6.918913841247559
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4762: train_loss=6.91876220703125
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4763: train_loss=6.91851806640625
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4764: train_loss=6.918942451477051
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4765: train_loss=6.918673992156982
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4766: train_loss=6.91867208480835
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4767: train_loss=6.918484687805176
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4768: train_loss=6.918867111206055
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4769: train_loss=6.918516159057617
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4770: train_loss=6.918632984161377
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4771: train_loss=6.9183831214904785
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4772: train_loss=6.91877555847168
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4773: train_loss=6.918564796447754
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4774: train_loss=6.918370246887207
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4775: train_loss=6.918067932128906
INFO - 04/15/25 16:39:16 - 0:07:39 - Epoch 4776: train_loss=6.9188385009765625
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4777: train_loss=6.9186625480651855
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4778: train_loss=6.918035507202148
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4779: train_loss=6.917715072631836
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4780: train_loss=6.919027805328369
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4781: train_loss=6.919039726257324
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4782: train_loss=6.917323112487793
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4783: train_loss=6.916930675506592
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4784: train_loss=6.919539928436279
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4785: train_loss=6.919406414031982
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4786: train_loss=6.916783809661865
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4787: train_loss=6.916929721832275
INFO - 04/15/25 16:39:16 - 0:07:40 - Epoch 4788: train_loss=6.9184346199035645
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4789: train_loss=6.917512893676758
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4790: train_loss=6.918612003326416
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4791: train_loss=6.918505668640137
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4792: train_loss=6.917525768280029
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4793: train_loss=6.918262481689453
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4794: train_loss=6.917545795440674
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4795: train_loss=6.918313026428223
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4796: train_loss=6.9181108474731445
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4797: train_loss=6.917600154876709
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4798: train_loss=6.9181976318359375
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4799: train_loss=6.9173583984375
INFO - 04/15/25 16:39:17 - 0:07:40 - Epoch 4800: train_loss=6.918853759765625
INFO - 04/15/25 16:39:17 - 0:07:40 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:39:17 - 0:07:40 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4800: ACC: 0.0, NMI: 0.6509143249923596, F1: 0.0, ARI: 0.509733027090467
INFO - 04/15/25 16:39:17 - 0:07:41 - -------------------------------------------------------------------------
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4801: train_loss=6.91879940032959
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4802: train_loss=6.9173383712768555
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4803: train_loss=6.9181718826293945
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4804: train_loss=6.9176506996154785
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4805: train_loss=6.917801856994629
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4806: train_loss=6.917779922485352
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4807: train_loss=6.917173862457275
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4808: train_loss=6.918266296386719
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4809: train_loss=6.9174065589904785
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4810: train_loss=6.918603897094727
INFO - 04/15/25 16:39:17 - 0:07:41 - Epoch 4811: train_loss=6.918491363525391
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4812: train_loss=6.917965888977051
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4813: train_loss=6.917438507080078
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4814: train_loss=6.918646335601807
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4815: train_loss=6.917365550994873
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4816: train_loss=6.919557094573975
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4817: train_loss=6.919898509979248
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4818: train_loss=6.916170597076416
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4819: train_loss=6.919411659240723
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4820: train_loss=6.919278621673584
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4821: train_loss=6.917359352111816
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4822: train_loss=6.918030261993408
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4823: train_loss=6.918482780456543
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4824: train_loss=6.919123649597168
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4825: train_loss=6.947412967681885
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4826: train_loss=6.9238481521606445
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4827: train_loss=6.951642990112305
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4828: train_loss=6.930071830749512
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4829: train_loss=6.935578346252441
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4830: train_loss=6.959076881408691
INFO - 04/15/25 16:39:18 - 0:07:41 - Epoch 4831: train_loss=6.931014060974121
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4832: train_loss=6.93098258972168
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4833: train_loss=6.943175315856934
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4834: train_loss=6.926326274871826
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4835: train_loss=6.921720504760742
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4836: train_loss=6.921847820281982
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4837: train_loss=6.925274848937988
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4838: train_loss=6.926388740539551
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4839: train_loss=6.9242658615112305
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4840: train_loss=6.92197322845459
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4841: train_loss=6.922996997833252
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4842: train_loss=6.923086166381836
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4843: train_loss=6.922481060028076
INFO - 04/15/25 16:39:18 - 0:07:42 - Epoch 4844: train_loss=6.921644687652588
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4845: train_loss=6.9215240478515625
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4846: train_loss=6.920938968658447
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4847: train_loss=6.920811176300049
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4848: train_loss=6.921207427978516
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4849: train_loss=6.919771194458008
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4850: train_loss=6.920200347900391
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4851: train_loss=6.919238567352295
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4852: train_loss=6.919423580169678
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4853: train_loss=6.9193434715271
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4854: train_loss=6.917794704437256
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4855: train_loss=6.91877555847168
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4856: train_loss=6.917850494384766
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4857: train_loss=6.919009208679199
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4858: train_loss=6.9189863204956055
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4859: train_loss=6.917933464050293
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4860: train_loss=6.918186664581299
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4861: train_loss=6.918023109436035
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4862: train_loss=6.917803764343262
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4863: train_loss=6.917658805847168
INFO - 04/15/25 16:39:19 - 0:07:42 - Epoch 4864: train_loss=6.917381763458252
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4865: train_loss=6.917575359344482
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4866: train_loss=6.917510032653809
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4867: train_loss=6.91696310043335
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4868: train_loss=6.918175220489502
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4869: train_loss=6.91779899597168
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4870: train_loss=6.917389392852783
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4871: train_loss=6.9174909591674805
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4872: train_loss=6.917268753051758
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4873: train_loss=6.916881084442139
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4874: train_loss=6.917590618133545
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4875: train_loss=6.916905879974365
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4876: train_loss=6.917544841766357
INFO - 04/15/25 16:39:19 - 0:07:43 - Epoch 4877: train_loss=6.917177200317383
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4878: train_loss=6.9172563552856445
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4879: train_loss=6.9180426597595215
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4880: train_loss=6.916714668273926
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4881: train_loss=6.921186923980713
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4882: train_loss=6.934764862060547
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4883: train_loss=6.923461437225342
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4884: train_loss=6.92357873916626
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4885: train_loss=6.949096202850342
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4886: train_loss=6.925586700439453
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4887: train_loss=6.926211833953857
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4888: train_loss=6.92294979095459
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4889: train_loss=6.920384883880615
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4890: train_loss=6.922360897064209
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4891: train_loss=6.922634601593018
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4892: train_loss=6.920804500579834
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4893: train_loss=6.918722152709961
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4894: train_loss=6.919467926025391
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4895: train_loss=6.919627666473389
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4896: train_loss=6.918087005615234
INFO - 04/15/25 16:39:20 - 0:07:43 - Epoch 4897: train_loss=6.918539524078369
INFO - 04/15/25 16:39:20 - 0:07:44 - Epoch 4898: train_loss=6.918801784515381
INFO - 04/15/25 16:39:20 - 0:07:44 - Epoch 4899: train_loss=6.917773723602295
INFO - 04/15/25 16:39:20 - 0:07:44 - Epoch 4900: train_loss=6.917413711547852
INFO - 04/15/25 16:39:20 - 0:07:44 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:39:21 - 0:07:44 - Decoding cost time:  0.419 s
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4900: ACC: 0.0, NMI: 0.6500018749342803, F1: 0.0, ARI: 0.5104182520435063
INFO - 04/15/25 16:39:21 - 0:07:44 - -------------------------------------------------------------------------
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4901: train_loss=6.918045520782471
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4902: train_loss=6.916829586029053
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4903: train_loss=6.917535305023193
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4904: train_loss=6.917916297912598
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4905: train_loss=6.916652202606201
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4906: train_loss=6.917061805725098
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4907: train_loss=6.917350769042969
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4908: train_loss=6.915886878967285
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4909: train_loss=6.917539596557617
INFO - 04/15/25 16:39:21 - 0:07:44 - Epoch 4910: train_loss=6.917285919189453
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4911: train_loss=6.916334629058838
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4912: train_loss=6.91660737991333
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4913: train_loss=6.916131019592285
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4914: train_loss=6.916749954223633
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4915: train_loss=6.91634464263916
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4916: train_loss=6.916353225708008
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4917: train_loss=6.916361331939697
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4918: train_loss=6.915933132171631
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4919: train_loss=6.916477203369141
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4920: train_loss=6.916040897369385
INFO - 04/15/25 16:39:21 - 0:07:45 - Epoch 4921: train_loss=6.916411399841309
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4922: train_loss=6.916064262390137
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4923: train_loss=6.916152477264404
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4924: train_loss=6.916012763977051
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4925: train_loss=6.915811061859131
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4926: train_loss=6.91596794128418
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4927: train_loss=6.915552616119385
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4928: train_loss=6.916221618652344
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4929: train_loss=6.9156999588012695
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4930: train_loss=6.916118621826172
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4931: train_loss=6.915547847747803
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4932: train_loss=6.915977478027344
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4933: train_loss=6.9152607917785645
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4934: train_loss=6.9153733253479
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4935: train_loss=6.915701866149902
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4936: train_loss=6.914798736572266
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4937: train_loss=6.91691255569458
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4938: train_loss=6.9167799949646
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4939: train_loss=6.915605068206787
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4940: train_loss=6.915561199188232
INFO - 04/15/25 16:39:22 - 0:07:45 - Epoch 4941: train_loss=6.9161810874938965
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4942: train_loss=6.915095329284668
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4943: train_loss=6.91692590713501
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4944: train_loss=6.917233467102051
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4945: train_loss=6.914427757263184
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4946: train_loss=6.916261672973633
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4947: train_loss=6.916388988494873
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4948: train_loss=6.915005683898926
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4949: train_loss=6.915841579437256
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4950: train_loss=6.916353225708008
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4951: train_loss=6.914018154144287
INFO - 04/15/25 16:39:22 - 0:07:46 - Epoch 4952: train_loss=6.916477203369141
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4953: train_loss=6.91727352142334
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4954: train_loss=6.915461540222168
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4955: train_loss=6.915191173553467
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4956: train_loss=6.916225433349609
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4957: train_loss=6.914846420288086
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4958: train_loss=6.915308475494385
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4959: train_loss=6.9158034324646
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4960: train_loss=6.914400100708008
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4961: train_loss=6.91542911529541
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4962: train_loss=6.915635108947754
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4963: train_loss=6.914219379425049
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4964: train_loss=6.91503381729126
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4965: train_loss=6.915009021759033
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4966: train_loss=6.914453506469727
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4967: train_loss=6.914418697357178
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4968: train_loss=6.91437292098999
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4969: train_loss=6.914333820343018
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4970: train_loss=6.913641929626465
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4971: train_loss=6.914224624633789
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4972: train_loss=6.913415431976318
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4973: train_loss=6.914621829986572
INFO - 04/15/25 16:39:23 - 0:07:46 - Epoch 4974: train_loss=6.9138312339782715
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4975: train_loss=6.914401054382324
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4976: train_loss=6.914495944976807
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4977: train_loss=6.91326379776001
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4978: train_loss=6.914677619934082
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4979: train_loss=6.913262367248535
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4980: train_loss=6.915161609649658
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4981: train_loss=6.914158344268799
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4982: train_loss=6.91519021987915
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4983: train_loss=6.914408206939697
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4984: train_loss=6.915256500244141
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4985: train_loss=6.914907932281494
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4986: train_loss=6.9148149490356445
INFO - 04/15/25 16:39:23 - 0:07:47 - Epoch 4987: train_loss=6.9144697189331055
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4988: train_loss=6.91472053527832
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4989: train_loss=6.91470193862915
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4990: train_loss=6.913834571838379
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4991: train_loss=6.913450241088867
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4992: train_loss=6.914764404296875
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4993: train_loss=6.913736343383789
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4994: train_loss=6.915510177612305
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4995: train_loss=6.915318489074707
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4996: train_loss=6.913674831390381
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4997: train_loss=6.913809776306152
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4998: train_loss=6.914370059967041
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 4999: train_loss=6.91380500793457
INFO - 04/15/25 16:39:24 - 0:07:47 - Epoch 5000: train_loss=6.914767742156982
INFO - 04/15/25 16:39:24 - 0:07:47 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:39:24 - 0:07:47 - Decoding cost time:  0.124 s
INFO - 04/15/25 16:39:24 - 0:07:48 - Epoch 5000: ACC: 0.0, NMI: 0.6323504714843248, F1: 0.0, ARI: 0.4939233154612987
INFO - 04/15/25 16:39:24 - 0:07:48 - -------------------------------------------------------------------------
INFO - 04/15/25 16:39:24 - 0:07:48 - ------------------Loading best model-------------------
INFO - 04/15/25 16:39:40 - 0:08:03 - Best Results according to nmi: ACC: 0.0, NMI: 0.6509143249923596, F1: 0.0, ARI: 0.509733027090467 
                                     
INFO - 04/15/25 16:39:40 - 0:08:03 - Best Results according to ari: ACC: 0.0, NMI: 0.6500018749342803, F1: 0.0, ARI: 0.5104182520435063 
                                     
INFO - 04/15/25 16:39:40 - 0:08:03 - 
                                     train iters 2
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 1: train_loss=5.848893165588379
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 2: train_loss=2.907803535461426
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 3: train_loss=2.069248676300049
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 4: train_loss=1.4546778202056885
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 5: train_loss=1.1109604835510254
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 6: train_loss=0.9379936456680298
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 7: train_loss=0.8431026339530945
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 8: train_loss=0.7303355932235718
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 9: train_loss=0.574201226234436
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 10: train_loss=0.5185187458992004
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 11: train_loss=0.525719165802002
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 12: train_loss=0.5006836652755737
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 13: train_loss=0.4417184591293335
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 14: train_loss=0.3842172920703888
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 15: train_loss=0.36889538168907166
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 16: train_loss=0.37933892011642456
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 17: train_loss=0.373025119304657
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 18: train_loss=0.34977808594703674
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 19: train_loss=0.32267290353775024
INFO - 04/15/25 16:39:40 - 0:08:03 - Epoch 20: train_loss=0.3027433753013611
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 21: train_loss=0.30923837423324585
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 22: train_loss=0.31620579957962036
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 23: train_loss=0.306105375289917
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 24: train_loss=0.2849820554256439
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 25: train_loss=0.27686306834220886
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 26: train_loss=0.2799260914325714
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 27: train_loss=0.2794305682182312
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 28: train_loss=0.27447637915611267
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 29: train_loss=0.2673264741897583
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 30: train_loss=0.2607191801071167
INFO - 04/15/25 16:39:40 - 0:08:04 - Epoch 31: train_loss=0.25908705592155457
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 32: train_loss=0.26127496361732483
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 33: train_loss=0.25884929299354553
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 34: train_loss=0.25126132369041443
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 35: train_loss=0.248244509100914
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 36: train_loss=0.2512671947479248
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 37: train_loss=0.24853119254112244
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 38: train_loss=0.24335598945617676
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 39: train_loss=0.24280504882335663
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 40: train_loss=0.24518820643424988
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 41: train_loss=0.24115340411663055
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 42: train_loss=0.23876014351844788
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 43: train_loss=0.24456433951854706
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 44: train_loss=0.2394731491804123
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 45: train_loss=0.24177326261997223
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 46: train_loss=0.23679839074611664
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 47: train_loss=0.23785582184791565
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 48: train_loss=0.24064792692661285
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 49: train_loss=0.23480860888957977
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 50: train_loss=0.2374807447195053
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 51: train_loss=0.2315785437822342
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 52: train_loss=0.2371792048215866
INFO - 04/15/25 16:39:41 - 0:08:04 - Epoch 53: train_loss=0.23053979873657227
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 54: train_loss=0.2279825657606125
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 55: train_loss=0.2351684868335724
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 56: train_loss=0.22968736290931702
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 57: train_loss=0.23335686326026917
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 58: train_loss=0.22623664140701294
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 59: train_loss=0.23655012249946594
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 60: train_loss=0.2327650785446167
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 61: train_loss=0.23145854473114014
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 62: train_loss=0.23230047523975372
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 63: train_loss=0.22649766504764557
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 64: train_loss=0.23168805241584778
INFO - 04/15/25 16:39:41 - 0:08:05 - Epoch 65: train_loss=0.2286965399980545
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 66: train_loss=0.22646652162075043
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 67: train_loss=0.23023445904254913
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 68: train_loss=0.22337521612644196
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 69: train_loss=0.23261316120624542
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 70: train_loss=0.226804718375206
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 71: train_loss=0.23012004792690277
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 72: train_loss=0.223349466919899
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 73: train_loss=0.2283419668674469
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 74: train_loss=0.2220202088356018
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 75: train_loss=0.2242935746908188
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 76: train_loss=0.22273777425289154
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 77: train_loss=0.2208251953125
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 78: train_loss=0.22039464116096497
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 79: train_loss=0.2213391661643982
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 80: train_loss=0.21502216160297394
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 81: train_loss=0.22634170949459076
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 82: train_loss=0.22055606544017792
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 83: train_loss=0.2261398732662201
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 84: train_loss=0.22241127490997314
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 85: train_loss=0.22496464848518372
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 86: train_loss=0.22095218300819397
INFO - 04/15/25 16:39:42 - 0:08:05 - Epoch 87: train_loss=0.22430385649204254
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 88: train_loss=0.22188016772270203
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 89: train_loss=0.22155018150806427
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 90: train_loss=0.21896277368068695
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 91: train_loss=0.22251832485198975
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 92: train_loss=0.21846072375774384
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 93: train_loss=0.22198481857776642
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 94: train_loss=0.22031794488430023
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 95: train_loss=0.2171388417482376
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 96: train_loss=0.2157687246799469
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 97: train_loss=0.2181873470544815
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 98: train_loss=0.2138766348361969
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 99: train_loss=0.22019533812999725
INFO - 04/15/25 16:39:42 - 0:08:06 - Epoch 100: train_loss=0.21793153882026672
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 101: train_loss=0.21464645862579346
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 102: train_loss=0.21440860629081726
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 103: train_loss=0.21406294405460358
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 104: train_loss=0.21112407743930817
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 105: train_loss=0.21806618571281433
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 106: train_loss=0.21512386202812195
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 107: train_loss=0.21485744416713715
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 108: train_loss=0.21450908482074738
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 109: train_loss=0.21182571351528168
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 110: train_loss=0.21103668212890625
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 111: train_loss=0.2129870355129242
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 112: train_loss=0.20933924615383148
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 113: train_loss=0.21557095646858215
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 114: train_loss=0.21346738934516907
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 115: train_loss=0.21104049682617188
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 116: train_loss=0.21103283762931824
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 117: train_loss=0.21060490608215332
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 118: train_loss=0.20802128314971924
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 119: train_loss=0.21368372440338135
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 120: train_loss=0.21137763559818268
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 121: train_loss=0.20999200642108917
INFO - 04/15/25 16:39:43 - 0:08:06 - Epoch 122: train_loss=0.20926432311534882
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 123: train_loss=0.20971113443374634
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 124: train_loss=0.20749050378799438
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 125: train_loss=0.21149876713752747
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 126: train_loss=0.21045659482479095
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 127: train_loss=0.20761707425117493
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 128: train_loss=0.20666715502738953
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 129: train_loss=0.20940321683883667
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 130: train_loss=0.20728333294391632
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 131: train_loss=0.20942378044128418
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 132: train_loss=0.20830747485160828
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 133: train_loss=0.20717765390872955
INFO - 04/15/25 16:39:43 - 0:08:07 - Epoch 134: train_loss=0.20600375533103943
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 135: train_loss=0.2082342803478241
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 136: train_loss=0.20654352009296417
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 137: train_loss=0.20787855982780457
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 138: train_loss=0.20715336501598358
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 139: train_loss=0.20564597845077515
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 140: train_loss=0.2046840637922287
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 141: train_loss=0.2072594165802002
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 142: train_loss=0.20545616745948792
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 143: train_loss=0.20643022656440735
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 144: train_loss=0.20553459227085114
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 145: train_loss=0.20528781414031982
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 146: train_loss=0.2044379562139511
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 147: train_loss=0.20605362951755524
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 148: train_loss=0.20443478226661682
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 149: train_loss=0.20526298880577087
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 150: train_loss=0.20415717363357544
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 151: train_loss=0.20504382252693176
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 152: train_loss=0.20396140217781067
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 153: train_loss=0.20418860018253326
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 154: train_loss=0.20286807417869568
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 155: train_loss=0.20533519983291626
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 156: train_loss=0.20427167415618896
INFO - 04/15/25 16:39:44 - 0:08:07 - Epoch 157: train_loss=0.2029140293598175
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 158: train_loss=0.20203766226768494
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 159: train_loss=0.2048230618238449
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 160: train_loss=0.20375972986221313
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 161: train_loss=0.20243819057941437
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 162: train_loss=0.2022266983985901
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 163: train_loss=0.20396007597446442
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 164: train_loss=0.20293128490447998
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 165: train_loss=0.20185518264770508
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 166: train_loss=0.2027697116136551
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 167: train_loss=0.20215098559856415
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 168: train_loss=0.20158717036247253
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 169: train_loss=0.2040141373872757
INFO - 04/15/25 16:39:44 - 0:08:08 - Epoch 170: train_loss=0.2028837502002716
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 171: train_loss=0.19863292574882507
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 172: train_loss=0.2015470415353775
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 173: train_loss=0.20391584932804108
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 174: train_loss=0.1974131017923355
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 175: train_loss=0.20977577567100525
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 176: train_loss=0.20425838232040405
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 177: train_loss=0.20847302675247192
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 178: train_loss=0.2058115154504776
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 179: train_loss=0.20728597044944763
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 180: train_loss=0.20228001475334167
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 181: train_loss=0.20671851933002472
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 182: train_loss=0.19982898235321045
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 183: train_loss=0.21386170387268066
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 184: train_loss=0.2120572179555893
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 185: train_loss=0.20091187953948975
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 186: train_loss=0.20263135433197021
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 187: train_loss=0.20257550477981567
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 188: train_loss=0.19943921267986298
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 189: train_loss=0.20803265273571014
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 190: train_loss=0.20238664746284485
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 191: train_loss=0.21151995658874512
INFO - 04/15/25 16:39:45 - 0:08:08 - Epoch 192: train_loss=0.2120676338672638
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 193: train_loss=0.19970257580280304
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 194: train_loss=0.2087661325931549
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 195: train_loss=0.20378635823726654
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 196: train_loss=0.20791631937026978
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 197: train_loss=0.20740103721618652
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 198: train_loss=0.2027854174375534
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 199: train_loss=0.20362260937690735
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 200: train_loss=0.20188802480697632
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 201: train_loss=0.20423078536987305
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 202: train_loss=0.200654998421669
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 203: train_loss=0.2070935070514679
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 204: train_loss=0.2057683914899826
INFO - 04/15/25 16:39:45 - 0:08:09 - Epoch 205: train_loss=0.20191329717636108
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 206: train_loss=0.20382025837898254
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 207: train_loss=0.20019088685512543
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 208: train_loss=0.20748038589954376
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 209: train_loss=0.2057536542415619
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 210: train_loss=0.20158334076404572
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 211: train_loss=0.20100551843643188
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 212: train_loss=0.202107772231102
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 213: train_loss=0.20010653138160706
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 214: train_loss=0.19895070791244507
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 215: train_loss=0.20395061373710632
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 216: train_loss=0.1983068734407425
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 217: train_loss=0.2099011093378067
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 218: train_loss=0.21001562476158142
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 219: train_loss=0.198950856924057
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 220: train_loss=0.20409861207008362
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 221: train_loss=0.20313003659248352
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 222: train_loss=0.1982193887233734
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 223: train_loss=0.20345251262187958
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 224: train_loss=0.19842271506786346
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 225: train_loss=0.2055467665195465
INFO - 04/15/25 16:39:46 - 0:08:09 - Epoch 226: train_loss=0.20498238503932953
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 227: train_loss=0.19896452128887177
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 228: train_loss=0.20092172920703888
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 229: train_loss=0.19959983229637146
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 230: train_loss=0.19872324168682098
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 231: train_loss=0.19825337827205658
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 232: train_loss=0.19783641397953033
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 233: train_loss=0.1980932354927063
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 234: train_loss=0.19441504776477814
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 235: train_loss=0.20341302454471588
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 236: train_loss=0.19635747373104095
INFO - 04/15/25 16:39:46 - 0:08:10 - Epoch 237: train_loss=0.21060658991336823
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 238: train_loss=0.21267245709896088
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 239: train_loss=0.19395339488983154
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 240: train_loss=0.2136184424161911
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 241: train_loss=0.21769605576992035
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 242: train_loss=0.2045721411705017
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 243: train_loss=0.20604117214679718
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 244: train_loss=0.2102855145931244
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 245: train_loss=0.2056749016046524
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 246: train_loss=0.20325759053230286
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 247: train_loss=0.2029714435338974
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 248: train_loss=0.20327338576316833
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 249: train_loss=0.19824419915676117
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 250: train_loss=0.20182950794696808
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 251: train_loss=0.1995602399110794
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 252: train_loss=0.2005942165851593
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 253: train_loss=0.19796887040138245
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 254: train_loss=0.20152314007282257
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 255: train_loss=0.1996670812368393
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 256: train_loss=0.1988936811685562
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 257: train_loss=0.19833159446716309
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 258: train_loss=0.19834016263484955
INFO - 04/15/25 16:39:47 - 0:08:10 - Epoch 259: train_loss=0.19649481773376465
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 260: train_loss=0.2003858983516693
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 261: train_loss=0.19910992681980133
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 262: train_loss=0.19742685556411743
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 263: train_loss=0.1964925080537796
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 264: train_loss=0.19872580468654633
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 265: train_loss=0.1963936686515808
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 266: train_loss=0.19978424906730652
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 267: train_loss=0.19863349199295044
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 268: train_loss=0.19679811596870422
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 269: train_loss=0.19591961801052094
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 270: train_loss=0.19818896055221558
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 271: train_loss=0.19640254974365234
INFO - 04/15/25 16:39:47 - 0:08:11 - Epoch 272: train_loss=0.19788263738155365
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 273: train_loss=0.19715994596481323
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 274: train_loss=0.1961742788553238
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 275: train_loss=0.19528134167194366
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 276: train_loss=0.1974722445011139
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 277: train_loss=0.19578489661216736
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 278: train_loss=0.19724245369434357
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 279: train_loss=0.19665846228599548
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 280: train_loss=0.19618389010429382
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 281: train_loss=0.19393935799598694
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 282: train_loss=0.19780895113945007
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 283: train_loss=0.19676125049591064
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 284: train_loss=0.19448073208332062
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 285: train_loss=0.19408753514289856
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 286: train_loss=0.19611480832099915
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 287: train_loss=0.19429460167884827
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 288: train_loss=0.1968832165002823
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 289: train_loss=0.19626910984516144
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 290: train_loss=0.19347791373729706
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 291: train_loss=0.19273383915424347
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 292: train_loss=0.19656632840633392
INFO - 04/15/25 16:39:48 - 0:08:11 - Epoch 293: train_loss=0.19464252889156342
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 294: train_loss=0.19499851763248444
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 295: train_loss=0.1949089616537094
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 296: train_loss=0.19324034452438354
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 297: train_loss=0.19207563996315002
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 298: train_loss=0.19569489359855652
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 299: train_loss=0.19356472790241241
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 300: train_loss=0.19559970498085022
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 301: train_loss=0.1953953206539154
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 302: train_loss=0.19187326729297638
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 303: train_loss=0.19342078268527985
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 304: train_loss=0.19250810146331787
INFO - 04/15/25 16:39:48 - 0:08:12 - Epoch 305: train_loss=0.19076478481292725
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 306: train_loss=0.19898031651973724
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 307: train_loss=0.19499114155769348
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 308: train_loss=0.19725501537322998
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 309: train_loss=0.19717690348625183
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 310: train_loss=0.19424858689308167
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 311: train_loss=0.2017166018486023
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 312: train_loss=0.2007731944322586
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 313: train_loss=0.1955278217792511
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 314: train_loss=0.19508038461208344
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 315: train_loss=0.19692756235599518
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 316: train_loss=0.19141648709774017
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 317: train_loss=0.1915898323059082
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 318: train_loss=0.19711263477802277
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 319: train_loss=0.19231738150119781
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 320: train_loss=0.19864557683467865
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 321: train_loss=0.19625608623027802
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 322: train_loss=0.19659042358398438
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 323: train_loss=0.19462420046329498
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 324: train_loss=0.19600912928581238
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 325: train_loss=0.19198618829250336
INFO - 04/15/25 16:39:49 - 0:08:12 - Epoch 326: train_loss=0.19613869488239288
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 327: train_loss=0.18920476734638214
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 328: train_loss=0.20061641931533813
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 329: train_loss=0.19494841992855072
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 330: train_loss=0.2013292759656906
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 331: train_loss=0.20061469078063965
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 332: train_loss=0.19632329046726227
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 333: train_loss=0.19601692259311676
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 334: train_loss=0.19786003232002258
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 335: train_loss=0.1932515650987625
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 336: train_loss=0.20139212906360626
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 337: train_loss=0.19907869398593903
INFO - 04/15/25 16:39:49 - 0:08:13 - Epoch 338: train_loss=0.19613683223724365
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 339: train_loss=0.19613130390644073
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 340: train_loss=0.1958998590707779
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 341: train_loss=0.19395990669727325
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 342: train_loss=0.1971699744462967
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 343: train_loss=0.19483593106269836
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 344: train_loss=0.19675034284591675
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 345: train_loss=0.19532835483551025
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 346: train_loss=0.19571642577648163
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 347: train_loss=0.19432629644870758
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 348: train_loss=0.1957526057958603
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 349: train_loss=0.19380128383636475
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 350: train_loss=0.19560442864894867
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 351: train_loss=0.1936824768781662
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 352: train_loss=0.19570015370845795
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 353: train_loss=0.19409723579883575
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 354: train_loss=0.19527997076511383
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 355: train_loss=0.1940850466489792
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 356: train_loss=0.1948644071817398
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 357: train_loss=0.19369690120220184
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 358: train_loss=0.19492727518081665
INFO - 04/15/25 16:39:50 - 0:08:13 - Epoch 359: train_loss=0.19362974166870117
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 360: train_loss=0.19476670026779175
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 361: train_loss=0.19374428689479828
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 362: train_loss=0.19394506514072418
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 363: train_loss=0.19270536303520203
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 364: train_loss=0.19448068737983704
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 365: train_loss=0.19338776171207428
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 366: train_loss=0.19337190687656403
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 367: train_loss=0.1921764612197876
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 368: train_loss=0.1942214071750641
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 369: train_loss=0.19295057654380798
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 370: train_loss=0.1932743787765503
INFO - 04/15/25 16:39:50 - 0:08:14 - Epoch 371: train_loss=0.1920796036720276
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 372: train_loss=0.19381344318389893
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 373: train_loss=0.1928439736366272
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 374: train_loss=0.19251012802124023
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 375: train_loss=0.19140063226222992
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 376: train_loss=0.1936252862215042
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 377: train_loss=0.19258007407188416
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 378: train_loss=0.19214777648448944
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 379: train_loss=0.19110876321792603
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 380: train_loss=0.19339975714683533
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 381: train_loss=0.1923699676990509
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 382: train_loss=0.19172854721546173
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 383: train_loss=0.19080138206481934
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 384: train_loss=0.19266188144683838
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 385: train_loss=0.19146879017353058
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 386: train_loss=0.19212079048156738
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 387: train_loss=0.1912030130624771
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 388: train_loss=0.1918027698993683
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 389: train_loss=0.19076095521450043
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 390: train_loss=0.19200444221496582
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 391: train_loss=0.19101250171661377
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 392: train_loss=0.1916344165802002
INFO - 04/15/25 16:39:51 - 0:08:14 - Epoch 393: train_loss=0.19078968465328217
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 394: train_loss=0.191419780254364
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 395: train_loss=0.19041019678115845
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 396: train_loss=0.19170407950878143
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 397: train_loss=0.19091086089611053
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 398: train_loss=0.19063010811805725
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 399: train_loss=0.18967178463935852
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 400: train_loss=0.19205519556999207
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 401: train_loss=0.19135965406894684
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 402: train_loss=0.1896713227033615
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 403: train_loss=0.18869705498218536
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 404: train_loss=0.19253742694854736
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 405: train_loss=0.1916588693857193
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 406: train_loss=0.18911220133304596
INFO - 04/15/25 16:39:51 - 0:08:15 - Epoch 407: train_loss=0.18910613656044006
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 408: train_loss=0.19081252813339233
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 409: train_loss=0.18891635537147522
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 410: train_loss=0.19177564978599548
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 411: train_loss=0.19150924682617188
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 412: train_loss=0.18796439468860626
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 413: train_loss=0.18707521259784698
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 414: train_loss=0.19372530281543732
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 415: train_loss=0.19251751899719238
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 416: train_loss=0.18877913057804108
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 417: train_loss=0.194339781999588
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 418: train_loss=0.18673568964004517
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 419: train_loss=0.2052011936903
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 420: train_loss=0.20827347040176392
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 421: train_loss=0.1937980353832245
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 422: train_loss=0.20159736275672913
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 423: train_loss=0.2047632336616516
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 424: train_loss=0.1997051239013672
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 425: train_loss=0.1974158138036728
INFO - 04/15/25 16:39:52 - 0:08:15 - Epoch 426: train_loss=0.19486387073993683
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 427: train_loss=0.20007163286209106
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 428: train_loss=0.19171833992004395
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 429: train_loss=0.20056317746639252
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 430: train_loss=0.20446407794952393
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 431: train_loss=0.19145141541957855
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 432: train_loss=0.19986000657081604
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 433: train_loss=0.20290756225585938
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 434: train_loss=0.19683586061000824
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 435: train_loss=0.19406366348266602
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 436: train_loss=0.19661496579647064
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 437: train_loss=0.198097825050354
INFO - 04/15/25 16:39:52 - 0:08:16 - Epoch 438: train_loss=0.1887582689523697
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 439: train_loss=0.19960437715053558
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 440: train_loss=0.20234328508377075
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 441: train_loss=0.19067373871803284
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 442: train_loss=0.1985798329114914
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 443: train_loss=0.2032947838306427
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 444: train_loss=0.19544053077697754
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 445: train_loss=0.1935858130455017
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 446: train_loss=0.19662143290042877
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 447: train_loss=0.1952432096004486
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 448: train_loss=0.19107019901275635
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 449: train_loss=0.19418801367282867
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 450: train_loss=0.19577845931053162
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 451: train_loss=0.1840241700410843
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 452: train_loss=0.20071890950202942
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 453: train_loss=0.2005854845046997
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 454: train_loss=0.18880829215049744
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 455: train_loss=0.19570723176002502
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 456: train_loss=0.19518989324569702
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 457: train_loss=0.19356533885002136
INFO - 04/15/25 16:39:53 - 0:08:16 - Epoch 458: train_loss=0.19084525108337402
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 459: train_loss=0.19307810068130493
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 460: train_loss=0.1933007389307022
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 461: train_loss=0.18881577253341675
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 462: train_loss=0.19201964139938354
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 463: train_loss=0.19085755944252014
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 464: train_loss=0.190471351146698
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 465: train_loss=0.18777135014533997
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 466: train_loss=0.19264934957027435
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 467: train_loss=0.18764492869377136
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 468: train_loss=0.19596992433071136
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 469: train_loss=0.19673721492290497
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 470: train_loss=0.18745990097522736
INFO - 04/15/25 16:39:53 - 0:08:17 - Epoch 471: train_loss=0.1945992261171341
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 472: train_loss=0.19460007548332214
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 473: train_loss=0.18778592348098755
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 474: train_loss=0.19102594256401062
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 475: train_loss=0.18955594301223755
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 476: train_loss=0.18945549428462982
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 477: train_loss=0.1878412663936615
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 478: train_loss=0.18829992413520813
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 479: train_loss=0.18694588541984558
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 480: train_loss=0.18795588612556458
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 481: train_loss=0.18700054287910461
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 482: train_loss=0.18495123088359833
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 483: train_loss=0.18801765143871307
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 484: train_loss=0.1864871084690094
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 485: train_loss=0.18465082347393036
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 486: train_loss=0.18878498673439026
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 487: train_loss=0.1841859072446823
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 488: train_loss=0.18782874941825867
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 489: train_loss=0.1865127980709076
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 490: train_loss=0.18556083738803864
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 491: train_loss=0.1889611780643463
INFO - 04/15/25 16:39:54 - 0:08:17 - Epoch 492: train_loss=0.18591748178005219
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 493: train_loss=0.19059287011623383
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 494: train_loss=0.18994972109794617
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 495: train_loss=0.18813456594944
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 496: train_loss=0.18724654614925385
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 497: train_loss=0.18962034583091736
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 498: train_loss=0.18708740174770355
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 499: train_loss=0.19077427685260773
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 500: train_loss=0.19085128605365753
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 501: train_loss=0.18671293556690216
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 502: train_loss=0.18739047646522522
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 503: train_loss=0.18796002864837646
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 504: train_loss=0.1851624697446823
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 505: train_loss=0.19238035380840302
INFO - 04/15/25 16:39:54 - 0:08:18 - Epoch 506: train_loss=0.19201608002185822
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 507: train_loss=0.1865832805633545
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 508: train_loss=0.1894512176513672
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 509: train_loss=0.1868676096200943
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 510: train_loss=0.1896819770336151
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 511: train_loss=0.1853925585746765
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 512: train_loss=0.19031170010566711
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 513: train_loss=0.1864176094532013
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 514: train_loss=0.19062532484531403
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 515: train_loss=0.19019092619419098
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 516: train_loss=0.18584562838077545
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 517: train_loss=0.19025394320487976
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 518: train_loss=0.1851215958595276
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 519: train_loss=0.193821981549263
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 520: train_loss=0.19287240505218506
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 521: train_loss=0.1892741471529007
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 522: train_loss=0.18897338211536407
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 523: train_loss=0.19087202847003937
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 524: train_loss=0.18547673523426056
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 525: train_loss=0.19388636946678162
INFO - 04/15/25 16:39:55 - 0:08:18 - Epoch 526: train_loss=0.19023650884628296
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 527: train_loss=0.19278235733509064
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 528: train_loss=0.19306588172912598
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 529: train_loss=0.18743957579135895
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 530: train_loss=0.1885683238506317
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 531: train_loss=0.18839487433433533
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 532: train_loss=0.186355859041214
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 533: train_loss=0.18901889026165009
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 534: train_loss=0.18516305088996887
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 535: train_loss=0.19271758198738098
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 536: train_loss=0.19069212675094604
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 537: train_loss=0.18889503180980682
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 538: train_loss=0.18862102925777435
INFO - 04/15/25 16:39:55 - 0:08:19 - Epoch 539: train_loss=0.18941517174243927
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 540: train_loss=0.18814648687839508
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 541: train_loss=0.19009342789649963
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 542: train_loss=0.18894529342651367
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 543: train_loss=0.18951714038848877
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 544: train_loss=0.18884655833244324
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 545: train_loss=0.18865182995796204
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 546: train_loss=0.18733441829681396
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 547: train_loss=0.1905062198638916
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 548: train_loss=0.18977856636047363
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 549: train_loss=0.18746522068977356
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 550: train_loss=0.1864655315876007
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 551: train_loss=0.19052916765213013
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 552: train_loss=0.18945789337158203
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 553: train_loss=0.1875988245010376
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 554: train_loss=0.18665054440498352
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 555: train_loss=0.19029928743839264
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 556: train_loss=0.18959026038646698
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 557: train_loss=0.18684804439544678
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 558: train_loss=0.18564988672733307
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 559: train_loss=0.19107642769813538
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 560: train_loss=0.1904333382844925
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 561: train_loss=0.18555572628974915
INFO - 04/15/25 16:39:56 - 0:08:19 - Epoch 562: train_loss=0.1845569610595703
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 563: train_loss=0.19153979420661926
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 564: train_loss=0.1907828450202942
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 565: train_loss=0.18497520685195923
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 566: train_loss=0.1839461326599121
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 567: train_loss=0.191873237490654
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 568: train_loss=0.1910959631204605
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 569: train_loss=0.18423013389110565
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 570: train_loss=0.18310479819774628
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 571: train_loss=0.19237776100635529
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 572: train_loss=0.1917557269334793
INFO - 04/15/25 16:39:56 - 0:08:20 - Epoch 573: train_loss=0.18329890072345734
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 574: train_loss=0.18350611627101898
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 575: train_loss=0.1907499134540558
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 576: train_loss=0.18811248242855072
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 577: train_loss=0.18956032395362854
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 578: train_loss=0.18963207304477692
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 579: train_loss=0.18648958206176758
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 580: train_loss=0.18857964873313904
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 581: train_loss=0.18470650911331177
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 582: train_loss=0.19409886002540588
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 583: train_loss=0.19322577118873596
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 584: train_loss=0.18534424901008606
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 585: train_loss=0.18627285957336426
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 586: train_loss=0.1873430460691452
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 587: train_loss=0.1854310929775238
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 588: train_loss=0.18596726655960083
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 589: train_loss=0.18678070604801178
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 590: train_loss=0.18384882807731628
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 591: train_loss=0.18602322041988373
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 592: train_loss=0.1851460337638855
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 593: train_loss=0.18530072271823883
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 594: train_loss=0.18187151849269867
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 595: train_loss=0.18916857242584229
INFO - 04/15/25 16:39:57 - 0:08:20 - Epoch 596: train_loss=0.1849168837070465
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 597: train_loss=0.19145222008228302
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 598: train_loss=0.19222865998744965
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 599: train_loss=0.1839379370212555
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 600: train_loss=0.1936163604259491
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 601: train_loss=0.1938149333000183
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 602: train_loss=0.18213923275470734
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 603: train_loss=0.191301167011261
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 604: train_loss=0.19022127985954285
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 605: train_loss=0.18554705381393433
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 606: train_loss=0.18654809892177582
INFO - 04/15/25 16:39:57 - 0:08:21 - Epoch 607: train_loss=0.18627364933490753
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 608: train_loss=0.18595798313617706
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 609: train_loss=0.1844222992658615
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 610: train_loss=0.18416249752044678
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 611: train_loss=0.18573175370693207
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 612: train_loss=0.183538556098938
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 613: train_loss=0.18563123047351837
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 614: train_loss=0.1828211545944214
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 615: train_loss=0.1848686933517456
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 616: train_loss=0.18460585176944733
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 617: train_loss=0.183507040143013
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 618: train_loss=0.18642252683639526
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 619: train_loss=0.18396371603012085
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 620: train_loss=0.18753677606582642
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 621: train_loss=0.18569394946098328
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 622: train_loss=0.18726292252540588
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 623: train_loss=0.18602131307125092
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 624: train_loss=0.18647965788841248
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 625: train_loss=0.18649570643901825
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 626: train_loss=0.18437574803829193
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 627: train_loss=0.18330246210098267
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 628: train_loss=0.18728239834308624
INFO - 04/15/25 16:39:58 - 0:08:21 - Epoch 629: train_loss=0.18518531322479248
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 630: train_loss=0.1876804381608963
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 631: train_loss=0.18775397539138794
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 632: train_loss=0.18326860666275024
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 633: train_loss=0.18331211805343628
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 634: train_loss=0.1871122121810913
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 635: train_loss=0.18524597585201263
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 636: train_loss=0.1867913454771042
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 637: train_loss=0.1867145150899887
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 638: train_loss=0.18386322259902954
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 639: train_loss=0.18606019020080566
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 640: train_loss=0.1833367645740509
INFO - 04/15/25 16:39:58 - 0:08:22 - Epoch 641: train_loss=0.18112517893314362
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 642: train_loss=0.1899207979440689
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 643: train_loss=0.1873127818107605
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 644: train_loss=0.18758036196231842
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 645: train_loss=0.18766693770885468
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 646: train_loss=0.1861129254102707
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 647: train_loss=0.1878555417060852
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 648: train_loss=0.18564817309379578
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 649: train_loss=0.1897057443857193
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 650: train_loss=0.18953461945056915
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 651: train_loss=0.18604497611522675
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 652: train_loss=0.18627960979938507
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 653: train_loss=0.18657702207565308
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 654: train_loss=0.18503394722938538
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 655: train_loss=0.18374945223331451
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 656: train_loss=0.1888292133808136
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 657: train_loss=0.1866448074579239
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 658: train_loss=0.1879502236843109
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 659: train_loss=0.18678021430969238
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 660: train_loss=0.18773877620697021
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 661: train_loss=0.18475696444511414
INFO - 04/15/25 16:39:59 - 0:08:22 - Epoch 662: train_loss=0.18762916326522827
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 663: train_loss=0.18353107571601868
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 664: train_loss=0.185620978474617
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 665: train_loss=0.18596020340919495
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 666: train_loss=0.18159057199954987
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 667: train_loss=0.1961153745651245
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 668: train_loss=0.1967523992061615
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 669: train_loss=0.18324631452560425
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 670: train_loss=0.19674471020698547
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 671: train_loss=0.19948700070381165
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 672: train_loss=0.19100072979927063
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 673: train_loss=0.19200363755226135
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 674: train_loss=0.19365036487579346
INFO - 04/15/25 16:39:59 - 0:08:23 - Epoch 675: train_loss=0.19143866002559662
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 676: train_loss=0.19032444059848785
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 677: train_loss=0.18876522779464722
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 678: train_loss=0.19108586013317108
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 679: train_loss=0.18614570796489716
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 680: train_loss=0.1911773830652237
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 681: train_loss=0.19226473569869995
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 682: train_loss=0.18469884991645813
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 683: train_loss=0.1898399442434311
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 684: train_loss=0.19091156125068665
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 685: train_loss=0.1855379045009613
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 686: train_loss=0.1890217512845993
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 687: train_loss=0.19072769582271576
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 688: train_loss=0.18416069447994232
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 689: train_loss=0.18935269117355347
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 690: train_loss=0.19110839068889618
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 691: train_loss=0.18505576252937317
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 692: train_loss=0.18878501653671265
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 693: train_loss=0.19136931002140045
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 694: train_loss=0.1851087361574173
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 695: train_loss=0.18857043981552124
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 696: train_loss=0.19157291948795319
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 697: train_loss=0.18588271737098694
INFO - 04/15/25 16:40:00 - 0:08:23 - Epoch 698: train_loss=0.18730543553829193
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 699: train_loss=0.19051769375801086
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 700: train_loss=0.1845933496952057
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 701: train_loss=0.1881927251815796
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 702: train_loss=0.19146722555160522
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 703: train_loss=0.18601731956005096
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 704: train_loss=0.18606647849082947
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 705: train_loss=0.18948227167129517
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 706: train_loss=0.18379297852516174
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 707: train_loss=0.18857420980930328
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 708: train_loss=0.19194306433200836
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 709: train_loss=0.18676209449768066
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 710: train_loss=0.18468855321407318
INFO - 04/15/25 16:40:00 - 0:08:24 - Epoch 711: train_loss=0.18844406306743622
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 712: train_loss=0.18417002260684967
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 713: train_loss=0.18778489530086517
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 714: train_loss=0.18980775773525238
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 715: train_loss=0.1855091005563736
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 716: train_loss=0.18484888970851898
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 717: train_loss=0.18769127130508423
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 718: train_loss=0.18272711336612701
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 719: train_loss=0.18983812630176544
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 720: train_loss=0.19199128448963165
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 721: train_loss=0.18703603744506836
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 722: train_loss=0.18570369482040405
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 723: train_loss=0.1885799616575241
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 724: train_loss=0.1886824518442154
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 725: train_loss=0.1811082363128662
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 726: train_loss=0.1911739557981491
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 727: train_loss=0.19139711558818817
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 728: train_loss=0.18582060933113098
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 729: train_loss=0.18660295009613037
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 730: train_loss=0.1874387562274933
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 731: train_loss=0.18773934245109558
INFO - 04/15/25 16:40:01 - 0:08:24 - Epoch 732: train_loss=0.18278706073760986
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 733: train_loss=0.18680155277252197
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 734: train_loss=0.18544775247573853
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 735: train_loss=0.18559329211711884
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 736: train_loss=0.18372729420661926
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 737: train_loss=0.18691040575504303
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 738: train_loss=0.1846373975276947
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 739: train_loss=0.18695135414600372
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 740: train_loss=0.18559522926807404
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 741: train_loss=0.18671706318855286
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 742: train_loss=0.1860465556383133
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 743: train_loss=0.18483923375606537
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 744: train_loss=0.1849524825811386
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 745: train_loss=0.18442176282405853
INFO - 04/15/25 16:40:01 - 0:08:25 - Epoch 746: train_loss=0.18334993720054626
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 747: train_loss=0.18665961921215057
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 748: train_loss=0.18455220758914948
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 749: train_loss=0.18774598836898804
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 750: train_loss=0.18744754791259766
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 751: train_loss=0.1842086911201477
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 752: train_loss=0.18498525023460388
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 753: train_loss=0.18332980573177338
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 754: train_loss=0.18489328026771545
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 755: train_loss=0.18222704529762268
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 756: train_loss=0.1828024536371231
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 757: train_loss=0.18465939164161682
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 758: train_loss=0.18167901039123535
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 759: train_loss=0.18430081009864807
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 760: train_loss=0.18071261048316956
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 761: train_loss=0.18991215527057648
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 762: train_loss=0.18805202841758728
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 763: train_loss=0.18533511459827423
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 764: train_loss=0.1857413649559021
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 765: train_loss=0.1848181039094925
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 766: train_loss=0.1848483681678772
INFO - 04/15/25 16:40:02 - 0:08:25 - Epoch 767: train_loss=0.18354882299900055
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 768: train_loss=0.18619297444820404
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 769: train_loss=0.18235653638839722
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 770: train_loss=0.19099107384681702
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 771: train_loss=0.19011104106903076
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 772: train_loss=0.18372675776481628
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 773: train_loss=0.18516743183135986
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 774: train_loss=0.1847013384103775
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 775: train_loss=0.18328768014907837
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 776: train_loss=0.18651404976844788
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 777: train_loss=0.18332867324352264
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 778: train_loss=0.18944720923900604
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 779: train_loss=0.18878301978111267
INFO - 04/15/25 16:40:02 - 0:08:26 - Epoch 780: train_loss=0.18377460539340973
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 781: train_loss=0.1846243292093277
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 782: train_loss=0.1847967654466629
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 783: train_loss=0.1832299530506134
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 784: train_loss=0.18548400700092316
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 785: train_loss=0.18322066962718964
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 786: train_loss=0.18589426577091217
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 787: train_loss=0.18400830030441284
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 788: train_loss=0.18621528148651123
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 789: train_loss=0.1854439079761505
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 790: train_loss=0.1843620240688324
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 791: train_loss=0.18448461592197418
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 792: train_loss=0.1837729662656784
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 793: train_loss=0.183201864361763
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 794: train_loss=0.18526461720466614
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 795: train_loss=0.1829761266708374
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 796: train_loss=0.18840095400810242
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 797: train_loss=0.188873291015625
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 798: train_loss=0.18097896873950958
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 799: train_loss=0.18608532845973969
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 800: train_loss=0.18201595544815063
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 801: train_loss=0.1897161453962326
INFO - 04/15/25 16:40:03 - 0:08:26 - Epoch 802: train_loss=0.18944784998893738
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 803: train_loss=0.18324436247348785
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 804: train_loss=0.18603786826133728
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 805: train_loss=0.18374574184417725
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 806: train_loss=0.18569594621658325
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 807: train_loss=0.1835583597421646
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 808: train_loss=0.1866558939218521
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 809: train_loss=0.1862790882587433
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 810: train_loss=0.18322572112083435
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 811: train_loss=0.18358513712882996
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 812: train_loss=0.1841856986284256
INFO - 04/15/25 16:40:03 - 0:08:27 - Epoch 813: train_loss=0.18236279487609863
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 814: train_loss=0.18702426552772522
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 815: train_loss=0.18668432533740997
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 816: train_loss=0.18274667859077454
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 817: train_loss=0.18469363451004028
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 818: train_loss=0.18214371800422668
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 819: train_loss=0.18275371193885803
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 820: train_loss=0.18568381667137146
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 821: train_loss=0.18192267417907715
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 822: train_loss=0.1896899789571762
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 823: train_loss=0.18919822573661804
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 824: train_loss=0.18490168452262878
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 825: train_loss=0.18598470091819763
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 826: train_loss=0.18576084077358246
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 827: train_loss=0.1843276023864746
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 828: train_loss=0.1852366030216217
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 829: train_loss=0.18340812623500824
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 830: train_loss=0.18389278650283813
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 831: train_loss=0.1840790957212448
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 832: train_loss=0.18245646357536316
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 833: train_loss=0.18576261401176453
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 834: train_loss=0.1838652640581131
INFO - 04/15/25 16:40:04 - 0:08:27 - Epoch 835: train_loss=0.18607285618782043
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 836: train_loss=0.18478918075561523
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 837: train_loss=0.18603090941905975
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 838: train_loss=0.18467000126838684
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 839: train_loss=0.1857225000858307
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 840: train_loss=0.18472720682621002
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 841: train_loss=0.18527579307556152
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 842: train_loss=0.18423974514007568
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 843: train_loss=0.1847495436668396
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 844: train_loss=0.183651402592659
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 845: train_loss=0.18349003791809082
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 846: train_loss=0.18498842418193817
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 847: train_loss=0.18219037353992462
INFO - 04/15/25 16:40:04 - 0:08:28 - Epoch 848: train_loss=0.18945646286010742
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 849: train_loss=0.1885363757610321
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 850: train_loss=0.1835576295852661
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 851: train_loss=0.18416406214237213
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 852: train_loss=0.1852249950170517
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 853: train_loss=0.18316693603992462
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 854: train_loss=0.18740415573120117
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 855: train_loss=0.18626965582370758
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 856: train_loss=0.18547409772872925
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 857: train_loss=0.18449172377586365
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 858: train_loss=0.18663039803504944
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 859: train_loss=0.18552066385746002
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 860: train_loss=0.1856822967529297
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 861: train_loss=0.18485461175441742
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 862: train_loss=0.1861557513475418
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 863: train_loss=0.18513646721839905
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 864: train_loss=0.18598832190036774
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 865: train_loss=0.18516723811626434
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 866: train_loss=0.18549764156341553
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 867: train_loss=0.18486399948596954
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 868: train_loss=0.18548955023288727
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 869: train_loss=0.18422189354896545
INFO - 04/15/25 16:40:05 - 0:08:28 - Epoch 870: train_loss=0.18676291406154633
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 871: train_loss=0.18638372421264648
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 872: train_loss=0.18378779292106628
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 873: train_loss=0.18282470107078552
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 874: train_loss=0.18741026520729065
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 875: train_loss=0.1864965558052063
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 876: train_loss=0.18424420058727264
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 877: train_loss=0.18358750641345978
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 878: train_loss=0.18628035485744476
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 879: train_loss=0.18514160811901093
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 880: train_loss=0.185202494263649
INFO - 04/15/25 16:40:05 - 0:08:29 - Epoch 881: train_loss=0.18452629446983337
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 882: train_loss=0.1855122596025467
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 883: train_loss=0.184809610247612
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 884: train_loss=0.18511995673179626
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 885: train_loss=0.18416747450828552
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 886: train_loss=0.18592853844165802
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 887: train_loss=0.18544721603393555
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 888: train_loss=0.18395668268203735
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 889: train_loss=0.18294194340705872
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 890: train_loss=0.1870795488357544
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 891: train_loss=0.18676842749118805
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 892: train_loss=0.1822459101676941
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 893: train_loss=0.18112744390964508
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 894: train_loss=0.18872450292110443
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 895: train_loss=0.18843907117843628
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 896: train_loss=0.18039298057556152
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 897: train_loss=0.17944858968257904
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 898: train_loss=0.18840548396110535
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 899: train_loss=0.18670761585235596
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 900: train_loss=0.1839597076177597
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 901: train_loss=0.1844390481710434
INFO - 04/15/25 16:40:06 - 0:08:29 - Epoch 902: train_loss=0.18408195674419403
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 903: train_loss=0.1833008974790573
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 904: train_loss=0.1850338578224182
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 905: train_loss=0.183872789144516
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 906: train_loss=0.18543599545955658
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 907: train_loss=0.18477000296115875
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 908: train_loss=0.18454226851463318
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 909: train_loss=0.18389135599136353
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 910: train_loss=0.1847611665725708
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 911: train_loss=0.18408961594104767
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 912: train_loss=0.18416787683963776
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 913: train_loss=0.18312425911426544
INFO - 04/15/25 16:40:06 - 0:08:30 - Epoch 914: train_loss=0.18597091734409332
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 915: train_loss=0.18527355790138245
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 916: train_loss=0.18384617567062378
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 917: train_loss=0.18366217613220215
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 918: train_loss=0.18417368829250336
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 919: train_loss=0.18306636810302734
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 920: train_loss=0.18562555313110352
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 921: train_loss=0.18493998050689697
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 922: train_loss=0.18393895030021667
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 923: train_loss=0.18362393975257874
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 924: train_loss=0.18431077897548676
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 925: train_loss=0.1830991506576538
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 926: train_loss=0.18563014268875122
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 927: train_loss=0.1852710247039795
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 928: train_loss=0.18278825283050537
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 929: train_loss=0.1821616291999817
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 930: train_loss=0.1856057047843933
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 931: train_loss=0.1843564808368683
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 932: train_loss=0.1845022588968277
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 933: train_loss=0.1842438131570816
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 934: train_loss=0.18359410762786865
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 935: train_loss=0.18302248418331146
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 936: train_loss=0.18474897742271423
INFO - 04/15/25 16:40:07 - 0:08:30 - Epoch 937: train_loss=0.18356816470623016
INFO - 04/15/25 16:40:07 - 0:08:31 - Epoch 938: train_loss=0.18510814011096954
INFO - 04/15/25 16:40:07 - 0:08:31 - Epoch 939: train_loss=0.1850072145462036
INFO - 04/15/25 16:40:07 - 0:08:31 - Epoch 940: train_loss=0.18248388171195984
INFO - 04/15/25 16:40:07 - 0:08:31 - Epoch 941: train_loss=0.1828637272119522
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 942: train_loss=0.1844330132007599
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 943: train_loss=0.18225780129432678
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 944: train_loss=0.18687807023525238
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 945: train_loss=0.18666033446788788
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 946: train_loss=0.18199275434017181
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 947: train_loss=0.18721747398376465
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 948: train_loss=0.1825416535139084
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 949: train_loss=0.192210391163826
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 950: train_loss=0.1937713623046875
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 951: train_loss=0.18329866230487823
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 952: train_loss=0.19249926507472992
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 953: train_loss=0.19506311416625977
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 954: train_loss=0.18898427486419678
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 955: train_loss=0.18742381036281586
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 956: train_loss=0.19040164351463318
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 957: train_loss=0.18956059217453003
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 958: train_loss=0.18322022259235382
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 959: train_loss=0.19057117402553558
INFO - 04/15/25 16:40:08 - 0:08:31 - Epoch 960: train_loss=0.1885877549648285
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 961: train_loss=0.18529067933559418
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 962: train_loss=0.18608546257019043
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 963: train_loss=0.18429020047187805
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 964: train_loss=0.1832396239042282
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 965: train_loss=0.1862492859363556
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 966: train_loss=0.18369081616401672
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 967: train_loss=0.18723168969154358
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 968: train_loss=0.18464985489845276
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 969: train_loss=0.18783624470233917
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 970: train_loss=0.18638260662555695
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 971: train_loss=0.1865769773721695
INFO - 04/15/25 16:40:08 - 0:08:32 - Epoch 972: train_loss=0.1854085624217987
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 973: train_loss=0.18729367852210999
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 974: train_loss=0.18595565855503082
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 975: train_loss=0.18645240366458893
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 976: train_loss=0.18620534241199493
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 977: train_loss=0.18494988977909088
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 978: train_loss=0.18376018106937408
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 979: train_loss=0.1877991408109665
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 980: train_loss=0.1870623528957367
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 981: train_loss=0.18441078066825867
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 982: train_loss=0.1837894469499588
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 983: train_loss=0.18685968220233917
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 984: train_loss=0.18480554223060608
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 985: train_loss=0.1875717043876648
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 986: train_loss=0.1873573660850525
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 987: train_loss=0.18370771408081055
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 988: train_loss=0.18303269147872925
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 989: train_loss=0.18750856816768646
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 990: train_loss=0.186052605509758
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 991: train_loss=0.18549798429012299
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 992: train_loss=0.1852763444185257
INFO - 04/15/25 16:40:09 - 0:08:32 - Epoch 993: train_loss=0.184889018535614
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 994: train_loss=0.18359659612178802
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 995: train_loss=0.18760952353477478
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 996: train_loss=0.187246635556221
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 997: train_loss=0.18290671706199646
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 998: train_loss=0.18197917938232422
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 999: train_loss=0.1880529671907425
INFO - 04/15/25 16:40:09 - 0:08:33 - --------------------------Training Start-------------------------
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 1: train_loss=10.238077163696289
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 2: train_loss=10.36193561553955
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 3: train_loss=10.333157539367676
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 4: train_loss=10.275040626525879
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 5: train_loss=10.232151985168457
INFO - 04/15/25 16:40:09 - 0:08:33 - Epoch 6: train_loss=10.247383117675781
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 7: train_loss=10.244400978088379
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 8: train_loss=10.222872734069824
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 9: train_loss=10.194192886352539
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 10: train_loss=10.18293285369873
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 11: train_loss=10.180848121643066
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 12: train_loss=10.169840812683105
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 13: train_loss=10.153605461120605
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 14: train_loss=10.140909194946289
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 15: train_loss=10.13171100616455
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 16: train_loss=10.116491317749023
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 17: train_loss=10.09599781036377
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 18: train_loss=10.088005065917969
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 19: train_loss=10.085782051086426
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 20: train_loss=10.080260276794434
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 21: train_loss=10.078633308410645
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 22: train_loss=10.074373245239258
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 23: train_loss=10.075793266296387
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 24: train_loss=10.075004577636719
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 25: train_loss=10.072036743164062
INFO - 04/15/25 16:40:10 - 0:08:33 - Epoch 26: train_loss=10.072912216186523
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 27: train_loss=10.072061538696289
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 28: train_loss=10.070054054260254
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 29: train_loss=10.069851875305176
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 30: train_loss=10.072521209716797
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 31: train_loss=10.070988655090332
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 32: train_loss=10.06842041015625
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 33: train_loss=10.068575859069824
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 34: train_loss=10.06861686706543
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 35: train_loss=10.071449279785156
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 36: train_loss=10.06706714630127
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 37: train_loss=10.06928825378418
INFO - 04/15/25 16:40:10 - 0:08:34 - Epoch 38: train_loss=10.069716453552246
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 39: train_loss=10.065834999084473
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 40: train_loss=10.067503929138184
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 41: train_loss=10.070147514343262
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 42: train_loss=10.065760612487793
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 43: train_loss=10.07172966003418
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 44: train_loss=10.065814971923828
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 45: train_loss=10.072687149047852
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 46: train_loss=10.067301750183105
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 47: train_loss=10.074738502502441
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 48: train_loss=10.073994636535645
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 49: train_loss=10.067766189575195
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 50: train_loss=10.06998348236084
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 51: train_loss=10.068840980529785
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 52: train_loss=10.066635131835938
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 53: train_loss=10.069300651550293
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 54: train_loss=10.065648078918457
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 55: train_loss=10.070923805236816
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 56: train_loss=10.06805419921875
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 57: train_loss=10.070130348205566
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 58: train_loss=10.069841384887695
INFO - 04/15/25 16:40:11 - 0:08:34 - Epoch 59: train_loss=10.06640338897705
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 60: train_loss=10.066519737243652
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 61: train_loss=10.067435264587402
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 62: train_loss=10.065074920654297
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 63: train_loss=10.069498062133789
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 64: train_loss=10.068495750427246
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 65: train_loss=10.06601333618164
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 66: train_loss=10.06628704071045
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 67: train_loss=10.065682411193848
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 68: train_loss=10.065423965454102
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 69: train_loss=10.064704895019531
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 70: train_loss=10.065866470336914
INFO - 04/15/25 16:40:11 - 0:08:35 - Epoch 71: train_loss=10.063109397888184
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 72: train_loss=10.068574905395508
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 73: train_loss=10.066009521484375
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 74: train_loss=10.06823444366455
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 75: train_loss=10.068336486816406
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 76: train_loss=10.06425666809082
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 77: train_loss=10.06582260131836
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 78: train_loss=10.063531875610352
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 79: train_loss=10.067328453063965
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 80: train_loss=10.06454086303711
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 81: train_loss=10.069049835205078
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 82: train_loss=10.069616317749023
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 83: train_loss=10.062166213989258
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 84: train_loss=10.066990852355957
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 85: train_loss=10.064905166625977
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 86: train_loss=10.065688133239746
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 87: train_loss=10.065857887268066
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 88: train_loss=10.062987327575684
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 89: train_loss=10.064157485961914
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 90: train_loss=10.062394142150879
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 91: train_loss=10.061967849731445
INFO - 04/15/25 16:40:12 - 0:08:35 - Epoch 92: train_loss=10.066280364990234
INFO - 04/15/25 16:40:12 - 0:08:36 - Epoch 93: train_loss=10.063612937927246
INFO - 04/15/25 16:40:12 - 0:08:36 - Epoch 94: train_loss=10.068058967590332
INFO - 04/15/25 16:40:12 - 0:08:36 - Epoch 95: train_loss=10.068472862243652
INFO - 04/15/25 16:40:12 - 0:08:36 - Epoch 96: train_loss=10.062859535217285
INFO - 04/15/25 16:40:12 - 0:08:36 - Epoch 97: train_loss=10.065673828125
INFO - 04/15/25 16:40:12 - 0:08:36 - Epoch 98: train_loss=10.064690589904785
INFO - 04/15/25 16:40:12 - 0:08:36 - Epoch 99: train_loss=10.063766479492188
INFO - 04/15/25 16:40:12 - 0:08:36 - Epoch 100: train_loss=10.064595222473145
INFO - 04/15/25 16:40:12 - 0:08:36 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:12 - 0:08:36 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:40:13 - 0:08:36 - ------------------Saving best model-------------------
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 100: ACC: 0.0, NMI: 0.3217376042137705, F1: 0.0, ARI: 0.14898850685178114
INFO - 04/15/25 16:40:13 - 0:08:36 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 101: train_loss=10.06237506866455
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 102: train_loss=10.064412117004395
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 103: train_loss=10.061694145202637
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 104: train_loss=10.06220531463623
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 105: train_loss=10.065574645996094
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 106: train_loss=10.063569068908691
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 107: train_loss=10.066719055175781
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 108: train_loss=10.065823554992676
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 109: train_loss=10.065314292907715
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 110: train_loss=10.064994812011719
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 111: train_loss=10.064682960510254
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 112: train_loss=10.063854217529297
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 113: train_loss=10.065766334533691
INFO - 04/15/25 16:40:13 - 0:08:36 - Epoch 114: train_loss=10.064526557922363
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 115: train_loss=10.065627098083496
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 116: train_loss=10.065394401550293
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 117: train_loss=10.06357192993164
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 118: train_loss=10.062838554382324
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 119: train_loss=10.066015243530273
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 120: train_loss=10.064599990844727
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 121: train_loss=10.065424919128418
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 122: train_loss=10.065505027770996
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 123: train_loss=10.063017845153809
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 124: train_loss=10.062278747558594
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 125: train_loss=10.06613540649414
INFO - 04/15/25 16:40:13 - 0:08:37 - Epoch 126: train_loss=10.064922332763672
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 127: train_loss=10.064361572265625
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 128: train_loss=10.064156532287598
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 129: train_loss=10.064255714416504
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 130: train_loss=10.063582420349121
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 131: train_loss=10.064849853515625
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 132: train_loss=10.06403923034668
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 133: train_loss=10.064515113830566
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 134: train_loss=10.064279556274414
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 135: train_loss=10.063451766967773
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 136: train_loss=10.062422752380371
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 137: train_loss=10.065999031066895
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 138: train_loss=10.065811157226562
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 139: train_loss=10.061760902404785
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 140: train_loss=10.061963081359863
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 141: train_loss=10.065366744995117
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 142: train_loss=10.063395500183105
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 143: train_loss=10.065325736999512
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 144: train_loss=10.065149307250977
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 145: train_loss=10.062758445739746
INFO - 04/15/25 16:40:14 - 0:08:37 - Epoch 146: train_loss=10.066556930541992
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 147: train_loss=10.062679290771484
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 148: train_loss=10.069756507873535
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 149: train_loss=10.069482803344727
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 150: train_loss=10.065305709838867
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 151: train_loss=10.065553665161133
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 152: train_loss=10.067398071289062
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 153: train_loss=10.064986228942871
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 154: train_loss=10.067427635192871
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 155: train_loss=10.067999839782715
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 156: train_loss=10.063545227050781
INFO - 04/15/25 16:40:14 - 0:08:38 - Epoch 157: train_loss=10.06474781036377
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 158: train_loss=10.064990043640137
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 159: train_loss=10.061897277832031
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 160: train_loss=10.064833641052246
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 161: train_loss=10.0603666305542
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 162: train_loss=10.070584297180176
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 163: train_loss=10.069116592407227
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 164: train_loss=10.06325626373291
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 165: train_loss=10.063846588134766
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 166: train_loss=10.065567970275879
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 167: train_loss=10.06379508972168
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 168: train_loss=10.067204475402832
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 169: train_loss=10.06677532196045
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 170: train_loss=10.063960075378418
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 171: train_loss=10.063916206359863
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 172: train_loss=10.065171241760254
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 173: train_loss=10.064149856567383
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 174: train_loss=10.065444946289062
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 175: train_loss=10.06423282623291
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 176: train_loss=10.06605052947998
INFO - 04/15/25 16:40:15 - 0:08:38 - Epoch 177: train_loss=10.065735816955566
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 178: train_loss=10.063217163085938
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 179: train_loss=10.062660217285156
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 180: train_loss=10.065849304199219
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 181: train_loss=10.064617156982422
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 182: train_loss=10.064820289611816
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 183: train_loss=10.064634323120117
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 184: train_loss=10.063688278198242
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 185: train_loss=10.063055992126465
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 186: train_loss=10.064996719360352
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 187: train_loss=10.063979148864746
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 188: train_loss=10.064631462097168
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 189: train_loss=10.064340591430664
INFO - 04/15/25 16:40:15 - 0:08:39 - Epoch 190: train_loss=10.06341552734375
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 191: train_loss=10.062769889831543
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 192: train_loss=10.064858436584473
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 193: train_loss=10.06412410736084
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 194: train_loss=10.063584327697754
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 195: train_loss=10.063124656677246
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 196: train_loss=10.064098358154297
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 197: train_loss=10.063481330871582
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 198: train_loss=10.063653945922852
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 199: train_loss=10.063035011291504
INFO - 04/15/25 16:40:16 - 0:08:39 - Epoch 200: train_loss=10.064002990722656
INFO - 04/15/25 16:40:16 - 0:08:39 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:16 - 0:08:39 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:40:16 - 0:08:39 - ------------------Saving best model-------------------
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 200: ACC: 0.0, NMI: 0.3938990877601923, F1: 0.0, ARI: 0.20004371735216359
INFO - 04/15/25 16:40:18 - 0:08:41 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 201: train_loss=10.063468933105469
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 202: train_loss=10.063257217407227
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 203: train_loss=10.062636375427246
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 204: train_loss=10.064129829406738
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 205: train_loss=10.063801765441895
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 206: train_loss=10.062535285949707
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 207: train_loss=10.061783790588379
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 208: train_loss=10.064802169799805
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 209: train_loss=10.064577102661133
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 210: train_loss=10.061429977416992
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 211: train_loss=10.061447143554688
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 212: train_loss=10.065303802490234
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 213: train_loss=10.063939094543457
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 214: train_loss=10.06370735168457
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 215: train_loss=10.065315246582031
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 216: train_loss=10.061623573303223
INFO - 04/15/25 16:40:18 - 0:08:41 - Epoch 217: train_loss=10.071446418762207
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 218: train_loss=10.072370529174805
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 219: train_loss=10.0641450881958
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 220: train_loss=10.068975448608398
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 221: train_loss=10.069748878479004
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 222: train_loss=10.068242073059082
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 223: train_loss=10.064270973205566
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 224: train_loss=10.069981575012207
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 225: train_loss=10.071471214294434
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 226: train_loss=10.061888694763184
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 227: train_loss=10.072827339172363
INFO - 04/15/25 16:40:18 - 0:08:42 - Epoch 228: train_loss=10.076417922973633
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 229: train_loss=10.071365356445312
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 230: train_loss=10.067659378051758
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 231: train_loss=10.067801475524902
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 232: train_loss=10.070854187011719
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 233: train_loss=10.069583892822266
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 234: train_loss=10.061773300170898
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 235: train_loss=10.06984806060791
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 236: train_loss=10.069742202758789
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 237: train_loss=10.063125610351562
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 238: train_loss=10.067585945129395
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 239: train_loss=10.068033218383789
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 240: train_loss=10.064225196838379
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 241: train_loss=10.066055297851562
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 242: train_loss=10.065668106079102
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 243: train_loss=10.064759254455566
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 244: train_loss=10.064189910888672
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 245: train_loss=10.064735412597656
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 246: train_loss=10.06269359588623
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 247: train_loss=10.065196990966797
INFO - 04/15/25 16:40:19 - 0:08:42 - Epoch 248: train_loss=10.062636375427246
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 249: train_loss=10.065863609313965
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 250: train_loss=10.065803527832031
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 251: train_loss=10.06270694732666
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 252: train_loss=10.065689086914062
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 253: train_loss=10.06452465057373
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 254: train_loss=10.064048767089844
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 255: train_loss=10.063883781433105
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 256: train_loss=10.063604354858398
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 257: train_loss=10.063462257385254
INFO - 04/15/25 16:40:19 - 0:08:43 - Epoch 258: train_loss=10.062474250793457
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 259: train_loss=10.064237594604492
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 260: train_loss=10.062219619750977
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 261: train_loss=10.064262390136719
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 262: train_loss=10.063041687011719
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 263: train_loss=10.062759399414062
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 264: train_loss=10.064581871032715
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 265: train_loss=10.062400817871094
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 266: train_loss=10.066627502441406
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 267: train_loss=10.066116333007812
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 268: train_loss=10.06407642364502
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 269: train_loss=10.063687324523926
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 270: train_loss=10.065286636352539
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 271: train_loss=10.061925888061523
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 272: train_loss=10.068480491638184
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 273: train_loss=10.068290710449219
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 274: train_loss=10.061396598815918
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 275: train_loss=10.065733909606934
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 276: train_loss=10.06322956085205
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 277: train_loss=10.066088676452637
INFO - 04/15/25 16:40:20 - 0:08:43 - Epoch 278: train_loss=10.066031455993652
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 279: train_loss=10.062952995300293
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 280: train_loss=10.063252449035645
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 281: train_loss=10.064181327819824
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 282: train_loss=10.06175708770752
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 283: train_loss=10.067340850830078
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 284: train_loss=10.06692886352539
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 285: train_loss=10.061619758605957
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 286: train_loss=10.062823295593262
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 287: train_loss=10.062477111816406
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 288: train_loss=10.061298370361328
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 289: train_loss=10.064020156860352
INFO - 04/15/25 16:40:20 - 0:08:44 - Epoch 290: train_loss=10.061559677124023
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 291: train_loss=10.065869331359863
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 292: train_loss=10.065131187438965
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 293: train_loss=10.063011169433594
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 294: train_loss=10.064032554626465
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 295: train_loss=10.062644958496094
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 296: train_loss=10.064618110656738
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 297: train_loss=10.063918113708496
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 298: train_loss=10.063249588012695
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 299: train_loss=10.06316089630127
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 300: train_loss=10.062620162963867
INFO - 04/15/25 16:40:21 - 0:08:44 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:21 - 0:08:44 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:40:21 - 0:08:44 - Epoch 300: ACC: 0.0, NMI: 0.35928495972718205, F1: 0.0, ARI: 0.16970757722751226
INFO - 04/15/25 16:40:21 - 0:08:44 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 301: train_loss=10.063313484191895
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 302: train_loss=10.061006546020508
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 303: train_loss=10.06580924987793
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 304: train_loss=10.064034461975098
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 305: train_loss=10.064788818359375
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 306: train_loss=10.06418228149414
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 307: train_loss=10.064493179321289
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 308: train_loss=10.063108444213867
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 309: train_loss=10.06552505493164
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 310: train_loss=10.063372611999512
INFO - 04/15/25 16:40:21 - 0:08:45 - Epoch 311: train_loss=10.066492080688477
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 312: train_loss=10.066437721252441
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 313: train_loss=10.062053680419922
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 314: train_loss=10.06361198425293
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 315: train_loss=10.061850547790527
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 316: train_loss=10.064188003540039
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 317: train_loss=10.061285972595215
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 318: train_loss=10.068647384643555
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 319: train_loss=10.069108009338379
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 320: train_loss=10.059004783630371
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 321: train_loss=10.07079029083252
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 322: train_loss=10.072237968444824
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 323: train_loss=10.064746856689453
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 324: train_loss=10.068314552307129
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 325: train_loss=10.07182788848877
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 326: train_loss=10.067558288574219
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 327: train_loss=10.065099716186523
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 328: train_loss=10.067248344421387
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 329: train_loss=10.067159652709961
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 330: train_loss=10.063687324523926
INFO - 04/15/25 16:40:22 - 0:08:45 - Epoch 331: train_loss=10.066547393798828
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 332: train_loss=10.067740440368652
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 333: train_loss=10.060998916625977
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 334: train_loss=10.06907844543457
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 335: train_loss=10.070940971374512
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 336: train_loss=10.064519882202148
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 337: train_loss=10.067172050476074
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 338: train_loss=10.069846153259277
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 339: train_loss=10.066191673278809
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 340: train_loss=10.064826011657715
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 341: train_loss=10.066540718078613
INFO - 04/15/25 16:40:22 - 0:08:46 - Epoch 342: train_loss=10.065645217895508
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 343: train_loss=10.06304931640625
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 344: train_loss=10.065834999084473
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 345: train_loss=10.06440258026123
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 346: train_loss=10.063523292541504
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 347: train_loss=10.064303398132324
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 348: train_loss=10.060990333557129
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 349: train_loss=10.063043594360352
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 350: train_loss=10.060673713684082
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 351: train_loss=10.06571102142334
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 352: train_loss=10.06546688079834
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 353: train_loss=10.061098098754883
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 354: train_loss=10.063525199890137
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 355: train_loss=10.06194019317627
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 356: train_loss=10.063643455505371
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 357: train_loss=10.063008308410645
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 358: train_loss=10.062442779541016
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 359: train_loss=10.062870979309082
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 360: train_loss=10.061071395874023
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 361: train_loss=10.06430721282959
INFO - 04/15/25 16:40:23 - 0:08:46 - Epoch 362: train_loss=10.0621337890625
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 363: train_loss=10.065455436706543
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 364: train_loss=10.065790176391602
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 365: train_loss=10.061861991882324
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 366: train_loss=10.064234733581543
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 367: train_loss=10.063416481018066
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 368: train_loss=10.062643051147461
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 369: train_loss=10.062973022460938
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 370: train_loss=10.06181526184082
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 371: train_loss=10.063667297363281
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 372: train_loss=10.062103271484375
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 373: train_loss=10.064433097839355
INFO - 04/15/25 16:40:23 - 0:08:47 - Epoch 374: train_loss=10.064022064208984
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 375: train_loss=10.062700271606445
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 376: train_loss=10.063067436218262
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 377: train_loss=10.06240463256836
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 378: train_loss=10.063400268554688
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 379: train_loss=10.062458038330078
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 380: train_loss=10.063420295715332
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 381: train_loss=10.06281852722168
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 382: train_loss=10.062950134277344
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 383: train_loss=10.062514305114746
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 384: train_loss=10.062379837036133
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 385: train_loss=10.06254768371582
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 386: train_loss=10.061677932739258
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 387: train_loss=10.063472747802734
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 388: train_loss=10.062490463256836
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 389: train_loss=10.06314754486084
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 390: train_loss=10.062840461730957
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 391: train_loss=10.062479019165039
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 392: train_loss=10.062390327453613
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 393: train_loss=10.06173038482666
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 394: train_loss=10.06346321105957
INFO - 04/15/25 16:40:24 - 0:08:47 - Epoch 395: train_loss=10.061898231506348
INFO - 04/15/25 16:40:24 - 0:08:48 - Epoch 396: train_loss=10.064592361450195
INFO - 04/15/25 16:40:24 - 0:08:48 - Epoch 397: train_loss=10.064278602600098
INFO - 04/15/25 16:40:24 - 0:08:48 - Epoch 398: train_loss=10.062472343444824
INFO - 04/15/25 16:40:24 - 0:08:48 - Epoch 399: train_loss=10.062629699707031
INFO - 04/15/25 16:40:24 - 0:08:48 - Epoch 400: train_loss=10.062873840332031
INFO - 04/15/25 16:40:24 - 0:08:48 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:24 - 0:08:48 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 400: ACC: 0.0, NMI: 0.35041672313618083, F1: 0.0, ARI: 0.16625257975976035
INFO - 04/15/25 16:40:25 - 0:08:48 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 401: train_loss=10.06131649017334
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 402: train_loss=10.06239128112793
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 403: train_loss=10.061211585998535
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 404: train_loss=10.06102180480957
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 405: train_loss=10.062586784362793
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 406: train_loss=10.060519218444824
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 407: train_loss=10.064866065979004
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 408: train_loss=10.064254760742188
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 409: train_loss=10.061240196228027
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 410: train_loss=10.06180191040039
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 411: train_loss=10.061990737915039
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 412: train_loss=10.060770034790039
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 413: train_loss=10.06317138671875
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 414: train_loss=10.061650276184082
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 415: train_loss=10.063509941101074
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 416: train_loss=10.063070297241211
INFO - 04/15/25 16:40:25 - 0:08:48 - Epoch 417: train_loss=10.062138557434082
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 418: train_loss=10.062492370605469
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 419: train_loss=10.061627388000488
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 420: train_loss=10.062886238098145
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 421: train_loss=10.062032699584961
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 422: train_loss=10.06252670288086
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 423: train_loss=10.062304496765137
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 424: train_loss=10.061263084411621
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 425: train_loss=10.062911033630371
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 426: train_loss=10.059489250183105
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 427: train_loss=10.067220687866211
INFO - 04/15/25 16:40:25 - 0:08:49 - Epoch 428: train_loss=10.066588401794434
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 429: train_loss=10.060834884643555
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 430: train_loss=10.063092231750488
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 431: train_loss=10.061498641967773
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 432: train_loss=10.063273429870605
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 433: train_loss=10.062320709228516
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 434: train_loss=10.063239097595215
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 435: train_loss=10.063105583190918
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 436: train_loss=10.06174373626709
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 437: train_loss=10.061538696289062
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 438: train_loss=10.062353134155273
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 439: train_loss=10.061439514160156
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 440: train_loss=10.063106536865234
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 441: train_loss=10.062705993652344
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 442: train_loss=10.061664581298828
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 443: train_loss=10.061251640319824
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 444: train_loss=10.063045501708984
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 445: train_loss=10.06269359588623
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 446: train_loss=10.06156063079834
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 447: train_loss=10.061450004577637
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 448: train_loss=10.062111854553223
INFO - 04/15/25 16:40:26 - 0:08:49 - Epoch 449: train_loss=10.061288833618164
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 450: train_loss=10.063055038452148
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 451: train_loss=10.06286907196045
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 452: train_loss=10.061080932617188
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 453: train_loss=10.06152057647705
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 454: train_loss=10.06118392944336
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 455: train_loss=10.060249328613281
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 456: train_loss=10.062901496887207
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 457: train_loss=10.061939239501953
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 458: train_loss=10.061786651611328
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 459: train_loss=10.062141418457031
INFO - 04/15/25 16:40:26 - 0:08:50 - Epoch 460: train_loss=10.060505867004395
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 461: train_loss=10.06100082397461
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 462: train_loss=10.062668800354004
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 463: train_loss=10.061009407043457
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 464: train_loss=10.062931060791016
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 465: train_loss=10.062411308288574
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 466: train_loss=10.061588287353516
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 467: train_loss=10.063343048095703
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 468: train_loss=10.060688018798828
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 469: train_loss=10.067151069641113
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 470: train_loss=10.06799602508545
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 471: train_loss=10.061843872070312
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 472: train_loss=10.06640911102295
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 473: train_loss=10.067461967468262
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 474: train_loss=10.065009117126465
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 475: train_loss=10.06339168548584
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 476: train_loss=10.065132141113281
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 477: train_loss=10.066107749938965
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 478: train_loss=10.059765815734863
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 479: train_loss=10.070594787597656
INFO - 04/15/25 16:40:27 - 0:08:50 - Epoch 480: train_loss=10.073845863342285
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 481: train_loss=10.06894588470459
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 482: train_loss=10.0650053024292
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 483: train_loss=10.066793441772461
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 484: train_loss=10.066534042358398
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 485: train_loss=10.067198753356934
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 486: train_loss=10.064221382141113
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 487: train_loss=10.064742088317871
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 488: train_loss=10.066705703735352
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 489: train_loss=10.062287330627441
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 490: train_loss=10.065812110900879
INFO - 04/15/25 16:40:27 - 0:08:51 - Epoch 491: train_loss=10.066295623779297
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 492: train_loss=10.06397819519043
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 493: train_loss=10.06379508972168
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 494: train_loss=10.063705444335938
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 495: train_loss=10.064218521118164
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 496: train_loss=10.061249732971191
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 497: train_loss=10.06371021270752
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 498: train_loss=10.061897277832031
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 499: train_loss=10.063471794128418
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 500: train_loss=10.062186241149902
INFO - 04/15/25 16:40:28 - 0:08:51 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:28 - 0:08:51 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 500: ACC: 0.0, NMI: 0.3667112324459572, F1: 0.0, ARI: 0.1715362730149611
INFO - 04/15/25 16:40:28 - 0:08:51 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 501: train_loss=10.062804222106934
INFO - 04/15/25 16:40:28 - 0:08:51 - Epoch 502: train_loss=10.061952590942383
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 503: train_loss=10.062381744384766
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 504: train_loss=10.06123161315918
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 505: train_loss=10.061530113220215
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 506: train_loss=10.062420845031738
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 507: train_loss=10.061339378356934
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 508: train_loss=10.060590744018555
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 509: train_loss=10.06246566772461
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 510: train_loss=10.060468673706055
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 511: train_loss=10.063577651977539
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 512: train_loss=10.061857223510742
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 513: train_loss=10.063483238220215
INFO - 04/15/25 16:40:28 - 0:08:52 - Epoch 514: train_loss=10.062122344970703
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 515: train_loss=10.063112258911133
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 516: train_loss=10.062466621398926
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 517: train_loss=10.062360763549805
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 518: train_loss=10.061938285827637
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 519: train_loss=10.062646865844727
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 520: train_loss=10.061619758605957
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 521: train_loss=10.062609672546387
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 522: train_loss=10.062159538269043
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 523: train_loss=10.06223201751709
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 524: train_loss=10.061628341674805
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 525: train_loss=10.063043594360352
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 526: train_loss=10.06233024597168
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 527: train_loss=10.062459945678711
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 528: train_loss=10.062363624572754
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 529: train_loss=10.06184196472168
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 530: train_loss=10.06121826171875
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 531: train_loss=10.063238143920898
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 532: train_loss=10.062586784362793
INFO - 04/15/25 16:40:29 - 0:08:52 - Epoch 533: train_loss=10.061967849731445
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 534: train_loss=10.062423706054688
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 535: train_loss=10.06100082397461
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 536: train_loss=10.059667587280273
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 537: train_loss=10.065418243408203
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 538: train_loss=10.065024375915527
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 539: train_loss=10.061197280883789
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 540: train_loss=10.065696716308594
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 541: train_loss=10.064801216125488
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 542: train_loss=10.062342643737793
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 543: train_loss=10.063148498535156
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 544: train_loss=10.061860084533691
INFO - 04/15/25 16:40:29 - 0:08:53 - Epoch 545: train_loss=10.064857482910156
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 546: train_loss=10.064391136169434
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 547: train_loss=10.06253719329834
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 548: train_loss=10.062663078308105
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 549: train_loss=10.062167167663574
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 550: train_loss=10.063602447509766
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 551: train_loss=10.062286376953125
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 552: train_loss=10.064390182495117
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 553: train_loss=10.0637845993042
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 554: train_loss=10.063620567321777
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 555: train_loss=10.062368392944336
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 556: train_loss=10.063753128051758
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 557: train_loss=10.060771942138672
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 558: train_loss=10.062617301940918
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 559: train_loss=10.062103271484375
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 560: train_loss=10.059988021850586
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 561: train_loss=10.065909385681152
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 562: train_loss=10.064120292663574
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 563: train_loss=10.064199447631836
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 564: train_loss=10.064242362976074
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 565: train_loss=10.063133239746094
INFO - 04/15/25 16:40:30 - 0:08:53 - Epoch 566: train_loss=10.06280517578125
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 567: train_loss=10.063396453857422
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 568: train_loss=10.06222915649414
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 569: train_loss=10.06342601776123
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 570: train_loss=10.062448501586914
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 571: train_loss=10.063223838806152
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 572: train_loss=10.062630653381348
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 573: train_loss=10.06291389465332
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 574: train_loss=10.06212329864502
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 575: train_loss=10.063780784606934
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 576: train_loss=10.062820434570312
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 577: train_loss=10.063773155212402
INFO - 04/15/25 16:40:30 - 0:08:54 - Epoch 578: train_loss=10.063209533691406
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 579: train_loss=10.063166618347168
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 580: train_loss=10.062752723693848
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 581: train_loss=10.063182830810547
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 582: train_loss=10.062568664550781
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 583: train_loss=10.0634183883667
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 584: train_loss=10.063048362731934
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 585: train_loss=10.062457084655762
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 586: train_loss=10.061908721923828
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 587: train_loss=10.063549041748047
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 588: train_loss=10.062902450561523
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 589: train_loss=10.06283950805664
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 590: train_loss=10.062273979187012
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 591: train_loss=10.063382148742676
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 592: train_loss=10.062989234924316
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 593: train_loss=10.062414169311523
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 594: train_loss=10.061829566955566
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 595: train_loss=10.063637733459473
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 596: train_loss=10.06310749053955
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 597: train_loss=10.062228202819824
INFO - 04/15/25 16:40:31 - 0:08:54 - Epoch 598: train_loss=10.061729431152344
INFO - 04/15/25 16:40:31 - 0:08:55 - Epoch 599: train_loss=10.063507080078125
INFO - 04/15/25 16:40:31 - 0:08:55 - Epoch 600: train_loss=10.062982559204102
INFO - 04/15/25 16:40:31 - 0:08:55 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:32 - 0:08:55 - Decoding cost time:  0.571 s
INFO - 04/15/25 16:40:32 - 0:08:55 - Epoch 600: ACC: 0.0, NMI: 0.07518454903527365, F1: 0.0, ARI: 0.005376910608387544
INFO - 04/15/25 16:40:32 - 0:08:55 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:32 - 0:08:55 - Epoch 601: train_loss=10.062320709228516
INFO - 04/15/25 16:40:32 - 0:08:55 - Epoch 602: train_loss=10.061774253845215
INFO - 04/15/25 16:40:32 - 0:08:55 - Epoch 603: train_loss=10.063453674316406
INFO - 04/15/25 16:40:32 - 0:08:55 - Epoch 604: train_loss=10.0630464553833
INFO - 04/15/25 16:40:32 - 0:08:55 - Epoch 605: train_loss=10.061973571777344
INFO - 04/15/25 16:40:32 - 0:08:55 - Epoch 606: train_loss=10.061473846435547
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 607: train_loss=10.063511848449707
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 608: train_loss=10.062990188598633
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 609: train_loss=10.062040328979492
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 610: train_loss=10.061572074890137
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 611: train_loss=10.063339233398438
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 612: train_loss=10.062854766845703
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 613: train_loss=10.061969757080078
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 614: train_loss=10.061511993408203
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 615: train_loss=10.06321907043457
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 616: train_loss=10.062637329101562
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 617: train_loss=10.06224536895752
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 618: train_loss=10.061782836914062
INFO - 04/15/25 16:40:32 - 0:08:56 - Epoch 619: train_loss=10.062897682189941
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 620: train_loss=10.062451362609863
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 621: train_loss=10.062200546264648
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 622: train_loss=10.06164264678955
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 623: train_loss=10.06299877166748
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 624: train_loss=10.062603950500488
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 625: train_loss=10.061972618103027
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 626: train_loss=10.061511039733887
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 627: train_loss=10.062944412231445
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 628: train_loss=10.062400817871094
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 629: train_loss=10.062131881713867
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 630: train_loss=10.061676979064941
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 631: train_loss=10.062691688537598
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 632: train_loss=10.062195777893066
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 633: train_loss=10.062240600585938
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 634: train_loss=10.061750411987305
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 635: train_loss=10.062679290771484
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 636: train_loss=10.062299728393555
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 637: train_loss=10.061925888061523
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 638: train_loss=10.06131362915039
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 639: train_loss=10.062901496887207
INFO - 04/15/25 16:40:33 - 0:08:56 - Epoch 640: train_loss=10.062505722045898
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 641: train_loss=10.06169319152832
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 642: train_loss=10.061195373535156
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 643: train_loss=10.062905311584473
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 644: train_loss=10.062439918518066
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 645: train_loss=10.06169319152832
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 646: train_loss=10.061281204223633
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 647: train_loss=10.062737464904785
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 648: train_loss=10.062158584594727
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 649: train_loss=10.061901092529297
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 650: train_loss=10.061445236206055
INFO - 04/15/25 16:40:33 - 0:08:57 - Epoch 651: train_loss=10.062411308288574
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 652: train_loss=10.0619478225708
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 653: train_loss=10.061984062194824
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 654: train_loss=10.061488151550293
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 655: train_loss=10.062295913696289
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 656: train_loss=10.061793327331543
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 657: train_loss=10.061925888061523
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 658: train_loss=10.061452865600586
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 659: train_loss=10.062151908874512
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 660: train_loss=10.061701774597168
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 661: train_loss=10.06196117401123
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 662: train_loss=10.06157112121582
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 663: train_loss=10.0619478225708
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 664: train_loss=10.06148624420166
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 665: train_loss=10.061951637268066
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 666: train_loss=10.061525344848633
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 667: train_loss=10.061836242675781
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 668: train_loss=10.06147575378418
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 669: train_loss=10.061768531799316
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 670: train_loss=10.061349868774414
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 671: train_loss=10.061872482299805
INFO - 04/15/25 16:40:34 - 0:08:57 - Epoch 672: train_loss=10.06154727935791
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 673: train_loss=10.061593055725098
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 674: train_loss=10.061222076416016
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 675: train_loss=10.061911582946777
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 676: train_loss=10.06155014038086
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 677: train_loss=10.061480522155762
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 678: train_loss=10.061055183410645
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 679: train_loss=10.061915397644043
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 680: train_loss=10.061502456665039
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 681: train_loss=10.061439514160156
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 682: train_loss=10.061040878295898
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 683: train_loss=10.06170654296875
INFO - 04/15/25 16:40:34 - 0:08:58 - Epoch 684: train_loss=10.061373710632324
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 685: train_loss=10.06132698059082
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 686: train_loss=10.060944557189941
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 687: train_loss=10.061751365661621
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 688: train_loss=10.061406135559082
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 689: train_loss=10.061161041259766
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 690: train_loss=10.060791969299316
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 691: train_loss=10.061751365661621
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 692: train_loss=10.061461448669434
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 693: train_loss=10.060995101928711
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 694: train_loss=10.060576438903809
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 695: train_loss=10.06177043914795
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 696: train_loss=10.061456680297852
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 697: train_loss=10.061001777648926
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 698: train_loss=10.060648918151855
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 699: train_loss=10.061630249023438
INFO - 04/15/25 16:40:35 - 0:08:58 - Epoch 700: train_loss=10.061224937438965
INFO - 04/15/25 16:40:35 - 0:08:58 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:35 - 0:08:58 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:40:35 - 0:08:59 - Epoch 700: ACC: 0.0, NMI: 0.37119436352246243, F1: 0.0, ARI: 0.17259926657905422
INFO - 04/15/25 16:40:35 - 0:08:59 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:35 - 0:08:59 - Epoch 701: train_loss=10.061026573181152
INFO - 04/15/25 16:40:35 - 0:08:59 - Epoch 702: train_loss=10.060707092285156
INFO - 04/15/25 16:40:35 - 0:08:59 - Epoch 703: train_loss=10.061506271362305
INFO - 04/15/25 16:40:35 - 0:08:59 - Epoch 704: train_loss=10.061277389526367
INFO - 04/15/25 16:40:35 - 0:08:59 - Epoch 705: train_loss=10.060898780822754
INFO - 04/15/25 16:40:35 - 0:08:59 - Epoch 706: train_loss=10.060508728027344
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 707: train_loss=10.061710357666016
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 708: train_loss=10.061393737792969
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 709: train_loss=10.060552597045898
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 710: train_loss=10.060096740722656
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 711: train_loss=10.062003135681152
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 712: train_loss=10.061750411987305
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 713: train_loss=10.060152053833008
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 714: train_loss=10.060370445251465
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 715: train_loss=10.06229019165039
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 716: train_loss=10.061202049255371
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 717: train_loss=10.061554908752441
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 718: train_loss=10.062378883361816
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 719: train_loss=10.059823036193848
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 720: train_loss=10.067283630371094
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 721: train_loss=10.068194389343262
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 722: train_loss=10.062149047851562
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 723: train_loss=10.066248893737793
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 724: train_loss=10.067153930664062
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 725: train_loss=10.06495475769043
INFO - 04/15/25 16:40:36 - 0:08:59 - Epoch 726: train_loss=10.064217567443848
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 727: train_loss=10.063063621520996
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 728: train_loss=10.065319061279297
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 729: train_loss=10.062139511108398
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 730: train_loss=10.06518840789795
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 731: train_loss=10.066943168640137
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 732: train_loss=10.061891555786133
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 733: train_loss=10.065492630004883
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 734: train_loss=10.06678581237793
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 735: train_loss=10.064112663269043
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 736: train_loss=10.0638427734375
INFO - 04/15/25 16:40:36 - 0:09:00 - Epoch 737: train_loss=10.063261985778809
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 738: train_loss=10.064785957336426
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 739: train_loss=10.06253719329834
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 740: train_loss=10.063603401184082
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 741: train_loss=10.064881324768066
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 742: train_loss=10.060647010803223
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 743: train_loss=10.064129829406738
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 744: train_loss=10.064833641052246
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 745: train_loss=10.062490463256836
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 746: train_loss=10.061909675598145
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 747: train_loss=10.063542366027832
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 748: train_loss=10.062349319458008
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 749: train_loss=10.061563491821289
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 750: train_loss=10.062183380126953
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 751: train_loss=10.060922622680664
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 752: train_loss=10.061380386352539
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 753: train_loss=10.061293601989746
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 754: train_loss=10.060491561889648
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 755: train_loss=10.062225341796875
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 756: train_loss=10.061182975769043
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 757: train_loss=10.061819076538086
INFO - 04/15/25 16:40:37 - 0:09:00 - Epoch 758: train_loss=10.061330795288086
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 759: train_loss=10.061114311218262
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 760: train_loss=10.061746597290039
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 761: train_loss=10.060879707336426
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 762: train_loss=10.0623779296875
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 763: train_loss=10.060924530029297
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 764: train_loss=10.062889099121094
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 765: train_loss=10.060715675354004
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 766: train_loss=10.064471244812012
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 767: train_loss=10.063922882080078
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 768: train_loss=10.061836242675781
INFO - 04/15/25 16:40:37 - 0:09:01 - Epoch 769: train_loss=10.062141418457031
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 770: train_loss=10.062250137329102
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 771: train_loss=10.061234474182129
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 772: train_loss=10.063456535339355
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 773: train_loss=10.06315803527832
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 774: train_loss=10.061319351196289
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 775: train_loss=10.061944007873535
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 776: train_loss=10.061712265014648
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 777: train_loss=10.060515403747559
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 778: train_loss=10.0625581741333
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 779: train_loss=10.060506820678711
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 780: train_loss=10.064496994018555
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 781: train_loss=10.064173698425293
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 782: train_loss=10.060715675354004
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 783: train_loss=10.06227970123291
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 784: train_loss=10.061396598815918
INFO - 04/15/25 16:40:38 - 0:09:01 - Epoch 785: train_loss=10.06051254272461
INFO - 04/15/25 16:40:38 - 0:09:02 - Epoch 786: train_loss=10.062482833862305
INFO - 04/15/25 16:40:38 - 0:09:02 - Epoch 787: train_loss=10.060445785522461
INFO - 04/15/25 16:40:38 - 0:09:02 - Epoch 788: train_loss=10.064838409423828
INFO - 04/15/25 16:40:38 - 0:09:02 - Epoch 789: train_loss=10.06542682647705
INFO - 04/15/25 16:40:38 - 0:09:02 - Epoch 790: train_loss=10.05908489227295
INFO - 04/15/25 16:40:38 - 0:09:02 - Epoch 791: train_loss=10.067933082580566
INFO - 04/15/25 16:40:38 - 0:09:02 - Epoch 792: train_loss=10.069225311279297
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 793: train_loss=10.064398765563965
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 794: train_loss=10.064695358276367
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 795: train_loss=10.06657886505127
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 796: train_loss=10.064295768737793
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 797: train_loss=10.063911437988281
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 798: train_loss=10.064909934997559
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 799: train_loss=10.061864852905273
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 800: train_loss=10.063517570495605
INFO - 04/15/25 16:40:39 - 0:09:02 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:39 - 0:09:02 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 800: ACC: 0.0, NMI: 0.37716686921178294, F1: 0.0, ARI: 0.1777275828956916
INFO - 04/15/25 16:40:39 - 0:09:02 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 801: train_loss=10.06350040435791
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 802: train_loss=10.061931610107422
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 803: train_loss=10.062405586242676
INFO - 04/15/25 16:40:39 - 0:09:02 - Epoch 804: train_loss=10.062540054321289
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 805: train_loss=10.061220169067383
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 806: train_loss=10.062999725341797
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 807: train_loss=10.062222480773926
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 808: train_loss=10.061590194702148
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 809: train_loss=10.062518119812012
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 810: train_loss=10.06018352508545
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 811: train_loss=10.060940742492676
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 812: train_loss=10.062503814697266
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 813: train_loss=10.060881614685059
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 814: train_loss=10.060528755187988
INFO - 04/15/25 16:40:39 - 0:09:03 - Epoch 815: train_loss=10.060615539550781
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 816: train_loss=10.063197135925293
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 817: train_loss=10.06029224395752
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 818: train_loss=10.061166763305664
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 819: train_loss=10.062761306762695
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 820: train_loss=10.059951782226562
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 821: train_loss=10.061287879943848
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 822: train_loss=10.059904098510742
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 823: train_loss=10.063576698303223
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 824: train_loss=10.059505462646484
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 825: train_loss=10.064935684204102
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 826: train_loss=10.063847541809082
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 827: train_loss=10.062334060668945
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 828: train_loss=10.06402587890625
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 829: train_loss=10.06247615814209
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 830: train_loss=10.064414978027344
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 831: train_loss=10.064610481262207
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 832: train_loss=10.062195777893066
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 833: train_loss=10.062833786010742
INFO - 04/15/25 16:40:40 - 0:09:03 - Epoch 834: train_loss=10.062337875366211
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 835: train_loss=10.062814712524414
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 836: train_loss=10.062275886535645
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 837: train_loss=10.06263256072998
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 838: train_loss=10.062548637390137
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 839: train_loss=10.061074256896973
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 840: train_loss=10.06515121459961
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 841: train_loss=10.063268661499023
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 842: train_loss=10.06494140625
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 843: train_loss=10.065113067626953
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 844: train_loss=10.06270694732666
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 845: train_loss=10.062166213989258
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 846: train_loss=10.064583778381348
INFO - 04/15/25 16:40:40 - 0:09:04 - Epoch 847: train_loss=10.062212944030762
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 848: train_loss=10.066858291625977
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 849: train_loss=10.067370414733887
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 850: train_loss=10.059314727783203
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 851: train_loss=10.061776161193848
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 852: train_loss=10.060371398925781
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 853: train_loss=10.064022064208984
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 854: train_loss=10.062789916992188
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 855: train_loss=10.063079833984375
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 856: train_loss=10.062671661376953
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 857: train_loss=10.062931060791016
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 858: train_loss=10.061376571655273
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 859: train_loss=10.062352180480957
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 860: train_loss=10.061500549316406
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 861: train_loss=10.060185432434082
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 862: train_loss=10.064650535583496
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 863: train_loss=10.06321907043457
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 864: train_loss=10.063641548156738
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 865: train_loss=10.062844276428223
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 866: train_loss=10.064118385314941
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 867: train_loss=10.062226295471191
INFO - 04/15/25 16:40:41 - 0:09:04 - Epoch 868: train_loss=10.065604209899902
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 869: train_loss=10.065794944763184
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 870: train_loss=10.060103416442871
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 871: train_loss=10.061023712158203
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 872: train_loss=10.061687469482422
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 873: train_loss=10.060747146606445
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 874: train_loss=10.061053276062012
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 875: train_loss=10.06043815612793
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 876: train_loss=10.062739372253418
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 877: train_loss=10.060308456420898
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 878: train_loss=10.065387725830078
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 879: train_loss=10.065237045288086
INFO - 04/15/25 16:40:41 - 0:09:05 - Epoch 880: train_loss=10.061576843261719
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 881: train_loss=10.063277244567871
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 882: train_loss=10.063426971435547
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 883: train_loss=10.060660362243652
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 884: train_loss=10.064205169677734
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 885: train_loss=10.063003540039062
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 886: train_loss=10.062734603881836
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 887: train_loss=10.062474250793457
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 888: train_loss=10.062990188598633
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 889: train_loss=10.060982704162598
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 890: train_loss=10.064197540283203
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 891: train_loss=10.061823844909668
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 892: train_loss=10.065654754638672
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 893: train_loss=10.066020965576172
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 894: train_loss=10.059865951538086
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 895: train_loss=10.06297779083252
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 896: train_loss=10.060569763183594
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 897: train_loss=10.064592361450195
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 898: train_loss=10.064291954040527
INFO - 04/15/25 16:40:42 - 0:09:05 - Epoch 899: train_loss=10.060717582702637
INFO - 04/15/25 16:40:42 - 0:09:06 - Epoch 900: train_loss=10.061336517333984
INFO - 04/15/25 16:40:42 - 0:09:06 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:42 - 0:09:06 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:40:42 - 0:09:06 - Epoch 900: ACC: 0.0, NMI: 0.3589484729248375, F1: 0.0, ARI: 0.16928223712099977
INFO - 04/15/25 16:40:42 - 0:09:06 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:42 - 0:09:06 - Epoch 901: train_loss=10.06179141998291
INFO - 04/15/25 16:40:42 - 0:09:06 - Epoch 902: train_loss=10.05988597869873
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 903: train_loss=10.064155578613281
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 904: train_loss=10.062908172607422
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 905: train_loss=10.062334060668945
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 906: train_loss=10.062371253967285
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 907: train_loss=10.061943054199219
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 908: train_loss=10.061583518981934
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 909: train_loss=10.062350273132324
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 910: train_loss=10.061484336853027
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 911: train_loss=10.062955856323242
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 912: train_loss=10.062712669372559
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 913: train_loss=10.061247825622559
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 914: train_loss=10.060951232910156
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 915: train_loss=10.062541007995605
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 916: train_loss=10.061455726623535
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 917: train_loss=10.062984466552734
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 918: train_loss=10.062623977661133
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 919: train_loss=10.061676979064941
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 920: train_loss=10.061575889587402
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 921: train_loss=10.061766624450684
INFO - 04/15/25 16:40:43 - 0:09:06 - Epoch 922: train_loss=10.060962677001953
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 923: train_loss=10.062867164611816
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 924: train_loss=10.06230354309082
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 925: train_loss=10.061633110046387
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 926: train_loss=10.06130313873291
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 927: train_loss=10.062335968017578
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 928: train_loss=10.061779022216797
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 929: train_loss=10.061884880065918
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 930: train_loss=10.061436653137207
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 931: train_loss=10.062191009521484
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 932: train_loss=10.061867713928223
INFO - 04/15/25 16:40:43 - 0:09:07 - Epoch 933: train_loss=10.061588287353516
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 934: train_loss=10.06097412109375
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 935: train_loss=10.062772750854492
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 936: train_loss=10.062504768371582
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 937: train_loss=10.060842514038086
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 938: train_loss=10.060477256774902
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 939: train_loss=10.062663078308105
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 940: train_loss=10.06197452545166
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 941: train_loss=10.061750411987305
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 942: train_loss=10.061408996582031
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 943: train_loss=10.061847686767578
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 944: train_loss=10.061491012573242
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 945: train_loss=10.061712265014648
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 946: train_loss=10.06104564666748
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 947: train_loss=10.062433242797852
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 948: train_loss=10.062268257141113
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 949: train_loss=10.060680389404297
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 950: train_loss=10.060166358947754
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 951: train_loss=10.063051223754883
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 952: train_loss=10.06253433227539
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 953: train_loss=10.060864448547363
INFO - 04/15/25 16:40:44 - 0:09:07 - Epoch 954: train_loss=10.061112403869629
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 955: train_loss=10.0610933303833
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 956: train_loss=10.059815406799316
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 957: train_loss=10.064260482788086
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 958: train_loss=10.064379692077637
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 959: train_loss=10.059678077697754
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 960: train_loss=10.065592765808105
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 961: train_loss=10.065255165100098
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 962: train_loss=10.060286521911621
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 963: train_loss=10.063641548156738
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 964: train_loss=10.06285285949707
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 965: train_loss=10.060977935791016
INFO - 04/15/25 16:40:44 - 0:09:08 - Epoch 966: train_loss=10.06108570098877
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 967: train_loss=10.06131649017334
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 968: train_loss=10.060890197753906
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 969: train_loss=10.061585426330566
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 970: train_loss=10.060657501220703
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 971: train_loss=10.062698364257812
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 972: train_loss=10.062570571899414
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 973: train_loss=10.060354232788086
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 974: train_loss=10.062313079833984
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 975: train_loss=10.058615684509277
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 976: train_loss=10.064577102661133
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 977: train_loss=10.061580657958984
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 978: train_loss=10.065802574157715
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 979: train_loss=10.066372871398926
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 980: train_loss=10.06136417388916
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 981: train_loss=10.0643892288208
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 982: train_loss=10.064225196838379
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 983: train_loss=10.062310218811035
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 984: train_loss=10.063151359558105
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 985: train_loss=10.06338119506836
INFO - 04/15/25 16:40:45 - 0:09:08 - Epoch 986: train_loss=10.060704231262207
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 987: train_loss=10.062678337097168
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 988: train_loss=10.06119155883789
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 989: train_loss=10.063004493713379
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 990: train_loss=10.063053131103516
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 991: train_loss=10.060144424438477
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 992: train_loss=10.06063175201416
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 993: train_loss=10.061039924621582
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 994: train_loss=10.060511589050293
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 995: train_loss=10.060179710388184
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 996: train_loss=10.059476852416992
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 997: train_loss=10.063069343566895
INFO - 04/15/25 16:40:45 - 0:09:09 - Epoch 998: train_loss=10.061298370361328
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 999: train_loss=10.06389045715332
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1000: train_loss=10.064325332641602
INFO - 04/15/25 16:40:46 - 0:09:09 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:46 - 0:09:09 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1000: ACC: 0.0, NMI: 0.3581919755199314, F1: 0.0, ARI: 0.1690469357305756
INFO - 04/15/25 16:40:46 - 0:09:09 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1001: train_loss=10.059855461120605
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1002: train_loss=10.06376838684082
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1003: train_loss=10.062875747680664
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1004: train_loss=10.061640739440918
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1005: train_loss=10.062185287475586
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1006: train_loss=10.061471939086914
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1007: train_loss=10.062198638916016
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1008: train_loss=10.061713218688965
INFO - 04/15/25 16:40:46 - 0:09:09 - Epoch 1009: train_loss=10.061684608459473
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1010: train_loss=10.061651229858398
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1011: train_loss=10.060561180114746
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1012: train_loss=10.063057899475098
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1013: train_loss=10.060540199279785
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1014: train_loss=10.066089630126953
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1015: train_loss=10.066776275634766
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1016: train_loss=10.061113357543945
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1017: train_loss=10.065011024475098
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1018: train_loss=10.065384864807129
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1019: train_loss=10.063410758972168
INFO - 04/15/25 16:40:46 - 0:09:10 - Epoch 1020: train_loss=10.06204891204834
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1021: train_loss=10.064449310302734
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1022: train_loss=10.063118934631348
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1023: train_loss=10.062276840209961
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1024: train_loss=10.062691688537598
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1025: train_loss=10.061507225036621
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1026: train_loss=10.061506271362305
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1027: train_loss=10.061324119567871
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1028: train_loss=10.061809539794922
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1029: train_loss=10.060772895812988
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1030: train_loss=10.063006401062012
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1031: train_loss=10.062289237976074
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1032: train_loss=10.062217712402344
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1033: train_loss=10.061325073242188
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1034: train_loss=10.062373161315918
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1035: train_loss=10.060229301452637
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1036: train_loss=10.061383247375488
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1037: train_loss=10.061081886291504
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1038: train_loss=10.059484481811523
INFO - 04/15/25 16:40:47 - 0:09:10 - Epoch 1039: train_loss=10.063677787780762
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1040: train_loss=10.062798500061035
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1041: train_loss=10.06165599822998
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1042: train_loss=10.061799049377441
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1043: train_loss=10.061664581298828
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1044: train_loss=10.061002731323242
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1045: train_loss=10.062118530273438
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1046: train_loss=10.060578346252441
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1047: train_loss=10.063608169555664
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1048: train_loss=10.063044548034668
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1049: train_loss=10.061327934265137
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1050: train_loss=10.061546325683594
INFO - 04/15/25 16:40:47 - 0:09:11 - Epoch 1051: train_loss=10.061553955078125
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1052: train_loss=10.060928344726562
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1053: train_loss=10.061814308166504
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1054: train_loss=10.060826301574707
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1055: train_loss=10.06239128112793
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1056: train_loss=10.061614990234375
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1057: train_loss=10.061903953552246
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1058: train_loss=10.061593055725098
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1059: train_loss=10.061527252197266
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1060: train_loss=10.061225891113281
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1061: train_loss=10.061415672302246
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1062: train_loss=10.060890197753906
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1063: train_loss=10.061627388000488
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1064: train_loss=10.06080150604248
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1065: train_loss=10.062370300292969
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1066: train_loss=10.061819076538086
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1067: train_loss=10.061320304870605
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1068: train_loss=10.061180114746094
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1069: train_loss=10.0614652633667
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1070: train_loss=10.060654640197754
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1071: train_loss=10.0626220703125
INFO - 04/15/25 16:40:48 - 0:09:11 - Epoch 1072: train_loss=10.062666893005371
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1073: train_loss=10.059913635253906
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1074: train_loss=10.06009578704834
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1075: train_loss=10.062206268310547
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1076: train_loss=10.060735702514648
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1077: train_loss=10.063132286071777
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1078: train_loss=10.06313705444336
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1079: train_loss=10.06045913696289
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1080: train_loss=10.063274383544922
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1081: train_loss=10.061333656311035
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1082: train_loss=10.064504623413086
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1083: train_loss=10.064934730529785
INFO - 04/15/25 16:40:48 - 0:09:12 - Epoch 1084: train_loss=10.060465812683105
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1085: train_loss=10.063444137573242
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1086: train_loss=10.063431739807129
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1087: train_loss=10.0594482421875
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1088: train_loss=10.063924789428711
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1089: train_loss=10.060786247253418
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1090: train_loss=10.066935539245605
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1091: train_loss=10.068373680114746
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1092: train_loss=10.06083869934082
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1093: train_loss=10.070106506347656
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1094: train_loss=10.074389457702637
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1095: train_loss=10.06948471069336
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1096: train_loss=10.061595916748047
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1097: train_loss=10.066798210144043
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1098: train_loss=10.066877365112305
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1099: train_loss=10.063814163208008
INFO - 04/15/25 16:40:49 - 0:09:12 - Epoch 1100: train_loss=10.063743591308594
INFO - 04/15/25 16:40:49 - 0:09:12 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:49 - 0:09:12 - Decoding cost time:  0.133 s
INFO - 04/15/25 16:40:49 - 0:09:13 - Epoch 1100: ACC: 0.0, NMI: 0.3581919755199314, F1: 0.0, ARI: 0.1690469357305756
INFO - 04/15/25 16:40:49 - 0:09:13 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:49 - 0:09:13 - Epoch 1101: train_loss=10.064776420593262
INFO - 04/15/25 16:40:49 - 0:09:13 - Epoch 1102: train_loss=10.064237594604492
INFO - 04/15/25 16:40:49 - 0:09:13 - Epoch 1103: train_loss=10.061264038085938
INFO - 04/15/25 16:40:49 - 0:09:13 - Epoch 1104: train_loss=10.064416885375977
INFO - 04/15/25 16:40:49 - 0:09:13 - Epoch 1105: train_loss=10.0630521774292
INFO - 04/15/25 16:40:49 - 0:09:13 - Epoch 1106: train_loss=10.062483787536621
INFO - 04/15/25 16:40:49 - 0:09:13 - Epoch 1107: train_loss=10.062691688537598
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1108: train_loss=10.061545372009277
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1109: train_loss=10.061159133911133
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1110: train_loss=10.062548637390137
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1111: train_loss=10.060857772827148
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1112: train_loss=10.064245223999023
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1113: train_loss=10.064038276672363
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1114: train_loss=10.060659408569336
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1115: train_loss=10.061514854431152
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1116: train_loss=10.061372756958008
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1117: train_loss=10.060287475585938
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1118: train_loss=10.062169075012207
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1119: train_loss=10.060355186462402
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1120: train_loss=10.063490867614746
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1121: train_loss=10.063041687011719
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1122: train_loss=10.060994148254395
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1123: train_loss=10.061898231506348
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1124: train_loss=10.060637474060059
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1125: train_loss=10.062614440917969
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1126: train_loss=10.061605453491211
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1127: train_loss=10.062445640563965
INFO - 04/15/25 16:40:50 - 0:09:13 - Epoch 1128: train_loss=10.062376976013184
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1129: train_loss=10.060956954956055
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1130: train_loss=10.060667991638184
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1131: train_loss=10.061814308166504
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1132: train_loss=10.060831069946289
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1133: train_loss=10.062446594238281
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1134: train_loss=10.062094688415527
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1135: train_loss=10.060977935791016
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1136: train_loss=10.061410903930664
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1137: train_loss=10.060322761535645
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1138: train_loss=10.062098503112793
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1139: train_loss=10.05980110168457
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1140: train_loss=10.065275192260742
INFO - 04/15/25 16:40:50 - 0:09:14 - Epoch 1141: train_loss=10.06560230255127
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1142: train_loss=10.058512687683105
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1143: train_loss=10.065940856933594
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1144: train_loss=10.065853118896484
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1145: train_loss=10.059615135192871
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1146: train_loss=10.066251754760742
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1147: train_loss=10.06816577911377
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1148: train_loss=10.063708305358887
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1149: train_loss=10.06296443939209
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1150: train_loss=10.065633773803711
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1151: train_loss=10.062849998474121
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1152: train_loss=10.062363624572754
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1153: train_loss=10.064071655273438
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1154: train_loss=10.060895919799805
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1155: train_loss=10.064042091369629
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1156: train_loss=10.065290451049805
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1157: train_loss=10.060524940490723
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1158: train_loss=10.065463066101074
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1159: train_loss=10.06807804107666
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1160: train_loss=10.06435775756836
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1161: train_loss=10.061548233032227
INFO - 04/15/25 16:40:51 - 0:09:14 - Epoch 1162: train_loss=10.064191818237305
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1163: train_loss=10.062873840332031
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1164: train_loss=10.060598373413086
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1165: train_loss=10.062610626220703
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1166: train_loss=10.059882164001465
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1167: train_loss=10.065014839172363
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1168: train_loss=10.065807342529297
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1169: train_loss=10.06007194519043
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1170: train_loss=10.066669464111328
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1171: train_loss=10.069494247436523
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1172: train_loss=10.065905570983887
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1173: train_loss=10.06155776977539
INFO - 04/15/25 16:40:51 - 0:09:15 - Epoch 1174: train_loss=10.064680099487305
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1175: train_loss=10.065217018127441
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1176: train_loss=10.062061309814453
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1177: train_loss=10.06326961517334
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1178: train_loss=10.064691543579102
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1179: train_loss=10.061718940734863
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1180: train_loss=10.062882423400879
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1181: train_loss=10.063932418823242
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1182: train_loss=10.061578750610352
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1183: train_loss=10.062244415283203
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1184: train_loss=10.063204765319824
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1185: train_loss=10.060430526733398
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1186: train_loss=10.063666343688965
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1187: train_loss=10.064498901367188
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1188: train_loss=10.060524940490723
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1189: train_loss=10.063492774963379
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1190: train_loss=10.064756393432617
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1191: train_loss=10.0621919631958
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1192: train_loss=10.061773300170898
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1193: train_loss=10.063192367553711
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1194: train_loss=10.061310768127441
INFO - 04/15/25 16:40:52 - 0:09:15 - Epoch 1195: train_loss=10.062127113342285
INFO - 04/15/25 16:40:52 - 0:09:16 - Epoch 1196: train_loss=10.062610626220703
INFO - 04/15/25 16:40:52 - 0:09:16 - Epoch 1197: train_loss=10.060417175292969
INFO - 04/15/25 16:40:52 - 0:09:16 - Epoch 1198: train_loss=10.061965942382812
INFO - 04/15/25 16:40:52 - 0:09:16 - Epoch 1199: train_loss=10.061548233032227
INFO - 04/15/25 16:40:52 - 0:09:16 - Epoch 1200: train_loss=10.060686111450195
INFO - 04/15/25 16:40:52 - 0:09:16 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:52 - 0:09:16 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1200: ACC: 0.0, NMI: 0.31107602616381846, F1: 0.0, ARI: 0.15150175322171516
INFO - 04/15/25 16:40:53 - 0:09:16 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1201: train_loss=10.06092643737793
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1202: train_loss=10.06033706665039
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1203: train_loss=10.060654640197754
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1204: train_loss=10.05945873260498
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1205: train_loss=10.061319351196289
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1206: train_loss=10.059906959533691
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1207: train_loss=10.061467170715332
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1208: train_loss=10.060723304748535
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1209: train_loss=10.061058044433594
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1210: train_loss=10.060436248779297
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1211: train_loss=10.061033248901367
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1212: train_loss=10.060369491577148
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1213: train_loss=10.060689926147461
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1214: train_loss=10.060726165771484
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1215: train_loss=10.059717178344727
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1216: train_loss=10.061905860900879
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1217: train_loss=10.060409545898438
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1218: train_loss=10.062747955322266
INFO - 04/15/25 16:40:53 - 0:09:16 - Epoch 1219: train_loss=10.062743186950684
INFO - 04/15/25 16:40:53 - 0:09:17 - Epoch 1220: train_loss=10.06008529663086
INFO - 04/15/25 16:40:53 - 0:09:17 - Epoch 1221: train_loss=10.061029434204102
INFO - 04/15/25 16:40:53 - 0:09:17 - Epoch 1222: train_loss=10.060164451599121
INFO - 04/15/25 16:40:53 - 0:09:17 - Epoch 1223: train_loss=10.0601806640625
INFO - 04/15/25 16:40:53 - 0:09:17 - Epoch 1224: train_loss=10.060697555541992
INFO - 04/15/25 16:40:53 - 0:09:17 - Epoch 1225: train_loss=10.05981731414795
INFO - 04/15/25 16:40:55 - 0:09:17 - Epoch 1226: train_loss=10.0595064163208
INFO - 04/15/25 16:40:55 - 0:09:18 - Epoch 1227: train_loss=10.061952590942383
INFO - 04/15/25 16:40:55 - 0:09:18 - Epoch 1228: train_loss=10.060372352600098
INFO - 04/15/25 16:40:55 - 0:09:18 - Epoch 1229: train_loss=10.062933921813965
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1230: train_loss=10.062655448913574
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1231: train_loss=10.06078052520752
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1232: train_loss=10.06181812286377
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1233: train_loss=10.059839248657227
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1234: train_loss=10.063786506652832
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1235: train_loss=10.062740325927734
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1236: train_loss=10.061797142028809
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1237: train_loss=10.061968803405762
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1238: train_loss=10.061419486999512
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1239: train_loss=10.061182022094727
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1240: train_loss=10.0612154006958
INFO - 04/15/25 16:40:55 - 0:09:19 - Epoch 1241: train_loss=10.060843467712402
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1242: train_loss=10.061360359191895
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1243: train_loss=10.060129165649414
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1244: train_loss=10.062444686889648
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1245: train_loss=10.061274528503418
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1246: train_loss=10.062206268310547
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1247: train_loss=10.061930656433105
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1248: train_loss=10.061299324035645
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1249: train_loss=10.061989784240723
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1250: train_loss=10.060523986816406
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1251: train_loss=10.064026832580566
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1252: train_loss=10.063748359680176
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1253: train_loss=10.06081485748291
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1254: train_loss=10.06147289276123
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1255: train_loss=10.061264038085938
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1256: train_loss=10.06092643737793
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1257: train_loss=10.060546875
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1258: train_loss=10.06141471862793
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1259: train_loss=10.060224533081055
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1260: train_loss=10.061105728149414
INFO - 04/15/25 16:40:56 - 0:09:19 - Epoch 1261: train_loss=10.060559272766113
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1262: train_loss=10.06041431427002
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1263: train_loss=10.060657501220703
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1264: train_loss=10.059558868408203
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1265: train_loss=10.062499046325684
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1266: train_loss=10.060150146484375
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1267: train_loss=10.064826011657715
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1268: train_loss=10.065038681030273
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1269: train_loss=10.0604829788208
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1270: train_loss=10.063706398010254
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1271: train_loss=10.064087867736816
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1272: train_loss=10.060131072998047
INFO - 04/15/25 16:40:56 - 0:09:20 - Epoch 1273: train_loss=10.065494537353516
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1274: train_loss=10.066707611083984
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1275: train_loss=10.060802459716797
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1276: train_loss=10.066853523254395
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1277: train_loss=10.070292472839355
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1278: train_loss=10.066905975341797
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1279: train_loss=10.061165809631348
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1280: train_loss=10.065813064575195
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1281: train_loss=10.067615509033203
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1282: train_loss=10.063027381896973
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1283: train_loss=10.063687324523926
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1284: train_loss=10.06678581237793
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1285: train_loss=10.063300132751465
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1286: train_loss=10.062238693237305
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1287: train_loss=10.064297676086426
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1288: train_loss=10.061399459838867
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1289: train_loss=10.063173294067383
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1290: train_loss=10.064661026000977
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1291: train_loss=10.059846878051758
INFO - 04/15/25 16:40:57 - 0:09:20 - Epoch 1292: train_loss=10.06640625
INFO - 04/15/25 16:40:57 - 0:09:21 - Epoch 1293: train_loss=10.069366455078125
INFO - 04/15/25 16:40:57 - 0:09:21 - Epoch 1294: train_loss=10.065887451171875
INFO - 04/15/25 16:40:57 - 0:09:21 - Epoch 1295: train_loss=10.06051254272461
INFO - 04/15/25 16:40:57 - 0:09:21 - Epoch 1296: train_loss=10.064929008483887
INFO - 04/15/25 16:40:57 - 0:09:21 - Epoch 1297: train_loss=10.065497398376465
INFO - 04/15/25 16:40:57 - 0:09:21 - Epoch 1298: train_loss=10.060110092163086
INFO - 04/15/25 16:40:57 - 0:09:21 - Epoch 1299: train_loss=10.066642761230469
INFO - 04/15/25 16:40:57 - 0:09:21 - Epoch 1300: train_loss=10.069507598876953
INFO - 04/15/25 16:40:57 - 0:09:21 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:40:58 - 0:09:21 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1300: ACC: 0.0, NMI: 0.3125870962758809, F1: 0.0, ARI: 0.1515347620981487
INFO - 04/15/25 16:40:58 - 0:09:21 - -------------------------------------------------------------------------
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1301: train_loss=10.066068649291992
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1302: train_loss=10.0619478225708
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1303: train_loss=10.064659118652344
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1304: train_loss=10.065984725952148
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1305: train_loss=10.062687873840332
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1306: train_loss=10.062969207763672
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1307: train_loss=10.064794540405273
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1308: train_loss=10.061766624450684
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1309: train_loss=10.06282901763916
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1310: train_loss=10.064050674438477
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1311: train_loss=10.061838150024414
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1312: train_loss=10.061716079711914
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1313: train_loss=10.063032150268555
INFO - 04/15/25 16:40:58 - 0:09:21 - Epoch 1314: train_loss=10.060178756713867
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1315: train_loss=10.063163757324219
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1316: train_loss=10.06418228149414
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1317: train_loss=10.0608549118042
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1318: train_loss=10.062992095947266
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1319: train_loss=10.064772605895996
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1320: train_loss=10.061604499816895
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1321: train_loss=10.062222480773926
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1322: train_loss=10.064014434814453
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1323: train_loss=10.061439514160156
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1324: train_loss=10.061805725097656
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1325: train_loss=10.063167572021484
INFO - 04/15/25 16:40:58 - 0:09:22 - Epoch 1326: train_loss=10.060623168945312
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1327: train_loss=10.062301635742188
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1328: train_loss=10.06356143951416
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1329: train_loss=10.060412406921387
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1330: train_loss=10.062811851501465
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1331: train_loss=10.064555168151855
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1332: train_loss=10.061849594116211
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1333: train_loss=10.06112289428711
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1334: train_loss=10.062872886657715
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1335: train_loss=10.060516357421875
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1336: train_loss=10.061847686767578
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1337: train_loss=10.063100814819336
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1338: train_loss=10.060258865356445
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1339: train_loss=10.062577247619629
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1340: train_loss=10.064167022705078
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1341: train_loss=10.061660766601562
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1342: train_loss=10.060831069946289
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1343: train_loss=10.062440872192383
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1344: train_loss=10.060054779052734
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1345: train_loss=10.062101364135742
INFO - 04/15/25 16:40:59 - 0:09:22 - Epoch 1346: train_loss=10.063314437866211
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1347: train_loss=10.060818672180176
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1348: train_loss=10.06173324584961
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1349: train_loss=10.06318473815918
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1350: train_loss=10.061073303222656
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1351: train_loss=10.061053276062012
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1352: train_loss=10.062216758728027
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1353: train_loss=10.060037612915039
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1354: train_loss=10.062106132507324
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1355: train_loss=10.063040733337402
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1356: train_loss=10.060954093933105
INFO - 04/15/25 16:40:59 - 0:09:23 - Epoch 1357: train_loss=10.061432838439941
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1358: train_loss=10.062341690063477
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1359: train_loss=10.060611724853516
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1360: train_loss=10.061444282531738
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1361: train_loss=10.06198501586914
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1362: train_loss=10.060279846191406
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1363: train_loss=10.062243461608887
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1364: train_loss=10.06223201751709
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1365: train_loss=10.061305046081543
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1366: train_loss=10.06115436553955
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1367: train_loss=10.06116771697998
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1368: train_loss=10.060664176940918
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1369: train_loss=10.061592102050781
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1370: train_loss=10.060259819030762
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1371: train_loss=10.06202507019043
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1372: train_loss=10.061806678771973
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1373: train_loss=10.061369895935059
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1374: train_loss=10.061331748962402
INFO - 04/15/25 16:41:00 - 0:09:23 - Epoch 1375: train_loss=10.061164855957031
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1376: train_loss=10.060921669006348
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1377: train_loss=10.061484336853027
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1378: train_loss=10.060734748840332
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1379: train_loss=10.061653137207031
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1380: train_loss=10.06108570098877
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1381: train_loss=10.060842514038086
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1382: train_loss=10.062063217163086
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1383: train_loss=10.061237335205078
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1384: train_loss=10.062226295471191
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1385: train_loss=10.060188293457031
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1386: train_loss=10.063081741333008
INFO - 04/15/25 16:41:00 - 0:09:24 - Epoch 1387: train_loss=10.059785842895508
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1388: train_loss=10.066540718078613
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1389: train_loss=10.067086219787598
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1390: train_loss=10.059788703918457
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1391: train_loss=10.068709373474121
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1392: train_loss=10.071319580078125
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1393: train_loss=10.066145896911621
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1394: train_loss=10.06386947631836
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1395: train_loss=10.066757202148438
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1396: train_loss=10.064477920532227
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1397: train_loss=10.06379222869873
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1398: train_loss=10.063973426818848
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1399: train_loss=10.063819885253906
INFO - 04/15/25 16:41:01 - 0:09:24 - Epoch 1400: train_loss=10.063162803649902
INFO - 04/15/25 16:41:01 - 0:09:24 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:01 - 0:09:24 - Decoding cost time:  0.124 s
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1400: ACC: 0.0, NMI: 0.08394768626046872, F1: 0.0, ARI: 0.006616342587768257
INFO - 04/15/25 16:41:01 - 0:09:25 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1401: train_loss=10.062154769897461
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1402: train_loss=10.063302040100098
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1403: train_loss=10.060134887695312
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1404: train_loss=10.064413070678711
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1405: train_loss=10.0632963180542
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1406: train_loss=10.061796188354492
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1407: train_loss=10.062179565429688
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1408: train_loss=10.061280250549316
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1409: train_loss=10.060436248779297
INFO - 04/15/25 16:41:01 - 0:09:25 - Epoch 1410: train_loss=10.063607215881348
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1411: train_loss=10.063178062438965
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1412: train_loss=10.060851097106934
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1413: train_loss=10.060664176940918
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1414: train_loss=10.062809944152832
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1415: train_loss=10.062000274658203
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1416: train_loss=10.062132835388184
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1417: train_loss=10.061890602111816
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1418: train_loss=10.061676025390625
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1419: train_loss=10.061100006103516
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1420: train_loss=10.062670707702637
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1421: train_loss=10.062226295471191
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1422: train_loss=10.061474800109863
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1423: train_loss=10.061126708984375
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1424: train_loss=10.062294006347656
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1425: train_loss=10.06177043914795
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1426: train_loss=10.061809539794922
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1427: train_loss=10.061490058898926
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1428: train_loss=10.061819076538086
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1429: train_loss=10.061403274536133
INFO - 04/15/25 16:41:02 - 0:09:25 - Epoch 1430: train_loss=10.062012672424316
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1431: train_loss=10.061653137207031
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1432: train_loss=10.061655044555664
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1433: train_loss=10.061193466186523
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1434: train_loss=10.062043190002441
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1435: train_loss=10.061635971069336
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1436: train_loss=10.061502456665039
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1437: train_loss=10.061117172241211
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1438: train_loss=10.062000274658203
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1439: train_loss=10.06161880493164
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1440: train_loss=10.061492919921875
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1441: train_loss=10.061166763305664
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1442: train_loss=10.061820030212402
INFO - 04/15/25 16:41:02 - 0:09:26 - Epoch 1443: train_loss=10.061333656311035
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1444: train_loss=10.061676979064941
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1445: train_loss=10.061395645141602
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1446: train_loss=10.061580657958984
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1447: train_loss=10.061120986938477
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1448: train_loss=10.061795234680176
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1449: train_loss=10.061480522155762
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1450: train_loss=10.061354637145996
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1451: train_loss=10.060935020446777
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1452: train_loss=10.061909675598145
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1453: train_loss=10.061591148376465
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1454: train_loss=10.061243057250977
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1455: train_loss=10.0608491897583
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1456: train_loss=10.061822891235352
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1457: train_loss=10.061437606811523
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1458: train_loss=10.061277389526367
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1459: train_loss=10.060858726501465
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1460: train_loss=10.061731338500977
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1461: train_loss=10.06123161315918
INFO - 04/15/25 16:41:03 - 0:09:26 - Epoch 1462: train_loss=10.061315536499023
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1463: train_loss=10.060958862304688
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1464: train_loss=10.061610221862793
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1465: train_loss=10.061293601989746
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1466: train_loss=10.061141014099121
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1467: train_loss=10.060823440551758
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1468: train_loss=10.061654090881348
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1469: train_loss=10.061298370361328
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1470: train_loss=10.06114673614502
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1471: train_loss=10.060827255249023
INFO - 04/15/25 16:41:03 - 0:09:27 - Epoch 1472: train_loss=10.061607360839844
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1473: train_loss=10.061317443847656
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1474: train_loss=10.060976028442383
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1475: train_loss=10.0606107711792
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1476: train_loss=10.061824798583984
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1477: train_loss=10.061468124389648
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1478: train_loss=10.060855865478516
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1479: train_loss=10.060466766357422
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1480: train_loss=10.061792373657227
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1481: train_loss=10.061474800109863
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1482: train_loss=10.060711860656738
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1483: train_loss=10.060381889343262
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1484: train_loss=10.061802864074707
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1485: train_loss=10.061448097229004
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1486: train_loss=10.060713768005371
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1487: train_loss=10.06036376953125
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1488: train_loss=10.061687469482422
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1489: train_loss=10.061352729797363
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1490: train_loss=10.060741424560547
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1491: train_loss=10.060406684875488
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1492: train_loss=10.061609268188477
INFO - 04/15/25 16:41:04 - 0:09:27 - Epoch 1493: train_loss=10.061315536499023
INFO - 04/15/25 16:41:04 - 0:09:28 - Epoch 1494: train_loss=10.06069564819336
INFO - 04/15/25 16:41:04 - 0:09:28 - Epoch 1495: train_loss=10.060320854187012
INFO - 04/15/25 16:41:04 - 0:09:28 - Epoch 1496: train_loss=10.06165599822998
INFO - 04/15/25 16:41:04 - 0:09:28 - Epoch 1497: train_loss=10.061281204223633
INFO - 04/15/25 16:41:04 - 0:09:28 - Epoch 1498: train_loss=10.060771942138672
INFO - 04/15/25 16:41:04 - 0:09:28 - Epoch 1499: train_loss=10.060439109802246
INFO - 04/15/25 16:41:04 - 0:09:28 - Epoch 1500: train_loss=10.061491012573242
INFO - 04/15/25 16:41:04 - 0:09:28 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:04 - 0:09:28 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1500: ACC: 0.0, NMI: 0.3099315637264345, F1: 0.0, ARI: 0.15089457689536434
INFO - 04/15/25 16:41:05 - 0:09:28 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1501: train_loss=10.061131477355957
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1502: train_loss=10.060790061950684
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1503: train_loss=10.06043815612793
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1504: train_loss=10.061508178710938
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1505: train_loss=10.061223983764648
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1506: train_loss=10.060593605041504
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1507: train_loss=10.06010913848877
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1508: train_loss=10.06174373626709
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1509: train_loss=10.061532974243164
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1510: train_loss=10.060230255126953
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1511: train_loss=10.059799194335938
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1512: train_loss=10.062091827392578
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1513: train_loss=10.061885833740234
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1514: train_loss=10.05975341796875
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1515: train_loss=10.059346199035645
INFO - 04/15/25 16:41:05 - 0:09:28 - Epoch 1516: train_loss=10.062372207641602
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1517: train_loss=10.062071800231934
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1518: train_loss=10.059686660766602
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1519: train_loss=10.059744834899902
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1520: train_loss=10.062240600585938
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1521: train_loss=10.061247825622559
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1522: train_loss=10.061455726623535
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1523: train_loss=10.061970710754395
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1524: train_loss=10.05974292755127
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1525: train_loss=10.065937995910645
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1526: train_loss=10.065951347351074
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1527: train_loss=10.059877395629883
INFO - 04/15/25 16:41:05 - 0:09:29 - Epoch 1528: train_loss=10.06358814239502
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1529: train_loss=10.063614845275879
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1530: train_loss=10.06080150604248
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1531: train_loss=10.064363479614258
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1532: train_loss=10.06518840789795
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1533: train_loss=10.059814453125
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1534: train_loss=10.065068244934082
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1535: train_loss=10.067397117614746
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1536: train_loss=10.06391716003418
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1537: train_loss=10.060705184936523
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1538: train_loss=10.063401222229004
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1539: train_loss=10.060325622558594
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1540: train_loss=10.064765930175781
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1541: train_loss=10.066335678100586
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1542: train_loss=10.062516212463379
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1543: train_loss=10.06270694732666
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1544: train_loss=10.064717292785645
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1545: train_loss=10.063167572021484
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1546: train_loss=10.06031322479248
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1547: train_loss=10.062125205993652
INFO - 04/15/25 16:41:06 - 0:09:29 - Epoch 1548: train_loss=10.058504104614258
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1549: train_loss=10.062456130981445
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1550: train_loss=10.060124397277832
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1551: train_loss=10.063814163208008
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1552: train_loss=10.06432056427002
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1553: train_loss=10.060126304626465
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1554: train_loss=10.06470012664795
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1555: train_loss=10.065888404846191
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1556: train_loss=10.0609130859375
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1557: train_loss=10.065020561218262
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1558: train_loss=10.067419052124023
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1559: train_loss=10.06429672241211
INFO - 04/15/25 16:41:06 - 0:09:30 - Epoch 1560: train_loss=10.061363220214844
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1561: train_loss=10.06420612335205
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1562: train_loss=10.063691139221191
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1563: train_loss=10.060251235961914
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1564: train_loss=10.06244945526123
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1565: train_loss=10.06151008605957
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1566: train_loss=10.061063766479492
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1567: train_loss=10.061819076538086
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1568: train_loss=10.059316635131836
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1569: train_loss=10.06348991394043
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1570: train_loss=10.062457084655762
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1571: train_loss=10.061674118041992
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1572: train_loss=10.061885833740234
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1573: train_loss=10.06149959564209
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1574: train_loss=10.061225891113281
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1575: train_loss=10.060835838317871
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1576: train_loss=10.062033653259277
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1577: train_loss=10.061211585998535
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1578: train_loss=10.062129020690918
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1579: train_loss=10.06128215789795
INFO - 04/15/25 16:41:07 - 0:09:30 - Epoch 1580: train_loss=10.061966896057129
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1581: train_loss=10.061090469360352
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1582: train_loss=10.061455726623535
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1583: train_loss=10.061206817626953
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1584: train_loss=10.06017017364502
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1585: train_loss=10.063547134399414
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1586: train_loss=10.06243896484375
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1587: train_loss=10.062324523925781
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1588: train_loss=10.06218147277832
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1589: train_loss=10.062095642089844
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1590: train_loss=10.061161994934082
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1591: train_loss=10.063196182250977
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1592: train_loss=10.062031745910645
INFO - 04/15/25 16:41:07 - 0:09:31 - Epoch 1593: train_loss=10.063007354736328
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1594: train_loss=10.062631607055664
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1595: train_loss=10.06181526184082
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1596: train_loss=10.061473846435547
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1597: train_loss=10.062567710876465
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1598: train_loss=10.0619535446167
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1599: train_loss=10.062176704406738
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1600: train_loss=10.061891555786133
INFO - 04/15/25 16:41:08 - 0:09:31 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:08 - 0:09:31 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1600: ACC: 0.0, NMI: 0.3526618764161857, F1: 0.0, ARI: 0.16745223741150347
INFO - 04/15/25 16:41:08 - 0:09:31 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1601: train_loss=10.06212043762207
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1602: train_loss=10.061396598815918
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1603: train_loss=10.062772750854492
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1604: train_loss=10.06229019165039
INFO - 04/15/25 16:41:08 - 0:09:31 - Epoch 1605: train_loss=10.061713218688965
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1606: train_loss=10.061288833618164
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1607: train_loss=10.062536239624023
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1608: train_loss=10.062057495117188
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1609: train_loss=10.061647415161133
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1610: train_loss=10.061232566833496
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1611: train_loss=10.06237506866455
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1612: train_loss=10.061931610107422
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1613: train_loss=10.06177043914795
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1614: train_loss=10.061288833618164
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1615: train_loss=10.062275886535645
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1616: train_loss=10.061826705932617
INFO - 04/15/25 16:41:08 - 0:09:32 - Epoch 1617: train_loss=10.06171703338623
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1618: train_loss=10.061227798461914
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1619: train_loss=10.062230110168457
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1620: train_loss=10.061844825744629
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1621: train_loss=10.0616455078125
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1622: train_loss=10.061217308044434
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1623: train_loss=10.062189102172852
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1624: train_loss=10.061758041381836
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1625: train_loss=10.061638832092285
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1626: train_loss=10.061216354370117
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1627: train_loss=10.061991691589355
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1628: train_loss=10.061617851257324
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1629: train_loss=10.061616897583008
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1630: train_loss=10.06120777130127
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1631: train_loss=10.0620756149292
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1632: train_loss=10.061674118041992
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1633: train_loss=10.061405181884766
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1634: train_loss=10.060941696166992
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1635: train_loss=10.062199592590332
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1636: train_loss=10.061841011047363
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1637: train_loss=10.06120777130127
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1638: train_loss=10.060701370239258
INFO - 04/15/25 16:41:09 - 0:09:32 - Epoch 1639: train_loss=10.062267303466797
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1640: train_loss=10.06181526184082
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1641: train_loss=10.06124210357666
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1642: train_loss=10.06085205078125
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1643: train_loss=10.062066078186035
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1644: train_loss=10.061494827270508
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1645: train_loss=10.061424255371094
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1646: train_loss=10.061098098754883
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1647: train_loss=10.061864852905273
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1648: train_loss=10.061394691467285
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1649: train_loss=10.061388969421387
INFO - 04/15/25 16:41:09 - 0:09:33 - Epoch 1650: train_loss=10.061005592346191
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1651: train_loss=10.061809539794922
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1652: train_loss=10.061452865600586
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1653: train_loss=10.06134033203125
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1654: train_loss=10.060851097106934
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1655: train_loss=10.061899185180664
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1656: train_loss=10.061534881591797
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1657: train_loss=10.061190605163574
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1658: train_loss=10.0608491897583
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1659: train_loss=10.061802864074707
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1660: train_loss=10.061383247375488
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1661: train_loss=10.061280250549316
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1662: train_loss=10.060873031616211
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1663: train_loss=10.061697959899902
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1664: train_loss=10.061372756958008
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1665: train_loss=10.061274528503418
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1666: train_loss=10.060873031616211
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1667: train_loss=10.06168270111084
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1668: train_loss=10.061274528503418
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1669: train_loss=10.061319351196289
INFO - 04/15/25 16:41:10 - 0:09:33 - Epoch 1670: train_loss=10.060921669006348
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1671: train_loss=10.061573028564453
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1672: train_loss=10.061205863952637
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1673: train_loss=10.061240196228027
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1674: train_loss=10.060774803161621
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1675: train_loss=10.061715126037598
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1676: train_loss=10.061406135559082
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1677: train_loss=10.061014175415039
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1678: train_loss=10.060589790344238
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1679: train_loss=10.061744689941406
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1680: train_loss=10.061356544494629
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1681: train_loss=10.061030387878418
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1682: train_loss=10.060724258422852
INFO - 04/15/25 16:41:10 - 0:09:34 - Epoch 1683: train_loss=10.061511993408203
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1684: train_loss=10.061084747314453
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1685: train_loss=10.061373710632324
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1686: train_loss=10.061164855957031
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1687: train_loss=10.061003684997559
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1688: train_loss=10.060653686523438
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1689: train_loss=10.061637878417969
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1690: train_loss=10.061185836791992
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1691: train_loss=10.061070442199707
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1692: train_loss=10.060821533203125
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1693: train_loss=10.061368942260742
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1694: train_loss=10.060929298400879
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1695: train_loss=10.061243057250977
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1696: train_loss=10.060918807983398
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1697: train_loss=10.061199188232422
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1698: train_loss=10.06081771850586
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1699: train_loss=10.061310768127441
INFO - 04/15/25 16:41:11 - 0:09:34 - Epoch 1700: train_loss=10.06101131439209
INFO - 04/15/25 16:41:11 - 0:09:34 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:11 - 0:09:34 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:41:11 - 0:09:35 - Epoch 1700: ACC: 0.0, NMI: 0.31239144276789577, F1: 0.0, ARI: 0.15070557452549171
INFO - 04/15/25 16:41:11 - 0:09:35 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:11 - 0:09:35 - Epoch 1701: train_loss=10.061128616333008
INFO - 04/15/25 16:41:11 - 0:09:35 - Epoch 1702: train_loss=10.060794830322266
INFO - 04/15/25 16:41:11 - 0:09:35 - Epoch 1703: train_loss=10.061246871948242
INFO - 04/15/25 16:41:11 - 0:09:35 - Epoch 1704: train_loss=10.060872077941895
INFO - 04/15/25 16:41:11 - 0:09:35 - Epoch 1705: train_loss=10.06123161315918
INFO - 04/15/25 16:41:11 - 0:09:35 - Epoch 1706: train_loss=10.0608549118042
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1707: train_loss=10.061128616333008
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1708: train_loss=10.060744285583496
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1709: train_loss=10.06118392944336
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1710: train_loss=10.060833930969238
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1711: train_loss=10.0612211227417
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1712: train_loss=10.060827255249023
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1713: train_loss=10.061040878295898
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1714: train_loss=10.060680389404297
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1715: train_loss=10.06125545501709
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1716: train_loss=10.06086254119873
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1717: train_loss=10.061017990112305
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1718: train_loss=10.060731887817383
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1719: train_loss=10.06119441986084
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1720: train_loss=10.060847282409668
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1721: train_loss=10.060996055603027
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1722: train_loss=10.060528755187988
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1723: train_loss=10.061274528503418
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1724: train_loss=10.060966491699219
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1725: train_loss=10.060833930969238
INFO - 04/15/25 16:41:12 - 0:09:35 - Epoch 1726: train_loss=10.060503005981445
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1727: train_loss=10.06119155883789
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1728: train_loss=10.060759544372559
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1729: train_loss=10.061027526855469
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1730: train_loss=10.060768127441406
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1731: train_loss=10.060752868652344
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1732: train_loss=10.06032657623291
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1733: train_loss=10.06132984161377
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1734: train_loss=10.061108589172363
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1735: train_loss=10.060491561889648
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1736: train_loss=10.060076713562012
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1737: train_loss=10.061495780944824
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1738: train_loss=10.061119079589844
INFO - 04/15/25 16:41:12 - 0:09:36 - Epoch 1739: train_loss=10.060371398925781
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1740: train_loss=10.059989929199219
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1741: train_loss=10.061517715454102
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1742: train_loss=10.06112289428711
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1743: train_loss=10.060259819030762
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1744: train_loss=10.06002426147461
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1745: train_loss=10.061384201049805
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1746: train_loss=10.060991287231445
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1747: train_loss=10.060310363769531
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1748: train_loss=10.060062408447266
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1749: train_loss=10.061206817626953
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1750: train_loss=10.060895919799805
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1751: train_loss=10.060416221618652
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1752: train_loss=10.06013298034668
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1753: train_loss=10.061116218566895
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1754: train_loss=10.060806274414062
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1755: train_loss=10.060495376586914
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1756: train_loss=10.060142517089844
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1757: train_loss=10.06110954284668
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1758: train_loss=10.060873985290527
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1759: train_loss=10.060235023498535
INFO - 04/15/25 16:41:13 - 0:09:36 - Epoch 1760: train_loss=10.059823036193848
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1761: train_loss=10.061285972595215
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1762: train_loss=10.061135292053223
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1763: train_loss=10.059877395629883
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1764: train_loss=10.059418678283691
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1765: train_loss=10.061798095703125
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1766: train_loss=10.061689376831055
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1767: train_loss=10.059181213378906
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1768: train_loss=10.058738708496094
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1769: train_loss=10.062301635742188
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1770: train_loss=10.06196117401123
INFO - 04/15/25 16:41:13 - 0:09:37 - Epoch 1771: train_loss=10.05925178527832
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1772: train_loss=10.061348915100098
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1773: train_loss=10.057750701904297
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1774: train_loss=10.060742378234863
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1775: train_loss=10.058917045593262
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1776: train_loss=10.062004089355469
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1777: train_loss=10.060362815856934
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1778: train_loss=10.062679290771484
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1779: train_loss=10.062774658203125
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1780: train_loss=10.06090259552002
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1781: train_loss=10.061339378356934
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1782: train_loss=10.061724662780762
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1783: train_loss=10.05924129486084
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1784: train_loss=10.062516212463379
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1785: train_loss=10.0601224899292
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1786: train_loss=10.064945220947266
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1787: train_loss=10.065732955932617
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1788: train_loss=10.059184074401855
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1789: train_loss=10.068918228149414
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1790: train_loss=10.072833061218262
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1791: train_loss=10.068995475769043
INFO - 04/15/25 16:41:14 - 0:09:37 - Epoch 1792: train_loss=10.060057640075684
INFO - 04/15/25 16:41:14 - 0:09:38 - Epoch 1793: train_loss=10.068275451660156
INFO - 04/15/25 16:41:14 - 0:09:38 - Epoch 1794: train_loss=10.071813583374023
INFO - 04/15/25 16:41:14 - 0:09:38 - Epoch 1795: train_loss=10.06873893737793
INFO - 04/15/25 16:41:14 - 0:09:38 - Epoch 1796: train_loss=10.062190055847168
INFO - 04/15/25 16:41:14 - 0:09:38 - Epoch 1797: train_loss=10.065996170043945
INFO - 04/15/25 16:41:14 - 0:09:38 - Epoch 1798: train_loss=10.068892478942871
INFO - 04/15/25 16:41:14 - 0:09:38 - Epoch 1799: train_loss=10.0673189163208
INFO - 04/15/25 16:41:14 - 0:09:38 - Epoch 1800: train_loss=10.062986373901367
INFO - 04/15/25 16:41:14 - 0:09:38 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:14 - 0:09:38 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1800: ACC: 0.0, NMI: 0.3630544258670238, F1: 0.0, ARI: 0.16895810720162094
INFO - 04/15/25 16:41:15 - 0:09:38 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1801: train_loss=10.063867568969727
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1802: train_loss=10.06647777557373
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1803: train_loss=10.064888000488281
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1804: train_loss=10.060811042785645
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1805: train_loss=10.064529418945312
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1806: train_loss=10.065587043762207
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1807: train_loss=10.061667442321777
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1808: train_loss=10.06348991394043
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1809: train_loss=10.06507682800293
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1810: train_loss=10.062444686889648
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1811: train_loss=10.062138557434082
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1812: train_loss=10.06332778930664
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1813: train_loss=10.062091827392578
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1814: train_loss=10.06124210357666
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1815: train_loss=10.062416076660156
INFO - 04/15/25 16:41:15 - 0:09:38 - Epoch 1816: train_loss=10.059874534606934
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1817: train_loss=10.063743591308594
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1818: train_loss=10.064253807067871
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1819: train_loss=10.059836387634277
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1820: train_loss=10.064066886901855
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1821: train_loss=10.065394401550293
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1822: train_loss=10.062440872192383
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1823: train_loss=10.061592102050781
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1824: train_loss=10.06351089477539
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1825: train_loss=10.062371253967285
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1826: train_loss=10.060047149658203
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1827: train_loss=10.061802864074707
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1828: train_loss=10.058932304382324
INFO - 04/15/25 16:41:15 - 0:09:39 - Epoch 1829: train_loss=10.064350128173828
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1830: train_loss=10.064486503601074
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1831: train_loss=10.060195922851562
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1832: train_loss=10.063189506530762
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1833: train_loss=10.06308364868164
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1834: train_loss=10.061662673950195
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1835: train_loss=10.061657905578613
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1836: train_loss=10.06184196472168
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1837: train_loss=10.060768127441406
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1838: train_loss=10.062174797058105
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1839: train_loss=10.061628341674805
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1840: train_loss=10.060685157775879
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1841: train_loss=10.0609712600708
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1842: train_loss=10.060452461242676
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1843: train_loss=10.060297012329102
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1844: train_loss=10.059946060180664
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1845: train_loss=10.061354637145996
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1846: train_loss=10.060015678405762
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1847: train_loss=10.062699317932129
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1848: train_loss=10.062881469726562
INFO - 04/15/25 16:41:16 - 0:09:39 - Epoch 1849: train_loss=10.060131072998047
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1850: train_loss=10.061263084411621
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1851: train_loss=10.061132431030273
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1852: train_loss=10.059950828552246
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1853: train_loss=10.061443328857422
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1854: train_loss=10.05965518951416
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1855: train_loss=10.062812805175781
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1856: train_loss=10.062094688415527
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1857: train_loss=10.06085205078125
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1858: train_loss=10.061036109924316
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1859: train_loss=10.060752868652344
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1860: train_loss=10.060312271118164
INFO - 04/15/25 16:41:16 - 0:09:40 - Epoch 1861: train_loss=10.061287879943848
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1862: train_loss=10.059991836547852
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1863: train_loss=10.06234073638916
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1864: train_loss=10.061543464660645
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1865: train_loss=10.06123161315918
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1866: train_loss=10.061103820800781
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1867: train_loss=10.061108589172363
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1868: train_loss=10.060567855834961
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1869: train_loss=10.061497688293457
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1870: train_loss=10.060566902160645
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1871: train_loss=10.061833381652832
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1872: train_loss=10.061352729797363
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1873: train_loss=10.061163902282715
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1874: train_loss=10.060829162597656
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1875: train_loss=10.061369895935059
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1876: train_loss=10.060690879821777
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1877: train_loss=10.06161117553711
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1878: train_loss=10.060901641845703
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1879: train_loss=10.061721801757812
INFO - 04/15/25 16:41:17 - 0:09:40 - Epoch 1880: train_loss=10.061349868774414
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1881: train_loss=10.060995101928711
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1882: train_loss=10.060662269592285
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1883: train_loss=10.061527252197266
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1884: train_loss=10.060918807983398
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1885: train_loss=10.061532020568848
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1886: train_loss=10.06122875213623
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1887: train_loss=10.06101131439209
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1888: train_loss=10.060654640197754
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1889: train_loss=10.061429977416992
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1890: train_loss=10.060972213745117
INFO - 04/15/25 16:41:17 - 0:09:41 - Epoch 1891: train_loss=10.06131649017334
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1892: train_loss=10.061087608337402
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1893: train_loss=10.06086254119873
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1894: train_loss=10.060348510742188
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1895: train_loss=10.06178092956543
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1896: train_loss=10.061556816101074
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1897: train_loss=10.060330390930176
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1898: train_loss=10.05987548828125
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1899: train_loss=10.062183380126953
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1900: train_loss=10.061884880065918
INFO - 04/15/25 16:41:18 - 0:09:41 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:18 - 0:09:41 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1900: ACC: 0.0, NMI: 0.355208909782215, F1: 0.0, ARI: 0.16709185917167604
INFO - 04/15/25 16:41:18 - 0:09:41 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:18 - 0:09:41 - Epoch 1901: train_loss=10.060009956359863
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1902: train_loss=10.05965805053711
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1903: train_loss=10.06204605102539
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1904: train_loss=10.061558723449707
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1905: train_loss=10.060453414916992
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1906: train_loss=10.060269355773926
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1907: train_loss=10.061199188232422
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1908: train_loss=10.060569763183594
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1909: train_loss=10.061320304870605
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1910: train_loss=10.061041831970215
INFO - 04/15/25 16:41:18 - 0:09:42 - Epoch 1911: train_loss=10.060757637023926
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1912: train_loss=10.060497283935547
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1913: train_loss=10.060966491699219
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1914: train_loss=10.060301780700684
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1915: train_loss=10.061326026916504
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1916: train_loss=10.06092357635498
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1917: train_loss=10.060800552368164
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1918: train_loss=10.06051254272461
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1919: train_loss=10.060900688171387
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1920: train_loss=10.060413360595703
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1921: train_loss=10.061031341552734
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1922: train_loss=10.060465812683105
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1923: train_loss=10.061108589172363
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1924: train_loss=10.060696601867676
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1925: train_loss=10.060790061950684
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1926: train_loss=10.060379028320312
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1927: train_loss=10.060871124267578
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1928: train_loss=10.060355186462402
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1929: train_loss=10.060934066772461
INFO - 04/15/25 16:41:19 - 0:09:42 - Epoch 1930: train_loss=10.060430526733398
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1931: train_loss=10.060866355895996
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1932: train_loss=10.06045913696289
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1933: train_loss=10.060709953308105
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1934: train_loss=10.060307502746582
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1935: train_loss=10.060503005981445
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1936: train_loss=10.0601806640625
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1937: train_loss=10.06030559539795
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1938: train_loss=10.06000804901123
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1939: train_loss=10.060135841369629
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1940: train_loss=10.059671401977539
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1941: train_loss=10.060885429382324
INFO - 04/15/25 16:41:19 - 0:09:43 - Epoch 1942: train_loss=10.060009956359863
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1943: train_loss=10.061408996582031
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1944: train_loss=10.061380386352539
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1945: train_loss=10.059391021728516
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1946: train_loss=10.059786796569824
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1947: train_loss=10.059703826904297
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1948: train_loss=10.059002876281738
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1949: train_loss=10.061760902404785
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1950: train_loss=10.06088638305664
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1951: train_loss=10.06092357635498
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1952: train_loss=10.06103229522705
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1953: train_loss=10.059927940368652
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1954: train_loss=10.06054401397705
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1955: train_loss=10.059637069702148
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1956: train_loss=10.060515403747559
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1957: train_loss=10.058939933776855
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1958: train_loss=10.063690185546875
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1959: train_loss=10.063984870910645
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1960: train_loss=10.059127807617188
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1961: train_loss=10.065107345581055
INFO - 04/15/25 16:41:20 - 0:09:43 - Epoch 1962: train_loss=10.066876411437988
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1963: train_loss=10.062810897827148
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1964: train_loss=10.062138557434082
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1965: train_loss=10.064536094665527
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1966: train_loss=10.062292098999023
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1967: train_loss=10.061367988586426
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1968: train_loss=10.062634468078613
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1969: train_loss=10.061511993408203
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1970: train_loss=10.06086254119873
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1971: train_loss=10.061687469482422
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1972: train_loss=10.06057071685791
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1973: train_loss=10.061492919921875
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1974: train_loss=10.061553001403809
INFO - 04/15/25 16:41:20 - 0:09:44 - Epoch 1975: train_loss=10.059240341186523
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1976: train_loss=10.059943199157715
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1977: train_loss=10.060094833374023
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1978: train_loss=10.05933952331543
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1979: train_loss=10.0610990524292
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1980: train_loss=10.05990219116211
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1981: train_loss=10.061820030212402
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1982: train_loss=10.061774253845215
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1983: train_loss=10.059721946716309
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1984: train_loss=10.062000274658203
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1985: train_loss=10.060647964477539
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1986: train_loss=10.062064170837402
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1987: train_loss=10.06167984008789
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1988: train_loss=10.06149673461914
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1989: train_loss=10.060513496398926
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1990: train_loss=10.061954498291016
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1991: train_loss=10.0596923828125
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1992: train_loss=10.06359577178955
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1993: train_loss=10.062997817993164
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1994: train_loss=10.060980796813965
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1995: train_loss=10.06142807006836
INFO - 04/15/25 16:41:21 - 0:09:44 - Epoch 1996: train_loss=10.061362266540527
INFO - 04/15/25 16:41:21 - 0:09:45 - Epoch 1997: train_loss=10.060274124145508
INFO - 04/15/25 16:41:21 - 0:09:45 - Epoch 1998: train_loss=10.061859130859375
INFO - 04/15/25 16:41:21 - 0:09:45 - Epoch 1999: train_loss=10.059828758239746
INFO - 04/15/25 16:41:21 - 0:09:45 - Epoch 2000: train_loss=10.063706398010254
INFO - 04/15/25 16:41:21 - 0:09:45 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:21 - 0:09:45 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2000: ACC: 0.0, NMI: 0.360498642958014, F1: 0.0, ARI: 0.16791946797789933
INFO - 04/15/25 16:41:22 - 0:09:45 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2001: train_loss=10.063076972961426
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2002: train_loss=10.060859680175781
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2003: train_loss=10.06121826171875
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2004: train_loss=10.06138801574707
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2005: train_loss=10.060284614562988
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2006: train_loss=10.063066482543945
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2007: train_loss=10.062578201293945
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2008: train_loss=10.060628890991211
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2009: train_loss=10.060567855834961
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2010: train_loss=10.06188678741455
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2011: train_loss=10.060846328735352
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2012: train_loss=10.062679290771484
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2013: train_loss=10.062616348266602
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2014: train_loss=10.060186386108398
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2015: train_loss=10.060084342956543
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2016: train_loss=10.062128067016602
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2017: train_loss=10.061004638671875
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2018: train_loss=10.062394142150879
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2019: train_loss=10.062363624572754
INFO - 04/15/25 16:41:22 - 0:09:45 - Epoch 2020: train_loss=10.060176849365234
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2021: train_loss=10.06006145477295
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2022: train_loss=10.061652183532715
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2023: train_loss=10.060365676879883
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2024: train_loss=10.062822341918945
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2025: train_loss=10.062833786010742
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2026: train_loss=10.05976676940918
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2027: train_loss=10.060562133789062
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2028: train_loss=10.06013298034668
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2029: train_loss=10.060086250305176
INFO - 04/15/25 16:41:22 - 0:09:46 - Epoch 2030: train_loss=10.059651374816895
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2031: train_loss=10.060598373413086
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2032: train_loss=10.059063911437988
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2033: train_loss=10.061944007873535
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2034: train_loss=10.06065559387207
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2035: train_loss=10.061954498291016
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2036: train_loss=10.062196731567383
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2037: train_loss=10.059556007385254
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2038: train_loss=10.060992240905762
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2039: train_loss=10.059540748596191
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2040: train_loss=10.062012672424316
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2041: train_loss=10.061300277709961
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2042: train_loss=10.060866355895996
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2043: train_loss=10.060864448547363
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2044: train_loss=10.060648918151855
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2045: train_loss=10.060277938842773
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2046: train_loss=10.060394287109375
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2047: train_loss=10.060550689697266
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2048: train_loss=10.059416770935059
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2049: train_loss=10.06301498413086
INFO - 04/15/25 16:41:23 - 0:09:46 - Epoch 2050: train_loss=10.06298828125
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2051: train_loss=10.059154510498047
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2052: train_loss=10.0612211227417
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2053: train_loss=10.060107231140137
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2054: train_loss=10.06113052368164
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2055: train_loss=10.061213493347168
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2056: train_loss=10.059109687805176
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2057: train_loss=10.05960750579834
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2058: train_loss=10.05965805053711
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2059: train_loss=10.058135986328125
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2060: train_loss=10.063462257385254
INFO - 04/15/25 16:41:23 - 0:09:47 - Epoch 2061: train_loss=10.063495635986328
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2062: train_loss=10.058626174926758
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2063: train_loss=10.064851760864258
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2064: train_loss=10.067070960998535
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2065: train_loss=10.06425666809082
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2066: train_loss=10.059289932250977
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2067: train_loss=10.063475608825684
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2068: train_loss=10.064146041870117
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2069: train_loss=10.060013771057129
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2070: train_loss=10.06395435333252
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2071: train_loss=10.066383361816406
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2072: train_loss=10.063871383666992
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2073: train_loss=10.06032657623291
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2074: train_loss=10.062719345092773
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2075: train_loss=10.062797546386719
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2076: train_loss=10.060689926147461
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2077: train_loss=10.061731338500977
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2078: train_loss=10.061887741088867
INFO - 04/15/25 16:41:24 - 0:09:47 - Epoch 2079: train_loss=10.06019401550293
INFO - 04/15/25 16:41:26 - 0:09:47 - Epoch 2080: train_loss=10.061347007751465
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2081: train_loss=10.059905052185059
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2082: train_loss=10.061628341674805
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2083: train_loss=10.061774253845215
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2084: train_loss=10.05936050415039
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2085: train_loss=10.06151008605957
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2086: train_loss=10.061505317687988
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2087: train_loss=10.059137344360352
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2088: train_loss=10.060489654541016
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2089: train_loss=10.059609413146973
INFO - 04/15/25 16:41:26 - 0:09:49 - Epoch 2090: train_loss=10.059805870056152
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2091: train_loss=10.059581756591797
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2092: train_loss=10.060304641723633
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2093: train_loss=10.058682441711426
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2094: train_loss=10.060872077941895
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2095: train_loss=10.060362815856934
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2096: train_loss=10.060020446777344
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2097: train_loss=10.059992790222168
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2098: train_loss=10.059745788574219
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2099: train_loss=10.05984878540039
INFO - 04/15/25 16:41:26 - 0:09:50 - Epoch 2100: train_loss=10.059538841247559
INFO - 04/15/25 16:41:26 - 0:09:50 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:27 - 0:09:50 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2100: ACC: 0.0, NMI: 0.37775587956628426, F1: 0.0, ARI: 0.17465023882828717
INFO - 04/15/25 16:41:27 - 0:09:50 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2101: train_loss=10.059113502502441
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2102: train_loss=10.060612678527832
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2103: train_loss=10.059929847717285
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2104: train_loss=10.060253143310547
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2105: train_loss=10.060175895690918
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2106: train_loss=10.059682846069336
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2107: train_loss=10.06019115447998
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2108: train_loss=10.059090614318848
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2109: train_loss=10.060506820678711
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2110: train_loss=10.059205055236816
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2111: train_loss=10.059247970581055
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2112: train_loss=10.061127662658691
INFO - 04/15/25 16:41:27 - 0:09:50 - Epoch 2113: train_loss=10.059924125671387
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2114: train_loss=10.061893463134766
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2115: train_loss=10.06173324584961
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2116: train_loss=10.060309410095215
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2117: train_loss=10.060284614562988
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2118: train_loss=10.060794830322266
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2119: train_loss=10.060468673706055
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2120: train_loss=10.060697555541992
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2121: train_loss=10.05990219116211
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2122: train_loss=10.061993598937988
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2123: train_loss=10.061769485473633
INFO - 04/15/25 16:41:27 - 0:09:51 - Epoch 2124: train_loss=10.059590339660645
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2125: train_loss=10.059335708618164
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2126: train_loss=10.06177806854248
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2127: train_loss=10.061189651489258
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2128: train_loss=10.060530662536621
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2129: train_loss=10.060367584228516
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2130: train_loss=10.061020851135254
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2131: train_loss=10.060688018798828
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2132: train_loss=10.060564994812012
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2133: train_loss=10.06006145477295
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2134: train_loss=10.061392784118652
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2135: train_loss=10.06125545501709
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2136: train_loss=10.059956550598145
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2137: train_loss=10.059503555297852
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2138: train_loss=10.061941146850586
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2139: train_loss=10.061661720275879
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2140: train_loss=10.059584617614746
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2141: train_loss=10.059281349182129
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2142: train_loss=10.061838150024414
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2143: train_loss=10.061430931091309
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2144: train_loss=10.059865951538086
INFO - 04/15/25 16:41:28 - 0:09:51 - Epoch 2145: train_loss=10.059659004211426
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2146: train_loss=10.06136703491211
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2147: train_loss=10.060988426208496
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2148: train_loss=10.060269355773926
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2149: train_loss=10.059874534606934
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2150: train_loss=10.061317443847656
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2151: train_loss=10.061057090759277
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2152: train_loss=10.059956550598145
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2153: train_loss=10.059585571289062
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2154: train_loss=10.0616455078125
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2155: train_loss=10.061368942260742
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2156: train_loss=10.05960750579834
INFO - 04/15/25 16:41:28 - 0:09:52 - Epoch 2157: train_loss=10.059239387512207
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2158: train_loss=10.061755180358887
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2159: train_loss=10.061339378356934
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2160: train_loss=10.059759140014648
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2161: train_loss=10.059575080871582
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2162: train_loss=10.061248779296875
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2163: train_loss=10.06088924407959
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2164: train_loss=10.060166358947754
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2165: train_loss=10.059764862060547
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2166: train_loss=10.061226844787598
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2167: train_loss=10.061030387878418
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2168: train_loss=10.059770584106445
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2169: train_loss=10.059303283691406
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2170: train_loss=10.061761856079102
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2171: train_loss=10.061631202697754
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2172: train_loss=10.05919075012207
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2173: train_loss=10.059358596801758
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2174: train_loss=10.061407089233398
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2175: train_loss=10.060497283935547
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2176: train_loss=10.061284065246582
INFO - 04/15/25 16:41:29 - 0:09:52 - Epoch 2177: train_loss=10.06106948852539
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2178: train_loss=10.0603666305542
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2179: train_loss=10.061229705810547
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2180: train_loss=10.059754371643066
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2181: train_loss=10.063356399536133
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2182: train_loss=10.063457489013672
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2183: train_loss=10.059297561645508
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2184: train_loss=10.061668395996094
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2185: train_loss=10.061005592346191
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2186: train_loss=10.060224533081055
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2187: train_loss=10.060294151306152
INFO - 04/15/25 16:41:29 - 0:09:53 - Epoch 2188: train_loss=10.060342788696289
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2189: train_loss=10.059704780578613
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2190: train_loss=10.061244010925293
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2191: train_loss=10.061059951782227
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2192: train_loss=10.05978775024414
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2193: train_loss=10.060506820678711
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2194: train_loss=10.059097290039062
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2195: train_loss=10.05958366394043
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2196: train_loss=10.06049633026123
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2197: train_loss=10.059161186218262
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2198: train_loss=10.059883117675781
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2199: train_loss=10.059107780456543
INFO - 04/15/25 16:41:30 - 0:09:53 - Epoch 2200: train_loss=10.062132835388184
INFO - 04/15/25 16:41:30 - 0:09:53 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:30 - 0:09:53 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2200: ACC: 0.0, NMI: 0.35976418253801073, F1: 0.0, ARI: 0.1682382251761742
INFO - 04/15/25 16:41:30 - 0:09:54 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2201: train_loss=10.061248779296875
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2202: train_loss=10.06105899810791
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2203: train_loss=10.060994148254395
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2204: train_loss=10.060944557189941
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2205: train_loss=10.060275077819824
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2206: train_loss=10.060447692871094
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2207: train_loss=10.060657501220703
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2208: train_loss=10.059554100036621
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2209: train_loss=10.062826156616211
INFO - 04/15/25 16:41:30 - 0:09:54 - Epoch 2210: train_loss=10.062810897827148
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2211: train_loss=10.06024169921875
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2212: train_loss=10.061135292053223
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2213: train_loss=10.061335563659668
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2214: train_loss=10.059067726135254
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2215: train_loss=10.062499046325684
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2216: train_loss=10.060506820678711
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2217: train_loss=10.06363296508789
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2218: train_loss=10.064399719238281
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2219: train_loss=10.05862808227539
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2220: train_loss=10.065630912780762
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2221: train_loss=10.067193984985352
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2222: train_loss=10.063201904296875
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2223: train_loss=10.062647819519043
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2224: train_loss=10.064409255981445
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2225: train_loss=10.06311321258545
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2226: train_loss=10.062081336975098
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2227: train_loss=10.062113761901855
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2228: train_loss=10.062941551208496
INFO - 04/15/25 16:41:31 - 0:09:54 - Epoch 2229: train_loss=10.060654640197754
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2230: train_loss=10.062933921813965
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2231: train_loss=10.06360912322998
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2232: train_loss=10.060053825378418
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2233: train_loss=10.062604904174805
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2234: train_loss=10.063075065612793
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2235: train_loss=10.060916900634766
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2236: train_loss=10.06129264831543
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2237: train_loss=10.062484741210938
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2238: train_loss=10.059656143188477
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2239: train_loss=10.063533782958984
INFO - 04/15/25 16:41:31 - 0:09:55 - Epoch 2240: train_loss=10.064894676208496
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2241: train_loss=10.061297416687012
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2242: train_loss=10.062509536743164
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2243: train_loss=10.063926696777344
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2244: train_loss=10.06242847442627
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2245: train_loss=10.06090259552002
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2246: train_loss=10.062374114990234
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2247: train_loss=10.0628080368042
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2248: train_loss=10.059181213378906
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2249: train_loss=10.063811302185059
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2250: train_loss=10.064576148986816
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2251: train_loss=10.060898780822754
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2252: train_loss=10.06293773651123
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2253: train_loss=10.063884735107422
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2254: train_loss=10.062081336975098
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2255: train_loss=10.061819076538086
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2256: train_loss=10.061962127685547
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2257: train_loss=10.061943054199219
INFO - 04/15/25 16:41:32 - 0:09:55 - Epoch 2258: train_loss=10.06078815460205
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2259: train_loss=10.061812400817871
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2260: train_loss=10.060943603515625
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2261: train_loss=10.06121826171875
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2262: train_loss=10.061410903930664
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2263: train_loss=10.060165405273438
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2264: train_loss=10.060567855834961
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2265: train_loss=10.0604829788208
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2266: train_loss=10.059745788574219
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2267: train_loss=10.0596342086792
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2268: train_loss=10.060412406921387
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2269: train_loss=10.059549331665039
INFO - 04/15/25 16:41:32 - 0:09:56 - Epoch 2270: train_loss=10.06058120727539
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2271: train_loss=10.060128211975098
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2272: train_loss=10.059785842895508
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2273: train_loss=10.06076717376709
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2274: train_loss=10.059191703796387
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2275: train_loss=10.063128471374512
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2276: train_loss=10.063314437866211
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2277: train_loss=10.059319496154785
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2278: train_loss=10.062382698059082
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2279: train_loss=10.062560081481934
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2280: train_loss=10.060583114624023
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2281: train_loss=10.061171531677246
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2282: train_loss=10.06180477142334
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2283: train_loss=10.0599365234375
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2284: train_loss=10.061553001403809
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2285: train_loss=10.061661720275879
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2286: train_loss=10.059800148010254
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2287: train_loss=10.061147689819336
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2288: train_loss=10.060630798339844
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2289: train_loss=10.060230255126953
INFO - 04/15/25 16:41:33 - 0:09:56 - Epoch 2290: train_loss=10.060317039489746
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2291: train_loss=10.059870719909668
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2292: train_loss=10.06004524230957
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2293: train_loss=10.059206008911133
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2294: train_loss=10.061260223388672
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2295: train_loss=10.060440063476562
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2296: train_loss=10.060956001281738
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2297: train_loss=10.060842514038086
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2298: train_loss=10.060275077819824
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2299: train_loss=10.060229301452637
INFO - 04/15/25 16:41:33 - 0:09:57 - Epoch 2300: train_loss=10.060149192810059
INFO - 04/15/25 16:41:33 - 0:09:57 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:34 - 0:09:57 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2300: ACC: 0.0, NMI: 0.362920155006335, F1: 0.0, ARI: 0.16877221816684063
INFO - 04/15/25 16:41:34 - 0:09:57 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2301: train_loss=10.05982780456543
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2302: train_loss=10.060125350952148
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2303: train_loss=10.059367179870605
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2304: train_loss=10.060901641845703
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2305: train_loss=10.059200286865234
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2306: train_loss=10.06300163269043
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2307: train_loss=10.063210487365723
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2308: train_loss=10.059114456176758
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2309: train_loss=10.062841415405273
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2310: train_loss=10.062736511230469
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2311: train_loss=10.060070037841797
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2312: train_loss=10.061659812927246
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2313: train_loss=10.061295509338379
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2314: train_loss=10.060627937316895
INFO - 04/15/25 16:41:34 - 0:09:57 - Epoch 2315: train_loss=10.060784339904785
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2316: train_loss=10.060404777526855
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2317: train_loss=10.060038566589355
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2318: train_loss=10.060771942138672
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2319: train_loss=10.059514045715332
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2320: train_loss=10.062004089355469
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2321: train_loss=10.062143325805664
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2322: train_loss=10.058833122253418
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2323: train_loss=10.061070442199707
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2324: train_loss=10.059584617614746
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2325: train_loss=10.061492919921875
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2326: train_loss=10.060733795166016
INFO - 04/15/25 16:41:34 - 0:09:58 - Epoch 2327: train_loss=10.060834884643555
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2328: train_loss=10.060737609863281
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2329: train_loss=10.060518264770508
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2330: train_loss=10.06005573272705
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2331: train_loss=10.06081485748291
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2332: train_loss=10.05954360961914
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2333: train_loss=10.061882972717285
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2334: train_loss=10.061554908752441
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2335: train_loss=10.059972763061523
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2336: train_loss=10.06090259552002
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2337: train_loss=10.059444427490234
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2338: train_loss=10.061979293823242
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2339: train_loss=10.060785293579102
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2340: train_loss=10.061589241027832
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2341: train_loss=10.061772346496582
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2342: train_loss=10.059986114501953
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2343: train_loss=10.061515808105469
INFO - 04/15/25 16:41:35 - 0:09:58 - Epoch 2344: train_loss=10.05986213684082
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2345: train_loss=10.063220024108887
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2346: train_loss=10.063251495361328
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2347: train_loss=10.059762954711914
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2348: train_loss=10.061793327331543
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2349: train_loss=10.061539649963379
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2350: train_loss=10.059515953063965
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2351: train_loss=10.061178207397461
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2352: train_loss=10.058819770812988
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2353: train_loss=10.061982154846191
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2354: train_loss=10.060547828674316
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2355: train_loss=10.061812400817871
INFO - 04/15/25 16:41:35 - 0:09:59 - Epoch 2356: train_loss=10.06137466430664
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2357: train_loss=10.061249732971191
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2358: train_loss=10.060698509216309
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2359: train_loss=10.061511039733887
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2360: train_loss=10.060637474060059
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2361: train_loss=10.061335563659668
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2362: train_loss=10.061095237731934
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2363: train_loss=10.060590744018555
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2364: train_loss=10.060858726501465
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2365: train_loss=10.059863090515137
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2366: train_loss=10.061529159545898
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2367: train_loss=10.059955596923828
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2368: train_loss=10.062821388244629
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2369: train_loss=10.062281608581543
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2370: train_loss=10.061264038085938
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2371: train_loss=10.061052322387695
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2372: train_loss=10.061881065368652
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2373: train_loss=10.061040878295898
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2374: train_loss=10.061860084533691
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2375: train_loss=10.061881065368652
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2376: train_loss=10.060370445251465
INFO - 04/15/25 16:41:36 - 0:09:59 - Epoch 2377: train_loss=10.059820175170898
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2378: train_loss=10.062313079833984
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2379: train_loss=10.060968399047852
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2380: train_loss=10.062505722045898
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2381: train_loss=10.062507629394531
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2382: train_loss=10.05997371673584
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2383: train_loss=10.059855461120605
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2384: train_loss=10.061995506286621
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2385: train_loss=10.060898780822754
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2386: train_loss=10.062190055847168
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2387: train_loss=10.062294960021973
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2388: train_loss=10.05996322631836
INFO - 04/15/25 16:41:36 - 0:10:00 - Epoch 2389: train_loss=10.06003475189209
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2390: train_loss=10.061360359191895
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2391: train_loss=10.059852600097656
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2392: train_loss=10.063080787658691
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2393: train_loss=10.063089370727539
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2394: train_loss=10.059199333190918
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2395: train_loss=10.060723304748535
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2396: train_loss=10.059263229370117
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2397: train_loss=10.061785697937012
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2398: train_loss=10.060632705688477
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2399: train_loss=10.061848640441895
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2400: train_loss=10.06203556060791
INFO - 04/15/25 16:41:37 - 0:10:00 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:37 - 0:10:00 - Decoding cost time:  0.132 s
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2400: ACC: 0.0, NMI: 0.35371818587644943, F1: 0.0, ARI: 0.16697181907682163
INFO - 04/15/25 16:41:37 - 0:10:00 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:37 - 0:10:00 - Epoch 2401: train_loss=10.059643745422363
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2402: train_loss=10.060853958129883
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2403: train_loss=10.05964183807373
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2404: train_loss=10.061968803405762
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2405: train_loss=10.0615873336792
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2406: train_loss=10.059944152832031
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2407: train_loss=10.059839248657227
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2408: train_loss=10.060961723327637
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2409: train_loss=10.060239791870117
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2410: train_loss=10.061105728149414
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2411: train_loss=10.060824394226074
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2412: train_loss=10.060320854187012
INFO - 04/15/25 16:41:37 - 0:10:01 - Epoch 2413: train_loss=10.060357093811035
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2414: train_loss=10.05997371673584
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2415: train_loss=10.0602445602417
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2416: train_loss=10.059675216674805
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2417: train_loss=10.059598922729492
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2418: train_loss=10.060577392578125
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2419: train_loss=10.058856010437012
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2420: train_loss=10.063897132873535
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2421: train_loss=10.06459903717041
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2422: train_loss=10.059381484985352
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2423: train_loss=10.065954208374023
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2424: train_loss=10.068975448608398
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2425: train_loss=10.06589126586914
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2426: train_loss=10.059500694274902
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2427: train_loss=10.064726829528809
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2428: train_loss=10.06619930267334
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2429: train_loss=10.06273365020752
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2430: train_loss=10.061392784118652
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2431: train_loss=10.063640594482422
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2432: train_loss=10.061752319335938
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2433: train_loss=10.060973167419434
INFO - 04/15/25 16:41:38 - 0:10:01 - Epoch 2434: train_loss=10.062127113342285
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2435: train_loss=10.060297966003418
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2436: train_loss=10.061723709106445
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2437: train_loss=10.06201171875
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2438: train_loss=10.059727668762207
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2439: train_loss=10.061320304870605
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2440: train_loss=10.061177253723145
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2441: train_loss=10.059477806091309
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2442: train_loss=10.061344146728516
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2443: train_loss=10.06026554107666
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2444: train_loss=10.06144905090332
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2445: train_loss=10.061727523803711
INFO - 04/15/25 16:41:38 - 0:10:02 - Epoch 2446: train_loss=10.059029579162598
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2447: train_loss=10.061177253723145
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2448: train_loss=10.059802055358887
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2449: train_loss=10.061955451965332
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2450: train_loss=10.06222915649414
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2451: train_loss=10.059494018554688
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2452: train_loss=10.061856269836426
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2453: train_loss=10.06173324584961
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2454: train_loss=10.0595064163208
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2455: train_loss=10.061296463012695
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2456: train_loss=10.060809135437012
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2457: train_loss=10.059839248657227
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2458: train_loss=10.060049057006836
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2459: train_loss=10.059491157531738
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2460: train_loss=10.060301780700684
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2461: train_loss=10.058472633361816
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2462: train_loss=10.062165260314941
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2463: train_loss=10.060942649841309
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2464: train_loss=10.061416625976562
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2465: train_loss=10.061732292175293
INFO - 04/15/25 16:41:39 - 0:10:02 - Epoch 2466: train_loss=10.059563636779785
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2467: train_loss=10.059554100036621
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2468: train_loss=10.060914993286133
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2469: train_loss=10.059648513793945
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2470: train_loss=10.062216758728027
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2471: train_loss=10.062311172485352
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2472: train_loss=10.059215545654297
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2473: train_loss=10.06087589263916
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2474: train_loss=10.059706687927246
INFO - 04/15/25 16:41:39 - 0:10:03 - Epoch 2475: train_loss=10.061293601989746
INFO - 04/15/25 16:41:40 - 0:10:03 - Epoch 2476: train_loss=10.060968399047852
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2477: train_loss=10.059906005859375
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2478: train_loss=10.05993366241455
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2479: train_loss=10.060294151306152
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2480: train_loss=10.059578895568848
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2481: train_loss=10.061491966247559
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2482: train_loss=10.061442375183105
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2483: train_loss=10.05918025970459
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2484: train_loss=10.060102462768555
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2485: train_loss=10.059351921081543
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2486: train_loss=10.059305191040039
INFO - 04/15/25 16:41:40 - 0:10:04 - Epoch 2487: train_loss=10.06027603149414
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2488: train_loss=10.059037208557129
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2489: train_loss=10.061918258666992
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2490: train_loss=10.061485290527344
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2491: train_loss=10.060312271118164
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2492: train_loss=10.060405731201172
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2493: train_loss=10.060449600219727
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2494: train_loss=10.060206413269043
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2495: train_loss=10.060171127319336
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2496: train_loss=10.059822082519531
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2497: train_loss=10.060132026672363
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2498: train_loss=10.059492111206055
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2499: train_loss=10.060005187988281
INFO - 04/15/25 16:41:41 - 0:10:04 - Epoch 2500: train_loss=10.059179306030273
INFO - 04/15/25 16:41:41 - 0:10:04 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:41 - 0:10:04 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2500: ACC: 0.0, NMI: 0.3561677073799445, F1: 0.0, ARI: 0.1670591547286756
INFO - 04/15/25 16:41:41 - 0:10:05 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2501: train_loss=10.061206817626953
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2502: train_loss=10.060763359069824
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2503: train_loss=10.06043529510498
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2504: train_loss=10.060225486755371
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2505: train_loss=10.060519218444824
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2506: train_loss=10.060303688049316
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2507: train_loss=10.060057640075684
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2508: train_loss=10.059749603271484
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2509: train_loss=10.06046199798584
INFO - 04/15/25 16:41:41 - 0:10:05 - Epoch 2510: train_loss=10.059859275817871
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2511: train_loss=10.060636520385742
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2512: train_loss=10.060341835021973
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2513: train_loss=10.06014633178711
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2514: train_loss=10.060070991516113
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2515: train_loss=10.060080528259277
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2516: train_loss=10.059553146362305
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2517: train_loss=10.06104564666748
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2518: train_loss=10.060775756835938
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2519: train_loss=10.05968189239502
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2520: train_loss=10.059781074523926
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2521: train_loss=10.06018352508545
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2522: train_loss=10.059407234191895
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2523: train_loss=10.061355590820312
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2524: train_loss=10.061245918273926
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2525: train_loss=10.059282302856445
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2526: train_loss=10.060954093933105
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2527: train_loss=10.058476448059082
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2528: train_loss=10.062759399414062
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2529: train_loss=10.061334609985352
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2530: train_loss=10.062254905700684
INFO - 04/15/25 16:41:42 - 0:10:05 - Epoch 2531: train_loss=10.062212944030762
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2532: train_loss=10.060362815856934
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2533: train_loss=10.060823440551758
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2534: train_loss=10.060815811157227
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2535: train_loss=10.05981731414795
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2536: train_loss=10.060881614685059
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2537: train_loss=10.059887886047363
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2538: train_loss=10.060784339904785
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2539: train_loss=10.05977725982666
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2540: train_loss=10.061485290527344
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2541: train_loss=10.060734748840332
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2542: train_loss=10.06092357635498
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2543: train_loss=10.06093692779541
INFO - 04/15/25 16:41:42 - 0:10:06 - Epoch 2544: train_loss=10.060343742370605
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2545: train_loss=10.059802055358887
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2546: train_loss=10.061684608459473
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2547: train_loss=10.061443328857422
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2548: train_loss=10.059954643249512
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2549: train_loss=10.059829711914062
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2550: train_loss=10.0609769821167
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2551: train_loss=10.060273170471191
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2552: train_loss=10.061314582824707
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2553: train_loss=10.06106948852539
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2554: train_loss=10.060325622558594
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2555: train_loss=10.060132026672363
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2556: train_loss=10.061023712158203
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2557: train_loss=10.060456275939941
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2558: train_loss=10.06107234954834
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2559: train_loss=10.060856819152832
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2560: train_loss=10.060262680053711
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2561: train_loss=10.059855461120605
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2562: train_loss=10.061439514160156
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2563: train_loss=10.061050415039062
INFO - 04/15/25 16:41:43 - 0:10:06 - Epoch 2564: train_loss=10.060083389282227
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2565: train_loss=10.059741973876953
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2566: train_loss=10.061507225036621
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2567: train_loss=10.061188697814941
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2568: train_loss=10.059924125671387
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2569: train_loss=10.059610366821289
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2570: train_loss=10.061494827270508
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2571: train_loss=10.061245918273926
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2572: train_loss=10.059844970703125
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2573: train_loss=10.059465408325195
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2574: train_loss=10.061633110046387
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2575: train_loss=10.061307907104492
INFO - 04/15/25 16:41:43 - 0:10:07 - Epoch 2576: train_loss=10.059730529785156
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2577: train_loss=10.059350967407227
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2578: train_loss=10.06178092956543
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2579: train_loss=10.061498641967773
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2580: train_loss=10.059468269348145
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2581: train_loss=10.05930233001709
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2582: train_loss=10.06145191192627
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2583: train_loss=10.060861587524414
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2584: train_loss=10.0604248046875
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2585: train_loss=10.06022834777832
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2586: train_loss=10.060577392578125
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2587: train_loss=10.060164451599121
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2588: train_loss=10.060857772827148
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2589: train_loss=10.060628890991211
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2590: train_loss=10.06050968170166
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2591: train_loss=10.060208320617676
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2592: train_loss=10.060633659362793
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2593: train_loss=10.060036659240723
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2594: train_loss=10.061094284057617
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2595: train_loss=10.060956001281738
INFO - 04/15/25 16:41:44 - 0:10:07 - Epoch 2596: train_loss=10.05980396270752
INFO - 04/15/25 16:41:44 - 0:10:08 - Epoch 2597: train_loss=10.059417724609375
INFO - 04/15/25 16:41:44 - 0:10:08 - Epoch 2598: train_loss=10.061409950256348
INFO - 04/15/25 16:41:44 - 0:10:08 - Epoch 2599: train_loss=10.060996055603027
INFO - 04/15/25 16:41:44 - 0:10:08 - Epoch 2600: train_loss=10.060070037841797
INFO - 04/15/25 16:41:44 - 0:10:08 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:44 - 0:10:08 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2600: ACC: 0.0, NMI: 0.35478229012749724, F1: 0.0, ARI: 0.16693406084566972
INFO - 04/15/25 16:41:45 - 0:10:08 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2601: train_loss=10.059919357299805
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2602: train_loss=10.060776710510254
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2603: train_loss=10.060248374938965
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2604: train_loss=10.060744285583496
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2605: train_loss=10.060518264770508
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2606: train_loss=10.060349464416504
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2607: train_loss=10.060047149658203
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2608: train_loss=10.060811042785645
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2609: train_loss=10.060376167297363
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2610: train_loss=10.060593605041504
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2611: train_loss=10.060437202453613
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2612: train_loss=10.060249328613281
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2613: train_loss=10.059853553771973
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2614: train_loss=10.061015129089355
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2615: train_loss=10.060821533203125
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2616: train_loss=10.059981346130371
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2617: train_loss=10.059654235839844
INFO - 04/15/25 16:41:45 - 0:10:08 - Epoch 2618: train_loss=10.060943603515625
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2619: train_loss=10.06050968170166
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2620: train_loss=10.0603609085083
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2621: train_loss=10.060126304626465
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2622: train_loss=10.060525894165039
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2623: train_loss=10.060205459594727
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2624: train_loss=10.060535430908203
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2625: train_loss=10.060208320617676
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2626: train_loss=10.060617446899414
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2627: train_loss=10.060276985168457
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2628: train_loss=10.060425758361816
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2629: train_loss=10.060070991516113
INFO - 04/15/25 16:41:45 - 0:10:09 - Epoch 2630: train_loss=10.06078052520752
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2631: train_loss=10.060460090637207
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2632: train_loss=10.060246467590332
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2633: train_loss=10.059850692749023
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2634: train_loss=10.060811042785645
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2635: train_loss=10.060440063476562
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2636: train_loss=10.06027603149414
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2637: train_loss=10.059975624084473
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2638: train_loss=10.06063175201416
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2639: train_loss=10.060317993164062
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2640: train_loss=10.060347557067871
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2641: train_loss=10.060017585754395
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2642: train_loss=10.060712814331055
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2643: train_loss=10.060466766357422
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2644: train_loss=10.060194969177246
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2645: train_loss=10.0599365234375
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2646: train_loss=10.060585021972656
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2647: train_loss=10.060178756713867
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2648: train_loss=10.060514450073242
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2649: train_loss=10.060269355773926
INFO - 04/15/25 16:41:46 - 0:10:09 - Epoch 2650: train_loss=10.060324668884277
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2651: train_loss=10.060056686401367
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2652: train_loss=10.060437202453613
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2653: train_loss=10.05992317199707
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2654: train_loss=10.060717582702637
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2655: train_loss=10.06049633026123
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2656: train_loss=10.060006141662598
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2657: train_loss=10.05970573425293
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2658: train_loss=10.060575485229492
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2659: train_loss=10.060033798217773
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2660: train_loss=10.060620307922363
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2661: train_loss=10.060399055480957
INFO - 04/15/25 16:41:46 - 0:10:10 - Epoch 2662: train_loss=10.060036659240723
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2663: train_loss=10.059900283813477
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2664: train_loss=10.06026554107666
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2665: train_loss=10.059741973876953
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2666: train_loss=10.060989379882812
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2667: train_loss=10.060864448547363
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2668: train_loss=10.059497833251953
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2669: train_loss=10.059530258178711
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2670: train_loss=10.0601806640625
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2671: train_loss=10.059367179870605
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2672: train_loss=10.061320304870605
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2673: train_loss=10.061184883117676
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2674: train_loss=10.059209823608398
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2675: train_loss=10.058926582336426
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2676: train_loss=10.061327934265137
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2677: train_loss=10.060925483703613
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2678: train_loss=10.059684753417969
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2679: train_loss=10.059610366821289
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2680: train_loss=10.060524940490723
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2681: train_loss=10.059991836547852
INFO - 04/15/25 16:41:47 - 0:10:10 - Epoch 2682: train_loss=10.060614585876465
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2683: train_loss=10.06063461303711
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2684: train_loss=10.0595064163208
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2685: train_loss=10.059209823608398
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2686: train_loss=10.060861587524414
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2687: train_loss=10.060284614562988
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2688: train_loss=10.06021785736084
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2689: train_loss=10.060288429260254
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2690: train_loss=10.05981731414795
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2691: train_loss=10.059351921081543
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2692: train_loss=10.061037063598633
INFO - 04/15/25 16:41:47 - 0:10:11 - Epoch 2693: train_loss=10.060646057128906
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2694: train_loss=10.059861183166504
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2695: train_loss=10.060309410095215
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2696: train_loss=10.059148788452148
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2697: train_loss=10.05854320526123
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2698: train_loss=10.061264991760254
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2699: train_loss=10.060044288635254
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2700: train_loss=10.060884475708008
INFO - 04/15/25 16:41:48 - 0:10:11 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:48 - 0:10:11 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2700: ACC: 0.0, NMI: 0.3526563760821298, F1: 0.0, ARI: 0.16731689467921054
INFO - 04/15/25 16:41:48 - 0:10:11 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2701: train_loss=10.061158180236816
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2702: train_loss=10.05908203125
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2703: train_loss=10.063138961791992
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2704: train_loss=10.062019348144531
INFO - 04/15/25 16:41:48 - 0:10:11 - Epoch 2705: train_loss=10.061264991760254
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2706: train_loss=10.061222076416016
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2707: train_loss=10.061493873596191
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2708: train_loss=10.060336112976074
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2709: train_loss=10.063139915466309
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2710: train_loss=10.062646865844727
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2711: train_loss=10.060447692871094
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2712: train_loss=10.060218811035156
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2713: train_loss=10.062346458435059
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2714: train_loss=10.061708450317383
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2715: train_loss=10.061278343200684
INFO - 04/15/25 16:41:48 - 0:10:12 - Epoch 2716: train_loss=10.061007499694824
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2717: train_loss=10.061656951904297
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2718: train_loss=10.061058044433594
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2719: train_loss=10.061882972717285
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2720: train_loss=10.061670303344727
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2721: train_loss=10.060811996459961
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2722: train_loss=10.060300827026367
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2723: train_loss=10.062421798706055
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2724: train_loss=10.062100410461426
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2725: train_loss=10.060487747192383
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2726: train_loss=10.060157775878906
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2727: train_loss=10.062289237976074
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2728: train_loss=10.061678886413574
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2729: train_loss=10.061001777648926
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2730: train_loss=10.060752868652344
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2731: train_loss=10.061495780944824
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2732: train_loss=10.061027526855469
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2733: train_loss=10.061541557312012
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2734: train_loss=10.061266899108887
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2735: train_loss=10.060968399047852
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2736: train_loss=10.06057071685791
INFO - 04/15/25 16:41:49 - 0:10:12 - Epoch 2737: train_loss=10.061769485473633
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2738: train_loss=10.061433792114258
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2739: train_loss=10.060778617858887
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2740: train_loss=10.06046199798584
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2741: train_loss=10.061705589294434
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2742: train_loss=10.061253547668457
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2743: train_loss=10.060845375061035
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2744: train_loss=10.060523986816406
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2745: train_loss=10.061538696289062
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2746: train_loss=10.06119155883789
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2747: train_loss=10.060809135437012
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2748: train_loss=10.060498237609863
INFO - 04/15/25 16:41:49 - 0:10:13 - Epoch 2749: train_loss=10.061534881591797
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2750: train_loss=10.061189651489258
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2751: train_loss=10.060812950134277
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2752: train_loss=10.06047534942627
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2753: train_loss=10.061436653137207
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2754: train_loss=10.060957908630371
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2755: train_loss=10.060943603515625
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2756: train_loss=10.060644149780273
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2757: train_loss=10.061263084411621
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2758: train_loss=10.060883522033691
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2759: train_loss=10.061012268066406
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2760: train_loss=10.060606956481934
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2761: train_loss=10.061190605163574
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2762: train_loss=10.060948371887207
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2763: train_loss=10.060760498046875
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2764: train_loss=10.060297966003418
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2765: train_loss=10.061524391174316
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2766: train_loss=10.061220169067383
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2767: train_loss=10.060452461242676
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2768: train_loss=10.060089111328125
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2769: train_loss=10.061538696289062
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2770: train_loss=10.061174392700195
INFO - 04/15/25 16:41:50 - 0:10:13 - Epoch 2771: train_loss=10.060514450073242
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2772: train_loss=10.060288429260254
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2773: train_loss=10.061356544494629
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2774: train_loss=10.060955047607422
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2775: train_loss=10.060643196105957
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2776: train_loss=10.060303688049316
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2777: train_loss=10.061178207397461
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2778: train_loss=10.060873031616211
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2779: train_loss=10.060688972473145
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2780: train_loss=10.060303688049316
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2781: train_loss=10.061138153076172
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2782: train_loss=10.060813903808594
INFO - 04/15/25 16:41:50 - 0:10:14 - Epoch 2783: train_loss=10.060632705688477
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2784: train_loss=10.060284614562988
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2785: train_loss=10.061175346374512
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2786: train_loss=10.060970306396484
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2787: train_loss=10.060354232788086
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2788: train_loss=10.059957504272461
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2789: train_loss=10.06153392791748
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2790: train_loss=10.061264038085938
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2791: train_loss=10.05998706817627
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2792: train_loss=10.059587478637695
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2793: train_loss=10.061851501464844
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2794: train_loss=10.061708450317383
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2795: train_loss=10.059489250183105
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2796: train_loss=10.059081077575684
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2797: train_loss=10.062251091003418
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2798: train_loss=10.061897277832031
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2799: train_loss=10.059289932250977
INFO - 04/15/25 16:41:51 - 0:10:14 - Epoch 2800: train_loss=10.059054374694824
INFO - 04/15/25 16:41:51 - 0:10:14 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:51 - 0:10:14 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2800: ACC: 0.0, NMI: 0.12683181188099704, F1: 0.0, ARI: 0.012198889506318013
INFO - 04/15/25 16:41:51 - 0:10:15 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2801: train_loss=10.062079429626465
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2802: train_loss=10.061759948730469
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2803: train_loss=10.059618949890137
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2804: train_loss=10.059470176696777
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2805: train_loss=10.061588287353516
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2806: train_loss=10.061100959777832
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2807: train_loss=10.060172080993652
INFO - 04/15/25 16:41:51 - 0:10:15 - Epoch 2808: train_loss=10.060037612915039
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2809: train_loss=10.06100845336914
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2810: train_loss=10.060603141784668
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2811: train_loss=10.060696601867676
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2812: train_loss=10.060502052307129
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2813: train_loss=10.060462951660156
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2814: train_loss=10.060036659240723
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2815: train_loss=10.061081886291504
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2816: train_loss=10.060845375061035
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2817: train_loss=10.060099601745605
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2818: train_loss=10.059805870056152
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2819: train_loss=10.061257362365723
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2820: train_loss=10.060989379882812
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2821: train_loss=10.06011962890625
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2822: train_loss=10.059876441955566
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2823: train_loss=10.060997009277344
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2824: train_loss=10.060544967651367
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2825: train_loss=10.060535430908203
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2826: train_loss=10.060401916503906
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2827: train_loss=10.060469627380371
INFO - 04/15/25 16:41:52 - 0:10:15 - Epoch 2828: train_loss=10.06008243560791
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2829: train_loss=10.060844421386719
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2830: train_loss=10.060587882995605
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2831: train_loss=10.060338973999023
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2832: train_loss=10.06000804901123
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2833: train_loss=10.060845375061035
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2834: train_loss=10.060562133789062
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2835: train_loss=10.060354232788086
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2836: train_loss=10.06004524230957
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2837: train_loss=10.06082534790039
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2838: train_loss=10.060567855834961
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2839: train_loss=10.060310363769531
INFO - 04/15/25 16:41:52 - 0:10:16 - Epoch 2840: train_loss=10.060052871704102
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2841: train_loss=10.060827255249023
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2842: train_loss=10.060550689697266
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2843: train_loss=10.060261726379395
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2844: train_loss=10.05994987487793
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2845: train_loss=10.06085205078125
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2846: train_loss=10.060553550720215
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2847: train_loss=10.060203552246094
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2848: train_loss=10.060028076171875
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2849: train_loss=10.060681343078613
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2850: train_loss=10.060162544250488
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2851: train_loss=10.060673713684082
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2852: train_loss=10.060530662536621
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2853: train_loss=10.060070991516113
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2854: train_loss=10.059761047363281
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2855: train_loss=10.060942649841309
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2856: train_loss=10.060575485229492
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2857: train_loss=10.060141563415527
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2858: train_loss=10.05996322631836
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2859: train_loss=10.060669898986816
INFO - 04/15/25 16:41:53 - 0:10:16 - Epoch 2860: train_loss=10.060287475585938
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2861: train_loss=10.060340881347656
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2862: train_loss=10.060110092163086
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2863: train_loss=10.060523986816406
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2864: train_loss=10.060149192810059
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2865: train_loss=10.060491561889648
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2866: train_loss=10.060139656066895
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2867: train_loss=10.060463905334473
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2868: train_loss=10.060118675231934
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2869: train_loss=10.060442924499512
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2870: train_loss=10.060172080993652
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2871: train_loss=10.060362815856934
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2872: train_loss=10.059962272644043
INFO - 04/15/25 16:41:53 - 0:10:17 - Epoch 2873: train_loss=10.060622215270996
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2874: train_loss=10.06039047241211
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2875: train_loss=10.060147285461426
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2876: train_loss=10.059972763061523
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2877: train_loss=10.060349464416504
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2878: train_loss=10.059887886047363
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2879: train_loss=10.060786247253418
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2880: train_loss=10.060729026794434
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2881: train_loss=10.059579849243164
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2882: train_loss=10.059157371520996
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2883: train_loss=10.061273574829102
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2884: train_loss=10.060988426208496
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2885: train_loss=10.05953598022461
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2886: train_loss=10.059229850769043
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2887: train_loss=10.061161994934082
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2888: train_loss=10.060988426208496
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2889: train_loss=10.059364318847656
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2890: train_loss=10.059136390686035
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2891: train_loss=10.061201095581055
INFO - 04/15/25 16:41:54 - 0:10:17 - Epoch 2892: train_loss=10.060836791992188
INFO - 04/15/25 16:41:54 - 0:10:18 - Epoch 2893: train_loss=10.059562683105469
INFO - 04/15/25 16:41:54 - 0:10:18 - Epoch 2894: train_loss=10.059355735778809
INFO - 04/15/25 16:41:54 - 0:10:18 - Epoch 2895: train_loss=10.061052322387695
INFO - 04/15/25 16:41:54 - 0:10:18 - Epoch 2896: train_loss=10.060750961303711
INFO - 04/15/25 16:41:54 - 0:10:18 - Epoch 2897: train_loss=10.059538841247559
INFO - 04/15/25 16:41:54 - 0:10:18 - Epoch 2898: train_loss=10.059164047241211
INFO - 04/15/25 16:41:54 - 0:10:18 - Epoch 2899: train_loss=10.061273574829102
INFO - 04/15/25 16:41:54 - 0:10:18 - Epoch 2900: train_loss=10.061039924621582
INFO - 04/15/25 16:41:54 - 0:10:18 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:54 - 0:10:18 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:41:55 - 0:10:18 - Epoch 2900: ACC: 0.0, NMI: 0.2163721070720115, F1: 0.0, ARI: 0.05918315264845604
INFO - 04/15/25 16:41:55 - 0:10:18 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:55 - 0:10:18 - Epoch 2901: train_loss=10.059212684631348
INFO - 04/15/25 16:41:55 - 0:10:18 - Epoch 2902: train_loss=10.058794021606445
INFO - 04/15/25 16:41:55 - 0:10:18 - Epoch 2903: train_loss=10.061769485473633
INFO - 04/15/25 16:41:56 - 0:10:18 - Epoch 2904: train_loss=10.061674118041992
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2905: train_loss=10.058528900146484
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2906: train_loss=10.06053352355957
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2907: train_loss=10.058457374572754
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2908: train_loss=10.05924129486084
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2909: train_loss=10.060111999511719
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2910: train_loss=10.058520317077637
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2911: train_loss=10.061019897460938
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2912: train_loss=10.05976390838623
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2913: train_loss=10.061456680297852
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2914: train_loss=10.061787605285645
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2915: train_loss=10.058771133422852
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2916: train_loss=10.06255054473877
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2917: train_loss=10.06209945678711
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2918: train_loss=10.059592247009277
INFO - 04/15/25 16:41:56 - 0:10:19 - Epoch 2919: train_loss=10.060542106628418
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2920: train_loss=10.059155464172363
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2921: train_loss=10.0623197555542
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2922: train_loss=10.061712265014648
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2923: train_loss=10.060223579406738
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2924: train_loss=10.060197830200195
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2925: train_loss=10.060657501220703
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2926: train_loss=10.059882164001465
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2927: train_loss=10.060997009277344
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2928: train_loss=10.06009578704834
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2929: train_loss=10.061037063598633
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2930: train_loss=10.060297012329102
INFO - 04/15/25 16:41:56 - 0:10:20 - Epoch 2931: train_loss=10.060818672180176
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2932: train_loss=10.06022834777832
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2933: train_loss=10.060497283935547
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2934: train_loss=10.06015682220459
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2935: train_loss=10.059924125671387
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2936: train_loss=10.060593605041504
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2937: train_loss=10.059308052062988
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2938: train_loss=10.062783241271973
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2939: train_loss=10.0629301071167
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2940: train_loss=10.058752059936523
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2941: train_loss=10.062219619750977
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2942: train_loss=10.061673164367676
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2943: train_loss=10.059361457824707
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2944: train_loss=10.060399055480957
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2945: train_loss=10.059194564819336
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2946: train_loss=10.060372352600098
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2947: train_loss=10.059037208557129
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2948: train_loss=10.060943603515625
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2949: train_loss=10.059992790222168
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2950: train_loss=10.061261177062988
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2951: train_loss=10.061050415039062
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2952: train_loss=10.06002426147461
INFO - 04/15/25 16:41:57 - 0:10:20 - Epoch 2953: train_loss=10.060088157653809
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2954: train_loss=10.060127258300781
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2955: train_loss=10.059690475463867
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2956: train_loss=10.060824394226074
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2957: train_loss=10.060283660888672
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2958: train_loss=10.060537338256836
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2959: train_loss=10.06032657623291
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2960: train_loss=10.060194969177246
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2961: train_loss=10.059988021850586
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2962: train_loss=10.060189247131348
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2963: train_loss=10.059866905212402
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2964: train_loss=10.060418128967285
INFO - 04/15/25 16:41:57 - 0:10:21 - Epoch 2965: train_loss=10.059942245483398
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2966: train_loss=10.060544967651367
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2967: train_loss=10.060258865356445
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2968: train_loss=10.059927940368652
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2969: train_loss=10.05979061126709
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2970: train_loss=10.060090065002441
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2971: train_loss=10.059605598449707
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2972: train_loss=10.060583114624023
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2973: train_loss=10.060271263122559
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2974: train_loss=10.059880256652832
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2975: train_loss=10.059772491455078
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2976: train_loss=10.060009956359863
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2977: train_loss=10.059457778930664
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2978: train_loss=10.060762405395508
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2979: train_loss=10.06071949005127
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2980: train_loss=10.059212684631348
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2981: train_loss=10.058961868286133
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2982: train_loss=10.061025619506836
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2983: train_loss=10.060585021972656
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2984: train_loss=10.059551239013672
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2985: train_loss=10.0595703125
INFO - 04/15/25 16:41:58 - 0:10:21 - Epoch 2986: train_loss=10.059934616088867
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2987: train_loss=10.059419631958008
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2988: train_loss=10.060824394226074
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2989: train_loss=10.060791015625
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2990: train_loss=10.058977127075195
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2991: train_loss=10.059667587280273
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2992: train_loss=10.059250831604004
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2993: train_loss=10.058555603027344
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2994: train_loss=10.06147289276123
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2995: train_loss=10.06061840057373
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2996: train_loss=10.060564994812012
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2997: train_loss=10.060677528381348
INFO - 04/15/25 16:41:58 - 0:10:22 - Epoch 2998: train_loss=10.05970287322998
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 2999: train_loss=10.060203552246094
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3000: train_loss=10.059223175048828
INFO - 04/15/25 16:41:59 - 0:10:22 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:41:59 - 0:10:22 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3000: ACC: 0.0, NMI: 0.2669740226787006, F1: 0.0, ARI: 0.10150999585619472
INFO - 04/15/25 16:41:59 - 0:10:22 - -------------------------------------------------------------------------
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3001: train_loss=10.06076431274414
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3002: train_loss=10.059587478637695
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3003: train_loss=10.061333656311035
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3004: train_loss=10.061077117919922
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3005: train_loss=10.059993743896484
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3006: train_loss=10.060688972473145
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3007: train_loss=10.05988597869873
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3008: train_loss=10.06122875213623
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3009: train_loss=10.060999870300293
INFO - 04/15/25 16:41:59 - 0:10:22 - Epoch 3010: train_loss=10.060076713562012
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3011: train_loss=10.059943199157715
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3012: train_loss=10.060256004333496
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3013: train_loss=10.059806823730469
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3014: train_loss=10.059618949890137
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3015: train_loss=10.060608863830566
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3016: train_loss=10.059219360351562
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3017: train_loss=10.062647819519043
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3018: train_loss=10.062955856323242
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3019: train_loss=10.059000015258789
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3020: train_loss=10.062488555908203
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3021: train_loss=10.062881469726562
INFO - 04/15/25 16:41:59 - 0:10:23 - Epoch 3022: train_loss=10.059459686279297
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3023: train_loss=10.062986373901367
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3024: train_loss=10.064498901367188
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3025: train_loss=10.06140422821045
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3026: train_loss=10.061493873596191
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3027: train_loss=10.063231468200684
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3028: train_loss=10.061315536499023
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3029: train_loss=10.060463905334473
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3030: train_loss=10.061776161193848
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3031: train_loss=10.060477256774902
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3032: train_loss=10.0607271194458
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3033: train_loss=10.061387062072754
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3034: train_loss=10.05837631225586
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3035: train_loss=10.062261581420898
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3036: train_loss=10.06198787689209
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3037: train_loss=10.059381484985352
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3038: train_loss=10.060297012329102
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3039: train_loss=10.059998512268066
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3040: train_loss=10.059707641601562
INFO - 04/15/25 16:42:00 - 0:10:23 - Epoch 3041: train_loss=10.059685707092285
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3042: train_loss=10.059693336486816
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3043: train_loss=10.059247016906738
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3044: train_loss=10.060136795043945
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3045: train_loss=10.059173583984375
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3046: train_loss=10.061355590820312
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3047: train_loss=10.06109619140625
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3048: train_loss=10.05991268157959
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3049: train_loss=10.060149192810059
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3050: train_loss=10.059871673583984
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3051: train_loss=10.059798240661621
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3052: train_loss=10.05965805053711
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3053: train_loss=10.059638977050781
INFO - 04/15/25 16:42:00 - 0:10:24 - Epoch 3054: train_loss=10.059186935424805
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3055: train_loss=10.060571670532227
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3056: train_loss=10.059606552124023
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3057: train_loss=10.061271667480469
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3058: train_loss=10.061311721801758
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3059: train_loss=10.059544563293457
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3060: train_loss=10.060052871704102
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3061: train_loss=10.059645652770996
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3062: train_loss=10.059822082519531
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3063: train_loss=10.059332847595215
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3064: train_loss=10.060400009155273
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3065: train_loss=10.059792518615723
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3066: train_loss=10.060458183288574
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3067: train_loss=10.06028938293457
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3068: train_loss=10.059808731079102
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3069: train_loss=10.059738159179688
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3070: train_loss=10.059786796569824
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3071: train_loss=10.059611320495605
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3072: train_loss=10.059290885925293
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3073: train_loss=10.059992790222168
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3074: train_loss=10.058553695678711
INFO - 04/15/25 16:42:01 - 0:10:24 - Epoch 3075: train_loss=10.06182861328125
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3076: train_loss=10.061155319213867
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3077: train_loss=10.060026168823242
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3078: train_loss=10.060091972351074
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3079: train_loss=10.060213088989258
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3080: train_loss=10.059724807739258
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3081: train_loss=10.06083869934082
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3082: train_loss=10.060356140136719
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3083: train_loss=10.060527801513672
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3084: train_loss=10.060514450073242
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3085: train_loss=10.059812545776367
INFO - 04/15/25 16:42:01 - 0:10:25 - Epoch 3086: train_loss=10.059427261352539
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3087: train_loss=10.061227798461914
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3088: train_loss=10.060955047607422
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3089: train_loss=10.059672355651855
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3090: train_loss=10.059442520141602
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3091: train_loss=10.06093692779541
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3092: train_loss=10.060694694519043
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3093: train_loss=10.059876441955566
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3094: train_loss=10.059528350830078
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3095: train_loss=10.060901641845703
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3096: train_loss=10.060516357421875
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3097: train_loss=10.059917449951172
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3098: train_loss=10.059596061706543
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3099: train_loss=10.060922622680664
INFO - 04/15/25 16:42:02 - 0:10:25 - Epoch 3100: train_loss=10.06060791015625
INFO - 04/15/25 16:42:02 - 0:10:25 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:02 - 0:10:25 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3100: ACC: 0.0, NMI: 0.10879057914058507, F1: 0.0, ARI: 0.012331835513253253
INFO - 04/15/25 16:42:03 - 0:10:26 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3101: train_loss=10.05976390838623
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3102: train_loss=10.059504508972168
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3103: train_loss=10.060893058776855
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3104: train_loss=10.060603141784668
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3105: train_loss=10.059865951538086
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3106: train_loss=10.059576988220215
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3107: train_loss=10.060608863830566
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3108: train_loss=10.060162544250488
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3109: train_loss=10.060304641723633
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3110: train_loss=10.06011962890625
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3111: train_loss=10.06017780303955
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3112: train_loss=10.059830665588379
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3113: train_loss=10.060430526733398
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3114: train_loss=10.06009292602539
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3115: train_loss=10.060335159301758
INFO - 04/15/25 16:42:03 - 0:10:26 - Epoch 3116: train_loss=10.060042381286621
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3117: train_loss=10.060256004333496
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3118: train_loss=10.059913635253906
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3119: train_loss=10.060296058654785
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3120: train_loss=10.060033798217773
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3121: train_loss=10.060283660888672
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3122: train_loss=10.060111999511719
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3123: train_loss=10.0601224899292
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3124: train_loss=10.059922218322754
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3125: train_loss=10.0603666305542
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3126: train_loss=10.060026168823242
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3127: train_loss=10.060270309448242
INFO - 04/15/25 16:42:03 - 0:10:27 - Epoch 3128: train_loss=10.059998512268066
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3129: train_loss=10.060184478759766
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3130: train_loss=10.059856414794922
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3131: train_loss=10.06031322479248
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3132: train_loss=10.060118675231934
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3133: train_loss=10.060018539428711
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3134: train_loss=10.05958366394043
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3135: train_loss=10.060708999633789
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3136: train_loss=10.060492515563965
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3137: train_loss=10.059479713439941
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3138: train_loss=10.059147834777832
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3139: train_loss=10.061224937438965
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3140: train_loss=10.061152458190918
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3141: train_loss=10.058710098266602
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3142: train_loss=10.057990074157715
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3143: train_loss=10.06283187866211
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3144: train_loss=10.063323974609375
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3145: train_loss=10.058969497680664
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3146: train_loss=10.064733505249023
INFO - 04/15/25 16:42:04 - 0:10:27 - Epoch 3147: train_loss=10.067591667175293
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3148: train_loss=10.065339088439941
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3149: train_loss=10.058711051940918
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3150: train_loss=10.06694507598877
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3151: train_loss=10.07149887084961
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3152: train_loss=10.07082462310791
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3153: train_loss=10.065573692321777
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3154: train_loss=10.059868812561035
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3155: train_loss=10.064212799072266
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3156: train_loss=10.064571380615234
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3157: train_loss=10.061605453491211
INFO - 04/15/25 16:42:04 - 0:10:28 - Epoch 3158: train_loss=10.062175750732422
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3159: train_loss=10.063202857971191
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3160: train_loss=10.061129570007324
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3161: train_loss=10.061986923217773
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3162: train_loss=10.062464714050293
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3163: train_loss=10.059894561767578
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3164: train_loss=10.06222152709961
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3165: train_loss=10.062814712524414
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3166: train_loss=10.059667587280273
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3167: train_loss=10.062576293945312
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3168: train_loss=10.06368350982666
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3169: train_loss=10.060738563537598
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3170: train_loss=10.061992645263672
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3171: train_loss=10.063541412353516
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3172: train_loss=10.060941696166992
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3173: train_loss=10.0614595413208
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3174: train_loss=10.062920570373535
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3175: train_loss=10.060269355773926
INFO - 04/15/25 16:42:05 - 0:10:28 - Epoch 3176: train_loss=10.061941146850586
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3177: train_loss=10.063455581665039
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3178: train_loss=10.060598373413086
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3179: train_loss=10.061710357666016
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3180: train_loss=10.063456535339355
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3181: train_loss=10.060687065124512
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3182: train_loss=10.061454772949219
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3183: train_loss=10.063193321228027
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3184: train_loss=10.060493469238281
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3185: train_loss=10.061490058898926
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3186: train_loss=10.063217163085938
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3187: train_loss=10.060362815856934
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3188: train_loss=10.06173038482666
INFO - 04/15/25 16:42:05 - 0:10:29 - Epoch 3189: train_loss=10.063506126403809
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3190: train_loss=10.060794830322266
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3191: train_loss=10.061171531677246
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3192: train_loss=10.062797546386719
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3193: train_loss=10.05999755859375
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3194: train_loss=10.062077522277832
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3195: train_loss=10.063834190368652
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3196: train_loss=10.061269760131836
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3197: train_loss=10.060615539550781
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3198: train_loss=10.062241554260254
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3199: train_loss=10.059489250183105
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3200: train_loss=10.062416076660156
INFO - 04/15/25 16:42:06 - 0:10:29 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:06 - 0:10:29 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3200: ACC: 0.0, NMI: 0.2945410154714062, F1: 0.0, ARI: 0.13376528240691354
INFO - 04/15/25 16:42:06 - 0:10:29 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:06 - 0:10:29 - Epoch 3201: train_loss=10.064131736755371
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3202: train_loss=10.061416625976562
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3203: train_loss=10.060401916503906
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3204: train_loss=10.062151908874512
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3205: train_loss=10.059494972229004
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3206: train_loss=10.06222915649414
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3207: train_loss=10.06387710571289
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3208: train_loss=10.061202049255371
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3209: train_loss=10.060636520385742
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3210: train_loss=10.062326431274414
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3211: train_loss=10.0596342086792
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3212: train_loss=10.062114715576172
INFO - 04/15/25 16:42:06 - 0:10:30 - Epoch 3213: train_loss=10.063860893249512
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3214: train_loss=10.061309814453125
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3215: train_loss=10.0603666305542
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3216: train_loss=10.062068939208984
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3217: train_loss=10.059382438659668
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3218: train_loss=10.062332153320312
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3219: train_loss=10.064007759094238
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3220: train_loss=10.061450958251953
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3221: train_loss=10.060274124145508
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3222: train_loss=10.061853408813477
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3223: train_loss=10.059364318847656
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3224: train_loss=10.06225299835205
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3225: train_loss=10.063712120056152
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3226: train_loss=10.061079025268555
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3227: train_loss=10.060644149780273
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3228: train_loss=10.062334060668945
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3229: train_loss=10.060096740722656
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3230: train_loss=10.061480522155762
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3231: train_loss=10.062840461730957
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3232: train_loss=10.060298919677734
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3233: train_loss=10.061250686645508
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3234: train_loss=10.062688827514648
INFO - 04/15/25 16:42:07 - 0:10:30 - Epoch 3235: train_loss=10.060049057006836
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3236: train_loss=10.061622619628906
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3237: train_loss=10.06317138671875
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3238: train_loss=10.060757637023926
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3239: train_loss=10.060791015625
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3240: train_loss=10.062270164489746
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3241: train_loss=10.059894561767578
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3242: train_loss=10.061578750610352
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3243: train_loss=10.062956809997559
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3244: train_loss=10.060425758361816
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3245: train_loss=10.061169624328613
INFO - 04/15/25 16:42:07 - 0:10:31 - Epoch 3246: train_loss=10.062833786010742
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3247: train_loss=10.060357093811035
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3248: train_loss=10.061070442199707
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3249: train_loss=10.062573432922363
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3250: train_loss=10.06009578704834
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3251: train_loss=10.061379432678223
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3252: train_loss=10.063009262084961
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3253: train_loss=10.060555458068848
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3254: train_loss=10.060893058776855
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3255: train_loss=10.0624418258667
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3256: train_loss=10.059971809387207
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3257: train_loss=10.06141185760498
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3258: train_loss=10.062941551208496
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3259: train_loss=10.060453414916992
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3260: train_loss=10.060973167419434
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3261: train_loss=10.062579154968262
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3262: train_loss=10.060257911682129
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3263: train_loss=10.061003684997559
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3264: train_loss=10.062479019165039
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3265: train_loss=10.059891700744629
INFO - 04/15/25 16:42:08 - 0:10:31 - Epoch 3266: train_loss=10.061535835266113
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3267: train_loss=10.063212394714355
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3268: train_loss=10.060868263244629
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3269: train_loss=10.060248374938965
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3270: train_loss=10.061681747436523
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3271: train_loss=10.059117317199707
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3272: train_loss=10.062284469604492
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3273: train_loss=10.0640869140625
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3274: train_loss=10.061781883239746
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3275: train_loss=10.059353828430176
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3276: train_loss=10.060800552368164
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3277: train_loss=10.058501243591309
INFO - 04/15/25 16:42:08 - 0:10:32 - Epoch 3278: train_loss=10.062243461608887
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3279: train_loss=10.06332015991211
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3280: train_loss=10.060689926147461
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3281: train_loss=10.060805320739746
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3282: train_loss=10.062392234802246
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3283: train_loss=10.06041145324707
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3284: train_loss=10.060683250427246
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3285: train_loss=10.061775207519531
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3286: train_loss=10.059650421142578
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3287: train_loss=10.061273574829102
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3288: train_loss=10.062151908874512
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3289: train_loss=10.059715270996094
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3290: train_loss=10.061446189880371
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3291: train_loss=10.062417984008789
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3292: train_loss=10.060256004333496
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3293: train_loss=10.061139106750488
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3294: train_loss=10.061999320983887
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3295: train_loss=10.059788703918457
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3296: train_loss=10.061233520507812
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3297: train_loss=10.061995506286621
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3298: train_loss=10.059675216674805
INFO - 04/15/25 16:42:09 - 0:10:32 - Epoch 3299: train_loss=10.061422348022461
INFO - 04/15/25 16:42:09 - 0:10:33 - Epoch 3300: train_loss=10.062296867370605
INFO - 04/15/25 16:42:09 - 0:10:33 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:09 - 0:10:33 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:42:09 - 0:10:33 - Epoch 3300: ACC: 0.0, NMI: 0.38862013837555764, F1: 0.0, ARI: 0.1808150214467769
INFO - 04/15/25 16:42:09 - 0:10:33 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:09 - 0:10:33 - Epoch 3301: train_loss=10.05986213684082
INFO - 04/15/25 16:42:09 - 0:10:33 - Epoch 3302: train_loss=10.061457633972168
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3303: train_loss=10.062487602233887
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3304: train_loss=10.060166358947754
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3305: train_loss=10.0611572265625
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3306: train_loss=10.062339782714844
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3307: train_loss=10.06003475189209
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3308: train_loss=10.061198234558105
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3309: train_loss=10.06260871887207
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3310: train_loss=10.06032657623291
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3311: train_loss=10.060883522033691
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3312: train_loss=10.062239646911621
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3313: train_loss=10.059895515441895
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3314: train_loss=10.061128616333008
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3315: train_loss=10.062610626220703
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3316: train_loss=10.060304641723633
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3317: train_loss=10.06069278717041
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3318: train_loss=10.06210708618164
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3319: train_loss=10.059799194335938
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3320: train_loss=10.06128215789795
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3321: train_loss=10.062779426574707
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3322: train_loss=10.060571670532227
INFO - 04/15/25 16:42:10 - 0:10:33 - Epoch 3323: train_loss=10.0604248046875
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3324: train_loss=10.061813354492188
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3325: train_loss=10.05941104888916
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3326: train_loss=10.061631202697754
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3327: train_loss=10.063220977783203
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3328: train_loss=10.061015129089355
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3329: train_loss=10.059844017028809
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3330: train_loss=10.061286926269531
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3331: train_loss=10.05903434753418
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3332: train_loss=10.061808586120605
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3333: train_loss=10.063074111938477
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3334: train_loss=10.060735702514648
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3335: train_loss=10.06029224395752
INFO - 04/15/25 16:42:10 - 0:10:34 - Epoch 3336: train_loss=10.061805725097656
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3337: train_loss=10.05964469909668
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3338: train_loss=10.061148643493652
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3339: train_loss=10.062378883361816
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3340: train_loss=10.060035705566406
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3341: train_loss=10.060942649841309
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3342: train_loss=10.062356948852539
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3343: train_loss=10.06013011932373
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3344: train_loss=10.060770988464355
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3345: train_loss=10.062226295471191
INFO - 04/15/25 16:42:11 - 0:10:34 - Epoch 3346: train_loss=10.060050010681152
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3347: train_loss=10.060789108276367
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3348: train_loss=10.06210994720459
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3349: train_loss=10.059776306152344
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3350: train_loss=10.0610933303833
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3351: train_loss=10.062536239624023
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3352: train_loss=10.060343742370605
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3353: train_loss=10.06042194366455
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3354: train_loss=10.061789512634277
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3355: train_loss=10.05952262878418
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3356: train_loss=10.061314582824707
INFO - 04/15/25 16:42:11 - 0:10:35 - Epoch 3357: train_loss=10.062694549560547
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3358: train_loss=10.060539245605469
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3359: train_loss=10.060253143310547
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3360: train_loss=10.061580657958984
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3361: train_loss=10.05928897857666
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3362: train_loss=10.061564445495605
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3363: train_loss=10.06297492980957
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3364: train_loss=10.060969352722168
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3365: train_loss=10.059727668762207
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3366: train_loss=10.060972213745117
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3367: train_loss=10.059036254882812
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3368: train_loss=10.06148910522461
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3369: train_loss=10.062082290649414
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3370: train_loss=10.0602388381958
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3371: train_loss=10.06114387512207
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3372: train_loss=10.061772346496582
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3373: train_loss=10.060553550720215
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3374: train_loss=10.060563087463379
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3375: train_loss=10.060824394226074
INFO - 04/15/25 16:42:12 - 0:10:35 - Epoch 3376: train_loss=10.059807777404785
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3377: train_loss=10.061498641967773
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3378: train_loss=10.060782432556152
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3379: train_loss=10.06081771850586
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3380: train_loss=10.060951232910156
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3381: train_loss=10.06042766571045
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3382: train_loss=10.06109619140625
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3383: train_loss=10.060809135437012
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3384: train_loss=10.060860633850098
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3385: train_loss=10.060022354125977
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3386: train_loss=10.059679985046387
INFO - 04/15/25 16:42:12 - 0:10:36 - Epoch 3387: train_loss=10.060039520263672
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3388: train_loss=10.061068534851074
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3389: train_loss=10.059027671813965
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3390: train_loss=10.063323974609375
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3391: train_loss=10.06269645690918
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3392: train_loss=10.062195777893066
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3393: train_loss=10.061110496520996
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3394: train_loss=10.062886238098145
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3395: train_loss=10.063100814819336
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3396: train_loss=10.060017585754395
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3397: train_loss=10.060502052307129
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3398: train_loss=10.061317443847656
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3399: train_loss=10.059418678283691
INFO - 04/15/25 16:42:13 - 0:10:36 - Epoch 3400: train_loss=10.063106536865234
INFO - 04/15/25 16:42:13 - 0:10:36 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:13 - 0:10:36 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3400: ACC: 0.0, NMI: 0.06132518947453587, F1: 0.0, ARI: 0.004459841470157862
INFO - 04/15/25 16:42:13 - 0:10:37 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3401: train_loss=10.062301635742188
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3402: train_loss=10.061492919921875
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3403: train_loss=10.06132984161377
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3404: train_loss=10.061698913574219
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3405: train_loss=10.061121940612793
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3406: train_loss=10.061566352844238
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3407: train_loss=10.06131362915039
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3408: train_loss=10.061264991760254
INFO - 04/15/25 16:42:13 - 0:10:37 - Epoch 3409: train_loss=10.060272216796875
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3410: train_loss=10.062569618225098
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3411: train_loss=10.06202507019043
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3412: train_loss=10.06082534790039
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3413: train_loss=10.060734748840332
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3414: train_loss=10.061197280883789
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3415: train_loss=10.060322761535645
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3416: train_loss=10.062288284301758
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3417: train_loss=10.06187915802002
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3418: train_loss=10.060608863830566
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3419: train_loss=10.060586929321289
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3420: train_loss=10.061001777648926
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3421: train_loss=10.060198783874512
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3422: train_loss=10.061898231506348
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3423: train_loss=10.0614013671875
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3424: train_loss=10.060887336730957
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3425: train_loss=10.060794830322266
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3426: train_loss=10.060789108276367
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3427: train_loss=10.06020736694336
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3428: train_loss=10.061711311340332
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3429: train_loss=10.061402320861816
INFO - 04/15/25 16:42:14 - 0:10:37 - Epoch 3430: train_loss=10.060359954833984
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3431: train_loss=10.060091018676758
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3432: train_loss=10.061529159545898
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3433: train_loss=10.06113052368164
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3434: train_loss=10.060688018798828
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3435: train_loss=10.060341835021973
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3436: train_loss=10.061304092407227
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3437: train_loss=10.060973167419434
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3438: train_loss=10.060630798339844
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3439: train_loss=10.060224533081055
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3440: train_loss=10.0614013671875
INFO - 04/15/25 16:42:14 - 0:10:38 - Epoch 3441: train_loss=10.06110668182373
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3442: train_loss=10.060324668884277
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3443: train_loss=10.05985164642334
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3444: train_loss=10.061677932739258
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3445: train_loss=10.061452865600586
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3446: train_loss=10.059864044189453
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3447: train_loss=10.059484481811523
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3448: train_loss=10.061895370483398
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3449: train_loss=10.061567306518555
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3450: train_loss=10.059833526611328
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3451: train_loss=10.059525489807129
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3452: train_loss=10.061721801757812
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3453: train_loss=10.061358451843262
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3454: train_loss=10.060018539428711
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3455: train_loss=10.059749603271484
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3456: train_loss=10.061461448669434
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3457: train_loss=10.061012268066406
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3458: train_loss=10.060184478759766
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3459: train_loss=10.059897422790527
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3460: train_loss=10.061245918273926
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3461: train_loss=10.060904502868652
INFO - 04/15/25 16:42:15 - 0:10:38 - Epoch 3462: train_loss=10.06020450592041
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3463: train_loss=10.059919357299805
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3464: train_loss=10.061092376708984
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3465: train_loss=10.060713768005371
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3466: train_loss=10.06036376953125
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3467: train_loss=10.060047149658203
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3468: train_loss=10.06084156036377
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3469: train_loss=10.060434341430664
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3470: train_loss=10.06058406829834
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3471: train_loss=10.060281753540039
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3472: train_loss=10.06054973602295
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3473: train_loss=10.060242652893066
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3474: train_loss=10.06054973602295
INFO - 04/15/25 16:42:15 - 0:10:39 - Epoch 3475: train_loss=10.060202598571777
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3476: train_loss=10.060688018798828
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3477: train_loss=10.060476303100586
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3478: train_loss=10.060247421264648
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3479: train_loss=10.059947967529297
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3480: train_loss=10.060812950134277
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3481: train_loss=10.060505867004395
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3482: train_loss=10.06016731262207
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3483: train_loss=10.059823989868164
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3484: train_loss=10.060759544372559
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3485: train_loss=10.06045150756836
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3486: train_loss=10.060127258300781
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3487: train_loss=10.05986499786377
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3488: train_loss=10.060623168945312
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3489: train_loss=10.060282707214355
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3490: train_loss=10.06030559539795
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3491: train_loss=10.060018539428711
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3492: train_loss=10.060441017150879
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3493: train_loss=10.060218811035156
INFO - 04/15/25 16:42:16 - 0:10:39 - Epoch 3494: train_loss=10.060186386108398
INFO - 04/15/25 16:42:16 - 0:10:40 - Epoch 3495: train_loss=10.059881210327148
INFO - 04/15/25 16:42:16 - 0:10:40 - Epoch 3496: train_loss=10.060482025146484
INFO - 04/15/25 16:42:16 - 0:10:40 - Epoch 3497: train_loss=10.060225486755371
INFO - 04/15/25 16:42:16 - 0:10:40 - Epoch 3498: train_loss=10.059996604919434
INFO - 04/15/25 16:42:16 - 0:10:40 - Epoch 3499: train_loss=10.059645652770996
INFO - 04/15/25 16:42:16 - 0:10:40 - Epoch 3500: train_loss=10.060620307922363
INFO - 04/15/25 16:42:16 - 0:10:40 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:16 - 0:10:40 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3500: ACC: 0.0, NMI: 0.27265232250141475, F1: 0.0, ARI: 0.11467684214568505
INFO - 04/15/25 16:42:17 - 0:10:40 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3501: train_loss=10.060406684875488
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3502: train_loss=10.059775352478027
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3503: train_loss=10.059471130371094
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3504: train_loss=10.06067180633545
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3505: train_loss=10.060479164123535
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3506: train_loss=10.059576034545898
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3507: train_loss=10.059322357177734
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3508: train_loss=10.060932159423828
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3509: train_loss=10.06069564819336
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3510: train_loss=10.059263229370117
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3511: train_loss=10.05906867980957
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3512: train_loss=10.060869216918945
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3513: train_loss=10.06045150756836
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3514: train_loss=10.059609413146973
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3515: train_loss=10.059500694274902
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3516: train_loss=10.060330390930176
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3517: train_loss=10.059866905212402
INFO - 04/15/25 16:42:17 - 0:10:40 - Epoch 3518: train_loss=10.06026554107666
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3519: train_loss=10.060145378112793
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3520: train_loss=10.05958366394043
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3521: train_loss=10.059239387512207
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3522: train_loss=10.060603141784668
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3523: train_loss=10.060359954833984
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3524: train_loss=10.059484481811523
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3525: train_loss=10.059396743774414
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3526: train_loss=10.060218811035156
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3527: train_loss=10.059752464294434
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3528: train_loss=10.060246467590332
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3529: train_loss=10.060211181640625
INFO - 04/15/25 16:42:17 - 0:10:41 - Epoch 3530: train_loss=10.059266090393066
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3531: train_loss=10.059333801269531
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3532: train_loss=10.060614585876465
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3533: train_loss=10.05980396270752
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3534: train_loss=10.060839653015137
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3535: train_loss=10.060694694519043
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3536: train_loss=10.059866905212402
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3537: train_loss=10.061219215393066
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3538: train_loss=10.060382843017578
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3539: train_loss=10.06131362915039
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3540: train_loss=10.061360359191895
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3541: train_loss=10.06023120880127
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3542: train_loss=10.060141563415527
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3543: train_loss=10.0604248046875
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3544: train_loss=10.05951976776123
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3545: train_loss=10.059059143066406
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3546: train_loss=10.062117576599121
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3547: train_loss=10.061482429504395
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3548: train_loss=10.060636520385742
INFO - 04/15/25 16:42:18 - 0:10:41 - Epoch 3549: train_loss=10.060336112976074
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3550: train_loss=10.061188697814941
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3551: train_loss=10.059916496276855
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3552: train_loss=10.062712669372559
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3553: train_loss=10.062260627746582
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3554: train_loss=10.060188293457031
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3555: train_loss=10.060287475585938
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3556: train_loss=10.061362266540527
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3557: train_loss=10.060535430908203
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3558: train_loss=10.061994552612305
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3559: train_loss=10.062042236328125
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3560: train_loss=10.059566497802734
INFO - 04/15/25 16:42:18 - 0:10:42 - Epoch 3561: train_loss=10.059317588806152
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3562: train_loss=10.061461448669434
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3563: train_loss=10.060016632080078
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3564: train_loss=10.06251335144043
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3565: train_loss=10.062516212463379
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3566: train_loss=10.059524536132812
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3567: train_loss=10.060269355773926
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3568: train_loss=10.0603609085083
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3569: train_loss=10.059053421020508
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3570: train_loss=10.062520980834961
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3571: train_loss=10.061838150024414
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3572: train_loss=10.06000804901123
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3573: train_loss=10.059959411621094
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3574: train_loss=10.061415672302246
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3575: train_loss=10.061009407043457
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3576: train_loss=10.060623168945312
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3577: train_loss=10.06025218963623
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3578: train_loss=10.061261177062988
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3579: train_loss=10.061006546020508
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3580: train_loss=10.060324668884277
INFO - 04/15/25 16:42:19 - 0:10:42 - Epoch 3581: train_loss=10.059894561767578
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3582: train_loss=10.06164264678955
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3583: train_loss=10.061469078063965
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3584: train_loss=10.059626579284668
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3585: train_loss=10.05911922454834
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3586: train_loss=10.062333106994629
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3587: train_loss=10.062211990356445
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3588: train_loss=10.058832168579102
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3589: train_loss=10.058420181274414
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3590: train_loss=10.062464714050293
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3591: train_loss=10.06199836730957
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3592: train_loss=10.059504508972168
INFO - 04/15/25 16:42:19 - 0:10:43 - Epoch 3593: train_loss=10.059931755065918
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3594: train_loss=10.05994701385498
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3595: train_loss=10.05921459197998
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3596: train_loss=10.060331344604492
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3597: train_loss=10.059257507324219
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3598: train_loss=10.060290336608887
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3599: train_loss=10.059770584106445
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3600: train_loss=10.059916496276855
INFO - 04/15/25 16:42:20 - 0:10:43 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:20 - 0:10:43 - Decoding cost time:  0.131 s
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3600: ACC: 0.0, NMI: 0.37510828357305714, F1: 0.0, ARI: 0.17479015016429433
INFO - 04/15/25 16:42:20 - 0:10:43 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3601: train_loss=10.05984115600586
INFO - 04/15/25 16:42:20 - 0:10:43 - Epoch 3602: train_loss=10.059427261352539
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3603: train_loss=10.05935287475586
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3604: train_loss=10.060160636901855
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3605: train_loss=10.059183120727539
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3606: train_loss=10.061555862426758
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3607: train_loss=10.061565399169922
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3608: train_loss=10.059110641479492
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3609: train_loss=10.060687065124512
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3610: train_loss=10.059887886047363
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3611: train_loss=10.060460090637207
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3612: train_loss=10.060687065124512
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3613: train_loss=10.059024810791016
INFO - 04/15/25 16:42:20 - 0:10:44 - Epoch 3614: train_loss=10.05936050415039
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3615: train_loss=10.058971405029297
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3616: train_loss=10.058341026306152
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3617: train_loss=10.061492919921875
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3618: train_loss=10.060172080993652
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3619: train_loss=10.06164264678955
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3620: train_loss=10.061941146850586
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3621: train_loss=10.05944538116455
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3622: train_loss=10.06102466583252
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3623: train_loss=10.060123443603516
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3624: train_loss=10.060755729675293
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3625: train_loss=10.060505867004395
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3626: train_loss=10.060199737548828
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3627: train_loss=10.060291290283203
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3628: train_loss=10.059822082519531
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3629: train_loss=10.060843467712402
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3630: train_loss=10.060112953186035
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3631: train_loss=10.060917854309082
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3632: train_loss=10.060803413391113
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3633: train_loss=10.060213088989258
INFO - 04/15/25 16:42:21 - 0:10:44 - Epoch 3634: train_loss=10.06018352508545
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3635: train_loss=10.059942245483398
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3636: train_loss=10.060317993164062
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3637: train_loss=10.059497833251953
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3638: train_loss=10.0609769821167
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3639: train_loss=10.06047534942627
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3640: train_loss=10.060417175292969
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3641: train_loss=10.060267448425293
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3642: train_loss=10.060093879699707
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3643: train_loss=10.06029224395752
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3644: train_loss=10.059575080871582
INFO - 04/15/25 16:42:21 - 0:10:45 - Epoch 3645: train_loss=10.06119155883789
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3646: train_loss=10.060760498046875
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3647: train_loss=10.060384750366211
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3648: train_loss=10.060145378112793
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3649: train_loss=10.060324668884277
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3650: train_loss=10.059782981872559
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3651: train_loss=10.05971622467041
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3652: train_loss=10.060513496398926
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3653: train_loss=10.059545516967773
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3654: train_loss=10.06180477142334
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3655: train_loss=10.061714172363281
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3656: train_loss=10.05993366241455
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3657: train_loss=10.060420036315918
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3658: train_loss=10.060367584228516
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3659: train_loss=10.05937385559082
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3660: train_loss=10.060248374938965
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3661: train_loss=10.05897045135498
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3662: train_loss=10.059964179992676
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3663: train_loss=10.05886173248291
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3664: train_loss=10.060194969177246
INFO - 04/15/25 16:42:22 - 0:10:45 - Epoch 3665: train_loss=10.059051513671875
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3666: train_loss=10.06065845489502
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3667: train_loss=10.060385704040527
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3668: train_loss=10.059346199035645
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3669: train_loss=10.06036376953125
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3670: train_loss=10.05838394165039
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3671: train_loss=10.063024520874023
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3672: train_loss=10.06266975402832
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3673: train_loss=10.059019088745117
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3674: train_loss=10.060748100280762
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3675: train_loss=10.059675216674805
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3676: train_loss=10.06071662902832
INFO - 04/15/25 16:42:22 - 0:10:46 - Epoch 3677: train_loss=10.060585975646973
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3678: train_loss=10.059535026550293
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3679: train_loss=10.059652328491211
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3680: train_loss=10.059896469116211
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3681: train_loss=10.059142112731934
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3682: train_loss=10.061206817626953
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3683: train_loss=10.060988426208496
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3684: train_loss=10.059158325195312
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3685: train_loss=10.059929847717285
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3686: train_loss=10.058610916137695
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3687: train_loss=10.060198783874512
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3688: train_loss=10.058587074279785
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3689: train_loss=10.060630798339844
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3690: train_loss=10.059591293334961
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3691: train_loss=10.060882568359375
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3692: train_loss=10.060759544372559
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3693: train_loss=10.05953598022461
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3694: train_loss=10.060210227966309
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3695: train_loss=10.058905601501465
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3696: train_loss=10.061748504638672
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3697: train_loss=10.061018943786621
INFO - 04/15/25 16:42:23 - 0:10:46 - Epoch 3698: train_loss=10.060186386108398
INFO - 04/15/25 16:42:23 - 0:10:47 - Epoch 3699: train_loss=10.060225486755371
INFO - 04/15/25 16:42:23 - 0:10:47 - Epoch 3700: train_loss=10.060361862182617
INFO - 04/15/25 16:42:23 - 0:10:47 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:23 - 0:10:47 - Decoding cost time:  0.129 s
INFO - 04/15/25 16:42:23 - 0:10:47 - Epoch 3700: ACC: 0.0, NMI: 0.06642587411213696, F1: 0.0, ARI: 0.004024958704040917
INFO - 04/15/25 16:42:23 - 0:10:47 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3701: train_loss=10.059836387634277
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3702: train_loss=10.060911178588867
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3703: train_loss=10.06031322479248
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3704: train_loss=10.060873031616211
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3705: train_loss=10.060669898986816
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3706: train_loss=10.06035327911377
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3707: train_loss=10.059996604919434
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3708: train_loss=10.06095027923584
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3709: train_loss=10.060446739196777
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3710: train_loss=10.060747146606445
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3711: train_loss=10.060513496398926
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3712: train_loss=10.060331344604492
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3713: train_loss=10.0599365234375
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3714: train_loss=10.060872077941895
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3715: train_loss=10.060623168945312
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3716: train_loss=10.060211181640625
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3717: train_loss=10.059977531433105
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3718: train_loss=10.060735702514648
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3719: train_loss=10.060324668884277
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3720: train_loss=10.06060791015625
INFO - 04/15/25 16:42:24 - 0:10:47 - Epoch 3721: train_loss=10.06039810180664
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3722: train_loss=10.060259819030762
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3723: train_loss=10.059864044189453
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3724: train_loss=10.060935974121094
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3725: train_loss=10.060704231262207
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3726: train_loss=10.059931755065918
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3727: train_loss=10.059635162353516
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3728: train_loss=10.061163902282715
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3729: train_loss=10.06086254119873
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3730: train_loss=10.059735298156738
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3731: train_loss=10.059420585632324
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3732: train_loss=10.061229705810547
INFO - 04/15/25 16:42:24 - 0:10:48 - Epoch 3733: train_loss=10.06103515625
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3734: train_loss=10.059627532958984
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3735: train_loss=10.059316635131836
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3736: train_loss=10.061283111572266
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3737: train_loss=10.061006546020508
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3738: train_loss=10.059632301330566
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3739: train_loss=10.059308052062988
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3740: train_loss=10.061254501342773
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3741: train_loss=10.060945510864258
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3742: train_loss=10.059606552124023
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3743: train_loss=10.059247016906738
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3744: train_loss=10.061241149902344
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3745: train_loss=10.06090259552002
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3746: train_loss=10.059650421142578
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3747: train_loss=10.059306144714355
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3748: train_loss=10.061212539672852
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3749: train_loss=10.060835838317871
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3750: train_loss=10.05966854095459
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3751: train_loss=10.059377670288086
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3752: train_loss=10.060925483703613
INFO - 04/15/25 16:42:25 - 0:10:48 - Epoch 3753: train_loss=10.060460090637207
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3754: train_loss=10.060179710388184
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3755: train_loss=10.059975624084473
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3756: train_loss=10.060393333435059
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3757: train_loss=10.06004810333252
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3758: train_loss=10.060348510742188
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3759: train_loss=10.059967041015625
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3760: train_loss=10.06064510345459
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3761: train_loss=10.06041145324707
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3762: train_loss=10.059916496276855
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3763: train_loss=10.05943775177002
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3764: train_loss=10.061120986938477
INFO - 04/15/25 16:42:25 - 0:10:49 - Epoch 3765: train_loss=10.060983657836914
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3766: train_loss=10.059407234191895
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3767: train_loss=10.059168815612793
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3768: train_loss=10.060966491699219
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3769: train_loss=10.060447692871094
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3770: train_loss=10.060153007507324
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3771: train_loss=10.060041427612305
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3772: train_loss=10.060227394104004
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3773: train_loss=10.05986499786377
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3774: train_loss=10.060569763183594
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3775: train_loss=10.060261726379395
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3776: train_loss=10.060127258300781
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3777: train_loss=10.059952735900879
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3778: train_loss=10.060324668884277
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3779: train_loss=10.059778213500977
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3780: train_loss=10.06075382232666
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3781: train_loss=10.060535430908203
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3782: train_loss=10.059629440307617
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3783: train_loss=10.059351921081543
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3784: train_loss=10.060855865478516
INFO - 04/15/25 16:42:26 - 0:10:49 - Epoch 3785: train_loss=10.06043529510498
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3786: train_loss=10.05992317199707
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3787: train_loss=10.05972957611084
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3788: train_loss=10.060470581054688
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3789: train_loss=10.060132026672363
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3790: train_loss=10.060248374938965
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3791: train_loss=10.059855461120605
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3792: train_loss=10.060465812683105
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3793: train_loss=10.060263633728027
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3794: train_loss=10.059901237487793
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3795: train_loss=10.059614181518555
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3796: train_loss=10.06064224243164
INFO - 04/15/25 16:42:26 - 0:10:50 - Epoch 3797: train_loss=10.060267448425293
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3798: train_loss=10.059996604919434
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3799: train_loss=10.059803009033203
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3800: train_loss=10.06038761138916
INFO - 04/15/25 16:42:27 - 0:10:50 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:27 - 0:10:50 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3800: ACC: 0.0, NMI: 0.35100348059649905, F1: 0.0, ARI: 0.17139098760177376
INFO - 04/15/25 16:42:27 - 0:10:50 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3801: train_loss=10.059992790222168
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3802: train_loss=10.060335159301758
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3803: train_loss=10.060072898864746
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3804: train_loss=10.060138702392578
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3805: train_loss=10.059807777404785
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3806: train_loss=10.060404777526855
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3807: train_loss=10.060033798217773
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3808: train_loss=10.060285568237305
INFO - 04/15/25 16:42:27 - 0:10:50 - Epoch 3809: train_loss=10.0601167678833
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3810: train_loss=10.059982299804688
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3811: train_loss=10.059696197509766
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3812: train_loss=10.060656547546387
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3813: train_loss=10.060442924499512
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3814: train_loss=10.059648513793945
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3815: train_loss=10.059186935424805
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3816: train_loss=10.061080932617188
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3817: train_loss=10.060982704162598
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3818: train_loss=10.059094429016113
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3819: train_loss=10.058823585510254
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3820: train_loss=10.061114311218262
INFO - 04/15/25 16:42:27 - 0:10:51 - Epoch 3821: train_loss=10.060674667358398
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3822: train_loss=10.059663772583008
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3823: train_loss=10.059572219848633
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3824: train_loss=10.0604248046875
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3825: train_loss=10.060079574584961
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3826: train_loss=10.060038566589355
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3827: train_loss=10.059751510620117
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3828: train_loss=10.060359001159668
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3829: train_loss=10.060114860534668
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3830: train_loss=10.05988597869873
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3831: train_loss=10.059578895568848
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3832: train_loss=10.060479164123535
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3833: train_loss=10.06017017364502
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3834: train_loss=10.059781074523926
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3835: train_loss=10.059511184692383
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3836: train_loss=10.060514450073242
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3837: train_loss=10.060090065002441
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3838: train_loss=10.059945106506348
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3839: train_loss=10.059688568115234
INFO - 04/15/25 16:42:28 - 0:10:51 - Epoch 3840: train_loss=10.060319900512695
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3841: train_loss=10.060007095336914
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3842: train_loss=10.060022354125977
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3843: train_loss=10.05984115600586
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3844: train_loss=10.060018539428711
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3845: train_loss=10.059646606445312
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3846: train_loss=10.060362815856934
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3847: train_loss=10.060066223144531
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3848: train_loss=10.059854507446289
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3849: train_loss=10.059711456298828
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3850: train_loss=10.059979438781738
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3851: train_loss=10.059555053710938
INFO - 04/15/25 16:42:28 - 0:10:52 - Epoch 3852: train_loss=10.060436248779297
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3853: train_loss=10.060161590576172
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3854: train_loss=10.059649467468262
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3855: train_loss=10.059453964233398
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3856: train_loss=10.060163497924805
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3857: train_loss=10.059741020202637
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3858: train_loss=10.060078620910645
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3859: train_loss=10.059810638427734
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3860: train_loss=10.059906959533691
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3861: train_loss=10.059667587280273
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3862: train_loss=10.060015678405762
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3863: train_loss=10.059774398803711
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3864: train_loss=10.060002326965332
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3865: train_loss=10.059723854064941
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3866: train_loss=10.059986114501953
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3867: train_loss=10.059659004211426
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3868: train_loss=10.060037612915039
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3869: train_loss=10.059944152832031
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3870: train_loss=10.059730529785156
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3871: train_loss=10.059514045715332
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3872: train_loss=10.06000804901123
INFO - 04/15/25 16:42:29 - 0:10:52 - Epoch 3873: train_loss=10.059701919555664
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3874: train_loss=10.05992317199707
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3875: train_loss=10.059627532958984
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3876: train_loss=10.059998512268066
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3877: train_loss=10.059806823730469
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3878: train_loss=10.059659004211426
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3879: train_loss=10.059364318847656
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3880: train_loss=10.060213088989258
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3881: train_loss=10.059924125671387
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3882: train_loss=10.059514999389648
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3883: train_loss=10.059273719787598
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3884: train_loss=10.060208320617676
INFO - 04/15/25 16:42:29 - 0:10:53 - Epoch 3885: train_loss=10.059943199157715
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3886: train_loss=10.059450149536133
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3887: train_loss=10.059233665466309
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3888: train_loss=10.060107231140137
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3889: train_loss=10.059747695922852
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3890: train_loss=10.05963134765625
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3891: train_loss=10.059401512145996
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3892: train_loss=10.059974670410156
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3893: train_loss=10.059754371643066
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3894: train_loss=10.05954647064209
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3895: train_loss=10.059237480163574
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3896: train_loss=10.060242652893066
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3897: train_loss=10.060160636901855
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3898: train_loss=10.059006690979004
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3899: train_loss=10.05861759185791
INFO - 04/15/25 16:42:30 - 0:10:53 - Epoch 3900: train_loss=10.060778617858887
INFO - 04/15/25 16:42:30 - 0:10:53 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:30 - 0:10:53 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3900: ACC: 0.0, NMI: 0.3512558576061635, F1: 0.0, ARI: 0.17164614743195286
INFO - 04/15/25 16:42:30 - 0:10:54 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3901: train_loss=10.060681343078613
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3902: train_loss=10.058526039123535
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3903: train_loss=10.058204650878906
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3904: train_loss=10.061263084411621
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3905: train_loss=10.0612211227417
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3906: train_loss=10.057960510253906
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3907: train_loss=10.0614013671875
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3908: train_loss=10.059743881225586
INFO - 04/15/25 16:42:30 - 0:10:54 - Epoch 3909: train_loss=10.061751365661621
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3910: train_loss=10.061860084533691
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3911: train_loss=10.060216903686523
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3912: train_loss=10.060504913330078
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3913: train_loss=10.061017036437988
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3914: train_loss=10.05936336517334
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3915: train_loss=10.062352180480957
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3916: train_loss=10.062435150146484
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3917: train_loss=10.059417724609375
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3918: train_loss=10.061018943786621
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3919: train_loss=10.060827255249023
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3920: train_loss=10.05968189239502
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3921: train_loss=10.061159133911133
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3922: train_loss=10.060566902160645
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3923: train_loss=10.060514450073242
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3924: train_loss=10.060226440429688
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3925: train_loss=10.060542106628418
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3926: train_loss=10.059906959533691
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3927: train_loss=10.060683250427246
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3928: train_loss=10.059649467468262
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3929: train_loss=10.061348915100098
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3930: train_loss=10.060169219970703
INFO - 04/15/25 16:42:31 - 0:10:54 - Epoch 3931: train_loss=10.061686515808105
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3932: train_loss=10.061724662780762
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3933: train_loss=10.059521675109863
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3934: train_loss=10.060210227966309
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3935: train_loss=10.059906005859375
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3936: train_loss=10.059755325317383
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3937: train_loss=10.059499740600586
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3938: train_loss=10.060563087463379
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3939: train_loss=10.059514045715332
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3940: train_loss=10.061689376831055
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3941: train_loss=10.061904907226562
INFO - 04/15/25 16:42:31 - 0:10:55 - Epoch 3942: train_loss=10.059000015258789
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3943: train_loss=10.060572624206543
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3944: train_loss=10.059521675109863
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3945: train_loss=10.061153411865234
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3946: train_loss=10.061081886291504
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3947: train_loss=10.059048652648926
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3948: train_loss=10.059088706970215
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3949: train_loss=10.060155868530273
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3950: train_loss=10.059248924255371
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3951: train_loss=10.061089515686035
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3952: train_loss=10.061270713806152
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3953: train_loss=10.058396339416504
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3954: train_loss=10.059123992919922
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3955: train_loss=10.059510231018066
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3956: train_loss=10.058191299438477
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3957: train_loss=10.061564445495605
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3958: train_loss=10.061270713806152
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3959: train_loss=10.058869361877441
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3960: train_loss=10.059739112854004
INFO - 04/15/25 16:42:32 - 0:10:55 - Epoch 3961: train_loss=10.059220314025879
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3962: train_loss=10.059195518493652
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3963: train_loss=10.059101104736328
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3964: train_loss=10.059212684631348
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3965: train_loss=10.058683395385742
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3966: train_loss=10.05897331237793
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3967: train_loss=10.059065818786621
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3968: train_loss=10.058588027954102
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3969: train_loss=10.058533668518066
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3970: train_loss=10.059260368347168
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3971: train_loss=10.058647155761719
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3972: train_loss=10.059869766235352
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3973: train_loss=10.058853149414062
INFO - 04/15/25 16:42:32 - 0:10:56 - Epoch 3974: train_loss=10.059961318969727
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3975: train_loss=10.059218406677246
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3976: train_loss=10.060188293457031
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3977: train_loss=10.059885025024414
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3978: train_loss=10.059640884399414
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3979: train_loss=10.05960750579834
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3980: train_loss=10.059234619140625
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3981: train_loss=10.059100151062012
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3982: train_loss=10.059886932373047
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3983: train_loss=10.059261322021484
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3984: train_loss=10.060245513916016
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3985: train_loss=10.060222625732422
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3986: train_loss=10.05905532836914
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3987: train_loss=10.06053352355957
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3988: train_loss=10.058647155761719
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3989: train_loss=10.062573432922363
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3990: train_loss=10.062577247619629
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3991: train_loss=10.059733390808105
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3992: train_loss=10.061328887939453
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3993: train_loss=10.060626983642578
INFO - 04/15/25 16:42:33 - 0:10:56 - Epoch 3994: train_loss=10.060731887817383
INFO - 04/15/25 16:42:33 - 0:10:57 - Epoch 3995: train_loss=10.060297966003418
INFO - 04/15/25 16:42:33 - 0:10:57 - Epoch 3996: train_loss=10.060315132141113
INFO - 04/15/25 16:42:33 - 0:10:57 - Epoch 3997: train_loss=10.060011863708496
INFO - 04/15/25 16:42:33 - 0:10:57 - Epoch 3998: train_loss=10.060185432434082
INFO - 04/15/25 16:42:33 - 0:10:57 - Epoch 3999: train_loss=10.059290885925293
INFO - 04/15/25 16:42:33 - 0:10:57 - Epoch 4000: train_loss=10.059869766235352
INFO - 04/15/25 16:42:33 - 0:10:57 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:33 - 0:10:57 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4000: ACC: 0.0, NMI: 0.34454287732933614, F1: 0.0, ARI: 0.1699219294176588
INFO - 04/15/25 16:42:34 - 0:10:57 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4001: train_loss=10.059016227722168
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4002: train_loss=10.060308456420898
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4003: train_loss=10.059371948242188
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4004: train_loss=10.060890197753906
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4005: train_loss=10.060490608215332
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4006: train_loss=10.060076713562012
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4007: train_loss=10.060173988342285
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4008: train_loss=10.059481620788574
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4009: train_loss=10.060383796691895
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4010: train_loss=10.058859825134277
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4011: train_loss=10.062495231628418
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4012: train_loss=10.062520027160645
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4013: train_loss=10.059024810791016
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4014: train_loss=10.060775756835938
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4015: train_loss=10.060282707214355
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4016: train_loss=10.05988883972168
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4017: train_loss=10.060375213623047
INFO - 04/15/25 16:42:34 - 0:10:57 - Epoch 4018: train_loss=10.059417724609375
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4019: train_loss=10.061216354370117
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4020: train_loss=10.060715675354004
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4021: train_loss=10.060037612915039
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4022: train_loss=10.059996604919434
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4023: train_loss=10.060090065002441
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4024: train_loss=10.059517860412598
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4025: train_loss=10.059845924377441
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4026: train_loss=10.059429168701172
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4027: train_loss=10.058472633361816
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4028: train_loss=10.062317848205566
INFO - 04/15/25 16:42:34 - 0:10:58 - Epoch 4029: train_loss=10.062080383300781
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4030: train_loss=10.059489250183105
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4031: train_loss=10.060534477233887
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4032: train_loss=10.060090065002441
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4033: train_loss=10.059652328491211
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4034: train_loss=10.060286521911621
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4035: train_loss=10.059027671813965
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4036: train_loss=10.061441421508789
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4037: train_loss=10.06059455871582
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4038: train_loss=10.060722351074219
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4039: train_loss=10.060872077941895
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4040: train_loss=10.059590339660645
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4041: train_loss=10.059491157531738
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4042: train_loss=10.060383796691895
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4043: train_loss=10.059127807617188
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4044: train_loss=10.06190299987793
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4045: train_loss=10.061641693115234
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4046: train_loss=10.059233665466309
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4047: train_loss=10.059610366821289
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4048: train_loss=10.06017780303955
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4049: train_loss=10.05915641784668
INFO - 04/15/25 16:42:35 - 0:10:58 - Epoch 4050: train_loss=10.061468124389648
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4051: train_loss=10.06102466583252
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4052: train_loss=10.059975624084473
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4053: train_loss=10.06000804901123
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4054: train_loss=10.0601167678833
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4055: train_loss=10.059589385986328
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4056: train_loss=10.060776710510254
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4057: train_loss=10.060341835021973
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4058: train_loss=10.060437202453613
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4059: train_loss=10.060246467590332
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4060: train_loss=10.060012817382812
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4061: train_loss=10.059730529785156
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4062: train_loss=10.060582160949707
INFO - 04/15/25 16:42:35 - 0:10:59 - Epoch 4063: train_loss=10.060127258300781
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4064: train_loss=10.060393333435059
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4065: train_loss=10.060209274291992
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4066: train_loss=10.060067176818848
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4067: train_loss=10.059744834899902
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4068: train_loss=10.060440063476562
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4069: train_loss=10.060052871704102
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4070: train_loss=10.060318946838379
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4071: train_loss=10.060044288635254
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4072: train_loss=10.06020450592041
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4073: train_loss=10.059833526611328
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4074: train_loss=10.060369491577148
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4075: train_loss=10.060120582580566
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4076: train_loss=10.060072898864746
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4077: train_loss=10.059764862060547
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4078: train_loss=10.060333251953125
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4079: train_loss=10.0600004196167
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4080: train_loss=10.060220718383789
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4081: train_loss=10.060070991516113
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4082: train_loss=10.059961318969727
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4083: train_loss=10.059600830078125
INFO - 04/15/25 16:42:36 - 0:10:59 - Epoch 4084: train_loss=10.060640335083008
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4085: train_loss=10.06038761138916
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4086: train_loss=10.059540748596191
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4087: train_loss=10.059212684631348
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4088: train_loss=10.06096076965332
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4089: train_loss=10.060791015625
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4090: train_loss=10.059026718139648
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4091: train_loss=10.058688163757324
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4092: train_loss=10.061306953430176
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4093: train_loss=10.061121940612793
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4094: train_loss=10.05877685546875
INFO - 04/15/25 16:42:36 - 0:11:00 - Epoch 4095: train_loss=10.058564186096191
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4096: train_loss=10.061217308044434
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4097: train_loss=10.060931205749512
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4098: train_loss=10.059011459350586
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4099: train_loss=10.058867454528809
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4100: train_loss=10.060900688171387
INFO - 04/15/25 16:42:37 - 0:11:00 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:37 - 0:11:00 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4100: ACC: 0.0, NMI: 0.3503127315885596, F1: 0.0, ARI: 0.1704627553513262
INFO - 04/15/25 16:42:37 - 0:11:00 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4101: train_loss=10.060437202453613
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4102: train_loss=10.059576988220215
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4103: train_loss=10.059480667114258
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4104: train_loss=10.060245513916016
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4105: train_loss=10.05989933013916
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4106: train_loss=10.060051918029785
INFO - 04/15/25 16:42:37 - 0:11:00 - Epoch 4107: train_loss=10.059847831726074
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4108: train_loss=10.05981731414795
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4109: train_loss=10.059412956237793
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4110: train_loss=10.060347557067871
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4111: train_loss=10.060117721557617
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4112: train_loss=10.0595703125
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4113: train_loss=10.059236526489258
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4114: train_loss=10.060530662536621
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4115: train_loss=10.060347557067871
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4116: train_loss=10.05926513671875
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4117: train_loss=10.058935165405273
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4118: train_loss=10.060681343078613
INFO - 04/15/25 16:42:37 - 0:11:01 - Epoch 4119: train_loss=10.060492515563965
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4120: train_loss=10.059273719787598
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4121: train_loss=10.059045791625977
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4122: train_loss=10.06059741973877
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4123: train_loss=10.060234069824219
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4124: train_loss=10.059454917907715
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4125: train_loss=10.059255599975586
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4126: train_loss=10.060297012329102
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4127: train_loss=10.060037612915039
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4128: train_loss=10.059507369995117
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4129: train_loss=10.059244155883789
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4130: train_loss=10.060419082641602
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4131: train_loss=10.060202598571777
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4132: train_loss=10.059367179870605
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4133: train_loss=10.059054374694824
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4134: train_loss=10.060535430908203
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4135: train_loss=10.060322761535645
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4136: train_loss=10.059185028076172
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4137: train_loss=10.058990478515625
INFO - 04/15/25 16:42:38 - 0:11:01 - Epoch 4138: train_loss=10.060482025146484
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4139: train_loss=10.060215950012207
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4140: train_loss=10.059309959411621
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4141: train_loss=10.059115409851074
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4142: train_loss=10.060302734375
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4143: train_loss=10.0599946975708
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4144: train_loss=10.059475898742676
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4145: train_loss=10.059333801269531
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4146: train_loss=10.060088157653809
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4147: train_loss=10.059834480285645
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4148: train_loss=10.059623718261719
INFO - 04/15/25 16:42:38 - 0:11:02 - Epoch 4149: train_loss=10.059408187866211
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4150: train_loss=10.059976577758789
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4151: train_loss=10.059739112854004
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4152: train_loss=10.05960464477539
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4153: train_loss=10.059396743774414
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4154: train_loss=10.060025215148926
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4155: train_loss=10.059755325317383
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4156: train_loss=10.059520721435547
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4157: train_loss=10.059185981750488
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4158: train_loss=10.060195922851562
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4159: train_loss=10.060192108154297
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4160: train_loss=10.059041976928711
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4161: train_loss=10.05871295928955
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4162: train_loss=10.060659408569336
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4163: train_loss=10.060603141784668
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4164: train_loss=10.058541297912598
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4165: train_loss=10.058026313781738
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4166: train_loss=10.061984062194824
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4167: train_loss=10.061781883239746
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4168: train_loss=10.059224128723145
INFO - 04/15/25 16:42:39 - 0:11:02 - Epoch 4169: train_loss=10.061463356018066
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4170: train_loss=10.061713218688965
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4171: train_loss=10.058043479919434
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4172: train_loss=10.0631685256958
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4173: train_loss=10.064334869384766
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4174: train_loss=10.061217308044434
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4175: train_loss=10.060883522033691
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4176: train_loss=10.062835693359375
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4177: train_loss=10.061058044433594
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4178: train_loss=10.060029029846191
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4179: train_loss=10.061213493347168
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4180: train_loss=10.05987548828125
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4181: train_loss=10.060577392578125
INFO - 04/15/25 16:42:39 - 0:11:03 - Epoch 4182: train_loss=10.061104774475098
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4183: train_loss=10.058476448059082
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4184: train_loss=10.061463356018066
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4185: train_loss=10.061007499694824
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4186: train_loss=10.059778213500977
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4187: train_loss=10.060165405273438
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4188: train_loss=10.05962085723877
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4189: train_loss=10.060331344604492
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4190: train_loss=10.059475898742676
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4191: train_loss=10.060792922973633
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4192: train_loss=10.060542106628418
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4193: train_loss=10.059858322143555
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4194: train_loss=10.06027603149414
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4195: train_loss=10.059850692749023
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4196: train_loss=10.060397148132324
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4197: train_loss=10.060175895690918
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4198: train_loss=10.060001373291016
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4199: train_loss=10.059826850891113
INFO - 04/15/25 16:42:40 - 0:11:03 - Epoch 4200: train_loss=10.059507369995117
INFO - 04/15/25 16:42:40 - 0:11:03 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:40 - 0:11:04 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:42:40 - 0:11:04 - Epoch 4200: ACC: 0.0, NMI: 0.3515876962632374, F1: 0.0, ARI: 0.16233190471032805
INFO - 04/15/25 16:42:40 - 0:11:04 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:40 - 0:11:04 - Epoch 4201: train_loss=10.060585975646973
INFO - 04/15/25 16:42:40 - 0:11:04 - Epoch 4202: train_loss=10.059595108032227
INFO - 04/15/25 16:42:40 - 0:11:04 - Epoch 4203: train_loss=10.061429977416992
INFO - 04/15/25 16:42:40 - 0:11:04 - Epoch 4204: train_loss=10.061538696289062
INFO - 04/15/25 16:42:40 - 0:11:04 - Epoch 4205: train_loss=10.059796333312988
INFO - 04/15/25 16:42:40 - 0:11:04 - Epoch 4206: train_loss=10.060214042663574
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4207: train_loss=10.06058120727539
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4208: train_loss=10.058899879455566
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4209: train_loss=10.061717987060547
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4210: train_loss=10.06055736541748
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4211: train_loss=10.06113338470459
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4212: train_loss=10.061346054077148
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4213: train_loss=10.059638977050781
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4214: train_loss=10.059951782226562
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4215: train_loss=10.05994987487793
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4216: train_loss=10.059426307678223
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4217: train_loss=10.05979061126709
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4218: train_loss=10.059584617614746
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4219: train_loss=10.059094429016113
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4220: train_loss=10.059618949890137
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4221: train_loss=10.059446334838867
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4222: train_loss=10.059165954589844
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4223: train_loss=10.058830261230469
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4224: train_loss=10.060355186462402
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4225: train_loss=10.05886173248291
INFO - 04/15/25 16:42:41 - 0:11:04 - Epoch 4226: train_loss=10.06185245513916
INFO - 04/15/25 16:42:41 - 0:11:05 - Epoch 4227: train_loss=10.06167984008789
INFO - 04/15/25 16:42:41 - 0:11:05 - Epoch 4228: train_loss=10.059664726257324
INFO - 04/15/25 16:42:41 - 0:11:05 - Epoch 4229: train_loss=10.060585975646973
INFO - 04/15/25 16:42:41 - 0:11:05 - Epoch 4230: train_loss=10.060317039489746
INFO - 04/15/25 16:42:41 - 0:11:05 - Epoch 4231: train_loss=10.059475898742676
INFO - 04/15/25 16:42:41 - 0:11:05 - Epoch 4232: train_loss=10.059989929199219
INFO - 04/15/25 16:42:41 - 0:11:05 - Epoch 4233: train_loss=10.05923080444336
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4234: train_loss=10.059749603271484
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4235: train_loss=10.059013366699219
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4236: train_loss=10.06081485748291
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4237: train_loss=10.060210227966309
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4238: train_loss=10.060087203979492
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4239: train_loss=10.060032844543457
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4240: train_loss=10.0597505569458
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4241: train_loss=10.05974292755127
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4242: train_loss=10.059396743774414
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4243: train_loss=10.059823036193848
INFO - 04/15/25 16:42:42 - 0:11:05 - Epoch 4244: train_loss=10.059033393859863
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4245: train_loss=10.06005573272705
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4246: train_loss=10.059011459350586
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4247: train_loss=10.061051368713379
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4248: train_loss=10.061006546020508
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4249: train_loss=10.05893325805664
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4250: train_loss=10.059844970703125
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4251: train_loss=10.058856964111328
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4252: train_loss=10.060704231262207
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4253: train_loss=10.060108184814453
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4254: train_loss=10.060042381286621
INFO - 04/15/25 16:42:42 - 0:11:06 - Epoch 4255: train_loss=10.060125350952148
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4256: train_loss=10.059550285339355
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4257: train_loss=10.059359550476074
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4258: train_loss=10.05967903137207
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4259: train_loss=10.059178352355957
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4260: train_loss=10.059700965881348
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4261: train_loss=10.059317588806152
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4262: train_loss=10.059393882751465
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4263: train_loss=10.059357643127441
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4264: train_loss=10.059179306030273
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4265: train_loss=10.05876350402832
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4266: train_loss=10.060456275939941
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4267: train_loss=10.05971908569336
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4268: train_loss=10.060359001159668
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4269: train_loss=10.060575485229492
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4270: train_loss=10.059001922607422
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4271: train_loss=10.059612274169922
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4272: train_loss=10.058773040771484
INFO - 04/15/25 16:42:43 - 0:11:06 - Epoch 4273: train_loss=10.060832023620605
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4274: train_loss=10.060158729553223
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4275: train_loss=10.060062408447266
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4276: train_loss=10.060154914855957
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4277: train_loss=10.0594482421875
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4278: train_loss=10.059134483337402
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4279: train_loss=10.060210227966309
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4280: train_loss=10.0595121383667
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4281: train_loss=10.06041145324707
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4282: train_loss=10.06006908416748
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4283: train_loss=10.059889793395996
INFO - 04/15/25 16:42:43 - 0:11:07 - Epoch 4284: train_loss=10.059741020202637
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4285: train_loss=10.05992317199707
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4286: train_loss=10.05928897857666
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4287: train_loss=10.060186386108398
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4288: train_loss=10.059431076049805
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4289: train_loss=10.060624122619629
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4290: train_loss=10.060148239135742
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4291: train_loss=10.060173988342285
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4292: train_loss=10.060020446777344
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4293: train_loss=10.059934616088867
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4294: train_loss=10.059592247009277
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4295: train_loss=10.060392379760742
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4296: train_loss=10.059925079345703
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4297: train_loss=10.0601806640625
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4298: train_loss=10.059959411621094
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4299: train_loss=10.060018539428711
INFO - 04/15/25 16:42:44 - 0:11:07 - Epoch 4300: train_loss=10.059844970703125
INFO - 04/15/25 16:42:44 - 0:11:07 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:44 - 0:11:08 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:42:44 - 0:11:08 - Epoch 4300: ACC: 0.0, NMI: 0.20211137750700167, F1: 0.0, ARI: 0.06108910475089124
INFO - 04/15/25 16:42:44 - 0:11:08 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:44 - 0:11:08 - Epoch 4301: train_loss=10.05989933013916
INFO - 04/15/25 16:42:44 - 0:11:08 - Epoch 4302: train_loss=10.059589385986328
INFO - 04/15/25 16:42:44 - 0:11:08 - Epoch 4303: train_loss=10.060384750366211
INFO - 04/15/25 16:42:44 - 0:11:08 - Epoch 4304: train_loss=10.0602388381958
INFO - 04/15/25 16:42:44 - 0:11:08 - Epoch 4305: train_loss=10.059497833251953
INFO - 04/15/25 16:42:44 - 0:11:08 - Epoch 4306: train_loss=10.059158325195312
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4307: train_loss=10.060588836669922
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4308: train_loss=10.060276985168457
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4309: train_loss=10.059615135192871
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4310: train_loss=10.059431076049805
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4311: train_loss=10.060236930847168
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4312: train_loss=10.059810638427734
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4313: train_loss=10.060155868530273
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4314: train_loss=10.059882164001465
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4315: train_loss=10.059927940368652
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4316: train_loss=10.059670448303223
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4317: train_loss=10.060096740722656
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4318: train_loss=10.059701919555664
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4319: train_loss=10.0601806640625
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4320: train_loss=10.060006141662598
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4321: train_loss=10.059709548950195
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4322: train_loss=10.059394836425781
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4323: train_loss=10.060431480407715
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4324: train_loss=10.060275077819824
INFO - 04/15/25 16:42:45 - 0:11:08 - Epoch 4325: train_loss=10.059435844421387
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4326: train_loss=10.059126853942871
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4327: train_loss=10.060705184936523
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4328: train_loss=10.060604095458984
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4329: train_loss=10.059012413024902
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4330: train_loss=10.058676719665527
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4331: train_loss=10.06114387512207
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4332: train_loss=10.061062812805176
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4333: train_loss=10.058467864990234
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4334: train_loss=10.05795955657959
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4335: train_loss=10.062444686889648
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4336: train_loss=10.062873840332031
INFO - 04/15/25 16:42:45 - 0:11:09 - Epoch 4337: train_loss=10.05904769897461
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4338: train_loss=10.063605308532715
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4339: train_loss=10.065882682800293
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4340: train_loss=10.063602447509766
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4341: train_loss=10.058563232421875
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4342: train_loss=10.062914848327637
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4343: train_loss=10.06393814086914
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4344: train_loss=10.061050415039062
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4345: train_loss=10.060750961303711
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4346: train_loss=10.062603950500488
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4347: train_loss=10.060900688171387
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4348: train_loss=10.059925079345703
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4349: train_loss=10.06104850769043
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4350: train_loss=10.059276580810547
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4351: train_loss=10.061220169067383
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4352: train_loss=10.061522483825684
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4353: train_loss=10.059226989746094
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4354: train_loss=10.06123161315918
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4355: train_loss=10.061388969421387
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4356: train_loss=10.059439659118652
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4357: train_loss=10.060403823852539
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4358: train_loss=10.059990882873535
INFO - 04/15/25 16:42:46 - 0:11:09 - Epoch 4359: train_loss=10.060076713562012
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4360: train_loss=10.059739112854004
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4361: train_loss=10.059592247009277
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4362: train_loss=10.059859275817871
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4363: train_loss=10.058572769165039
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4364: train_loss=10.060229301452637
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4365: train_loss=10.059366226196289
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4366: train_loss=10.06041431427002
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4367: train_loss=10.059918403625488
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4368: train_loss=10.060145378112793
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4369: train_loss=10.060203552246094
INFO - 04/15/25 16:42:46 - 0:11:10 - Epoch 4370: train_loss=10.059114456176758
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4371: train_loss=10.059685707092285
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4372: train_loss=10.059259414672852
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4373: train_loss=10.058773040771484
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4374: train_loss=10.059526443481445
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4375: train_loss=10.05945110321045
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4376: train_loss=10.058540344238281
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4377: train_loss=10.059516906738281
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4378: train_loss=10.058856010437012
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4379: train_loss=10.059723854064941
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4380: train_loss=10.058613777160645
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4381: train_loss=10.059396743774414
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4382: train_loss=10.058525085449219
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4383: train_loss=10.060132026672363
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4384: train_loss=10.059530258178711
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4385: train_loss=10.059791564941406
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4386: train_loss=10.059783935546875
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4387: train_loss=10.059101104736328
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4388: train_loss=10.059164047241211
INFO - 04/15/25 16:42:47 - 0:11:10 - Epoch 4389: train_loss=10.059404373168945
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4390: train_loss=10.05905532836914
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4391: train_loss=10.059440612792969
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4392: train_loss=10.058923721313477
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4393: train_loss=10.059930801391602
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4394: train_loss=10.05953598022461
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4395: train_loss=10.05954360961914
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4396: train_loss=10.059505462646484
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4397: train_loss=10.059414863586426
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4398: train_loss=10.059012413024902
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4399: train_loss=10.05994987487793
INFO - 04/15/25 16:42:47 - 0:11:11 - Epoch 4400: train_loss=10.059540748596191
INFO - 04/15/25 16:42:47 - 0:11:11 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:48 - 0:11:11 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4400: ACC: 0.0, NMI: 0.3755484886025902, F1: 0.0, ARI: 0.18394309134762282
INFO - 04/15/25 16:42:48 - 0:11:11 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4401: train_loss=10.059433937072754
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4402: train_loss=10.059409141540527
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4403: train_loss=10.059186935424805
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4404: train_loss=10.05888557434082
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4405: train_loss=10.059751510620117
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4406: train_loss=10.059389114379883
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4407: train_loss=10.059579849243164
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4408: train_loss=10.059343338012695
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4409: train_loss=10.059493064880371
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4410: train_loss=10.059264183044434
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4411: train_loss=10.059536933898926
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4412: train_loss=10.059331893920898
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4413: train_loss=10.05940055847168
INFO - 04/15/25 16:42:48 - 0:11:11 - Epoch 4414: train_loss=10.059196472167969
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4415: train_loss=10.059473991394043
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4416: train_loss=10.059184074401855
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4417: train_loss=10.059751510620117
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4418: train_loss=10.059602737426758
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4419: train_loss=10.059062004089355
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4420: train_loss=10.058839797973633
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4421: train_loss=10.05979061126709
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4422: train_loss=10.059514045715332
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4423: train_loss=10.05919075012207
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4424: train_loss=10.05903148651123
INFO - 04/15/25 16:42:48 - 0:11:12 - Epoch 4425: train_loss=10.059745788574219
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4426: train_loss=10.059420585632324
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4427: train_loss=10.059175491333008
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4428: train_loss=10.059172630310059
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4429: train_loss=10.059520721435547
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4430: train_loss=10.059154510498047
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4431: train_loss=10.059404373168945
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4432: train_loss=10.059189796447754
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4433: train_loss=10.05962085723877
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4434: train_loss=10.059370994567871
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4435: train_loss=10.059076309204102
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4436: train_loss=10.059247970581055
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4437: train_loss=10.05949592590332
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4438: train_loss=10.05909252166748
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4439: train_loss=10.059179306030273
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4440: train_loss=10.058942794799805
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4441: train_loss=10.060166358947754
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4442: train_loss=10.059778213500977
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4443: train_loss=10.059538841247559
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4444: train_loss=10.060349464416504
INFO - 04/15/25 16:42:49 - 0:11:12 - Epoch 4445: train_loss=10.059005737304688
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4446: train_loss=10.062190055847168
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4447: train_loss=10.062455177307129
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4448: train_loss=10.059919357299805
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4449: train_loss=10.06067180633545
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4450: train_loss=10.061177253723145
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4451: train_loss=10.060490608215332
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4452: train_loss=10.059961318969727
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4453: train_loss=10.060230255126953
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4454: train_loss=10.059172630310059
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4455: train_loss=10.06016731262207
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4456: train_loss=10.059093475341797
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4457: train_loss=10.061388969421387
INFO - 04/15/25 16:42:49 - 0:11:13 - Epoch 4458: train_loss=10.061380386352539
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4459: train_loss=10.060144424438477
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4460: train_loss=10.05980396270752
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4461: train_loss=10.060998916625977
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4462: train_loss=10.058945655822754
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4463: train_loss=10.063394546508789
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4464: train_loss=10.064403533935547
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4465: train_loss=10.060331344604492
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4466: train_loss=10.06340503692627
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4467: train_loss=10.064935684204102
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4468: train_loss=10.062054634094238
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4469: train_loss=10.062545776367188
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4470: train_loss=10.062760353088379
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4471: train_loss=10.061280250549316
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4472: train_loss=10.062577247619629
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4473: train_loss=10.06067180633545
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4474: train_loss=10.062335968017578
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4475: train_loss=10.063470840454102
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4476: train_loss=10.059176445007324
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4477: train_loss=10.064985275268555
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4478: train_loss=10.067473411560059
INFO - 04/15/25 16:42:50 - 0:11:13 - Epoch 4479: train_loss=10.064628601074219
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4480: train_loss=10.060941696166992
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4481: train_loss=10.063211441040039
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4482: train_loss=10.062691688537598
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4483: train_loss=10.062379837036133
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4484: train_loss=10.06204605102539
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4485: train_loss=10.060093879699707
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4486: train_loss=10.062117576599121
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4487: train_loss=10.060540199279785
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4488: train_loss=10.061519622802734
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4489: train_loss=10.062321662902832
INFO - 04/15/25 16:42:50 - 0:11:14 - Epoch 4490: train_loss=10.058965682983398
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4491: train_loss=10.061820030212402
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4492: train_loss=10.061920166015625
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4493: train_loss=10.060220718383789
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4494: train_loss=10.06037712097168
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4495: train_loss=10.061168670654297
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4496: train_loss=10.059957504272461
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4497: train_loss=10.060550689697266
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4498: train_loss=10.06086540222168
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4499: train_loss=10.05959701538086
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4500: train_loss=10.060300827026367
INFO - 04/15/25 16:42:51 - 0:11:14 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:51 - 0:11:14 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4500: ACC: 0.0, NMI: 0.04750496525698958, F1: 0.0, ARI: 0.002267822233826428
INFO - 04/15/25 16:42:51 - 0:11:14 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4501: train_loss=10.06046199798584
INFO - 04/15/25 16:42:51 - 0:11:14 - Epoch 4502: train_loss=10.058780670166016
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4503: train_loss=10.059858322143555
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4504: train_loss=10.058784484863281
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4505: train_loss=10.060593605041504
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4506: train_loss=10.060115814208984
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4507: train_loss=10.05988597869873
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4508: train_loss=10.059757232666016
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4509: train_loss=10.059739112854004
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4510: train_loss=10.059534072875977
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4511: train_loss=10.059361457824707
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4512: train_loss=10.059654235839844
INFO - 04/15/25 16:42:51 - 0:11:15 - Epoch 4513: train_loss=10.059264183044434
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4514: train_loss=10.059624671936035
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4515: train_loss=10.05927848815918
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4516: train_loss=10.059652328491211
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4517: train_loss=10.059396743774414
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4518: train_loss=10.059391021728516
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4519: train_loss=10.059408187866211
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4520: train_loss=10.05879020690918
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4521: train_loss=10.060298919677734
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4522: train_loss=10.059213638305664
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4523: train_loss=10.06123161315918
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4524: train_loss=10.061429023742676
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4525: train_loss=10.05869197845459
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4526: train_loss=10.060274124145508
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4527: train_loss=10.059776306152344
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4528: train_loss=10.059691429138184
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4529: train_loss=10.059412002563477
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4530: train_loss=10.059487342834473
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4531: train_loss=10.059439659118652
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4532: train_loss=10.058836936950684
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4533: train_loss=10.060248374938965
INFO - 04/15/25 16:42:52 - 0:11:15 - Epoch 4534: train_loss=10.059099197387695
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4535: train_loss=10.060977935791016
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4536: train_loss=10.06119441986084
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4537: train_loss=10.05906867980957
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4538: train_loss=10.060234069824219
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4539: train_loss=10.060131072998047
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4540: train_loss=10.05917739868164
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4541: train_loss=10.060311317443848
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4542: train_loss=10.059703826904297
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4543: train_loss=10.059952735900879
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4544: train_loss=10.059918403625488
INFO - 04/15/25 16:42:52 - 0:11:16 - Epoch 4545: train_loss=10.059337615966797
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4546: train_loss=10.059297561645508
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4547: train_loss=10.059333801269531
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4548: train_loss=10.059183120727539
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4549: train_loss=10.05864429473877
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4550: train_loss=10.060550689697266
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4551: train_loss=10.059672355651855
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4552: train_loss=10.060551643371582
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4553: train_loss=10.060555458068848
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4554: train_loss=10.059370994567871
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4555: train_loss=10.059776306152344
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4556: train_loss=10.059162139892578
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4557: train_loss=10.059588432312012
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4558: train_loss=10.05953598022461
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4559: train_loss=10.058422088623047
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4560: train_loss=10.060994148254395
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4561: train_loss=10.059215545654297
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4562: train_loss=10.06245231628418
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4563: train_loss=10.06287956237793
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4564: train_loss=10.058874130249023
INFO - 04/15/25 16:42:53 - 0:11:16 - Epoch 4565: train_loss=10.063103675842285
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4566: train_loss=10.0636568069458
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4567: train_loss=10.060158729553223
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4568: train_loss=10.062604904174805
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4569: train_loss=10.063850402832031
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4570: train_loss=10.061182022094727
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4571: train_loss=10.06159496307373
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4572: train_loss=10.0626802444458
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4573: train_loss=10.060769081115723
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4574: train_loss=10.061251640319824
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4575: train_loss=10.06180477142334
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4576: train_loss=10.060206413269043
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4577: train_loss=10.061017990112305
INFO - 04/15/25 16:42:53 - 0:11:17 - Epoch 4578: train_loss=10.060811996459961
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4579: train_loss=10.060269355773926
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4580: train_loss=10.060333251953125
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4581: train_loss=10.059929847717285
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4582: train_loss=10.06014347076416
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4583: train_loss=10.05923080444336
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4584: train_loss=10.060304641723633
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4585: train_loss=10.05898666381836
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4586: train_loss=10.061458587646484
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4587: train_loss=10.060965538024902
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4588: train_loss=10.059882164001465
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4589: train_loss=10.060062408447266
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4590: train_loss=10.05978012084961
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4591: train_loss=10.059487342834473
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4592: train_loss=10.060129165649414
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4593: train_loss=10.059508323669434
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4594: train_loss=10.060481071472168
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4595: train_loss=10.060094833374023
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4596: train_loss=10.060070037841797
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4597: train_loss=10.059815406799316
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4598: train_loss=10.0599946975708
INFO - 04/15/25 16:42:54 - 0:11:17 - Epoch 4599: train_loss=10.05951976776123
INFO - 04/15/25 16:42:54 - 0:11:18 - Epoch 4600: train_loss=10.06042766571045
INFO - 04/15/25 16:42:54 - 0:11:18 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:54 - 0:11:18 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:42:54 - 0:11:18 - Epoch 4600: ACC: 0.0, NMI: 0.045316941579378975, F1: 0.0, ARI: 0.002264336965110178
INFO - 04/15/25 16:42:54 - 0:11:18 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:54 - 0:11:18 - Epoch 4601: train_loss=10.05994987487793
INFO - 04/15/25 16:42:54 - 0:11:18 - Epoch 4602: train_loss=10.060136795043945
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4603: train_loss=10.05997371673584
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4604: train_loss=10.059892654418945
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4605: train_loss=10.059715270996094
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4606: train_loss=10.059854507446289
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4607: train_loss=10.059457778930664
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4608: train_loss=10.060096740722656
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4609: train_loss=10.059577941894531
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4610: train_loss=10.060188293457031
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4611: train_loss=10.059853553771973
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4612: train_loss=10.059907913208008
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4613: train_loss=10.059721946716309
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4614: train_loss=10.059871673583984
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4615: train_loss=10.059545516967773
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4616: train_loss=10.059957504272461
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4617: train_loss=10.059550285339355
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4618: train_loss=10.060133934020996
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4619: train_loss=10.05986213684082
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4620: train_loss=10.05980110168457
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4621: train_loss=10.059547424316406
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4622: train_loss=10.059985160827637
INFO - 04/15/25 16:42:55 - 0:11:18 - Epoch 4623: train_loss=10.059657096862793
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4624: train_loss=10.060097694396973
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4625: train_loss=10.06000804901123
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4626: train_loss=10.059396743774414
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4627: train_loss=10.059011459350586
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4628: train_loss=10.060688018798828
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4629: train_loss=10.06059455871582
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4630: train_loss=10.058826446533203
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4631: train_loss=10.058616638183594
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4632: train_loss=10.060890197753906
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4633: train_loss=10.060454368591309
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4634: train_loss=10.059263229370117
INFO - 04/15/25 16:42:55 - 0:11:19 - Epoch 4635: train_loss=10.059221267700195
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4636: train_loss=10.060006141662598
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4637: train_loss=10.059389114379883
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4638: train_loss=10.060456275939941
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4639: train_loss=10.0604248046875
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4640: train_loss=10.059097290039062
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4641: train_loss=10.059087753295898
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4642: train_loss=10.060062408447266
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4643: train_loss=10.059263229370117
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4644: train_loss=10.060894012451172
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4645: train_loss=10.06115436553955
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4646: train_loss=10.0584077835083
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4647: train_loss=10.061565399169922
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4648: train_loss=10.060455322265625
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4649: train_loss=10.060874938964844
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4650: train_loss=10.061235427856445
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4651: train_loss=10.059335708618164
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4652: train_loss=10.059965133666992
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4653: train_loss=10.059581756591797
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4654: train_loss=10.060154914855957
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4655: train_loss=10.059624671936035
INFO - 04/15/25 16:42:56 - 0:11:19 - Epoch 4656: train_loss=10.060632705688477
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4657: train_loss=10.060455322265625
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4658: train_loss=10.05971908569336
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4659: train_loss=10.059847831726074
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4660: train_loss=10.05939769744873
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4661: train_loss=10.060110092163086
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4662: train_loss=10.058846473693848
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4663: train_loss=10.061689376831055
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4664: train_loss=10.061202049255371
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4665: train_loss=10.059978485107422
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4666: train_loss=10.05990982055664
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4667: train_loss=10.060632705688477
INFO - 04/15/25 16:42:56 - 0:11:20 - Epoch 4668: train_loss=10.059576988220215
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4669: train_loss=10.06171703338623
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4670: train_loss=10.061631202697754
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4671: train_loss=10.059148788452148
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4672: train_loss=10.059638023376465
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4673: train_loss=10.059743881225586
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4674: train_loss=10.059090614318848
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4675: train_loss=10.059106826782227
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4676: train_loss=10.060107231140137
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4677: train_loss=10.05843448638916
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4678: train_loss=10.062908172607422
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4679: train_loss=10.063155174255371
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4680: train_loss=10.05866527557373
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4681: train_loss=10.063511848449707
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4682: train_loss=10.064743995666504
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4683: train_loss=10.061996459960938
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4684: train_loss=10.0613374710083
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4685: train_loss=10.06222152709961
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4686: train_loss=10.06208324432373
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4687: train_loss=10.06123161315918
INFO - 04/15/25 16:42:57 - 0:11:20 - Epoch 4688: train_loss=10.060154914855957
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4689: train_loss=10.061466217041016
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4690: train_loss=10.059660911560059
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4691: train_loss=10.061665534973145
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4692: train_loss=10.062161445617676
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4693: train_loss=10.059511184692383
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4694: train_loss=10.061272621154785
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4695: train_loss=10.061725616455078
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4696: train_loss=10.060063362121582
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4697: train_loss=10.06045150756836
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4698: train_loss=10.061226844787598
INFO - 04/15/25 16:42:57 - 0:11:21 - Epoch 4699: train_loss=10.059127807617188
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4700: train_loss=10.061351776123047
INFO - 04/15/25 16:42:58 - 0:11:21 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:42:58 - 0:11:21 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4700: ACC: 0.0, NMI: 0.3523537606330243, F1: 0.0, ARI: 0.16267790322790168
INFO - 04/15/25 16:42:58 - 0:11:21 - -------------------------------------------------------------------------
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4701: train_loss=10.062019348144531
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4702: train_loss=10.05967903137207
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4703: train_loss=10.06090259552002
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4704: train_loss=10.061995506286621
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4705: train_loss=10.060193061828613
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4706: train_loss=10.060073852539062
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4707: train_loss=10.06121826171875
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4708: train_loss=10.059270858764648
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4709: train_loss=10.061142921447754
INFO - 04/15/25 16:42:58 - 0:11:21 - Epoch 4710: train_loss=10.06226921081543
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4711: train_loss=10.059953689575195
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4712: train_loss=10.060638427734375
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4713: train_loss=10.061836242675781
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4714: train_loss=10.060457229614258
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4715: train_loss=10.059393882751465
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4716: train_loss=10.060617446899414
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4717: train_loss=10.058443069458008
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4718: train_loss=10.062651634216309
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4719: train_loss=10.06390380859375
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4720: train_loss=10.061410903930664
INFO - 04/15/25 16:42:58 - 0:11:22 - Epoch 4721: train_loss=10.06065559387207
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4722: train_loss=10.061522483825684
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4723: train_loss=10.061666488647461
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4724: train_loss=10.060384750366211
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4725: train_loss=10.060439109802246
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4726: train_loss=10.061426162719727
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4727: train_loss=10.058785438537598
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4728: train_loss=10.062055587768555
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4729: train_loss=10.063080787658691
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4730: train_loss=10.060922622680664
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4731: train_loss=10.060478210449219
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4732: train_loss=10.061176300048828
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4733: train_loss=10.061354637145996
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4734: train_loss=10.059555053710938
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4735: train_loss=10.061524391174316
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4736: train_loss=10.0621976852417
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4737: train_loss=10.059514999389648
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4738: train_loss=10.061347961425781
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4739: train_loss=10.06174087524414
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4740: train_loss=10.060578346252441
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4741: train_loss=10.060164451599121
INFO - 04/15/25 16:42:59 - 0:11:22 - Epoch 4742: train_loss=10.060713768005371
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4743: train_loss=10.060527801513672
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4744: train_loss=10.059507369995117
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4745: train_loss=10.060018539428711
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4746: train_loss=10.059197425842285
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4747: train_loss=10.05943775177002
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4748: train_loss=10.059049606323242
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4749: train_loss=10.059645652770996
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4750: train_loss=10.058752059936523
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4751: train_loss=10.060521125793457
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4752: train_loss=10.060391426086426
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4753: train_loss=10.059623718261719
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4754: train_loss=10.059592247009277
INFO - 04/15/25 16:42:59 - 0:11:23 - Epoch 4755: train_loss=10.059697151184082
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4756: train_loss=10.059123992919922
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4757: train_loss=10.05906867980957
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4758: train_loss=10.059860229492188
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4759: train_loss=10.059281349182129
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4760: train_loss=10.05980396270752
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4761: train_loss=10.059552192687988
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4762: train_loss=10.05921745300293
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4763: train_loss=10.059993743896484
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4764: train_loss=10.059294700622559
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4765: train_loss=10.06037425994873
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4766: train_loss=10.06017780303955
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4767: train_loss=10.059826850891113
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4768: train_loss=10.059531211853027
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4769: train_loss=10.060057640075684
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4770: train_loss=10.05911922454834
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4771: train_loss=10.060708045959473
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4772: train_loss=10.059783935546875
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4773: train_loss=10.06100845336914
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4774: train_loss=10.061083793640137
INFO - 04/15/25 16:43:00 - 0:11:23 - Epoch 4775: train_loss=10.058932304382324
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4776: train_loss=10.059560775756836
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4777: train_loss=10.05919361114502
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4778: train_loss=10.059083938598633
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4779: train_loss=10.05925178527832
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4780: train_loss=10.058893203735352
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4781: train_loss=10.059752464294434
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4782: train_loss=10.058455467224121
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4783: train_loss=10.061423301696777
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4784: train_loss=10.060969352722168
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4785: train_loss=10.059574127197266
INFO - 04/15/25 16:43:00 - 0:11:24 - Epoch 4786: train_loss=10.059812545776367
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4787: train_loss=10.059868812561035
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4788: train_loss=10.059452056884766
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4789: train_loss=10.060182571411133
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4790: train_loss=10.059746742248535
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4791: train_loss=10.060213088989258
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4792: train_loss=10.059759140014648
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4793: train_loss=10.060331344604492
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4794: train_loss=10.060271263122559
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4795: train_loss=10.059530258178711
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4796: train_loss=10.059366226196289
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4797: train_loss=10.060149192810059
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4798: train_loss=10.059459686279297
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4799: train_loss=10.06058120727539
INFO - 04/15/25 16:43:01 - 0:11:24 - Epoch 4800: train_loss=10.060365676879883
INFO - 04/15/25 16:43:01 - 0:11:24 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:43:01 - 0:11:24 - Decoding cost time:  0.134 s
INFO - 04/15/25 16:43:01 - 0:11:25 - Epoch 4800: ACC: 0.0, NMI: 0.3543954325533516, F1: 0.0, ARI: 0.1630655599817061
INFO - 04/15/25 16:43:01 - 0:11:25 - -------------------------------------------------------------------------
INFO - 04/15/25 16:43:01 - 0:11:25 - Epoch 4801: train_loss=10.059569358825684
INFO - 04/15/25 16:43:01 - 0:11:25 - Epoch 4802: train_loss=10.059432029724121
INFO - 04/15/25 16:43:01 - 0:11:25 - Epoch 4803: train_loss=10.060047149658203
INFO - 04/15/25 16:43:01 - 0:11:25 - Epoch 4804: train_loss=10.059566497802734
INFO - 04/15/25 16:43:01 - 0:11:25 - Epoch 4805: train_loss=10.060342788696289
INFO - 04/15/25 16:43:01 - 0:11:25 - Epoch 4806: train_loss=10.06013011932373
INFO - 04/15/25 16:43:01 - 0:11:25 - Epoch 4807: train_loss=10.059688568115234
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4808: train_loss=10.059556007385254
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4809: train_loss=10.060006141662598
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4810: train_loss=10.059575080871582
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4811: train_loss=10.06013298034668
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4812: train_loss=10.059818267822266
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4813: train_loss=10.060064315795898
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4814: train_loss=10.059892654418945
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4815: train_loss=10.059614181518555
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4816: train_loss=10.059385299682617
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4817: train_loss=10.060164451599121
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4818: train_loss=10.059765815734863
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4819: train_loss=10.059959411621094
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4820: train_loss=10.05966567993164
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4821: train_loss=10.059930801391602
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4822: train_loss=10.059670448303223
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4823: train_loss=10.059883117675781
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4824: train_loss=10.059560775756836
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4825: train_loss=10.060100555419922
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4826: train_loss=10.059906005859375
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4827: train_loss=10.059582710266113
INFO - 04/15/25 16:43:02 - 0:11:25 - Epoch 4828: train_loss=10.059398651123047
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4829: train_loss=10.059897422790527
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4830: train_loss=10.059456825256348
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4831: train_loss=10.060179710388184
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4832: train_loss=10.059874534606934
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4833: train_loss=10.059746742248535
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4834: train_loss=10.059605598449707
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4835: train_loss=10.059712409973145
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4836: train_loss=10.059338569641113
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4837: train_loss=10.06015682220459
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4838: train_loss=10.059808731079102
INFO - 04/15/25 16:43:02 - 0:11:26 - Epoch 4839: train_loss=10.059649467468262
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4840: train_loss=10.059358596801758
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4841: train_loss=10.060141563415527
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4842: train_loss=10.060027122497559
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4843: train_loss=10.0592679977417
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4844: train_loss=10.058980941772461
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4845: train_loss=10.060596466064453
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4846: train_loss=10.060544967651367
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4847: train_loss=10.058781623840332
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4848: train_loss=10.058429718017578
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4849: train_loss=10.06089973449707
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4850: train_loss=10.060473442077637
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4851: train_loss=10.059021949768066
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4852: train_loss=10.05881118774414
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4853: train_loss=10.060454368591309
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4854: train_loss=10.06016731262207
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4855: train_loss=10.059212684631348
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4856: train_loss=10.058837890625
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4857: train_loss=10.060676574707031
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4858: train_loss=10.060545921325684
INFO - 04/15/25 16:43:03 - 0:11:26 - Epoch 4859: train_loss=10.058756828308105
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4860: train_loss=10.058571815490723
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4861: train_loss=10.060873985290527
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4862: train_loss=10.06038761138916
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4863: train_loss=10.0594482421875
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4864: train_loss=10.059937477111816
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4865: train_loss=10.058650970458984
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4866: train_loss=10.060973167419434
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4867: train_loss=10.059194564819336
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4868: train_loss=10.062812805175781
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4869: train_loss=10.063225746154785
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4870: train_loss=10.058876991271973
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4871: train_loss=10.063082695007324
INFO - 04/15/25 16:43:03 - 0:11:27 - Epoch 4872: train_loss=10.063633918762207
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4873: train_loss=10.06087875366211
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4874: train_loss=10.061647415161133
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4875: train_loss=10.061841011047363
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4876: train_loss=10.061814308166504
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4877: train_loss=10.06066608428955
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4878: train_loss=10.060995101928711
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4879: train_loss=10.061787605285645
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4880: train_loss=10.059009552001953
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4881: train_loss=10.061615943908691
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4882: train_loss=10.062043190002441
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4883: train_loss=10.059843063354492
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4884: train_loss=10.060976028442383
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4885: train_loss=10.061518669128418
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4886: train_loss=10.0599365234375
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4887: train_loss=10.060403823852539
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4888: train_loss=10.060686111450195
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4889: train_loss=10.059798240661621
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4890: train_loss=10.06022834777832
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4891: train_loss=10.060200691223145
INFO - 04/15/25 16:43:04 - 0:11:27 - Epoch 4892: train_loss=10.05924129486084
INFO - 04/15/25 16:43:04 - 0:11:28 - Epoch 4893: train_loss=10.05942440032959
INFO - 04/15/25 16:43:04 - 0:11:28 - Epoch 4894: train_loss=10.059113502502441
INFO - 04/15/25 16:43:04 - 0:11:28 - Epoch 4895: train_loss=10.059544563293457
INFO - 04/15/25 16:43:04 - 0:11:28 - Epoch 4896: train_loss=10.05854606628418
INFO - 04/15/25 16:43:04 - 0:11:28 - Epoch 4897: train_loss=10.06027889251709
INFO - 04/15/25 16:43:04 - 0:11:28 - Epoch 4898: train_loss=10.059304237365723
INFO - 04/15/25 16:43:04 - 0:11:28 - Epoch 4899: train_loss=10.060419082641602
INFO - 04/15/25 16:43:04 - 0:11:28 - Epoch 4900: train_loss=10.060197830200195
INFO - 04/15/25 16:43:04 - 0:11:28 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:43:04 - 0:11:28 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4900: ACC: 0.0, NMI: 0.3569476720431033, F1: 0.0, ARI: 0.16377910080052754
INFO - 04/15/25 16:43:05 - 0:11:28 - -------------------------------------------------------------------------
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4901: train_loss=10.059683799743652
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4902: train_loss=10.059561729431152
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4903: train_loss=10.059786796569824
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4904: train_loss=10.058860778808594
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4905: train_loss=10.05971908569336
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4906: train_loss=10.058601379394531
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4907: train_loss=10.058991432189941
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4908: train_loss=10.059660911560059
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4909: train_loss=10.058430671691895
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4910: train_loss=10.061532974243164
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4911: train_loss=10.06140422821045
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4912: train_loss=10.0588960647583
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4913: train_loss=10.059850692749023
INFO - 04/15/25 16:43:05 - 0:11:28 - Epoch 4914: train_loss=10.059342384338379
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4915: train_loss=10.059538841247559
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4916: train_loss=10.058873176574707
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4917: train_loss=10.059622764587402
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4918: train_loss=10.058634757995605
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4919: train_loss=10.060201644897461
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4920: train_loss=10.059467315673828
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4921: train_loss=10.0601806640625
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4922: train_loss=10.059768676757812
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4923: train_loss=10.060057640075684
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4924: train_loss=10.059605598449707
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4925: train_loss=10.060150146484375
INFO - 04/15/25 16:43:05 - 0:11:29 - Epoch 4926: train_loss=10.05944538116455
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4927: train_loss=10.060696601867676
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4928: train_loss=10.060225486755371
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4929: train_loss=10.05989933013916
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4930: train_loss=10.059895515441895
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4931: train_loss=10.059513092041016
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4932: train_loss=10.059154510498047
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4933: train_loss=10.06053352355957
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4934: train_loss=10.060223579406738
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4935: train_loss=10.059575080871582
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4936: train_loss=10.059402465820312
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4937: train_loss=10.06008529663086
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4938: train_loss=10.059635162353516
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4939: train_loss=10.060223579406738
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4940: train_loss=10.060043334960938
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4941: train_loss=10.059724807739258
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4942: train_loss=10.059514999389648
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4943: train_loss=10.060043334960938
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4944: train_loss=10.059762954711914
INFO - 04/15/25 16:43:06 - 0:11:29 - Epoch 4945: train_loss=10.059788703918457
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4946: train_loss=10.059508323669434
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4947: train_loss=10.060127258300781
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4948: train_loss=10.059943199157715
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4949: train_loss=10.059630393981934
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4950: train_loss=10.059392929077148
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4951: train_loss=10.060009002685547
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4952: train_loss=10.059688568115234
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4953: train_loss=10.059892654418945
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4954: train_loss=10.059747695922852
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4955: train_loss=10.059671401977539
INFO - 04/15/25 16:43:06 - 0:11:30 - Epoch 4956: train_loss=10.05929946899414
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4957: train_loss=10.060141563415527
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4958: train_loss=10.059896469116211
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4959: train_loss=10.059479713439941
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4960: train_loss=10.05920124053955
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4961: train_loss=10.060114860534668
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4962: train_loss=10.059840202331543
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4963: train_loss=10.0595703125
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4964: train_loss=10.059364318847656
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4965: train_loss=10.059964179992676
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4966: train_loss=10.059732437133789
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4967: train_loss=10.059592247009277
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4968: train_loss=10.059392929077148
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4969: train_loss=10.059814453125
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4970: train_loss=10.059599876403809
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4971: train_loss=10.059720993041992
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4972: train_loss=10.05945873260498
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4973: train_loss=10.059816360473633
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4974: train_loss=10.059661865234375
INFO - 04/15/25 16:43:07 - 0:11:30 - Epoch 4975: train_loss=10.059521675109863
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4976: train_loss=10.059146881103516
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4977: train_loss=10.060211181640625
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4978: train_loss=10.060227394104004
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4979: train_loss=10.058857917785645
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4980: train_loss=10.058448791503906
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4981: train_loss=10.060832023620605
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4982: train_loss=10.060654640197754
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4983: train_loss=10.058381080627441
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4984: train_loss=10.058601379394531
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4985: train_loss=10.061182975769043
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4986: train_loss=10.060142517089844
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4987: train_loss=10.061047554016113
INFO - 04/15/25 16:43:07 - 0:11:31 - Epoch 4988: train_loss=10.060833930969238
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4989: train_loss=10.060225486755371
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4990: train_loss=10.059932708740234
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4991: train_loss=10.060934066772461
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4992: train_loss=10.059576034545898
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4993: train_loss=10.059857368469238
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4994: train_loss=10.06053352355957
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4995: train_loss=10.058954238891602
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4996: train_loss=10.063740730285645
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4997: train_loss=10.064006805419922
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4998: train_loss=10.059233665466309
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 4999: train_loss=10.064308166503906
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 5000: train_loss=10.065811157226562
INFO - 04/15/25 16:43:08 - 0:11:31 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:43:08 - 0:11:31 - Decoding cost time:  0.115 s
INFO - 04/15/25 16:43:08 - 0:11:31 - Epoch 5000: ACC: 0.0, NMI: 0.3479952079678895, F1: 0.0, ARI: 0.16788249989663326
INFO - 04/15/25 16:43:08 - 0:11:31 - -------------------------------------------------------------------------
INFO - 04/15/25 16:43:08 - 0:11:31 - ------------------Loading best model-------------------
INFO - 04/15/25 16:43:23 - 0:11:46 - Best Results according to nmi: ACC: 0.0, NMI: 0.3938990877601923, F1: 0.0, ARI: 0.20004371735216359 
                                     
INFO - 04/15/25 16:43:23 - 0:11:46 - Best Results according to ari: ACC: 0.0, NMI: 0.3938990877601923, F1: 0.0, ARI: 0.20004371735216359 
                                     
INFO - 04/15/25 16:43:23 - 0:11:46 - 
                                     train iters 3
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 1: train_loss=5.853609561920166
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 2: train_loss=2.888542652130127
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 3: train_loss=1.9469668865203857
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 4: train_loss=1.429124355316162
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 5: train_loss=1.1859959363937378
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 6: train_loss=0.993851900100708
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 7: train_loss=0.8066900968551636
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 8: train_loss=0.6972629427909851
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 9: train_loss=0.6485013961791992
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 10: train_loss=0.5707711577415466
INFO - 04/15/25 16:43:23 - 0:11:46 - Epoch 11: train_loss=0.512982189655304
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 12: train_loss=0.4832386374473572
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 13: train_loss=0.44886600971221924
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 14: train_loss=0.42271459102630615
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 15: train_loss=0.41204938292503357
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 16: train_loss=0.38921061158180237
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 17: train_loss=0.3549409508705139
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 18: train_loss=0.3501550555229187
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 19: train_loss=0.3565519154071808
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 20: train_loss=0.3429751396179199
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 21: train_loss=0.3134063184261322
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 22: train_loss=0.3081880211830139
INFO - 04/15/25 16:43:23 - 0:11:47 - Epoch 23: train_loss=0.317465603351593
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 24: train_loss=0.30999207496643066
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 25: train_loss=0.2899852991104126
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 26: train_loss=0.2857811152935028
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 27: train_loss=0.29161369800567627
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 28: train_loss=0.28522592782974243
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 29: train_loss=0.27421629428863525
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 30: train_loss=0.27232566475868225
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 31: train_loss=0.2728506922721863
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 32: train_loss=0.26938876509666443
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 33: train_loss=0.2617102861404419
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 34: train_loss=0.26261651515960693
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 35: train_loss=0.25943270325660706
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 36: train_loss=0.25728753209114075
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 37: train_loss=0.25667205452919006
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 38: train_loss=0.2529851198196411
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 39: train_loss=0.25781017541885376
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 40: train_loss=0.2535640299320221
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 41: train_loss=0.24902936816215515
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 42: train_loss=0.25400227308273315
INFO - 04/15/25 16:43:24 - 0:11:47 - Epoch 43: train_loss=0.25064927339553833
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 44: train_loss=0.24906189739704132
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 45: train_loss=0.24587096273899078
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 46: train_loss=0.2488349974155426
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 47: train_loss=0.2432882934808731
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 48: train_loss=0.24382373690605164
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 49: train_loss=0.24554377794265747
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 50: train_loss=0.24031448364257812
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 51: train_loss=0.2420985996723175
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 52: train_loss=0.24055901169776917
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 53: train_loss=0.2392897754907608
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 54: train_loss=0.23842290043830872
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 55: train_loss=0.2370302677154541
INFO - 04/15/25 16:43:24 - 0:11:48 - Epoch 56: train_loss=0.23899975419044495
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 57: train_loss=0.23948213458061218
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 58: train_loss=0.23339161276817322
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 59: train_loss=0.23302027583122253
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 60: train_loss=0.23848342895507812
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 61: train_loss=0.23044660687446594
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 62: train_loss=0.2348790019750595
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 63: train_loss=0.23211082816123962
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 64: train_loss=0.23409220576286316
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 65: train_loss=0.22981904447078705
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 66: train_loss=0.23239004611968994
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 67: train_loss=0.22867324948310852
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 68: train_loss=0.2346706986427307
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 69: train_loss=0.22738605737686157
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 70: train_loss=0.2305511087179184
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 71: train_loss=0.2283259779214859
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 72: train_loss=0.23161019384860992
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 73: train_loss=0.22803181409835815
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 74: train_loss=0.22827596962451935
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 75: train_loss=0.22749914228916168
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 76: train_loss=0.22736559808254242
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 77: train_loss=0.22580526769161224
INFO - 04/15/25 16:43:25 - 0:11:48 - Epoch 78: train_loss=0.22638720273971558
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 79: train_loss=0.22471751272678375
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 80: train_loss=0.22505655884742737
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 81: train_loss=0.22202283143997192
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 82: train_loss=0.22465397417545319
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 83: train_loss=0.22112523019313812
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 84: train_loss=0.2252720296382904
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 85: train_loss=0.2228231579065323
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 86: train_loss=0.22246553003787994
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 87: train_loss=0.22201581299304962
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 88: train_loss=0.22102385759353638
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 89: train_loss=0.22127655148506165
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 90: train_loss=0.22025737166404724
INFO - 04/15/25 16:43:25 - 0:11:49 - Epoch 91: train_loss=0.22044238448143005
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 92: train_loss=0.21853239834308624
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 93: train_loss=0.22044718265533447
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 94: train_loss=0.21948124468326569
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 95: train_loss=0.2185806781053543
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 96: train_loss=0.21987299621105194
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 97: train_loss=0.2186294049024582
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 98: train_loss=0.2179916501045227
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 99: train_loss=0.21774247288703918
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 100: train_loss=0.2170129418373108
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 101: train_loss=0.21664129197597504
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 102: train_loss=0.21651482582092285
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 103: train_loss=0.21605905890464783
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 104: train_loss=0.21544039249420166
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 105: train_loss=0.21662911772727966
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 106: train_loss=0.21408215165138245
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 107: train_loss=0.2172500193119049
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 108: train_loss=0.21318693459033966
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 109: train_loss=0.21635043621063232
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 110: train_loss=0.21359679102897644
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 111: train_loss=0.2136644423007965
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 112: train_loss=0.21428772807121277
INFO - 04/15/25 16:43:26 - 0:11:49 - Epoch 113: train_loss=0.21294283866882324
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 114: train_loss=0.21256202459335327
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 115: train_loss=0.21445564925670624
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 116: train_loss=0.2103038728237152
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 117: train_loss=0.21494784951210022
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 118: train_loss=0.21054446697235107
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 119: train_loss=0.21263720095157623
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 120: train_loss=0.21175307035446167
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 121: train_loss=0.21260233223438263
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 122: train_loss=0.20992133021354675
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 123: train_loss=0.21221455931663513
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 124: train_loss=0.21051979064941406
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 125: train_loss=0.210987851023674
INFO - 04/15/25 16:43:26 - 0:11:50 - Epoch 126: train_loss=0.20984481275081635
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 127: train_loss=0.21134383976459503
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 128: train_loss=0.20964080095291138
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 129: train_loss=0.20933231711387634
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 130: train_loss=0.20908333361148834
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 131: train_loss=0.211823970079422
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 132: train_loss=0.2084863781929016
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 133: train_loss=0.2077687531709671
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 134: train_loss=0.20895572006702423
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 135: train_loss=0.21297232806682587
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 136: train_loss=0.20675425231456757
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 137: train_loss=0.21059533953666687
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 138: train_loss=0.21247665584087372
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 139: train_loss=0.20278798043727875
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 140: train_loss=0.22227728366851807
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 141: train_loss=0.2180858552455902
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 142: train_loss=0.21477213501930237
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 143: train_loss=0.21293114125728607
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 144: train_loss=0.21710918843746185
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 145: train_loss=0.214015394449234
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 146: train_loss=0.21358360350131989
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 147: train_loss=0.21302716434001923
INFO - 04/15/25 16:43:27 - 0:11:50 - Epoch 148: train_loss=0.21258005499839783
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 149: train_loss=0.20903299748897552
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 150: train_loss=0.21396170556545258
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 151: train_loss=0.20912235975265503
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 152: train_loss=0.2148444652557373
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 153: train_loss=0.21201810240745544
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 154: train_loss=0.2127731293439865
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 155: train_loss=0.21085578203201294
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 156: train_loss=0.21197891235351562
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 157: train_loss=0.20987898111343384
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 158: train_loss=0.21114301681518555
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 159: train_loss=0.20869171619415283
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 160: train_loss=0.21115261316299438
INFO - 04/15/25 16:43:27 - 0:11:51 - Epoch 161: train_loss=0.20762361586093903
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 162: train_loss=0.21174007654190063
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 163: train_loss=0.20895113050937653
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 164: train_loss=0.2104015201330185
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 165: train_loss=0.20850524306297302
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 166: train_loss=0.2096264362335205
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 167: train_loss=0.20748594403266907
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 168: train_loss=0.20927734673023224
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 169: train_loss=0.20678693056106567
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 170: train_loss=0.20916542410850525
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 171: train_loss=0.20669904351234436
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 172: train_loss=0.20888599753379822
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 173: train_loss=0.20651280879974365
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 174: train_loss=0.20853514969348907
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 175: train_loss=0.2066083550453186
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 176: train_loss=0.2076444923877716
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 177: train_loss=0.2056940793991089
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 178: train_loss=0.2075551152229309
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 179: train_loss=0.20532330870628357
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 180: train_loss=0.20748457312583923
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 181: train_loss=0.2053024023771286
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 182: train_loss=0.20720131695270538
INFO - 04/15/25 16:43:28 - 0:11:51 - Epoch 183: train_loss=0.20540839433670044
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 184: train_loss=0.20645102858543396
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 185: train_loss=0.20466871559619904
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 186: train_loss=0.2063603699207306
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 187: train_loss=0.20446449518203735
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 188: train_loss=0.20611980557441711
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 189: train_loss=0.20428809523582458
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 190: train_loss=0.205873042345047
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 191: train_loss=0.20432345569133759
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 192: train_loss=0.2051147073507309
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 193: train_loss=0.2036157101392746
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 194: train_loss=0.205094113945961
INFO - 04/15/25 16:43:28 - 0:11:52 - Epoch 195: train_loss=0.2035447210073471
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 196: train_loss=0.20466755330562592
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 197: train_loss=0.20327745378017426
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 198: train_loss=0.20427240431308746
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 199: train_loss=0.20305462181568146
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 200: train_loss=0.20368795096874237
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 201: train_loss=0.2023313045501709
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 202: train_loss=0.20390170812606812
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 203: train_loss=0.20271191000938416
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 204: train_loss=0.20282019674777985
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 205: train_loss=0.2016770839691162
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 206: train_loss=0.20318108797073364
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 207: train_loss=0.2019779086112976
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 208: train_loss=0.20236951112747192
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 209: train_loss=0.20128308236598969
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 210: train_loss=0.2024189829826355
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 211: train_loss=0.2013436108827591
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 212: train_loss=0.20175933837890625
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 213: train_loss=0.20069052278995514
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 214: train_loss=0.2019003927707672
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 215: train_loss=0.20088373124599457
INFO - 04/15/25 16:43:29 - 0:11:52 - Epoch 216: train_loss=0.20110005140304565
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 217: train_loss=0.20004074275493622
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 218: train_loss=0.20150288939476013
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 219: train_loss=0.20058922469615936
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 220: train_loss=0.200271338224411
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 221: train_loss=0.19918666779994965
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 222: train_loss=0.20134997367858887
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 223: train_loss=0.20049844682216644
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 224: train_loss=0.19935573637485504
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 225: train_loss=0.19837859272956848
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 226: train_loss=0.20144426822662354
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 227: train_loss=0.20118702948093414
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 228: train_loss=0.19774585962295532
INFO - 04/15/25 16:43:29 - 0:11:53 - Epoch 229: train_loss=0.20023681223392487
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 230: train_loss=0.20349285006523132
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 231: train_loss=0.19960780441761017
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 232: train_loss=0.19475769996643066
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 233: train_loss=0.20986589789390564
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 234: train_loss=0.19635754823684692
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 235: train_loss=0.22455880045890808
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 236: train_loss=0.22586935758590698
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 237: train_loss=0.20230531692504883
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 238: train_loss=0.22264309227466583
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 239: train_loss=0.2249758541584015
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 240: train_loss=0.20946931838989258
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 241: train_loss=0.21800056099891663
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 242: train_loss=0.21491022408008575
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 243: train_loss=0.20904392004013062
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 244: train_loss=0.21512606739997864
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 245: train_loss=0.20085087418556213
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 246: train_loss=0.21923856437206268
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 247: train_loss=0.22558747231960297
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 248: train_loss=0.20670360326766968
INFO - 04/15/25 16:43:30 - 0:11:53 - Epoch 249: train_loss=0.21646025776863098
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 250: train_loss=0.22541821002960205
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 251: train_loss=0.21215376257896423
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 252: train_loss=0.2106981724500656
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 253: train_loss=0.21626439690589905
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 254: train_loss=0.20549282431602478
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 255: train_loss=0.21166695654392242
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 256: train_loss=0.2139378935098648
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 257: train_loss=0.20131319761276245
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 258: train_loss=0.21140336990356445
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 259: train_loss=0.21461616456508636
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 260: train_loss=0.20086190104484558
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 261: train_loss=0.211399644613266
INFO - 04/15/25 16:43:30 - 0:11:54 - Epoch 262: train_loss=0.21810583770275116
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 263: train_loss=0.20587779581546783
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 264: train_loss=0.20508532226085663
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 265: train_loss=0.21253006160259247
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 266: train_loss=0.20185495913028717
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 267: train_loss=0.20638114213943481
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 268: train_loss=0.21219778060913086
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 269: train_loss=0.20033922791481018
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 270: train_loss=0.20773042738437653
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 271: train_loss=0.2138354778289795
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 272: train_loss=0.20322862267494202
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 273: train_loss=0.20370927453041077
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 274: train_loss=0.2091364860534668
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 275: train_loss=0.20165811479091644
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 276: train_loss=0.20198675990104675
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 277: train_loss=0.20488813519477844
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 278: train_loss=0.19935330748558044
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 279: train_loss=0.20079702138900757
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 280: train_loss=0.20181633532047272
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 281: train_loss=0.19790047407150269
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 282: train_loss=0.19918756186962128
INFO - 04/15/25 16:43:31 - 0:11:54 - Epoch 283: train_loss=0.19982227683067322
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 284: train_loss=0.19484414160251617
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 285: train_loss=0.20011337101459503
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 286: train_loss=0.19719044864177704
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 287: train_loss=0.19877351820468903
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 288: train_loss=0.1985461711883545
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 289: train_loss=0.19625480473041534
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 290: train_loss=0.1967296302318573
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 291: train_loss=0.19602656364440918
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 292: train_loss=0.19502677023410797
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 293: train_loss=0.19849848747253418
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 294: train_loss=0.1956752985715866
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 295: train_loss=0.19947582483291626
INFO - 04/15/25 16:43:31 - 0:11:55 - Epoch 296: train_loss=0.19950710237026215
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 297: train_loss=0.19473975896835327
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 298: train_loss=0.19975979626178741
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 299: train_loss=0.19590741395950317
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 300: train_loss=0.2011263072490692
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 301: train_loss=0.20049342513084412
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 302: train_loss=0.1973755806684494
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 303: train_loss=0.19685852527618408
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 304: train_loss=0.1988454908132553
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 305: train_loss=0.19513970613479614
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 306: train_loss=0.20092356204986572
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 307: train_loss=0.19854246079921722
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 308: train_loss=0.19939769804477692
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 309: train_loss=0.19731341302394867
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 310: train_loss=0.20031766593456268
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 311: train_loss=0.1974404901266098
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 312: train_loss=0.20072050392627716
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 313: train_loss=0.20024268329143524
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 314: train_loss=0.19618265330791473
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 315: train_loss=0.1955450028181076
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 316: train_loss=0.1998548060655594
INFO - 04/15/25 16:43:32 - 0:11:55 - Epoch 317: train_loss=0.1974087655544281
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 318: train_loss=0.19953584671020508
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 319: train_loss=0.19946619868278503
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 320: train_loss=0.195284903049469
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 321: train_loss=0.19573919475078583
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 322: train_loss=0.19750221073627472
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 323: train_loss=0.19309401512145996
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 324: train_loss=0.20412996411323547
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 325: train_loss=0.20387285947799683
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 326: train_loss=0.19299247860908508
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 327: train_loss=0.20334061980247498
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 328: train_loss=0.19834189116954803
INFO - 04/15/25 16:43:32 - 0:11:56 - Epoch 329: train_loss=0.20249612629413605
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 330: train_loss=0.20297755300998688
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 331: train_loss=0.19713327288627625
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 332: train_loss=0.19869156181812286
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 333: train_loss=0.19779935479164124
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 334: train_loss=0.19685101509094238
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 335: train_loss=0.19579607248306274
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 336: train_loss=0.19859683513641357
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 337: train_loss=0.194800466299057
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 338: train_loss=0.2022794783115387
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 339: train_loss=0.20107030868530273
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 340: train_loss=0.19661833345890045
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 341: train_loss=0.19816292822360992
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 342: train_loss=0.19564978778362274
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 343: train_loss=0.19962909817695618
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 344: train_loss=0.1972227841615677
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 345: train_loss=0.1990957260131836
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 346: train_loss=0.19849222898483276
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 347: train_loss=0.19638130068778992
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 348: train_loss=0.19640643894672394
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 349: train_loss=0.19511157274246216
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 350: train_loss=0.19743183255195618
INFO - 04/15/25 16:43:33 - 0:11:56 - Epoch 351: train_loss=0.19225025177001953
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 352: train_loss=0.20648185908794403
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 353: train_loss=0.20659486949443817
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 354: train_loss=0.1905340850353241
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 355: train_loss=0.20083479583263397
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 356: train_loss=0.19777865707874298
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 357: train_loss=0.1958819329738617
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 358: train_loss=0.19803138077259064
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 359: train_loss=0.19197535514831543
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 360: train_loss=0.20265823602676392
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 361: train_loss=0.19848968088626862
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 362: train_loss=0.20053091645240784
INFO - 04/15/25 16:43:33 - 0:11:57 - Epoch 363: train_loss=0.19993476569652557
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 364: train_loss=0.19778648018836975
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 365: train_loss=0.1977708786725998
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 366: train_loss=0.19631430506706238
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 367: train_loss=0.19763851165771484
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 368: train_loss=0.1939052939414978
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 369: train_loss=0.19959643483161926
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 370: train_loss=0.1945512741804123
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 371: train_loss=0.2001037746667862
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 372: train_loss=0.19683738052845
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 373: train_loss=0.1988966315984726
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 374: train_loss=0.1960403323173523
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 375: train_loss=0.19749458134174347
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 376: train_loss=0.19501231610774994
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 377: train_loss=0.19334763288497925
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 378: train_loss=0.20174860954284668
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 379: train_loss=0.19978177547454834
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 380: train_loss=0.19695696234703064
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 381: train_loss=0.19596987962722778
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 382: train_loss=0.19859269261360168
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 383: train_loss=0.19402676820755005
INFO - 04/15/25 16:43:34 - 0:11:57 - Epoch 384: train_loss=0.20215380191802979
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 385: train_loss=0.19802863895893097
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 386: train_loss=0.20119211077690125
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 387: train_loss=0.20131352543830872
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 388: train_loss=0.1941700428724289
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 389: train_loss=0.19385148584842682
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 390: train_loss=0.1996278613805771
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 391: train_loss=0.1966395229101181
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 392: train_loss=0.19920198619365692
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 393: train_loss=0.19900333881378174
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 394: train_loss=0.1943560093641281
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 395: train_loss=0.1928906887769699
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 396: train_loss=0.19985033571720123
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 397: train_loss=0.1973339021205902
INFO - 04/15/25 16:43:34 - 0:11:58 - Epoch 398: train_loss=0.19729168713092804
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 399: train_loss=0.19716250896453857
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 400: train_loss=0.194854736328125
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 401: train_loss=0.19310824573040009
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 402: train_loss=0.19920487701892853
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 403: train_loss=0.19776786863803864
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 404: train_loss=0.1943923532962799
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 405: train_loss=0.1936352550983429
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 406: train_loss=0.19731265306472778
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 407: train_loss=0.1957266628742218
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 408: train_loss=0.1955726444721222
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 409: train_loss=0.1946253478527069
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 410: train_loss=0.19588248431682587
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 411: train_loss=0.19478273391723633
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 412: train_loss=0.19532760977745056
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 413: train_loss=0.1939709186553955
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 414: train_loss=0.19619326293468475
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 415: train_loss=0.19543282687664032
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 416: train_loss=0.19377750158309937
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 417: train_loss=0.19230549037456512
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 418: train_loss=0.19722481071949005
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 419: train_loss=0.19645433127880096
INFO - 04/15/25 16:43:35 - 0:11:58 - Epoch 420: train_loss=0.192183256149292
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 421: train_loss=0.19098471105098724
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 422: train_loss=0.19740252196788788
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 423: train_loss=0.19620949029922485
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 424: train_loss=0.19222714006900787
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 425: train_loss=0.1914491504430771
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 426: train_loss=0.19590207934379578
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 427: train_loss=0.1944064348936081
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 428: train_loss=0.19365251064300537
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 429: train_loss=0.1929473876953125
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 430: train_loss=0.1941634863615036
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 431: train_loss=0.1929723024368286
INFO - 04/15/25 16:43:35 - 0:11:59 - Epoch 432: train_loss=0.19421115517616272
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 433: train_loss=0.19311970472335815
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 434: train_loss=0.19381706416606903
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 435: train_loss=0.19298329949378967
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 436: train_loss=0.1933661550283432
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 437: train_loss=0.19210778176784515
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 438: train_loss=0.1943022906780243
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 439: train_loss=0.1934419721364975
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 440: train_loss=0.19253595173358917
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 441: train_loss=0.1915479451417923
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 442: train_loss=0.19400252401828766
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 443: train_loss=0.19286799430847168
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 444: train_loss=0.19280728697776794
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 445: train_loss=0.19197586178779602
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 446: train_loss=0.19310306012630463
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 447: train_loss=0.1920783817768097
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 448: train_loss=0.19295266270637512
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 449: train_loss=0.19195783138275146
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 450: train_loss=0.1928848922252655
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 451: train_loss=0.1920408010482788
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 452: train_loss=0.19244453310966492
INFO - 04/15/25 16:43:36 - 0:11:59 - Epoch 453: train_loss=0.19142049551010132
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 454: train_loss=0.19302091002464294
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 455: train_loss=0.19221504032611847
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 456: train_loss=0.19188012182712555
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 457: train_loss=0.19088870286941528
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 458: train_loss=0.19318199157714844
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 459: train_loss=0.1924286186695099
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 460: train_loss=0.19124414026737213
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 461: train_loss=0.19019430875778198
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 462: train_loss=0.19358445703983307
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 463: train_loss=0.19289764761924744
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 464: train_loss=0.19034242630004883
INFO - 04/15/25 16:43:36 - 0:12:00 - Epoch 465: train_loss=0.1893261969089508
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 466: train_loss=0.19403831660747528
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 467: train_loss=0.1933673471212387
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 468: train_loss=0.18948233127593994
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 469: train_loss=0.1885819137096405
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 470: train_loss=0.19432689249515533
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 471: train_loss=0.19352753460407257
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 472: train_loss=0.18911263346672058
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 473: train_loss=0.18822181224822998
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 474: train_loss=0.19437181949615479
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 475: train_loss=0.19360573589801788
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 476: train_loss=0.18879301846027374
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 477: train_loss=0.18948577344417572
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 478: train_loss=0.19223931431770325
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 479: train_loss=0.18958686292171478
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 480: train_loss=0.19353929162025452
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 481: train_loss=0.19325479865074158
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 482: train_loss=0.1886041909456253
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 483: train_loss=0.19455182552337646
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 484: train_loss=0.1856541782617569
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 485: train_loss=0.2097010463476181
INFO - 04/15/25 16:43:37 - 0:12:00 - Epoch 486: train_loss=0.21380141377449036
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 487: train_loss=0.19678696990013123
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 488: train_loss=0.20619048178195953
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 489: train_loss=0.21652185916900635
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 490: train_loss=0.20579379796981812
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 491: train_loss=0.19439204037189484
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 492: train_loss=0.20236867666244507
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 493: train_loss=0.19650179147720337
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 494: train_loss=0.19796989858150482
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 495: train_loss=0.19794943928718567
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 496: train_loss=0.19392015039920807
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 497: train_loss=0.19583114981651306
INFO - 04/15/25 16:43:37 - 0:12:01 - Epoch 498: train_loss=0.1916331946849823
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 499: train_loss=0.19462981820106506
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 500: train_loss=0.19104593992233276
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 501: train_loss=0.1946219652891159
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 502: train_loss=0.1920427531003952
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 503: train_loss=0.19439364969730377
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 504: train_loss=0.1930040419101715
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 505: train_loss=0.19294480979442596
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 506: train_loss=0.1923074573278427
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 507: train_loss=0.1921057254076004
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 508: train_loss=0.1911468505859375
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 509: train_loss=0.19233137369155884
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 510: train_loss=0.19103780388832092
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 511: train_loss=0.19246378540992737
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 512: train_loss=0.1913103610277176
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 513: train_loss=0.19212135672569275
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 514: train_loss=0.19106754660606384
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 515: train_loss=0.19220329821109772
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 516: train_loss=0.19101813435554504
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 517: train_loss=0.1922142654657364
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 518: train_loss=0.1912740021944046
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 519: train_loss=0.1915741115808487
INFO - 04/15/25 16:43:38 - 0:12:01 - Epoch 520: train_loss=0.19058188796043396
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 521: train_loss=0.19201765954494476
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 522: train_loss=0.19093342125415802
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 523: train_loss=0.19169999659061432
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 524: train_loss=0.1907804310321808
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 525: train_loss=0.19156835973262787
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 526: train_loss=0.19059863686561584
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 527: train_loss=0.19160406291484833
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 528: train_loss=0.19070908427238464
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 529: train_loss=0.19126446545124054
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 530: train_loss=0.1903720647096634
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 531: train_loss=0.19128696620464325
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 532: train_loss=0.19037994742393494
INFO - 04/15/25 16:43:38 - 0:12:02 - Epoch 533: train_loss=0.191121906042099
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 534: train_loss=0.19024212658405304
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 535: train_loss=0.19101089239120483
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 536: train_loss=0.1900835633277893
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 537: train_loss=0.1910063773393631
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 538: train_loss=0.19017097353935242
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 539: train_loss=0.19065998494625092
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 540: train_loss=0.1897035837173462
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 541: train_loss=0.19105954468250275
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 542: train_loss=0.19031649827957153
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 543: train_loss=0.19010910391807556
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 544: train_loss=0.18918438255786896
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 545: train_loss=0.19124963879585266
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 546: train_loss=0.1905469298362732
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 547: train_loss=0.18953464925289154
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 548: train_loss=0.1886027455329895
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 549: train_loss=0.19140206277370453
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 550: train_loss=0.190621018409729
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 551: train_loss=0.18913738429546356
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 552: train_loss=0.18830053508281708
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 553: train_loss=0.19132839143276215
INFO - 04/15/25 16:43:39 - 0:12:02 - Epoch 554: train_loss=0.19053344428539276
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 555: train_loss=0.18888422846794128
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 556: train_loss=0.18814125657081604
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 557: train_loss=0.19103868305683136
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 558: train_loss=0.1901828646659851
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 559: train_loss=0.18901102244853973
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 560: train_loss=0.18829099833965302
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 561: train_loss=0.190582275390625
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 562: train_loss=0.18973736464977264
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 563: train_loss=0.18907058238983154
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 564: train_loss=0.18834879994392395
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 565: train_loss=0.19018837809562683
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 566: train_loss=0.18937145173549652
INFO - 04/15/25 16:43:39 - 0:12:03 - Epoch 567: train_loss=0.18917378783226013
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 568: train_loss=0.188460573554039
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 569: train_loss=0.18978266417980194
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 570: train_loss=0.1889563798904419
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 571: train_loss=0.18921147286891937
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 572: train_loss=0.18848688900470734
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 573: train_loss=0.18947219848632812
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 574: train_loss=0.18870829045772552
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 575: train_loss=0.1890655905008316
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 576: train_loss=0.18830810487270355
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 577: train_loss=0.18940389156341553
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 578: train_loss=0.1886993944644928
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 579: train_loss=0.18876877427101135
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 580: train_loss=0.18801994621753693
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 581: train_loss=0.18939317762851715
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 582: train_loss=0.18871010839939117
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 583: train_loss=0.18844813108444214
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 584: train_loss=0.18770164251327515
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 585: train_loss=0.18941523134708405
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 586: train_loss=0.18876442313194275
INFO - 04/15/25 16:43:40 - 0:12:03 - Epoch 587: train_loss=0.1881534308195114
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 588: train_loss=0.1874023824930191
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 589: train_loss=0.18947139382362366
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 590: train_loss=0.18884965777397156
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 591: train_loss=0.18776853382587433
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 592: train_loss=0.18700948357582092
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 593: train_loss=0.189636692404747
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 594: train_loss=0.18906214833259583
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 595: train_loss=0.1872020959854126
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 596: train_loss=0.18637438118457794
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 597: train_loss=0.19008876383304596
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 598: train_loss=0.18958087265491486
INFO - 04/15/25 16:43:40 - 0:12:04 - Epoch 599: train_loss=0.1863623410463333
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 600: train_loss=0.18551476299762726
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 601: train_loss=0.19075451791286469
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 602: train_loss=0.19026915729045868
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 603: train_loss=0.18554000556468964
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 604: train_loss=0.1861249953508377
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 605: train_loss=0.19066229462623596
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 606: train_loss=0.1881578266620636
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 607: train_loss=0.1904279589653015
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 608: train_loss=0.19004936516284943
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 609: train_loss=0.1877330094575882
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 610: train_loss=0.1932154893875122
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 611: train_loss=0.1915482133626938
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 612: train_loss=0.19010983407497406
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 613: train_loss=0.18955889344215393
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 614: train_loss=0.19115684926509857
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 615: train_loss=0.1873350441455841
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 616: train_loss=0.19320914149284363
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 617: train_loss=0.18833284080028534
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 618: train_loss=0.1969045251607895
INFO - 04/15/25 16:43:41 - 0:12:04 - Epoch 619: train_loss=0.1964629888534546
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 620: train_loss=0.18730679154396057
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 621: train_loss=0.18909789621829987
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 622: train_loss=0.19046221673488617
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 623: train_loss=0.1864759474992752
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 624: train_loss=0.1979677826166153
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 625: train_loss=0.19950726628303528
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 626: train_loss=0.18505851924419403
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 627: train_loss=0.20330744981765747
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 628: train_loss=0.20835447311401367
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 629: train_loss=0.19840185344219208
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 630: train_loss=0.19416770339012146
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 631: train_loss=0.19825027883052826
INFO - 04/15/25 16:43:41 - 0:12:05 - Epoch 632: train_loss=0.19625115394592285
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 633: train_loss=0.19585219025611877
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 634: train_loss=0.1911538541316986
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 635: train_loss=0.19562624394893646
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 636: train_loss=0.19783847033977509
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 637: train_loss=0.1855531930923462
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 638: train_loss=0.2042047381401062
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 639: train_loss=0.21144147217273712
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 640: train_loss=0.20182742178440094
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 641: train_loss=0.1888846606016159
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 642: train_loss=0.19706185162067413
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 643: train_loss=0.1953415423631668
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 644: train_loss=0.19201688468456268
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 645: train_loss=0.19150109589099884
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 646: train_loss=0.19244904816150665
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 647: train_loss=0.19241008162498474
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 648: train_loss=0.18719251453876495
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 649: train_loss=0.19161395728588104
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 650: train_loss=0.18847531080245972
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 651: train_loss=0.19120579957962036
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 652: train_loss=0.19024412333965302
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 653: train_loss=0.18944044411182404
INFO - 04/15/25 16:43:42 - 0:12:05 - Epoch 654: train_loss=0.18873079121112823
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 655: train_loss=0.1895533949136734
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 656: train_loss=0.18830405175685883
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 657: train_loss=0.1896713376045227
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 658: train_loss=0.18820828199386597
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 659: train_loss=0.19005519151687622
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 660: train_loss=0.18863318860530853
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 661: train_loss=0.19001926481723785
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 662: train_loss=0.18871180713176727
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 663: train_loss=0.19013428688049316
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 664: train_loss=0.18915137648582458
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 665: train_loss=0.18934553861618042
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 666: train_loss=0.188527449965477
INFO - 04/15/25 16:43:42 - 0:12:06 - Epoch 667: train_loss=0.18939168751239777
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 668: train_loss=0.18854588270187378
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 669: train_loss=0.1891184151172638
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 670: train_loss=0.18792009353637695
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 671: train_loss=0.1901170164346695
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 672: train_loss=0.18920952081680298
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 673: train_loss=0.18866296112537384
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 674: train_loss=0.18791425228118896
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 675: train_loss=0.18947312235832214
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 676: train_loss=0.18861013650894165
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 677: train_loss=0.18865905702114105
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 678: train_loss=0.1876477599143982
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 679: train_loss=0.18978069722652435
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 680: train_loss=0.1891205608844757
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 681: train_loss=0.18781839311122894
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 682: train_loss=0.18680420517921448
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 683: train_loss=0.19032594561576843
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 684: train_loss=0.18981167674064636
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 685: train_loss=0.18673530220985413
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 686: train_loss=0.18565134704113007
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 687: train_loss=0.19125403463840485
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 688: train_loss=0.1907418817281723
INFO - 04/15/25 16:43:43 - 0:12:06 - Epoch 689: train_loss=0.18558689951896667
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 690: train_loss=0.1847774237394333
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 691: train_loss=0.19126492738723755
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 692: train_loss=0.19013838469982147
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 693: train_loss=0.18649618327617645
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 694: train_loss=0.18604591488838196
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 695: train_loss=0.18970784544944763
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 696: train_loss=0.18853650987148285
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 697: train_loss=0.18780121207237244
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 698: train_loss=0.18724411725997925
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 699: train_loss=0.1885814666748047
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 700: train_loss=0.18777331709861755
INFO - 04/15/25 16:43:43 - 0:12:07 - Epoch 701: train_loss=0.18806055188179016
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 702: train_loss=0.18721680343151093
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 703: train_loss=0.18866977095603943
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 704: train_loss=0.18807974457740784
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 705: train_loss=0.1872936636209488
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 706: train_loss=0.18629488348960876
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 707: train_loss=0.18948690593242645
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 708: train_loss=0.18906629085540771
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 709: train_loss=0.18598845601081848
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 710: train_loss=0.18497206270694733
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 711: train_loss=0.19041875004768372
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 712: train_loss=0.18988588452339172
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 713: train_loss=0.1850769966840744
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 714: train_loss=0.18434365093708038
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 715: train_loss=0.19034670293331146
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 716: train_loss=0.18941916525363922
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 717: train_loss=0.1857048124074936
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 718: train_loss=0.18526385724544525
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 719: train_loss=0.18922650814056396
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 720: train_loss=0.18824025988578796
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 721: train_loss=0.1867043823003769
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 722: train_loss=0.18618950247764587
INFO - 04/15/25 16:43:44 - 0:12:07 - Epoch 723: train_loss=0.18823719024658203
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 724: train_loss=0.18742451071739197
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 725: train_loss=0.18714451789855957
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 726: train_loss=0.18633931875228882
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 727: train_loss=0.18819652497768402
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 728: train_loss=0.1877235770225525
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 729: train_loss=0.18638238310813904
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 730: train_loss=0.1854526400566101
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 731: train_loss=0.18901361525058746
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 732: train_loss=0.18851041793823242
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 733: train_loss=0.1853080540895462
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 734: train_loss=0.1844448447227478
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 735: train_loss=0.18980634212493896
INFO - 04/15/25 16:43:44 - 0:12:08 - Epoch 736: train_loss=0.1893657147884369
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 737: train_loss=0.18449978530406952
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 738: train_loss=0.1854144036769867
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 739: train_loss=0.18769219517707825
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 740: train_loss=0.18484467267990112
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 741: train_loss=0.1906404346227646
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 742: train_loss=0.19049528241157532
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 743: train_loss=0.18504855036735535
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 744: train_loss=0.1917433738708496
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 745: train_loss=0.18946082890033722
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 746: train_loss=0.1888318657875061
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 747: train_loss=0.18887464702129364
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 748: train_loss=0.1880933940410614
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 749: train_loss=0.18709678947925568
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 750: train_loss=0.1879410594701767
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 751: train_loss=0.18667112290859222
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 752: train_loss=0.18490657210350037
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 753: train_loss=0.1928379386663437
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 754: train_loss=0.1915203332901001
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 755: train_loss=0.18712054193019867
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 756: train_loss=0.18695861101150513
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 757: train_loss=0.18947595357894897
INFO - 04/15/25 16:43:45 - 0:12:08 - Epoch 758: train_loss=0.18624521791934967
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 759: train_loss=0.1923263967037201
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 760: train_loss=0.19061559438705444
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 761: train_loss=0.1891445815563202
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 762: train_loss=0.1889398694038391
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 763: train_loss=0.18901558220386505
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 764: train_loss=0.18775540590286255
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 765: train_loss=0.1903463751077652
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 766: train_loss=0.18961647152900696
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 767: train_loss=0.18782930076122284
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 768: train_loss=0.1870558112859726
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 769: train_loss=0.1900736540555954
INFO - 04/15/25 16:43:45 - 0:12:09 - Epoch 770: train_loss=0.18868538737297058
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 771: train_loss=0.18922048807144165
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 772: train_loss=0.18864835798740387
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 773: train_loss=0.1883413940668106
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 774: train_loss=0.18709638714790344
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 775: train_loss=0.1902497559785843
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 776: train_loss=0.18949085474014282
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 777: train_loss=0.18724584579467773
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 778: train_loss=0.18637575209140778
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 779: train_loss=0.19026170670986176
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 780: train_loss=0.18946081399917603
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 781: train_loss=0.18686488270759583
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 782: train_loss=0.1859542429447174
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 783: train_loss=0.19038528203964233
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 784: train_loss=0.18964214622974396
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 785: train_loss=0.1864430457353592
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 786: train_loss=0.1855883002281189
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 787: train_loss=0.19021914899349213
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 788: train_loss=0.18926136195659637
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 789: train_loss=0.1867385059595108
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 790: train_loss=0.18612533807754517
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 791: train_loss=0.18926581740379333
INFO - 04/15/25 16:43:46 - 0:12:09 - Epoch 792: train_loss=0.1881815791130066
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 793: train_loss=0.18764621019363403
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 794: train_loss=0.18695715069770813
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 795: train_loss=0.18827024102210999
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 796: train_loss=0.18736563622951508
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 797: train_loss=0.1879568248987198
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 798: train_loss=0.18715456128120422
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 799: train_loss=0.18802721798419952
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 800: train_loss=0.18729862570762634
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 801: train_loss=0.18751753866672516
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 802: train_loss=0.18659083545207977
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 803: train_loss=0.18840722739696503
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 804: train_loss=0.18785995244979858
INFO - 04/15/25 16:43:46 - 0:12:10 - Epoch 805: train_loss=0.18664193153381348
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 806: train_loss=0.18563488125801086
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 807: train_loss=0.1891944259405136
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 808: train_loss=0.18870198726654053
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 809: train_loss=0.18546094000339508
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 810: train_loss=0.18438901007175446
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 811: train_loss=0.19017064571380615
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 812: train_loss=0.18974357843399048
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 813: train_loss=0.18415270745754242
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 814: train_loss=0.18319955468177795
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 815: train_loss=0.1909317672252655
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 816: train_loss=0.1903589814901352
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 817: train_loss=0.18343333899974823
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 818: train_loss=0.18342222273349762
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 819: train_loss=0.18862181901931763
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 820: train_loss=0.18665723502635956
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 821: train_loss=0.1878582090139389
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 822: train_loss=0.18802163004875183
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 823: train_loss=0.18487048149108887
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 824: train_loss=0.18456719815731049
INFO - 04/15/25 16:43:47 - 0:12:10 - Epoch 825: train_loss=0.18706460297107697
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 826: train_loss=0.18503272533416748
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 827: train_loss=0.1887042373418808
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 828: train_loss=0.18867671489715576
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 829: train_loss=0.18382568657398224
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 830: train_loss=0.18537192046642303
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 831: train_loss=0.18385767936706543
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 832: train_loss=0.1844726800918579
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 833: train_loss=0.1844990849494934
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 834: train_loss=0.18270820379257202
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 835: train_loss=0.1862875521183014
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 836: train_loss=0.18247267603874207
INFO - 04/15/25 16:43:47 - 0:12:11 - Epoch 837: train_loss=0.19091109931468964
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 838: train_loss=0.19110669195652008
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 839: train_loss=0.18188664317131042
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 840: train_loss=0.19309699535369873
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 841: train_loss=0.19490012526512146
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 842: train_loss=0.1862616389989853
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 843: train_loss=0.19237418472766876
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 844: train_loss=0.19762448966503143
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 845: train_loss=0.19218716025352478
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 846: train_loss=0.1852037012577057
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 847: train_loss=0.19015514850616455
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 848: train_loss=0.1895279884338379
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 849: train_loss=0.18443706631660461
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 850: train_loss=0.18958771228790283
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 851: train_loss=0.19032394886016846
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 852: train_loss=0.1825695037841797
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 853: train_loss=0.19260214269161224
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 854: train_loss=0.1955319344997406
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 855: train_loss=0.18850116431713104
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 856: train_loss=0.1881784349679947
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 857: train_loss=0.192399799823761
INFO - 04/15/25 16:43:48 - 0:12:11 - Epoch 858: train_loss=0.18730120360851288
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 859: train_loss=0.18767203390598297
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 860: train_loss=0.19001278281211853
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 861: train_loss=0.18598152697086334
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 862: train_loss=0.18728268146514893
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 863: train_loss=0.188259094953537
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 864: train_loss=0.18564076721668243
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 865: train_loss=0.1859215795993805
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 866: train_loss=0.18689516186714172
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 867: train_loss=0.18400759994983673
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 868: train_loss=0.1872164011001587
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 869: train_loss=0.18727253377437592
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 870: train_loss=0.18311253190040588
INFO - 04/15/25 16:43:48 - 0:12:12 - Epoch 871: train_loss=0.1853092759847641
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 872: train_loss=0.18448761105537415
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 873: train_loss=0.1836087852716446
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 874: train_loss=0.18508702516555786
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 875: train_loss=0.1827852725982666
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 876: train_loss=0.18719585239887238
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 877: train_loss=0.18722477555274963
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 878: train_loss=0.18305613100528717
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 879: train_loss=0.18603459000587463
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 880: train_loss=0.18518730998039246
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 881: train_loss=0.18385790288448334
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 882: train_loss=0.18541689217090607
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 883: train_loss=0.18279244005680084
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 884: train_loss=0.18833284080028534
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 885: train_loss=0.1880929172039032
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 886: train_loss=0.18482224643230438
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 887: train_loss=0.1853204220533371
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 888: train_loss=0.18606026470661163
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 889: train_loss=0.18407829105854034
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 890: train_loss=0.1861211657524109
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 891: train_loss=0.18546734750270844
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 892: train_loss=0.1847282350063324
INFO - 04/15/25 16:43:49 - 0:12:12 - Epoch 893: train_loss=0.1850927621126175
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 894: train_loss=0.18418370187282562
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 895: train_loss=0.18576721847057343
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 896: train_loss=0.1845824271440506
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 897: train_loss=0.18607071042060852
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 898: train_loss=0.18393827974796295
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 899: train_loss=0.18740785121917725
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 900: train_loss=0.18489471077919006
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 901: train_loss=0.1884111911058426
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 902: train_loss=0.1886574774980545
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 903: train_loss=0.18355558812618256
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 904: train_loss=0.18590345978736877
INFO - 04/15/25 16:43:49 - 0:12:13 - Epoch 905: train_loss=0.18465615808963776
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 906: train_loss=0.1849227100610733
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 907: train_loss=0.18455541133880615
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 908: train_loss=0.18483765423297882
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 909: train_loss=0.183711975812912
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 910: train_loss=0.18660619854927063
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 911: train_loss=0.18635527789592743
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 912: train_loss=0.18357309699058533
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 913: train_loss=0.1843567192554474
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 914: train_loss=0.18281669914722443
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 915: train_loss=0.1846262663602829
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 916: train_loss=0.1824086308479309
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 917: train_loss=0.18308696150779724
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 918: train_loss=0.18280425667762756
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 919: train_loss=0.18514059484004974
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 920: train_loss=0.18142057955265045
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 921: train_loss=0.19165648519992828
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 922: train_loss=0.19234822690486908
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 923: train_loss=0.18347245454788208
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 924: train_loss=0.1921411007642746
INFO - 04/15/25 16:43:50 - 0:12:13 - Epoch 925: train_loss=0.19484230875968933
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 926: train_loss=0.18905135989189148
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 927: train_loss=0.18860135972499847
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 928: train_loss=0.19002220034599304
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 929: train_loss=0.18830548226833344
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 930: train_loss=0.18851587176322937
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 931: train_loss=0.18608835339546204
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 932: train_loss=0.18811367452144623
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 933: train_loss=0.18756292760372162
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 934: train_loss=0.18535691499710083
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 935: train_loss=0.1860039085149765
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 936: train_loss=0.18556448817253113
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 937: train_loss=0.18469735980033875
INFO - 04/15/25 16:43:50 - 0:12:14 - Epoch 938: train_loss=0.18572577834129333
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 939: train_loss=0.1848234087228775
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 940: train_loss=0.18567566573619843
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 941: train_loss=0.18474282324314117
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 942: train_loss=0.18603016436100006
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 943: train_loss=0.18550264835357666
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 944: train_loss=0.18487383425235748
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 945: train_loss=0.1843867301940918
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 946: train_loss=0.1852710247039795
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 947: train_loss=0.1836400181055069
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 948: train_loss=0.1861865520477295
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 949: train_loss=0.18402951955795288
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 950: train_loss=0.18719489872455597
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 951: train_loss=0.18646745383739471
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 952: train_loss=0.18493613600730896
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 953: train_loss=0.18473877012729645
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 954: train_loss=0.18560506403446198
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 955: train_loss=0.1839119791984558
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 956: train_loss=0.18734724819660187
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 957: train_loss=0.18643151223659515
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 958: train_loss=0.18483266234397888
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 959: train_loss=0.18483521044254303
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 960: train_loss=0.18525320291519165
INFO - 04/15/25 16:43:51 - 0:12:14 - Epoch 961: train_loss=0.18401487171649933
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 962: train_loss=0.1871437281370163
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 963: train_loss=0.1871366798877716
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 964: train_loss=0.1828286200761795
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 965: train_loss=0.18214593827724457
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 966: train_loss=0.18719126284122467
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 967: train_loss=0.18587112426757812
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 968: train_loss=0.18511877954006195
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 969: train_loss=0.18494299054145813
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 970: train_loss=0.18504732847213745
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 971: train_loss=0.18405285477638245
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 972: train_loss=0.18622738122940063
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 973: train_loss=0.1849694848060608
INFO - 04/15/25 16:43:51 - 0:12:15 - Epoch 974: train_loss=0.18600620329380035
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 975: train_loss=0.1858128309249878
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 976: train_loss=0.1842842698097229
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 977: train_loss=0.1836143136024475
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 978: train_loss=0.18654075264930725
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 979: train_loss=0.18583093583583832
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 980: train_loss=0.18429292738437653
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 981: train_loss=0.18369759619235992
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 982: train_loss=0.18643763661384583
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 983: train_loss=0.18600623309612274
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 984: train_loss=0.18381477892398834
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 985: train_loss=0.18302831053733826
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 986: train_loss=0.18709219992160797
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 987: train_loss=0.18664509057998657
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 988: train_loss=0.18305908143520355
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 989: train_loss=0.18250541388988495
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 990: train_loss=0.18693654239177704
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 991: train_loss=0.18596269190311432
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 992: train_loss=0.18422171473503113
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 993: train_loss=0.1840599775314331
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 994: train_loss=0.18525251746177673
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 995: train_loss=0.18421964347362518
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 996: train_loss=0.18586993217468262
INFO - 04/15/25 16:43:52 - 0:12:15 - Epoch 997: train_loss=0.185374453663826
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 998: train_loss=0.18447495996952057
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 999: train_loss=0.18402817845344543
INFO - 04/15/25 16:43:52 - 0:12:16 - --------------------------Training Start-------------------------
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 1: train_loss=10.076010704040527
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 2: train_loss=10.188197135925293
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 3: train_loss=10.168489456176758
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 4: train_loss=10.120282173156738
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 5: train_loss=10.080422401428223
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 6: train_loss=10.109594345092773
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 7: train_loss=10.113433837890625
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 8: train_loss=10.100041389465332
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 9: train_loss=10.08348560333252
INFO - 04/15/25 16:43:52 - 0:12:16 - Epoch 10: train_loss=10.084836959838867
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 11: train_loss=10.089473724365234
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 12: train_loss=10.086407661437988
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 13: train_loss=10.080656051635742
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 14: train_loss=10.080531120300293
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 15: train_loss=10.07983684539795
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 16: train_loss=10.074193954467773
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 17: train_loss=10.071001052856445
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 18: train_loss=10.074994087219238
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 19: train_loss=10.074198722839355
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 20: train_loss=10.06991958618164
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 21: train_loss=10.071084022521973
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 22: train_loss=10.072449684143066
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 23: train_loss=10.068686485290527
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 24: train_loss=10.068878173828125
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 25: train_loss=10.072144508361816
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 26: train_loss=10.068225860595703
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 27: train_loss=10.068784713745117
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 28: train_loss=10.069703102111816
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 29: train_loss=10.06657600402832
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 30: train_loss=10.068873405456543
INFO - 04/15/25 16:43:53 - 0:12:16 - Epoch 31: train_loss=10.067914009094238
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 32: train_loss=10.066421508789062
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 33: train_loss=10.068081855773926
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 34: train_loss=10.066008567810059
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 35: train_loss=10.066293716430664
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 36: train_loss=10.066786766052246
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 37: train_loss=10.06482982635498
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 38: train_loss=10.066307067871094
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 39: train_loss=10.065526962280273
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 40: train_loss=10.063191413879395
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 41: train_loss=10.066126823425293
INFO - 04/15/25 16:43:53 - 0:12:17 - Epoch 42: train_loss=10.065773010253906
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 43: train_loss=10.063817977905273
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 44: train_loss=10.067755699157715
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 45: train_loss=10.06535816192627
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 46: train_loss=10.067455291748047
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 47: train_loss=10.064164161682129
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 48: train_loss=10.068315505981445
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 49: train_loss=10.063902854919434
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 50: train_loss=10.0703706741333
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 51: train_loss=10.070231437683105
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 52: train_loss=10.064656257629395
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 53: train_loss=10.067647933959961
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 54: train_loss=10.066422462463379
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 55: train_loss=10.06530475616455
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 56: train_loss=10.065193176269531
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 57: train_loss=10.064842224121094
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 58: train_loss=10.0642671585083
INFO - 04/15/25 16:43:54 - 0:12:17 - Epoch 59: train_loss=10.064075469970703
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 60: train_loss=10.064515113830566
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 61: train_loss=10.06103801727295
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 62: train_loss=10.066566467285156
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 63: train_loss=10.061779975891113
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 64: train_loss=10.068739891052246
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 65: train_loss=10.065563201904297
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 66: train_loss=10.068069458007812
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 67: train_loss=10.066378593444824
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 68: train_loss=10.066801071166992
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 69: train_loss=10.06649398803711
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 70: train_loss=10.06534481048584
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 71: train_loss=10.064602851867676
INFO - 04/15/25 16:43:54 - 0:12:18 - Epoch 72: train_loss=10.06676197052002
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 73: train_loss=10.064631462097168
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 74: train_loss=10.066019058227539
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 75: train_loss=10.065909385681152
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 76: train_loss=10.064210891723633
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 77: train_loss=10.06490707397461
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 78: train_loss=10.064062118530273
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 79: train_loss=10.065949440002441
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 80: train_loss=10.063224792480469
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 81: train_loss=10.067174911499023
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 82: train_loss=10.064803123474121
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 83: train_loss=10.06766414642334
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 84: train_loss=10.066778182983398
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 85: train_loss=10.065189361572266
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 86: train_loss=10.065083503723145
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 87: train_loss=10.06468677520752
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 88: train_loss=10.063840866088867
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 89: train_loss=10.065783500671387
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 90: train_loss=10.064515113830566
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 91: train_loss=10.065740585327148
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 92: train_loss=10.064605712890625
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 93: train_loss=10.06562328338623
INFO - 04/15/25 16:43:55 - 0:12:18 - Epoch 94: train_loss=10.064796447753906
INFO - 04/15/25 16:43:55 - 0:12:19 - Epoch 95: train_loss=10.064827919006348
INFO - 04/15/25 16:43:55 - 0:12:19 - Epoch 96: train_loss=10.064435958862305
INFO - 04/15/25 16:43:55 - 0:12:19 - Epoch 97: train_loss=10.064287185668945
INFO - 04/15/25 16:43:55 - 0:12:19 - Epoch 98: train_loss=10.063931465148926
INFO - 04/15/25 16:43:55 - 0:12:19 - Epoch 99: train_loss=10.063456535339355
INFO - 04/15/25 16:43:55 - 0:12:19 - Epoch 100: train_loss=10.06384563446045
INFO - 04/15/25 16:43:55 - 0:12:19 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:43:55 - 0:12:19 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:43:56 - 0:12:19 - ------------------Saving best model-------------------
INFO - 04/15/25 16:43:57 - 0:12:20 - Epoch 100: ACC: 0.0, NMI: 0.4160648188354468, F1: 0.0, ARI: 0.17827338054648903
INFO - 04/15/25 16:43:57 - 0:12:20 - -------------------------------------------------------------------------
INFO - 04/15/25 16:43:57 - 0:12:20 - Epoch 101: train_loss=10.06240463256836
INFO - 04/15/25 16:43:57 - 0:12:20 - Epoch 102: train_loss=10.064619064331055
INFO - 04/15/25 16:43:57 - 0:12:20 - Epoch 103: train_loss=10.062834739685059
INFO - 04/15/25 16:43:57 - 0:12:20 - Epoch 104: train_loss=10.066173553466797
INFO - 04/15/25 16:43:57 - 0:12:20 - Epoch 105: train_loss=10.062990188598633
INFO - 04/15/25 16:43:57 - 0:12:20 - Epoch 106: train_loss=10.06562328338623
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 107: train_loss=10.063820838928223
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 108: train_loss=10.066667556762695
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 109: train_loss=10.065558433532715
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 110: train_loss=10.064745903015137
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 111: train_loss=10.065523147583008
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 112: train_loss=10.063185691833496
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 113: train_loss=10.063653945922852
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 114: train_loss=10.0637845993042
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 115: train_loss=10.064947128295898
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 116: train_loss=10.063291549682617
INFO - 04/15/25 16:43:57 - 0:12:21 - Epoch 117: train_loss=10.063960075378418
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 118: train_loss=10.06187629699707
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 119: train_loss=10.068120002746582
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 120: train_loss=10.06823444366455
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 121: train_loss=10.062141418457031
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 122: train_loss=10.071557998657227
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 123: train_loss=10.070487022399902
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 124: train_loss=10.066116333007812
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 125: train_loss=10.065713882446289
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 126: train_loss=10.068456649780273
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 127: train_loss=10.062972068786621
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 128: train_loss=10.072539329528809
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 129: train_loss=10.071197509765625
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 130: train_loss=10.066825866699219
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 131: train_loss=10.067272186279297
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 132: train_loss=10.066964149475098
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 133: train_loss=10.065888404846191
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 134: train_loss=10.067750930786133
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 135: train_loss=10.065499305725098
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 136: train_loss=10.069107055664062
INFO - 04/15/25 16:43:58 - 0:12:21 - Epoch 137: train_loss=10.068796157836914
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 138: train_loss=10.064567565917969
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 139: train_loss=10.064287185668945
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 140: train_loss=10.06710433959961
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 141: train_loss=10.063897132873535
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 142: train_loss=10.069562911987305
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 143: train_loss=10.069239616394043
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 144: train_loss=10.064054489135742
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 145: train_loss=10.064926147460938
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 146: train_loss=10.06541919708252
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 147: train_loss=10.063220977783203
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 148: train_loss=10.067400932312012
INFO - 04/15/25 16:43:58 - 0:12:22 - Epoch 149: train_loss=10.065540313720703
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 150: train_loss=10.066445350646973
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 151: train_loss=10.065718650817871
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 152: train_loss=10.065597534179688
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 153: train_loss=10.064642906188965
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 154: train_loss=10.06607437133789
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 155: train_loss=10.064684867858887
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 156: train_loss=10.06640625
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 157: train_loss=10.065709114074707
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 158: train_loss=10.064522743225098
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 159: train_loss=10.06410026550293
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 160: train_loss=10.065230369567871
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 161: train_loss=10.063491821289062
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 162: train_loss=10.066770553588867
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 163: train_loss=10.06615924835205
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 164: train_loss=10.063525199890137
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 165: train_loss=10.063398361206055
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 166: train_loss=10.064595222473145
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 167: train_loss=10.063019752502441
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 168: train_loss=10.06585693359375
INFO - 04/15/25 16:43:59 - 0:12:22 - Epoch 169: train_loss=10.064897537231445
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 170: train_loss=10.063955307006836
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 171: train_loss=10.063943862915039
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 172: train_loss=10.063499450683594
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 173: train_loss=10.06282901763916
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 174: train_loss=10.064120292663574
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 175: train_loss=10.06258773803711
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 176: train_loss=10.065790176391602
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 177: train_loss=10.06531047821045
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 178: train_loss=10.062515258789062
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 179: train_loss=10.061870574951172
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 180: train_loss=10.065608024597168
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 181: train_loss=10.064697265625
INFO - 04/15/25 16:43:59 - 0:12:23 - Epoch 182: train_loss=10.0630521774292
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 183: train_loss=10.062823295593262
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 184: train_loss=10.063735008239746
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 185: train_loss=10.062596321105957
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 186: train_loss=10.064589500427246
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 187: train_loss=10.064050674438477
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 188: train_loss=10.06275463104248
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 189: train_loss=10.0621337890625
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 190: train_loss=10.064393043518066
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 191: train_loss=10.063501358032227
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 192: train_loss=10.06326961517334
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 193: train_loss=10.062957763671875
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 194: train_loss=10.0629243850708
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 195: train_loss=10.062195777893066
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 196: train_loss=10.063841819763184
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 197: train_loss=10.062992095947266
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 198: train_loss=10.063068389892578
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 199: train_loss=10.062684059143066
INFO - 04/15/25 16:44:00 - 0:12:23 - Epoch 200: train_loss=10.062655448913574
INFO - 04/15/25 16:44:00 - 0:12:23 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:00 - 0:12:24 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:44:01 - 0:12:24 - Epoch 200: ACC: 0.0, NMI: 0.35373400932214916, F1: 0.0, ARI: 0.11449726922756201
INFO - 04/15/25 16:44:01 - 0:12:24 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:01 - 0:12:24 - Epoch 201: train_loss=10.06190299987793
INFO - 04/15/25 16:44:01 - 0:12:24 - Epoch 202: train_loss=10.063721656799316
INFO - 04/15/25 16:44:01 - 0:12:24 - Epoch 203: train_loss=10.063013076782227
INFO - 04/15/25 16:44:01 - 0:12:24 - Epoch 204: train_loss=10.06236743927002
INFO - 04/15/25 16:44:01 - 0:12:24 - Epoch 205: train_loss=10.062390327453613
INFO - 04/15/25 16:44:01 - 0:12:24 - Epoch 206: train_loss=10.062439918518066
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 207: train_loss=10.06141471862793
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 208: train_loss=10.06325912475586
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 209: train_loss=10.06233024597168
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 210: train_loss=10.062748908996582
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 211: train_loss=10.062621116638184
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 212: train_loss=10.061525344848633
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 213: train_loss=10.060859680175781
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 214: train_loss=10.064192771911621
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 215: train_loss=10.063824653625488
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 216: train_loss=10.059965133666992
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 217: train_loss=10.064915657043457
INFO - 04/15/25 16:44:01 - 0:12:25 - Epoch 218: train_loss=10.061351776123047
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 219: train_loss=10.061575889587402
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 220: train_loss=10.061446189880371
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 221: train_loss=10.061227798461914
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 222: train_loss=10.060603141784668
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 223: train_loss=10.061120986938477
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 224: train_loss=10.061781883239746
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 225: train_loss=10.060713768005371
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 226: train_loss=10.063848495483398
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 227: train_loss=10.058768272399902
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 228: train_loss=10.06834602355957
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 229: train_loss=10.06599235534668
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 230: train_loss=10.06397533416748
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 231: train_loss=10.064214706420898
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 232: train_loss=10.063673973083496
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 233: train_loss=10.062582969665527
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 234: train_loss=10.064726829528809
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 235: train_loss=10.06273078918457
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 236: train_loss=10.065580368041992
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 237: train_loss=10.064844131469727
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 238: train_loss=10.063004493713379
INFO - 04/15/25 16:44:02 - 0:12:25 - Epoch 239: train_loss=10.062921524047852
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 240: train_loss=10.063127517700195
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 241: train_loss=10.062024116516113
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 242: train_loss=10.062870979309082
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 243: train_loss=10.061793327331543
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 244: train_loss=10.062026023864746
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 245: train_loss=10.061930656433105
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 246: train_loss=10.060970306396484
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 247: train_loss=10.061145782470703
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 248: train_loss=10.062289237976074
INFO - 04/15/25 16:44:02 - 0:12:26 - Epoch 249: train_loss=10.058837890625
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 250: train_loss=10.069098472595215
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 251: train_loss=10.069272994995117
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 252: train_loss=10.059062004089355
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 253: train_loss=10.0689697265625
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 254: train_loss=10.070409774780273
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 255: train_loss=10.063948631286621
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 256: train_loss=10.065059661865234
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 257: train_loss=10.0676908493042
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 258: train_loss=10.06545639038086
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 259: train_loss=10.061895370483398
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 260: train_loss=10.064873695373535
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 261: train_loss=10.064886093139648
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 262: train_loss=10.061878204345703
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 263: train_loss=10.062480926513672
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 264: train_loss=10.064299583435059
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 265: train_loss=10.05920124053955
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 266: train_loss=10.06628131866455
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 267: train_loss=10.067071914672852
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 268: train_loss=10.064387321472168
INFO - 04/15/25 16:44:03 - 0:12:26 - Epoch 269: train_loss=10.063080787658691
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 270: train_loss=10.062360763549805
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 271: train_loss=10.063958168029785
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 272: train_loss=10.062045097351074
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 273: train_loss=10.05984878540039
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 274: train_loss=10.065665245056152
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 275: train_loss=10.06329345703125
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 276: train_loss=10.063372611999512
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 277: train_loss=10.062729835510254
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 278: train_loss=10.0645112991333
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 279: train_loss=10.063031196594238
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 280: train_loss=10.064606666564941
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 281: train_loss=10.063531875610352
INFO - 04/15/25 16:44:03 - 0:12:27 - Epoch 282: train_loss=10.061308860778809
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 283: train_loss=10.063573837280273
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 284: train_loss=10.061896324157715
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 285: train_loss=10.058430671691895
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 286: train_loss=10.065166473388672
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 287: train_loss=10.062666893005371
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 288: train_loss=10.064640045166016
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 289: train_loss=10.064502716064453
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 290: train_loss=10.060356140136719
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 291: train_loss=10.060840606689453
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 292: train_loss=10.063216209411621
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 293: train_loss=10.060676574707031
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 294: train_loss=10.063176155090332
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 295: train_loss=10.06082534790039
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 296: train_loss=10.065375328063965
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 297: train_loss=10.06515121459961
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 298: train_loss=10.060461044311523
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 299: train_loss=10.063790321350098
INFO - 04/15/25 16:44:04 - 0:12:27 - Epoch 300: train_loss=10.059305191040039
INFO - 04/15/25 16:44:04 - 0:12:27 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:04 - 0:12:28 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:44:04 - 0:12:28 - Epoch 300: ACC: 0.0, NMI: 0.32099608474794233, F1: 0.0, ARI: 0.1726193315436993
INFO - 04/15/25 16:44:04 - 0:12:28 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:04 - 0:12:28 - Epoch 301: train_loss=10.06348991394043
INFO - 04/15/25 16:44:04 - 0:12:28 - Epoch 302: train_loss=10.062407493591309
INFO - 04/15/25 16:44:04 - 0:12:28 - Epoch 303: train_loss=10.060070037841797
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 304: train_loss=10.062139511108398
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 305: train_loss=10.060678482055664
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 306: train_loss=10.061388969421387
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 307: train_loss=10.058206558227539
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 308: train_loss=10.064777374267578
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 309: train_loss=10.063591957092285
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 310: train_loss=10.06068229675293
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 311: train_loss=10.062150955200195
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 312: train_loss=10.059852600097656
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 313: train_loss=10.059633255004883
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 314: train_loss=10.060678482055664
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 315: train_loss=10.060065269470215
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 316: train_loss=10.060209274291992
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 317: train_loss=10.059301376342773
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 318: train_loss=10.059866905212402
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 319: train_loss=10.058300971984863
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 320: train_loss=10.060863494873047
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 321: train_loss=10.058701515197754
INFO - 04/15/25 16:44:05 - 0:12:28 - Epoch 322: train_loss=10.061423301696777
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 323: train_loss=10.059110641479492
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 324: train_loss=10.060932159423828
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 325: train_loss=10.05931568145752
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 326: train_loss=10.061470031738281
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 327: train_loss=10.060001373291016
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 328: train_loss=10.060013771057129
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 329: train_loss=10.058863639831543
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 330: train_loss=10.060575485229492
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 331: train_loss=10.059784889221191
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 332: train_loss=10.060307502746582
INFO - 04/15/25 16:44:05 - 0:12:29 - Epoch 333: train_loss=10.05954647064209
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 334: train_loss=10.059684753417969
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 335: train_loss=10.058557510375977
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 336: train_loss=10.059652328491211
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 337: train_loss=10.058385848999023
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 338: train_loss=10.05982780456543
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 339: train_loss=10.05949878692627
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 340: train_loss=10.057561874389648
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 341: train_loss=10.056800842285156
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 342: train_loss=10.059775352478027
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 343: train_loss=10.058920860290527
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 344: train_loss=10.055658340454102
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 345: train_loss=10.057694435119629
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 346: train_loss=10.060261726379395
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 347: train_loss=10.056323051452637
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 348: train_loss=10.06098747253418
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 349: train_loss=10.059064865112305
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 350: train_loss=10.05834674835205
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 351: train_loss=10.060327529907227
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 352: train_loss=10.058220863342285
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 353: train_loss=10.06017017364502
INFO - 04/15/25 16:44:06 - 0:12:29 - Epoch 354: train_loss=10.059300422668457
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 355: train_loss=10.058638572692871
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 356: train_loss=10.059043884277344
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 357: train_loss=10.057931900024414
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 358: train_loss=10.059465408325195
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 359: train_loss=10.05802059173584
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 360: train_loss=10.059052467346191
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 361: train_loss=10.0565824508667
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 362: train_loss=10.05691146850586
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 363: train_loss=10.059226036071777
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 364: train_loss=10.056939125061035
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 365: train_loss=10.060776710510254
INFO - 04/15/25 16:44:06 - 0:12:30 - Epoch 366: train_loss=10.058938980102539
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 367: train_loss=10.060737609863281
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 368: train_loss=10.058178901672363
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 369: train_loss=10.061863899230957
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 370: train_loss=10.06177806854248
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 371: train_loss=10.054830551147461
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 372: train_loss=10.054856300354004
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 373: train_loss=10.058792114257812
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 374: train_loss=10.055766105651855
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 375: train_loss=10.061039924621582
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 376: train_loss=10.060480117797852
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 377: train_loss=10.056113243103027
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 378: train_loss=10.05665397644043
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 379: train_loss=10.057371139526367
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 380: train_loss=10.05522632598877
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 381: train_loss=10.060002326965332
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 382: train_loss=10.059597969055176
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 383: train_loss=10.054298400878906
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 384: train_loss=10.05418586730957
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 385: train_loss=10.05737590789795
INFO - 04/15/25 16:44:07 - 0:12:30 - Epoch 386: train_loss=10.054586410522461
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 387: train_loss=10.059697151184082
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 388: train_loss=10.059152603149414
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 389: train_loss=10.054889678955078
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 390: train_loss=10.055973052978516
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 391: train_loss=10.055660247802734
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 392: train_loss=10.053812980651855
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 393: train_loss=10.057780265808105
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 394: train_loss=10.055368423461914
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 395: train_loss=10.058544158935547
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 396: train_loss=10.058906555175781
INFO - 04/15/25 16:44:07 - 0:12:31 - Epoch 397: train_loss=10.052477836608887
INFO - 04/15/25 16:44:08 - 0:12:31 - Epoch 398: train_loss=10.057022094726562
INFO - 04/15/25 16:44:08 - 0:12:31 - Epoch 399: train_loss=10.050896644592285
INFO - 04/15/25 16:44:08 - 0:12:31 - Epoch 400: train_loss=10.065589904785156
INFO - 04/15/25 16:44:08 - 0:12:31 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:08 - 0:12:31 - Decoding cost time:  0.131 s
INFO - 04/15/25 16:44:08 - 0:12:31 - ------------------Saving best model-------------------
INFO - 04/15/25 16:44:08 - 0:12:32 - Epoch 400: ACC: 0.0, NMI: 0.4850728665914267, F1: 0.0, ARI: 0.3366434465301323
INFO - 04/15/25 16:44:08 - 0:12:32 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:08 - 0:12:32 - Epoch 401: train_loss=10.066085815429688
INFO - 04/15/25 16:44:08 - 0:12:32 - Epoch 402: train_loss=10.054018020629883
INFO - 04/15/25 16:44:08 - 0:12:32 - Epoch 403: train_loss=10.066856384277344
INFO - 04/15/25 16:44:08 - 0:12:32 - Epoch 404: train_loss=10.07114315032959
INFO - 04/15/25 16:44:08 - 0:12:32 - Epoch 405: train_loss=10.062983512878418
INFO - 04/15/25 16:44:08 - 0:12:32 - Epoch 406: train_loss=10.059572219848633
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 407: train_loss=10.063179969787598
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 408: train_loss=10.060707092285156
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 409: train_loss=10.05945110321045
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 410: train_loss=10.0584135055542
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 411: train_loss=10.05862808227539
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 412: train_loss=10.058286666870117
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 413: train_loss=10.055672645568848
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 414: train_loss=10.05785083770752
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 415: train_loss=10.05617904663086
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 416: train_loss=10.055157661437988
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 417: train_loss=10.055551528930664
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 418: train_loss=10.053738594055176
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 419: train_loss=10.05334186553955
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 420: train_loss=10.055296897888184
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 421: train_loss=10.053597450256348
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 422: train_loss=10.05567741394043
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 423: train_loss=10.054429054260254
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 424: train_loss=10.05494499206543
INFO - 04/15/25 16:44:09 - 0:12:32 - Epoch 425: train_loss=10.053916931152344
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 426: train_loss=10.054441452026367
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 427: train_loss=10.053498268127441
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 428: train_loss=10.05384635925293
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 429: train_loss=10.052947044372559
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 430: train_loss=10.053956985473633
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 431: train_loss=10.052519798278809
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 432: train_loss=10.054642677307129
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 433: train_loss=10.053308486938477
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 434: train_loss=10.05416488647461
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 435: train_loss=10.053805351257324
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 436: train_loss=10.052708625793457
INFO - 04/15/25 16:44:09 - 0:12:33 - Epoch 437: train_loss=10.052027702331543
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 438: train_loss=10.053765296936035
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 439: train_loss=10.05285930633545
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 440: train_loss=10.052912712097168
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 441: train_loss=10.052604675292969
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 442: train_loss=10.05213737487793
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 443: train_loss=10.051009178161621
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 444: train_loss=10.054081916809082
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 445: train_loss=10.053667068481445
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 446: train_loss=10.050935745239258
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 447: train_loss=10.053257942199707
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 448: train_loss=10.049747467041016
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 449: train_loss=10.053836822509766
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 450: train_loss=10.051526069641113
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 451: train_loss=10.053300857543945
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 452: train_loss=10.053332328796387
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 453: train_loss=10.050590515136719
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 454: train_loss=10.05556869506836
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 455: train_loss=10.053314208984375
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 456: train_loss=10.054452896118164
INFO - 04/15/25 16:44:10 - 0:12:33 - Epoch 457: train_loss=10.054279327392578
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 458: train_loss=10.052687644958496
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 459: train_loss=10.051921844482422
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 460: train_loss=10.05350112915039
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 461: train_loss=10.050670623779297
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 462: train_loss=10.056595802307129
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 463: train_loss=10.055619239807129
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 464: train_loss=10.051621437072754
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 465: train_loss=10.051648139953613
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 466: train_loss=10.053119659423828
INFO - 04/15/25 16:44:10 - 0:12:34 - Epoch 467: train_loss=10.050729751586914
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 468: train_loss=10.056083679199219
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 469: train_loss=10.055374145507812
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 470: train_loss=10.049697875976562
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 471: train_loss=10.049080848693848
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 472: train_loss=10.055713653564453
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 473: train_loss=10.054242134094238
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 474: train_loss=10.05109691619873
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 475: train_loss=10.050729751586914
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 476: train_loss=10.053139686584473
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 477: train_loss=10.05186939239502
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 478: train_loss=10.051973342895508
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 479: train_loss=10.051325798034668
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 480: train_loss=10.051457405090332
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 481: train_loss=10.050625801086426
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 482: train_loss=10.051759719848633
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 483: train_loss=10.051017761230469
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 484: train_loss=10.051159858703613
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 485: train_loss=10.050287246704102
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 486: train_loss=10.050088882446289
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 487: train_loss=10.04858112335205
INFO - 04/15/25 16:44:11 - 0:12:34 - Epoch 488: train_loss=10.050004959106445
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 489: train_loss=10.047525405883789
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 490: train_loss=10.041571617126465
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 491: train_loss=10.038175582885742
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 492: train_loss=10.034822463989258
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 493: train_loss=10.020968437194824
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 494: train_loss=10.009373664855957
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 495: train_loss=9.988316535949707
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 496: train_loss=9.99001693725586
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 497: train_loss=9.98129653930664
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 498: train_loss=9.9830904006958
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 499: train_loss=9.98134708404541
INFO - 04/15/25 16:44:11 - 0:12:35 - Epoch 500: train_loss=9.985576629638672
INFO - 04/15/25 16:44:11 - 0:12:35 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:12 - 0:12:35 - Decoding cost time:  0.139 s
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 500: ACC: 0.0, NMI: 0.28217577157372103, F1: 0.0, ARI: 0.10231267905702594
INFO - 04/15/25 16:44:12 - 0:12:35 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 501: train_loss=9.978979110717773
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 502: train_loss=9.992393493652344
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 503: train_loss=9.989509582519531
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 504: train_loss=9.984918594360352
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 505: train_loss=9.983634948730469
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 506: train_loss=9.9865083694458
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 507: train_loss=9.979392051696777
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 508: train_loss=9.992110252380371
INFO - 04/15/25 16:44:12 - 0:12:35 - Epoch 509: train_loss=9.988920211791992
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 510: train_loss=9.985736846923828
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 511: train_loss=9.98271369934082
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 512: train_loss=9.98857307434082
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 513: train_loss=9.986980438232422
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 514: train_loss=9.981658935546875
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 515: train_loss=9.98037338256836
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 516: train_loss=9.985624313354492
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 517: train_loss=9.981575965881348
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 518: train_loss=9.985114097595215
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 519: train_loss=9.983468055725098
INFO - 04/15/25 16:44:12 - 0:12:36 - Epoch 520: train_loss=9.982207298278809
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 521: train_loss=9.98087215423584
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 522: train_loss=9.983962059020996
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 523: train_loss=9.98235034942627
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 524: train_loss=9.98222827911377
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 525: train_loss=9.98126220703125
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 526: train_loss=9.980802536010742
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 527: train_loss=9.979700088500977
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 528: train_loss=9.98091983795166
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 529: train_loss=9.979400634765625
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 530: train_loss=9.980278015136719
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 531: train_loss=9.978714942932129
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 532: train_loss=9.982266426086426
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 533: train_loss=9.980896949768066
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 534: train_loss=9.977842330932617
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 535: train_loss=9.977054595947266
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 536: train_loss=9.981141090393066
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 537: train_loss=9.979175567626953
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 538: train_loss=9.978852272033691
INFO - 04/15/25 16:44:13 - 0:12:36 - Epoch 539: train_loss=9.978462219238281
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 540: train_loss=9.978903770446777
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 541: train_loss=9.97744083404541
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 542: train_loss=9.978598594665527
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 543: train_loss=9.977543830871582
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 544: train_loss=9.979832649230957
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 545: train_loss=9.977677345275879
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 546: train_loss=9.9776611328125
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 547: train_loss=9.976858139038086
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 548: train_loss=9.980097770690918
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 549: train_loss=9.978528022766113
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 550: train_loss=9.977555274963379
INFO - 04/15/25 16:44:13 - 0:12:37 - Epoch 551: train_loss=9.97620964050293
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 552: train_loss=9.979689598083496
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 553: train_loss=9.978899002075195
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 554: train_loss=9.975512504577637
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 555: train_loss=9.974328994750977
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 556: train_loss=9.97958755493164
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 557: train_loss=9.978797912597656
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 558: train_loss=9.974486351013184
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 559: train_loss=9.973150253295898
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 560: train_loss=9.980137825012207
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 561: train_loss=9.978285789489746
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 562: train_loss=9.975296974182129
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 563: train_loss=9.974516868591309
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 564: train_loss=9.979649543762207
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 565: train_loss=9.978128433227539
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 566: train_loss=9.975963592529297
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 567: train_loss=9.975578308105469
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 568: train_loss=9.976341247558594
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 569: train_loss=9.975103378295898
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 570: train_loss=9.977020263671875
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 571: train_loss=9.975966453552246
INFO - 04/15/25 16:44:14 - 0:12:37 - Epoch 572: train_loss=9.975714683532715
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 573: train_loss=9.974738121032715
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 574: train_loss=9.976837158203125
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 575: train_loss=9.975469589233398
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 576: train_loss=9.976277351379395
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 577: train_loss=9.975569725036621
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 578: train_loss=9.974836349487305
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 579: train_loss=9.973509788513184
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 580: train_loss=9.977038383483887
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 581: train_loss=9.975923538208008
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 582: train_loss=9.974455833435059
INFO - 04/15/25 16:44:14 - 0:12:38 - Epoch 583: train_loss=9.973158836364746
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 584: train_loss=9.976405143737793
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 585: train_loss=9.974719047546387
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 586: train_loss=9.976667404174805
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 587: train_loss=9.975404739379883
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 588: train_loss=9.975432395935059
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 589: train_loss=9.974263191223145
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 590: train_loss=9.975494384765625
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 591: train_loss=9.97419548034668
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 592: train_loss=9.975713729858398
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 593: train_loss=9.974909782409668
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 594: train_loss=9.973916053771973
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 595: train_loss=9.972468376159668
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 596: train_loss=9.976752281188965
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 597: train_loss=9.975814819335938
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 598: train_loss=9.973085403442383
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 599: train_loss=9.971759796142578
INFO - 04/15/25 16:44:15 - 0:12:38 - Epoch 600: train_loss=9.976800918579102
INFO - 04/15/25 16:44:15 - 0:12:38 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:15 - 0:12:39 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:44:15 - 0:12:39 - Epoch 600: ACC: 0.0, NMI: 0.3684581830126612, F1: 0.0, ARI: 0.18601650728636138
INFO - 04/15/25 16:44:15 - 0:12:39 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:15 - 0:12:39 - Epoch 601: train_loss=9.975288391113281
INFO - 04/15/25 16:44:15 - 0:12:39 - Epoch 602: train_loss=9.973100662231445
INFO - 04/15/25 16:44:15 - 0:12:39 - Epoch 603: train_loss=9.97204303741455
INFO - 04/15/25 16:44:15 - 0:12:39 - Epoch 604: train_loss=9.975473403930664
INFO - 04/15/25 16:44:15 - 0:12:39 - Epoch 605: train_loss=9.973734855651855
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 606: train_loss=9.974808692932129
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 607: train_loss=9.973648071289062
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 608: train_loss=9.974040985107422
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 609: train_loss=9.972431182861328
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 610: train_loss=9.977437019348145
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 611: train_loss=9.975987434387207
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 612: train_loss=9.974259376525879
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 613: train_loss=9.973426818847656
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 614: train_loss=9.975008964538574
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 615: train_loss=9.972963333129883
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 616: train_loss=9.976741790771484
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 617: train_loss=9.976452827453613
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 618: train_loss=9.97080135345459
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 619: train_loss=9.96990966796875
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 620: train_loss=9.976761817932129
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 621: train_loss=9.9751615524292
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 622: train_loss=9.972953796386719
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 623: train_loss=9.973182678222656
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 624: train_loss=9.972582817077637
INFO - 04/15/25 16:44:16 - 0:12:39 - Epoch 625: train_loss=9.971796989440918
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 626: train_loss=9.973349571228027
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 627: train_loss=9.971319198608398
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 628: train_loss=9.9749755859375
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 629: train_loss=9.974398612976074
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 630: train_loss=9.971755981445312
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 631: train_loss=9.971592903137207
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 632: train_loss=9.97263240814209
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 633: train_loss=9.970769882202148
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 634: train_loss=9.975372314453125
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 635: train_loss=9.974309921264648
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 636: train_loss=9.971309661865234
INFO - 04/15/25 16:44:16 - 0:12:40 - Epoch 637: train_loss=9.971128463745117
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 638: train_loss=9.973198890686035
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 639: train_loss=9.970990180969238
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 640: train_loss=9.974745750427246
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 641: train_loss=9.974394798278809
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 642: train_loss=9.971084594726562
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 643: train_loss=9.96953010559082
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 644: train_loss=9.975419044494629
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 645: train_loss=9.974431037902832
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 646: train_loss=9.970026016235352
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 647: train_loss=9.969709396362305
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 648: train_loss=9.973151206970215
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 649: train_loss=9.971601486206055
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 650: train_loss=9.972171783447266
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 651: train_loss=9.971722602844238
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 652: train_loss=9.970724105834961
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 653: train_loss=9.970039367675781
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 654: train_loss=9.972123146057129
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 655: train_loss=9.970731735229492
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 656: train_loss=9.972055435180664
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 657: train_loss=9.971517562866211
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 658: train_loss=9.970399856567383
INFO - 04/15/25 16:44:17 - 0:12:40 - Epoch 659: train_loss=9.969206809997559
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 660: train_loss=9.972868919372559
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 661: train_loss=9.971492767333984
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 662: train_loss=9.970291137695312
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 663: train_loss=9.969808578491211
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 664: train_loss=9.97063159942627
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 665: train_loss=9.968992233276367
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 666: train_loss=9.97264575958252
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 667: train_loss=9.97193717956543
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 668: train_loss=9.969191551208496
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 669: train_loss=9.968173027038574
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 670: train_loss=9.974039077758789
INFO - 04/15/25 16:44:17 - 0:12:41 - Epoch 671: train_loss=9.972480773925781
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 672: train_loss=9.96962833404541
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 673: train_loss=9.973930358886719
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 674: train_loss=9.967094421386719
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 675: train_loss=9.980803489685059
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 676: train_loss=9.980008125305176
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 677: train_loss=9.973691940307617
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 678: train_loss=9.972410202026367
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 679: train_loss=9.976455688476562
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 680: train_loss=9.97195053100586
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 681: train_loss=9.980579376220703
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 682: train_loss=9.97767162322998
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 683: train_loss=9.97617244720459
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 684: train_loss=9.973182678222656
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 685: train_loss=9.977886199951172
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 686: train_loss=9.975971221923828
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 687: train_loss=9.974591255187988
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 688: train_loss=9.973223686218262
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 689: train_loss=9.975354194641113
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 690: train_loss=9.972822189331055
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 691: train_loss=9.973427772521973
INFO - 04/15/25 16:44:18 - 0:12:41 - Epoch 692: train_loss=9.971512794494629
INFO - 04/15/25 16:44:18 - 0:12:42 - Epoch 693: train_loss=9.975268363952637
INFO - 04/15/25 16:44:18 - 0:12:42 - Epoch 694: train_loss=9.972587585449219
INFO - 04/15/25 16:44:18 - 0:12:42 - Epoch 695: train_loss=9.974017143249512
INFO - 04/15/25 16:44:18 - 0:12:42 - Epoch 696: train_loss=9.973467826843262
INFO - 04/15/25 16:44:18 - 0:12:42 - Epoch 697: train_loss=9.971504211425781
INFO - 04/15/25 16:44:18 - 0:12:42 - Epoch 698: train_loss=9.969324111938477
INFO - 04/15/25 16:44:18 - 0:12:42 - Epoch 699: train_loss=9.974446296691895
INFO - 04/15/25 16:44:18 - 0:12:42 - Epoch 700: train_loss=9.971686363220215
INFO - 04/15/25 16:44:18 - 0:12:42 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:18 - 0:12:42 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 700: ACC: 0.0, NMI: 0.2793196670376721, F1: 0.0, ARI: 0.11879486478288319
INFO - 04/15/25 16:44:19 - 0:12:42 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 701: train_loss=9.973860740661621
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 702: train_loss=9.973121643066406
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 703: train_loss=9.969367027282715
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 704: train_loss=9.968427658081055
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 705: train_loss=9.974675178527832
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 706: train_loss=9.972277641296387
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 707: train_loss=9.96972942352295
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 708: train_loss=9.96900463104248
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 709: train_loss=9.973731994628906
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 710: train_loss=9.9714994430542
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 711: train_loss=9.969732284545898
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 712: train_loss=9.969158172607422
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 713: train_loss=9.972450256347656
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 714: train_loss=9.969731330871582
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 715: train_loss=9.971734046936035
INFO - 04/15/25 16:44:19 - 0:12:42 - Epoch 716: train_loss=9.97130012512207
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 717: train_loss=9.969770431518555
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 718: train_loss=9.968110084533691
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 719: train_loss=9.972319602966309
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 720: train_loss=9.97087287902832
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 721: train_loss=9.967828750610352
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 722: train_loss=9.9669771194458
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 723: train_loss=9.971342086791992
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 724: train_loss=9.969915390014648
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 725: train_loss=9.96911334991455
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 726: train_loss=9.967894554138184
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 727: train_loss=9.969022750854492
INFO - 04/15/25 16:44:19 - 0:12:43 - Epoch 728: train_loss=9.967679977416992
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 729: train_loss=9.969039916992188
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 730: train_loss=9.967427253723145
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 731: train_loss=9.967723846435547
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 732: train_loss=9.966264724731445
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 733: train_loss=9.968551635742188
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 734: train_loss=9.96642780303955
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 735: train_loss=9.965201377868652
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 736: train_loss=9.965765953063965
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 737: train_loss=9.97098159790039
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 738: train_loss=9.968734741210938
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 739: train_loss=9.968111038208008
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 740: train_loss=9.970032691955566
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 741: train_loss=9.964221000671387
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 742: train_loss=9.966968536376953
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 743: train_loss=9.96557331085205
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 744: train_loss=9.964364051818848
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 745: train_loss=9.960514068603516
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 746: train_loss=9.957289695739746
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 747: train_loss=9.951639175415039
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 748: train_loss=9.94698429107666
INFO - 04/15/25 16:44:20 - 0:12:43 - Epoch 749: train_loss=9.936700820922852
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 750: train_loss=9.935476303100586
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 751: train_loss=9.935457229614258
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 752: train_loss=9.93294620513916
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 753: train_loss=9.935700416564941
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 754: train_loss=9.933611869812012
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 755: train_loss=9.929418563842773
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 756: train_loss=9.937621116638184
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 757: train_loss=9.928752899169922
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 758: train_loss=9.938338279724121
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 759: train_loss=9.93543529510498
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 760: train_loss=9.936020851135254
INFO - 04/15/25 16:44:20 - 0:12:44 - Epoch 761: train_loss=9.932622909545898
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 762: train_loss=9.932719230651855
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 763: train_loss=9.931519508361816
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 764: train_loss=9.932496070861816
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 765: train_loss=9.927395820617676
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 766: train_loss=9.927704811096191
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 767: train_loss=9.92162799835205
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 768: train_loss=9.930951118469238
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 769: train_loss=9.91196060180664
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 770: train_loss=9.937687873840332
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 771: train_loss=9.968350410461426
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 772: train_loss=10.013388633728027
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 773: train_loss=9.986342430114746
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 774: train_loss=9.974658966064453
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 775: train_loss=9.97311782836914
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 776: train_loss=9.97647476196289
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 777: train_loss=9.98863697052002
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 778: train_loss=9.97618579864502
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 779: train_loss=9.967981338500977
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 780: train_loss=9.969820022583008
INFO - 04/15/25 16:44:21 - 0:12:44 - Epoch 781: train_loss=9.953603744506836
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 782: train_loss=9.951469421386719
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 783: train_loss=9.96337604522705
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 784: train_loss=9.958139419555664
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 785: train_loss=9.95177173614502
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 786: train_loss=9.947869300842285
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 787: train_loss=9.944169998168945
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 788: train_loss=9.925057411193848
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 789: train_loss=9.921544075012207
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 790: train_loss=9.937572479248047
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 791: train_loss=9.923506736755371
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 792: train_loss=9.93419075012207
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 793: train_loss=9.921062469482422
INFO - 04/15/25 16:44:21 - 0:12:45 - Epoch 794: train_loss=9.94164752960205
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 795: train_loss=9.938154220581055
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 796: train_loss=9.930438995361328
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 797: train_loss=9.928092002868652
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 798: train_loss=9.927218437194824
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 799: train_loss=9.936769485473633
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 800: train_loss=9.92317008972168
INFO - 04/15/25 16:44:22 - 0:12:45 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:22 - 0:12:45 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 800: ACC: 0.0, NMI: 0.3027262353455594, F1: 0.0, ARI: 0.11359520524043269
INFO - 04/15/25 16:44:22 - 0:12:45 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 801: train_loss=9.94528865814209
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 802: train_loss=9.936766624450684
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 803: train_loss=9.932517051696777
INFO - 04/15/25 16:44:22 - 0:12:45 - Epoch 804: train_loss=9.930076599121094
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 805: train_loss=9.933189392089844
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 806: train_loss=9.924695014953613
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 807: train_loss=9.938100814819336
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 808: train_loss=9.935148239135742
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 809: train_loss=9.917903900146484
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 810: train_loss=9.915531158447266
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 811: train_loss=9.915842056274414
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 812: train_loss=9.919475555419922
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 813: train_loss=9.914767265319824
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 814: train_loss=9.906084060668945
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 815: train_loss=9.912858963012695
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 816: train_loss=9.907938957214355
INFO - 04/15/25 16:44:22 - 0:12:46 - Epoch 817: train_loss=9.910789489746094
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 818: train_loss=9.901240348815918
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 819: train_loss=9.90238094329834
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 820: train_loss=9.873733520507812
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 821: train_loss=9.85350513458252
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 822: train_loss=9.817886352539062
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 823: train_loss=9.801633834838867
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 824: train_loss=9.806584358215332
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 825: train_loss=9.787575721740723
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 826: train_loss=9.78803539276123
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 827: train_loss=9.78506851196289
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 828: train_loss=9.779321670532227
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 829: train_loss=9.799121856689453
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 830: train_loss=9.794471740722656
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 831: train_loss=9.787569046020508
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 832: train_loss=9.771510124206543
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 833: train_loss=9.780620574951172
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 834: train_loss=9.765995025634766
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 835: train_loss=9.757076263427734
INFO - 04/15/25 16:44:23 - 0:12:46 - Epoch 836: train_loss=9.755019187927246
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 837: train_loss=9.737454414367676
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 838: train_loss=9.726203918457031
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 839: train_loss=9.720605850219727
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 840: train_loss=9.712127685546875
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 841: train_loss=9.695161819458008
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 842: train_loss=9.651005744934082
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 843: train_loss=9.624837875366211
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 844: train_loss=9.609374046325684
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 845: train_loss=9.597829818725586
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 846: train_loss=9.572036743164062
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 847: train_loss=9.506624221801758
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 848: train_loss=9.500870704650879
INFO - 04/15/25 16:44:23 - 0:12:47 - Epoch 849: train_loss=9.514010429382324
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 850: train_loss=9.495494842529297
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 851: train_loss=9.50220012664795
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 852: train_loss=9.497603416442871
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 853: train_loss=9.51169490814209
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 854: train_loss=9.491666793823242
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 855: train_loss=9.503214836120605
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 856: train_loss=9.48236083984375
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 857: train_loss=9.509602546691895
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 858: train_loss=9.485066413879395
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 859: train_loss=9.462050437927246
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 860: train_loss=9.439437866210938
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 861: train_loss=9.426876068115234
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 862: train_loss=9.364290237426758
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 863: train_loss=9.317804336547852
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 864: train_loss=9.250149726867676
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 865: train_loss=9.243651390075684
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 866: train_loss=9.233030319213867
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 867: train_loss=9.216913223266602
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 868: train_loss=9.214442253112793
INFO - 04/15/25 16:44:24 - 0:12:47 - Epoch 869: train_loss=9.2329683303833
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 870: train_loss=9.206594467163086
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 871: train_loss=9.206621170043945
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 872: train_loss=9.19430923461914
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 873: train_loss=9.18100357055664
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 874: train_loss=9.161288261413574
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 875: train_loss=9.146027565002441
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 876: train_loss=9.101179122924805
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 877: train_loss=9.084532737731934
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 878: train_loss=9.034777641296387
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 879: train_loss=9.012211799621582
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 880: train_loss=8.966340065002441
INFO - 04/15/25 16:44:24 - 0:12:48 - Epoch 881: train_loss=8.93809986114502
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 882: train_loss=8.931633949279785
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 883: train_loss=8.919760704040527
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 884: train_loss=8.918277740478516
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 885: train_loss=8.922375679016113
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 886: train_loss=8.897639274597168
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 887: train_loss=8.836424827575684
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 888: train_loss=8.748414993286133
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 889: train_loss=8.740052223205566
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 890: train_loss=8.743584632873535
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 891: train_loss=8.73265552520752
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 892: train_loss=8.725079536437988
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 893: train_loss=8.73459529876709
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 894: train_loss=8.727518081665039
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 895: train_loss=8.728754043579102
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 896: train_loss=8.725373268127441
INFO - 04/15/25 16:44:25 - 0:12:48 - Epoch 897: train_loss=8.730134010314941
INFO - 04/15/25 16:44:25 - 0:12:49 - Epoch 898: train_loss=8.724530220031738
INFO - 04/15/25 16:44:25 - 0:12:49 - Epoch 899: train_loss=8.721336364746094
INFO - 04/15/25 16:44:25 - 0:12:49 - Epoch 900: train_loss=8.724254608154297
INFO - 04/15/25 16:44:25 - 0:12:49 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:25 - 0:12:49 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 900: ACC: 0.0, NMI: 0.35105005734614464, F1: 0.0, ARI: 0.07960810543407207
INFO - 04/15/25 16:44:26 - 0:12:49 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 901: train_loss=8.725494384765625
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 902: train_loss=8.720932960510254
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 903: train_loss=8.720945358276367
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 904: train_loss=8.726655960083008
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 905: train_loss=8.71646785736084
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 906: train_loss=8.7200345993042
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 907: train_loss=8.723607063293457
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 908: train_loss=8.716230392456055
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 909: train_loss=8.71799087524414
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 910: train_loss=8.721111297607422
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 911: train_loss=8.712198257446289
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 912: train_loss=8.720015525817871
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 913: train_loss=8.714680671691895
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 914: train_loss=8.713348388671875
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 915: train_loss=8.715145111083984
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 916: train_loss=8.711771011352539
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 917: train_loss=8.712337493896484
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 918: train_loss=8.71078109741211
INFO - 04/15/25 16:44:26 - 0:12:49 - Epoch 919: train_loss=8.710245132446289
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 920: train_loss=8.708453178405762
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 921: train_loss=8.711624145507812
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 922: train_loss=8.703779220581055
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 923: train_loss=8.7116060256958
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 924: train_loss=8.70326042175293
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 925: train_loss=8.706421852111816
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 926: train_loss=8.70614242553711
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 927: train_loss=8.702177047729492
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 928: train_loss=8.705390930175781
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 929: train_loss=8.702009201049805
INFO - 04/15/25 16:44:26 - 0:12:50 - Epoch 930: train_loss=8.705632209777832
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 931: train_loss=8.698358535766602
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 932: train_loss=8.706281661987305
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 933: train_loss=8.699424743652344
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 934: train_loss=8.699423789978027
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 935: train_loss=8.699870109558105
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 936: train_loss=8.704559326171875
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 937: train_loss=8.702032089233398
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 938: train_loss=8.698827743530273
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 939: train_loss=8.700881004333496
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 940: train_loss=8.695958137512207
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 941: train_loss=8.713761329650879
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 942: train_loss=8.710042953491211
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 943: train_loss=8.711587905883789
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 944: train_loss=8.704099655151367
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 945: train_loss=8.71718978881836
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 946: train_loss=8.712570190429688
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 947: train_loss=8.713014602661133
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 948: train_loss=8.707697868347168
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 949: train_loss=8.714475631713867
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 950: train_loss=8.708765983581543
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 951: train_loss=8.710400581359863
INFO - 04/15/25 16:44:27 - 0:12:50 - Epoch 952: train_loss=8.71204662322998
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 953: train_loss=8.70688533782959
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 954: train_loss=8.702980041503906
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 955: train_loss=8.714727401733398
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 956: train_loss=8.696436882019043
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 957: train_loss=8.69155216217041
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 958: train_loss=8.673187255859375
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 959: train_loss=8.67271900177002
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 960: train_loss=8.67943000793457
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 961: train_loss=8.671499252319336
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 962: train_loss=8.674229621887207
INFO - 04/15/25 16:44:27 - 0:12:51 - Epoch 963: train_loss=8.675440788269043
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 964: train_loss=8.664776802062988
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 965: train_loss=8.66641616821289
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 966: train_loss=8.640872955322266
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 967: train_loss=8.618805885314941
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 968: train_loss=8.624192237854004
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 969: train_loss=8.610321998596191
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 970: train_loss=8.605198860168457
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 971: train_loss=8.592365264892578
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 972: train_loss=8.588935852050781
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 973: train_loss=8.587104797363281
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 974: train_loss=8.599916458129883
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 975: train_loss=8.58691692352295
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 976: train_loss=8.599149703979492
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 977: train_loss=8.583578109741211
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 978: train_loss=8.614585876464844
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 979: train_loss=8.602110862731934
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 980: train_loss=8.603391647338867
INFO - 04/15/25 16:44:28 - 0:12:51 - Epoch 981: train_loss=8.595108985900879
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 982: train_loss=8.585271835327148
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 983: train_loss=8.580205917358398
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 984: train_loss=8.591644287109375
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 985: train_loss=8.583093643188477
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 986: train_loss=8.59028434753418
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 987: train_loss=8.584783554077148
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 988: train_loss=8.587926864624023
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 989: train_loss=8.580388069152832
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 990: train_loss=8.580748558044434
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 991: train_loss=8.578656196594238
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 992: train_loss=8.574822425842285
INFO - 04/15/25 16:44:28 - 0:12:52 - Epoch 993: train_loss=8.57192611694336
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 994: train_loss=8.575471878051758
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 995: train_loss=8.570611000061035
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 996: train_loss=8.574117660522461
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 997: train_loss=8.572290420532227
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 998: train_loss=8.566948890686035
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 999: train_loss=8.565410614013672
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 1000: train_loss=8.564735412597656
INFO - 04/15/25 16:44:29 - 0:12:52 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:29 - 0:12:52 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 1000: ACC: 0.0, NMI: 0.33178311429139, F1: 0.0, ARI: 0.11534636635663871
INFO - 04/15/25 16:44:29 - 0:12:52 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 1001: train_loss=8.561302185058594
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 1002: train_loss=8.564505577087402
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 1003: train_loss=8.559666633605957
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 1004: train_loss=8.564493179321289
INFO - 04/15/25 16:44:29 - 0:12:52 - Epoch 1005: train_loss=8.561375617980957
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1006: train_loss=8.560051918029785
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1007: train_loss=8.559663772583008
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1008: train_loss=8.554574966430664
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1009: train_loss=8.562361717224121
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1010: train_loss=8.551543235778809
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1011: train_loss=8.57359504699707
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1012: train_loss=8.571290016174316
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1013: train_loss=8.553084373474121
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1014: train_loss=8.562204360961914
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1015: train_loss=8.558056831359863
INFO - 04/15/25 16:44:29 - 0:12:53 - Epoch 1016: train_loss=8.555574417114258
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1017: train_loss=8.559115409851074
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1018: train_loss=8.552550315856934
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1019: train_loss=8.561869621276855
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1020: train_loss=8.554900169372559
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1021: train_loss=8.56525707244873
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1022: train_loss=8.558238983154297
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1023: train_loss=8.565977096557617
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1024: train_loss=8.563102722167969
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1025: train_loss=8.557783126831055
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1026: train_loss=8.55584716796875
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1027: train_loss=8.566731452941895
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1028: train_loss=8.587967872619629
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1029: train_loss=8.56857967376709
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1030: train_loss=8.570205688476562
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1031: train_loss=8.561746597290039
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1032: train_loss=8.561206817626953
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1033: train_loss=8.561251640319824
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1034: train_loss=8.557731628417969
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1035: train_loss=8.565107345581055
INFO - 04/15/25 16:44:30 - 0:12:53 - Epoch 1036: train_loss=8.558207511901855
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1037: train_loss=8.56746768951416
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1038: train_loss=8.560928344726562
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1039: train_loss=8.569774627685547
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1040: train_loss=8.567173957824707
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1041: train_loss=8.557937622070312
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1042: train_loss=8.557753562927246
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1043: train_loss=8.562938690185547
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1044: train_loss=8.558167457580566
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1045: train_loss=8.563350677490234
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1046: train_loss=8.561485290527344
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1047: train_loss=8.558060646057129
INFO - 04/15/25 16:44:30 - 0:12:54 - Epoch 1048: train_loss=8.555708885192871
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1049: train_loss=8.562259674072266
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1050: train_loss=8.557159423828125
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1051: train_loss=8.558011054992676
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1052: train_loss=8.555105209350586
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1053: train_loss=8.559892654418945
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1054: train_loss=8.556001663208008
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1055: train_loss=8.557487487792969
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1056: train_loss=8.553815841674805
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1057: train_loss=8.560134887695312
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1058: train_loss=8.557475090026855
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1059: train_loss=8.559029579162598
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1060: train_loss=8.556343078613281
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1061: train_loss=8.557618141174316
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1062: train_loss=8.55412769317627
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1063: train_loss=8.561996459960938
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1064: train_loss=8.559736251831055
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1065: train_loss=8.555587768554688
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1066: train_loss=8.55292797088623
INFO - 04/15/25 16:44:31 - 0:12:54 - Epoch 1067: train_loss=8.561284065246582
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1068: train_loss=8.556493759155273
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1069: train_loss=8.55770206451416
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1070: train_loss=8.554808616638184
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1071: train_loss=8.559067726135254
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1072: train_loss=8.55672550201416
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1073: train_loss=8.553780555725098
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1074: train_loss=8.551278114318848
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1075: train_loss=8.560612678527832
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1076: train_loss=8.558077812194824
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1077: train_loss=8.551315307617188
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1078: train_loss=8.543582916259766
INFO - 04/15/25 16:44:31 - 0:12:55 - Epoch 1079: train_loss=8.558192253112793
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1080: train_loss=8.537577629089355
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1081: train_loss=8.559646606445312
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1082: train_loss=8.559221267700195
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1083: train_loss=8.557284355163574
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1084: train_loss=8.530027389526367
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1085: train_loss=8.53591537475586
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1086: train_loss=8.529831886291504
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1087: train_loss=8.533555030822754
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1088: train_loss=8.522658348083496
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1089: train_loss=8.522644996643066
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1090: train_loss=8.503076553344727
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1091: train_loss=8.509303092956543
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1092: train_loss=8.510151863098145
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1093: train_loss=8.502341270446777
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1094: train_loss=8.520652770996094
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1095: train_loss=8.511568069458008
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1096: train_loss=8.509169578552246
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1097: train_loss=8.501026153564453
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1098: train_loss=8.50568675994873
INFO - 04/15/25 16:44:32 - 0:12:55 - Epoch 1099: train_loss=8.502901077270508
INFO - 04/15/25 16:44:32 - 0:12:56 - Epoch 1100: train_loss=8.499798774719238
INFO - 04/15/25 16:44:32 - 0:12:56 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:32 - 0:12:56 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:44:32 - 0:12:56 - Epoch 1100: ACC: 0.0, NMI: 0.36538490898164044, F1: 0.0, ARI: 0.12116568674985587
INFO - 04/15/25 16:44:32 - 0:12:56 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:32 - 0:12:56 - Epoch 1101: train_loss=8.494779586791992
INFO - 04/15/25 16:44:32 - 0:12:56 - Epoch 1102: train_loss=8.500513076782227
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1103: train_loss=8.494911193847656
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1104: train_loss=8.502823829650879
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1105: train_loss=8.500506401062012
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1106: train_loss=8.495379447937012
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1107: train_loss=8.494431495666504
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1108: train_loss=8.494424819946289
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1109: train_loss=8.493400573730469
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1110: train_loss=8.487651824951172
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1111: train_loss=8.49767780303955
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1112: train_loss=8.489253044128418
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1113: train_loss=8.50385570526123
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1114: train_loss=8.500577926635742
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1115: train_loss=8.492839813232422
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1116: train_loss=8.493064880371094
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1117: train_loss=8.493700981140137
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1118: train_loss=8.490279197692871
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1119: train_loss=8.49573802947998
INFO - 04/15/25 16:44:33 - 0:12:56 - Epoch 1120: train_loss=8.491536140441895
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1121: train_loss=8.491264343261719
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1122: train_loss=8.489045143127441
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1123: train_loss=8.491227149963379
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1124: train_loss=8.48867416381836
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1125: train_loss=8.490665435791016
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1126: train_loss=8.487028121948242
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1127: train_loss=8.48978042602539
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1128: train_loss=8.486680030822754
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1129: train_loss=8.488866806030273
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1130: train_loss=8.485688209533691
INFO - 04/15/25 16:44:33 - 0:12:57 - Epoch 1131: train_loss=8.487953186035156
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1132: train_loss=8.487771034240723
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1133: train_loss=8.484832763671875
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1134: train_loss=8.489810943603516
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1135: train_loss=8.483407974243164
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1136: train_loss=8.49402141571045
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1137: train_loss=8.490275382995605
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1138: train_loss=8.491477012634277
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1139: train_loss=8.49017333984375
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1140: train_loss=8.488255500793457
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1141: train_loss=8.484166145324707
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1142: train_loss=8.494745254516602
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1143: train_loss=8.490544319152832
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1144: train_loss=8.491035461425781
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1145: train_loss=8.492855072021484
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1146: train_loss=8.484357833862305
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1147: train_loss=8.503403663635254
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1148: train_loss=8.495368957519531
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1149: train_loss=8.498822212219238
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1150: train_loss=8.49244213104248
INFO - 04/15/25 16:44:34 - 0:12:57 - Epoch 1151: train_loss=8.49813175201416
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1152: train_loss=8.490906715393066
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1153: train_loss=8.503549575805664
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1154: train_loss=8.503533363342285
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1155: train_loss=8.480644226074219
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1156: train_loss=8.488120079040527
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1157: train_loss=8.485288619995117
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1158: train_loss=8.471903800964355
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1159: train_loss=8.468208312988281
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1160: train_loss=8.472319602966309
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1161: train_loss=8.48440170288086
INFO - 04/15/25 16:44:34 - 0:12:58 - Epoch 1162: train_loss=8.463358879089355
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1163: train_loss=8.462401390075684
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1164: train_loss=8.465792655944824
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1165: train_loss=8.471487998962402
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1166: train_loss=8.466882705688477
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1167: train_loss=8.457988739013672
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1168: train_loss=8.460386276245117
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1169: train_loss=8.460504531860352
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1170: train_loss=8.456025123596191
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1171: train_loss=8.45395565032959
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1172: train_loss=8.455597877502441
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1173: train_loss=8.462000846862793
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1174: train_loss=8.454330444335938
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1175: train_loss=8.452181816101074
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1176: train_loss=8.455900192260742
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1177: train_loss=8.456693649291992
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1178: train_loss=8.450081825256348
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1179: train_loss=8.451584815979004
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1180: train_loss=8.44798469543457
INFO - 04/15/25 16:44:35 - 0:12:58 - Epoch 1181: train_loss=8.469021797180176
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1182: train_loss=8.4570951461792
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1183: train_loss=8.478354454040527
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1184: train_loss=8.472940444946289
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1185: train_loss=8.463619232177734
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1186: train_loss=8.465025901794434
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1187: train_loss=8.46271800994873
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1188: train_loss=8.455116271972656
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1189: train_loss=8.477078437805176
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1190: train_loss=8.47223949432373
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1191: train_loss=8.461956024169922
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1192: train_loss=8.462630271911621
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1193: train_loss=8.463927268981934
INFO - 04/15/25 16:44:35 - 0:12:59 - Epoch 1194: train_loss=8.459175109863281
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1195: train_loss=8.470050811767578
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1196: train_loss=8.467621803283691
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1197: train_loss=8.458245277404785
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1198: train_loss=8.457962989807129
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1199: train_loss=8.464385032653809
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1200: train_loss=8.459561347961426
INFO - 04/15/25 16:44:36 - 0:12:59 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:36 - 0:12:59 - Decoding cost time:  0.131 s
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1200: ACC: 0.0, NMI: 0.31087998886246215, F1: 0.0, ARI: 0.13557199619353963
INFO - 04/15/25 16:44:36 - 0:12:59 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1201: train_loss=8.464629173278809
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1202: train_loss=8.465173721313477
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1203: train_loss=8.45624828338623
INFO - 04/15/25 16:44:36 - 0:12:59 - Epoch 1204: train_loss=8.453339576721191
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1205: train_loss=8.4647216796875
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1206: train_loss=8.462714195251465
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1207: train_loss=8.458967208862305
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1208: train_loss=8.456849098205566
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1209: train_loss=8.458110809326172
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1210: train_loss=8.454360008239746
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1211: train_loss=8.464391708374023
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1212: train_loss=8.460716247558594
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1213: train_loss=8.4550199508667
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1214: train_loss=8.456369400024414
INFO - 04/15/25 16:44:36 - 0:13:00 - Epoch 1215: train_loss=8.454366683959961
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1216: train_loss=8.449440002441406
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1217: train_loss=8.464881896972656
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1218: train_loss=8.463994979858398
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1219: train_loss=8.446927070617676
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1220: train_loss=8.453142166137695
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1221: train_loss=8.450446128845215
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1222: train_loss=8.45083999633789
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1223: train_loss=8.449434280395508
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1224: train_loss=8.468348503112793
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1225: train_loss=8.516974449157715
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1226: train_loss=8.555116653442383
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1227: train_loss=8.65306568145752
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1228: train_loss=8.617348670959473
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1229: train_loss=8.610669136047363
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1230: train_loss=8.568986892700195
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1231: train_loss=8.558600425720215
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1232: train_loss=8.65091609954834
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1233: train_loss=8.619123458862305
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1234: train_loss=8.584466934204102
INFO - 04/15/25 16:44:37 - 0:13:00 - Epoch 1235: train_loss=8.581074714660645
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1236: train_loss=8.592963218688965
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1237: train_loss=8.586782455444336
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1238: train_loss=8.581375122070312
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1239: train_loss=8.563847541809082
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1240: train_loss=8.540218353271484
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1241: train_loss=8.570276260375977
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1242: train_loss=8.541505813598633
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1243: train_loss=8.564469337463379
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1244: train_loss=8.517220497131348
INFO - 04/15/25 16:44:37 - 0:13:01 - Epoch 1245: train_loss=8.508783340454102
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1246: train_loss=8.519681930541992
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1247: train_loss=8.533870697021484
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1248: train_loss=8.574362754821777
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1249: train_loss=8.520401000976562
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1250: train_loss=8.50445556640625
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1251: train_loss=8.494487762451172
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1252: train_loss=8.472164154052734
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1253: train_loss=8.454346656799316
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1254: train_loss=8.459467887878418
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1255: train_loss=8.428238868713379
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1256: train_loss=8.437439918518066
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1257: train_loss=8.415528297424316
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1258: train_loss=8.401782035827637
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1259: train_loss=8.40280532836914
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1260: train_loss=8.398256301879883
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1261: train_loss=8.396326065063477
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1262: train_loss=8.388086318969727
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1263: train_loss=8.380769729614258
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1264: train_loss=8.387835502624512
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1265: train_loss=8.383935928344727
INFO - 04/15/25 16:44:38 - 0:13:01 - Epoch 1266: train_loss=8.376276016235352
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1267: train_loss=8.363439559936523
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1268: train_loss=8.36983585357666
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1269: train_loss=8.364801406860352
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1270: train_loss=8.365665435791016
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1271: train_loss=8.363113403320312
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1272: train_loss=8.36131763458252
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1273: train_loss=8.362424850463867
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1274: train_loss=8.355376243591309
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1275: train_loss=8.358917236328125
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1276: train_loss=8.360286712646484
INFO - 04/15/25 16:44:38 - 0:13:02 - Epoch 1277: train_loss=8.352157592773438
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1278: train_loss=8.357417106628418
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1279: train_loss=8.354310989379883
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1280: train_loss=8.348405838012695
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1281: train_loss=8.35178279876709
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1282: train_loss=8.35464096069336
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1283: train_loss=8.354925155639648
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1284: train_loss=8.354058265686035
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1285: train_loss=8.35921859741211
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1286: train_loss=8.356978416442871
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1287: train_loss=8.349617004394531
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1288: train_loss=8.34825611114502
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1289: train_loss=8.350414276123047
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1290: train_loss=8.357301712036133
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1291: train_loss=8.342395782470703
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1292: train_loss=8.360135078430176
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1293: train_loss=8.3490571975708
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1294: train_loss=8.357418060302734
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1295: train_loss=8.359460830688477
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1296: train_loss=8.35245132446289
INFO - 04/15/25 16:44:39 - 0:13:02 - Epoch 1297: train_loss=8.338727951049805
INFO - 04/15/25 16:44:39 - 0:13:03 - Epoch 1298: train_loss=8.33655834197998
INFO - 04/15/25 16:44:39 - 0:13:03 - Epoch 1299: train_loss=8.331961631774902
INFO - 04/15/25 16:44:39 - 0:13:03 - Epoch 1300: train_loss=8.333641052246094
INFO - 04/15/25 16:44:39 - 0:13:03 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:39 - 0:13:03 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1300: ACC: 0.0, NMI: 0.3796644289400106, F1: 0.0, ARI: 0.1834258653733525
INFO - 04/15/25 16:44:40 - 0:13:03 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1301: train_loss=8.321924209594727
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1302: train_loss=8.324065208435059
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1303: train_loss=8.32780933380127
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1304: train_loss=8.323847770690918
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1305: train_loss=8.323165893554688
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1306: train_loss=8.323446273803711
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1307: train_loss=8.312163352966309
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1308: train_loss=8.326146125793457
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1309: train_loss=8.319717407226562
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1310: train_loss=8.324297904968262
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1311: train_loss=8.322381973266602
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1312: train_loss=8.316052436828613
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1313: train_loss=8.31253433227539
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1314: train_loss=8.31673526763916
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1315: train_loss=8.313238143920898
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1316: train_loss=8.312665939331055
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1317: train_loss=8.3035888671875
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1318: train_loss=8.311702728271484
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1319: train_loss=8.309041976928711
INFO - 04/15/25 16:44:40 - 0:13:03 - Epoch 1320: train_loss=8.308585166931152
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1321: train_loss=8.30474853515625
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1322: train_loss=8.305523872375488
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1323: train_loss=8.304069519042969
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1324: train_loss=8.302596092224121
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1325: train_loss=8.298796653747559
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1326: train_loss=8.307046890258789
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1327: train_loss=8.29944896697998
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1328: train_loss=8.302519798278809
INFO - 04/15/25 16:44:41 - 0:13:04 - Epoch 1329: train_loss=8.299811363220215
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1330: train_loss=8.301560401916504
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1331: train_loss=8.300070762634277
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1332: train_loss=8.303988456726074
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1333: train_loss=8.298544883728027
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1334: train_loss=8.304542541503906
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1335: train_loss=8.30467700958252
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1336: train_loss=8.295775413513184
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1337: train_loss=8.29443645477295
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1338: train_loss=8.302787780761719
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1339: train_loss=8.301459312438965
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1340: train_loss=8.300159454345703
INFO - 04/15/25 16:44:41 - 0:13:05 - Epoch 1341: train_loss=8.322395324707031
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1342: train_loss=8.284677505493164
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1343: train_loss=8.315112113952637
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1344: train_loss=8.323832511901855
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1345: train_loss=8.322361946105957
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1346: train_loss=8.306422233581543
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1347: train_loss=8.270963668823242
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1348: train_loss=8.274779319763184
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1349: train_loss=8.260566711425781
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1350: train_loss=8.27934455871582
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1351: train_loss=8.262727737426758
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1352: train_loss=8.2619047164917
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1353: train_loss=8.258637428283691
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1354: train_loss=8.252691268920898
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1355: train_loss=8.255407333374023
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1356: train_loss=8.244050025939941
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1357: train_loss=8.244301795959473
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1358: train_loss=8.241013526916504
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1359: train_loss=8.242632865905762
INFO - 04/15/25 16:44:42 - 0:13:05 - Epoch 1360: train_loss=8.238261222839355
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1361: train_loss=8.234442710876465
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1362: train_loss=8.2394380569458
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1363: train_loss=8.232888221740723
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1364: train_loss=8.2343168258667
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1365: train_loss=8.22331428527832
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1366: train_loss=8.22939682006836
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1367: train_loss=8.231185913085938
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1368: train_loss=8.225669860839844
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1369: train_loss=8.226113319396973
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1370: train_loss=8.226642608642578
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1371: train_loss=8.223278045654297
INFO - 04/15/25 16:44:42 - 0:13:06 - Epoch 1372: train_loss=8.219192504882812
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1373: train_loss=8.219050407409668
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1374: train_loss=8.2224760055542
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1375: train_loss=8.223217964172363
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1376: train_loss=8.223773002624512
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1377: train_loss=8.217462539672852
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1378: train_loss=8.22198486328125
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1379: train_loss=8.219583511352539
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1380: train_loss=8.221142768859863
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1381: train_loss=8.221368789672852
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1382: train_loss=8.217617988586426
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1383: train_loss=8.219944953918457
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1384: train_loss=8.222970962524414
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1385: train_loss=8.216854095458984
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1386: train_loss=8.21536636352539
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1387: train_loss=8.223203659057617
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1388: train_loss=8.21822452545166
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1389: train_loss=8.226927757263184
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1390: train_loss=8.221600532531738
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1391: train_loss=8.219572067260742
INFO - 04/15/25 16:44:43 - 0:13:06 - Epoch 1392: train_loss=8.2151460647583
INFO - 04/15/25 16:44:43 - 0:13:07 - Epoch 1393: train_loss=8.228583335876465
INFO - 04/15/25 16:44:43 - 0:13:07 - Epoch 1394: train_loss=8.219416618347168
INFO - 04/15/25 16:44:43 - 0:13:07 - Epoch 1395: train_loss=8.227890968322754
INFO - 04/15/25 16:44:43 - 0:13:07 - Epoch 1396: train_loss=8.21823787689209
INFO - 04/15/25 16:44:43 - 0:13:07 - Epoch 1397: train_loss=8.225317001342773
INFO - 04/15/25 16:44:43 - 0:13:07 - Epoch 1398: train_loss=8.225549697875977
INFO - 04/15/25 16:44:43 - 0:13:07 - Epoch 1399: train_loss=8.217236518859863
INFO - 04/15/25 16:44:43 - 0:13:07 - Epoch 1400: train_loss=8.22541332244873
INFO - 04/15/25 16:44:43 - 0:13:07 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:44 - 0:13:07 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1400: ACC: 0.0, NMI: 0.4227993943422465, F1: 0.0, ARI: 0.22775602292357938
INFO - 04/15/25 16:44:44 - 0:13:07 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1401: train_loss=8.21920394897461
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1402: train_loss=8.241150856018066
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1403: train_loss=8.446288108825684
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1404: train_loss=8.295592308044434
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1405: train_loss=8.283101081848145
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1406: train_loss=8.336187362670898
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1407: train_loss=8.322089195251465
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1408: train_loss=8.312854766845703
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1409: train_loss=8.300168991088867
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1410: train_loss=8.35804271697998
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1411: train_loss=8.29732894897461
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1412: train_loss=8.29768180847168
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1413: train_loss=8.283758163452148
INFO - 04/15/25 16:44:44 - 0:13:07 - Epoch 1414: train_loss=8.269989013671875
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1415: train_loss=8.265837669372559
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1416: train_loss=8.274415969848633
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1417: train_loss=8.263382911682129
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1418: train_loss=8.262458801269531
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1419: train_loss=8.264544486999512
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1420: train_loss=8.268386840820312
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1421: train_loss=8.25220775604248
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1422: train_loss=8.254281997680664
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1423: train_loss=8.256427764892578
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1424: train_loss=8.250099182128906
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1425: train_loss=8.24396800994873
INFO - 04/15/25 16:44:44 - 0:13:08 - Epoch 1426: train_loss=8.237380981445312
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1427: train_loss=8.238911628723145
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1428: train_loss=8.242002487182617
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1429: train_loss=8.230199813842773
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1430: train_loss=8.242568016052246
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1431: train_loss=8.235513687133789
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1432: train_loss=8.235291481018066
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1433: train_loss=8.230472564697266
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1434: train_loss=8.224092483520508
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1435: train_loss=8.229536056518555
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1436: train_loss=8.223065376281738
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1437: train_loss=8.231033325195312
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1438: train_loss=8.230379104614258
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1439: train_loss=8.227137565612793
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1440: train_loss=8.229559898376465
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1441: train_loss=8.224678039550781
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1442: train_loss=8.224860191345215
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1443: train_loss=8.219776153564453
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1444: train_loss=8.236894607543945
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1445: train_loss=8.216207504272461
INFO - 04/15/25 16:44:45 - 0:13:08 - Epoch 1446: train_loss=8.237436294555664
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1447: train_loss=8.22899341583252
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1448: train_loss=8.277563095092773
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1449: train_loss=8.244266510009766
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1450: train_loss=8.256296157836914
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1451: train_loss=8.244617462158203
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1452: train_loss=8.253870010375977
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1453: train_loss=8.246793746948242
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1454: train_loss=8.247479438781738
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1455: train_loss=8.24523639678955
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1456: train_loss=8.2423677444458
INFO - 04/15/25 16:44:45 - 0:13:09 - Epoch 1457: train_loss=8.23676586151123
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1458: train_loss=8.249573707580566
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1459: train_loss=8.248052597045898
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1460: train_loss=8.232707977294922
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1461: train_loss=8.235194206237793
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1462: train_loss=8.233418464660645
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1463: train_loss=8.227829933166504
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1464: train_loss=8.24127197265625
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1465: train_loss=8.232362747192383
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1466: train_loss=8.238500595092773
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1467: train_loss=8.238652229309082
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1468: train_loss=8.226219177246094
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1469: train_loss=8.22724723815918
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1470: train_loss=8.22929573059082
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1471: train_loss=8.224498748779297
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1472: train_loss=8.231651306152344
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1473: train_loss=8.216676712036133
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1474: train_loss=8.220587730407715
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1475: train_loss=8.241032600402832
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1476: train_loss=8.229736328125
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1477: train_loss=8.209216117858887
INFO - 04/15/25 16:44:46 - 0:13:09 - Epoch 1478: train_loss=8.22867202758789
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1479: train_loss=8.226663589477539
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1480: train_loss=8.258733749389648
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1481: train_loss=8.230225563049316
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1482: train_loss=8.224263191223145
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1483: train_loss=8.237502098083496
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1484: train_loss=8.224564552307129
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1485: train_loss=8.240949630737305
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1486: train_loss=8.2392578125
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1487: train_loss=8.233428001403809
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1488: train_loss=8.225013732910156
INFO - 04/15/25 16:44:46 - 0:13:10 - Epoch 1489: train_loss=8.237372398376465
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1490: train_loss=8.22701358795166
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1491: train_loss=8.241504669189453
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1492: train_loss=8.24074649810791
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1493: train_loss=8.224296569824219
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1494: train_loss=8.227733612060547
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1495: train_loss=8.2121000289917
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1496: train_loss=8.2235746383667
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1497: train_loss=8.223176956176758
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1498: train_loss=8.212800025939941
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1499: train_loss=8.243949890136719
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1500: train_loss=8.247605323791504
INFO - 04/15/25 16:44:47 - 0:13:10 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:47 - 0:13:10 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:44:47 - 0:13:10 - Epoch 1500: ACC: 0.0, NMI: 0.4109930205720775, F1: 0.0, ARI: 0.23299902505806003
INFO - 04/15/25 16:44:47 - 0:13:10 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1501: train_loss=8.2456636428833
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1502: train_loss=8.251275062561035
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1503: train_loss=8.213717460632324
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1504: train_loss=8.202391624450684
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1505: train_loss=8.186549186706543
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1506: train_loss=8.19261360168457
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1507: train_loss=8.202797889709473
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1508: train_loss=8.221721649169922
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1509: train_loss=8.226762771606445
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1510: train_loss=8.230118751525879
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1511: train_loss=8.22823429107666
INFO - 04/15/25 16:44:47 - 0:13:11 - Epoch 1512: train_loss=8.208613395690918
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1513: train_loss=8.190256118774414
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1514: train_loss=8.171731948852539
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1515: train_loss=8.193374633789062
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1516: train_loss=8.173726081848145
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1517: train_loss=8.17315673828125
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1518: train_loss=8.171154022216797
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1519: train_loss=8.1646146774292
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1520: train_loss=8.161101341247559
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1521: train_loss=8.157855033874512
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1522: train_loss=8.151993751525879
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1523: train_loss=8.14696979522705
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1524: train_loss=8.141733169555664
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1525: train_loss=8.144299507141113
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1526: train_loss=8.137181282043457
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1527: train_loss=8.139760971069336
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1528: train_loss=8.130744934082031
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1529: train_loss=8.141961097717285
INFO - 04/15/25 16:44:48 - 0:13:11 - Epoch 1530: train_loss=8.137231826782227
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1531: train_loss=8.136466979980469
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1532: train_loss=8.126354217529297
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1533: train_loss=8.09800910949707
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1534: train_loss=8.091534614562988
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1535: train_loss=8.085843086242676
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1536: train_loss=8.09196662902832
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1537: train_loss=8.088188171386719
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1538: train_loss=8.084447860717773
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1539: train_loss=8.076494216918945
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1540: train_loss=8.087786674499512
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1541: train_loss=8.076013565063477
INFO - 04/15/25 16:44:48 - 0:13:12 - Epoch 1542: train_loss=8.086628913879395
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1543: train_loss=8.092358589172363
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1544: train_loss=8.075325965881348
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1545: train_loss=8.091792106628418
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1546: train_loss=8.082295417785645
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1547: train_loss=8.088785171508789
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1548: train_loss=8.082331657409668
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1549: train_loss=8.071571350097656
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1550: train_loss=8.075965881347656
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1551: train_loss=8.068342208862305
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1552: train_loss=8.064492225646973
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1553: train_loss=8.064268112182617
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1554: train_loss=8.062017440795898
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1555: train_loss=8.08095932006836
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1556: train_loss=8.064963340759277
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1557: train_loss=8.055377006530762
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1558: train_loss=8.063050270080566
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1559: train_loss=8.056530952453613
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1560: train_loss=8.066977500915527
INFO - 04/15/25 16:44:49 - 0:13:12 - Epoch 1561: train_loss=8.020540237426758
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1562: train_loss=8.038538932800293
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1563: train_loss=8.034997940063477
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1564: train_loss=8.035456657409668
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1565: train_loss=8.022284507751465
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1566: train_loss=8.02847957611084
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1567: train_loss=8.018308639526367
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1568: train_loss=8.022388458251953
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1569: train_loss=8.01569938659668
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1570: train_loss=8.03586196899414
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1571: train_loss=8.024653434753418
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1572: train_loss=8.037702560424805
INFO - 04/15/25 16:44:49 - 0:13:13 - Epoch 1573: train_loss=8.036874771118164
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1574: train_loss=8.019397735595703
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1575: train_loss=8.024742126464844
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1576: train_loss=8.015769958496094
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1577: train_loss=8.026432037353516
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1578: train_loss=8.022374153137207
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1579: train_loss=8.026741027832031
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1580: train_loss=8.024479866027832
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1581: train_loss=8.03799057006836
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1582: train_loss=8.022226333618164
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1583: train_loss=8.025104522705078
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1584: train_loss=8.024162292480469
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1585: train_loss=8.021493911743164
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1586: train_loss=8.011008262634277
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1587: train_loss=8.028420448303223
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1588: train_loss=8.0081787109375
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1589: train_loss=8.01346492767334
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1590: train_loss=8.004674911499023
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1591: train_loss=7.979686737060547
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1592: train_loss=7.988648891448975
INFO - 04/15/25 16:44:50 - 0:13:13 - Epoch 1593: train_loss=8.00828742980957
INFO - 04/15/25 16:44:50 - 0:13:14 - Epoch 1594: train_loss=7.989986896514893
INFO - 04/15/25 16:44:50 - 0:13:14 - Epoch 1595: train_loss=7.993166923522949
INFO - 04/15/25 16:44:50 - 0:13:14 - Epoch 1596: train_loss=7.979750633239746
INFO - 04/15/25 16:44:50 - 0:13:14 - Epoch 1597: train_loss=7.954470157623291
INFO - 04/15/25 16:44:50 - 0:13:14 - Epoch 1598: train_loss=7.959989547729492
INFO - 04/15/25 16:44:50 - 0:13:14 - Epoch 1599: train_loss=7.966224193572998
INFO - 04/15/25 16:44:50 - 0:13:14 - Epoch 1600: train_loss=7.949726581573486
INFO - 04/15/25 16:44:50 - 0:13:14 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:50 - 0:13:14 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1600: ACC: 0.0, NMI: 0.46109802243757086, F1: 0.0, ARI: 0.30150900513818235
INFO - 04/15/25 16:44:51 - 0:13:14 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1601: train_loss=7.967631816864014
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1602: train_loss=7.960127353668213
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1603: train_loss=7.9472527503967285
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1604: train_loss=7.947735786437988
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1605: train_loss=7.955159664154053
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1606: train_loss=7.943538188934326
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1607: train_loss=7.953316688537598
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1608: train_loss=7.95196533203125
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1609: train_loss=7.927518844604492
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1610: train_loss=7.943594932556152
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1611: train_loss=7.921584129333496
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1612: train_loss=7.911713600158691
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1613: train_loss=7.937798500061035
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1614: train_loss=7.917069911956787
INFO - 04/15/25 16:44:51 - 0:13:14 - Epoch 1615: train_loss=7.918057918548584
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1616: train_loss=7.90767240524292
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1617: train_loss=7.914431095123291
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1618: train_loss=7.909761905670166
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1619: train_loss=7.923643589019775
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1620: train_loss=7.907006740570068
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1621: train_loss=7.88867712020874
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1622: train_loss=7.916421890258789
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1623: train_loss=7.900994777679443
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1624: train_loss=7.917035102844238
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1625: train_loss=7.902410507202148
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1626: train_loss=7.901241779327393
INFO - 04/15/25 16:44:51 - 0:13:15 - Epoch 1627: train_loss=7.8784356117248535
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1628: train_loss=7.84113073348999
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1629: train_loss=7.823042869567871
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1630: train_loss=7.808116912841797
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1631: train_loss=7.804872035980225
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1632: train_loss=7.7989983558654785
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1633: train_loss=7.782638072967529
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1634: train_loss=7.789039611816406
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1635: train_loss=7.773892879486084
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1636: train_loss=7.779244422912598
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1637: train_loss=7.766202449798584
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1638: train_loss=7.761638641357422
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1639: train_loss=7.758113384246826
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1640: train_loss=7.751645565032959
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1641: train_loss=7.7500739097595215
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1642: train_loss=7.746040344238281
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1643: train_loss=7.7351226806640625
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1644: train_loss=7.734226226806641
INFO - 04/15/25 16:44:52 - 0:13:15 - Epoch 1645: train_loss=7.742742538452148
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1646: train_loss=7.741010665893555
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1647: train_loss=7.738548755645752
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1648: train_loss=7.7380876541137695
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1649: train_loss=7.745593070983887
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1650: train_loss=7.741966247558594
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1651: train_loss=7.741692543029785
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1652: train_loss=7.754446983337402
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1653: train_loss=7.721253395080566
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1654: train_loss=7.750506401062012
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1655: train_loss=7.779140949249268
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1656: train_loss=7.818546772003174
INFO - 04/15/25 16:44:52 - 0:13:16 - Epoch 1657: train_loss=7.886482238769531
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1658: train_loss=7.8613128662109375
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1659: train_loss=7.8583455085754395
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1660: train_loss=7.792326927185059
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1661: train_loss=7.74855899810791
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1662: train_loss=7.714596748352051
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1663: train_loss=7.674744606018066
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1664: train_loss=7.661688804626465
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1665: train_loss=7.636163711547852
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1666: train_loss=7.676000118255615
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1667: train_loss=7.6642842292785645
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1668: train_loss=7.6657490730285645
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1669: train_loss=7.631356239318848
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1670: train_loss=7.651795387268066
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1671: train_loss=7.610414028167725
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1672: train_loss=7.563295841217041
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1673: train_loss=7.542438983917236
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1674: train_loss=7.5278472900390625
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1675: train_loss=7.509819030761719
INFO - 04/15/25 16:44:53 - 0:13:16 - Epoch 1676: train_loss=7.485594749450684
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1677: train_loss=7.4760284423828125
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1678: train_loss=7.47334623336792
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1679: train_loss=7.450771808624268
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1680: train_loss=7.466119289398193
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1681: train_loss=7.459880828857422
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1682: train_loss=7.449458599090576
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1683: train_loss=7.448199272155762
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1684: train_loss=7.452569484710693
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1685: train_loss=7.441269874572754
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1686: train_loss=7.435272216796875
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1687: train_loss=7.437156677246094
INFO - 04/15/25 16:44:53 - 0:13:17 - Epoch 1688: train_loss=7.439651012420654
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1689: train_loss=7.403039932250977
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1690: train_loss=7.433372497558594
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1691: train_loss=7.420519828796387
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1692: train_loss=7.422807216644287
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1693: train_loss=7.411909103393555
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1694: train_loss=7.40384578704834
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1695: train_loss=7.401579856872559
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1696: train_loss=7.396255970001221
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1697: train_loss=7.388457775115967
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1698: train_loss=7.379918098449707
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1699: train_loss=7.317652702331543
INFO - 04/15/25 16:44:54 - 0:13:17 - Epoch 1700: train_loss=7.272066593170166
INFO - 04/15/25 16:44:54 - 0:13:17 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:54 - 0:13:17 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1700: ACC: 0.0, NMI: 0.4130432803143303, F1: 0.0, ARI: 0.2304359409017085
INFO - 04/15/25 16:44:54 - 0:13:18 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1701: train_loss=7.298182010650635
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1702: train_loss=7.313669681549072
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1703: train_loss=7.282571315765381
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1704: train_loss=7.275692939758301
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1705: train_loss=7.268677711486816
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1706: train_loss=7.267301082611084
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1707: train_loss=7.2612504959106445
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1708: train_loss=7.2611517906188965
INFO - 04/15/25 16:44:54 - 0:13:18 - Epoch 1709: train_loss=7.25487756729126
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1710: train_loss=7.253718376159668
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1711: train_loss=7.2501020431518555
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1712: train_loss=7.25208044052124
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1713: train_loss=7.249208450317383
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1714: train_loss=7.250885009765625
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1715: train_loss=7.244852542877197
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1716: train_loss=7.246754169464111
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1717: train_loss=7.243311882019043
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1718: train_loss=7.243039608001709
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1719: train_loss=7.24490213394165
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1720: train_loss=7.245970726013184
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1721: train_loss=7.244228839874268
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1722: train_loss=7.248826026916504
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1723: train_loss=7.247316360473633
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1724: train_loss=7.250516891479492
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1725: train_loss=7.281139373779297
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1726: train_loss=7.214540481567383
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1727: train_loss=7.1639227867126465
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1728: train_loss=7.14847993850708
INFO - 04/15/25 16:44:55 - 0:13:18 - Epoch 1729: train_loss=7.133327484130859
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1730: train_loss=7.135998249053955
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1731: train_loss=7.122772693634033
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1732: train_loss=7.119861602783203
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1733: train_loss=7.115846157073975
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1734: train_loss=7.109830856323242
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1735: train_loss=7.099377155303955
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1736: train_loss=7.059151649475098
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1737: train_loss=7.030709266662598
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1738: train_loss=7.025180339813232
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1739: train_loss=7.007979869842529
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1740: train_loss=7.02107048034668
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1741: train_loss=7.004247665405273
INFO - 04/15/25 16:44:55 - 0:13:19 - Epoch 1742: train_loss=7.004847049713135
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1743: train_loss=6.993597507476807
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1744: train_loss=6.99517822265625
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1745: train_loss=6.978349685668945
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1746: train_loss=6.972402572631836
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1747: train_loss=6.962388515472412
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1748: train_loss=6.966166019439697
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1749: train_loss=6.963949680328369
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1750: train_loss=6.962948799133301
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1751: train_loss=6.961116313934326
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1752: train_loss=6.95937967300415
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1753: train_loss=6.955352783203125
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1754: train_loss=6.958643913269043
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1755: train_loss=6.959009170532227
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1756: train_loss=6.974268436431885
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1757: train_loss=6.995809078216553
INFO - 04/15/25 16:44:56 - 0:13:19 - Epoch 1758: train_loss=6.989516258239746
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1759: train_loss=6.981490135192871
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1760: train_loss=6.978790760040283
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1761: train_loss=6.984188079833984
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1762: train_loss=6.974897384643555
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1763: train_loss=6.998604774475098
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1764: train_loss=7.000711917877197
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1765: train_loss=7.015248775482178
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1766: train_loss=7.04550313949585
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1767: train_loss=7.079775810241699
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1768: train_loss=7.068462371826172
INFO - 04/15/25 16:44:56 - 0:13:20 - Epoch 1769: train_loss=7.05731201171875
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1770: train_loss=7.041091442108154
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1771: train_loss=7.049116134643555
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1772: train_loss=7.0480451583862305
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1773: train_loss=7.037428855895996
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1774: train_loss=7.030709266662598
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1775: train_loss=7.035348892211914
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1776: train_loss=7.040613174438477
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1777: train_loss=7.035214900970459
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1778: train_loss=7.033136367797852
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1779: train_loss=7.036744594573975
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1780: train_loss=7.045237064361572
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1781: train_loss=7.028533935546875
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1782: train_loss=7.029860496520996
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1783: train_loss=7.030272483825684
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1784: train_loss=7.013638496398926
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1785: train_loss=7.039251327514648
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1786: train_loss=7.021755218505859
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1787: train_loss=7.029208183288574
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1788: train_loss=7.029716491699219
INFO - 04/15/25 16:44:57 - 0:13:20 - Epoch 1789: train_loss=7.0354156494140625
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1790: train_loss=7.027090072631836
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1791: train_loss=7.042254447937012
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1792: train_loss=7.034481048583984
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1793: train_loss=7.0033440589904785
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1794: train_loss=7.005278587341309
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1795: train_loss=7.00535249710083
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1796: train_loss=7.003505229949951
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1797: train_loss=6.981888771057129
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1798: train_loss=6.993066787719727
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1799: train_loss=6.9948811531066895
INFO - 04/15/25 16:44:57 - 0:13:21 - Epoch 1800: train_loss=6.988428592681885
INFO - 04/15/25 16:44:57 - 0:13:21 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:44:58 - 0:13:21 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1800: ACC: 0.0, NMI: 0.3588184922145476, F1: 0.0, ARI: 0.18164667526504988
INFO - 04/15/25 16:44:58 - 0:13:21 - -------------------------------------------------------------------------
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1801: train_loss=6.966205596923828
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1802: train_loss=6.985202789306641
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1803: train_loss=6.981086254119873
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1804: train_loss=7.000833034515381
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1805: train_loss=6.9640326499938965
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1806: train_loss=6.988848686218262
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1807: train_loss=6.983276844024658
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1808: train_loss=6.9591898918151855
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1809: train_loss=6.965147495269775
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1810: train_loss=6.978684425354004
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1811: train_loss=6.954876899719238
INFO - 04/15/25 16:44:58 - 0:13:21 - Epoch 1812: train_loss=6.973970413208008
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1813: train_loss=6.985341548919678
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1814: train_loss=6.980608940124512
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1815: train_loss=6.954331398010254
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1816: train_loss=6.934243679046631
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1817: train_loss=6.933822154998779
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1818: train_loss=6.93433952331543
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1819: train_loss=6.93781042098999
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1820: train_loss=6.926368713378906
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1821: train_loss=6.924534320831299
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1822: train_loss=6.951113700866699
INFO - 04/15/25 16:44:58 - 0:13:22 - Epoch 1823: train_loss=6.933962345123291
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1824: train_loss=6.930784702301025
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1825: train_loss=6.9281158447265625
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1826: train_loss=6.9245758056640625
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1827: train_loss=6.91894006729126
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1828: train_loss=6.925375938415527
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1829: train_loss=6.927877902984619
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1830: train_loss=6.924752712249756
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1831: train_loss=6.916965484619141
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1832: train_loss=6.917208671569824
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1833: train_loss=6.912588596343994
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1834: train_loss=6.919556140899658
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1835: train_loss=6.916754245758057
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1836: train_loss=6.913464546203613
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1837: train_loss=6.912428379058838
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1838: train_loss=6.913826942443848
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1839: train_loss=6.907655715942383
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1840: train_loss=6.910744667053223
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1841: train_loss=6.907525062561035
INFO - 04/15/25 16:44:59 - 0:13:22 - Epoch 1842: train_loss=6.901325225830078
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1843: train_loss=6.902859210968018
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1844: train_loss=6.897541046142578
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1845: train_loss=6.900263786315918
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1846: train_loss=6.89408540725708
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1847: train_loss=6.9044575691223145
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1848: train_loss=6.8975114822387695
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1849: train_loss=6.897680282592773
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1850: train_loss=6.894518852233887
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1851: train_loss=6.893829822540283
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1852: train_loss=6.891746997833252
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1853: train_loss=6.893649578094482
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1854: train_loss=6.892539024353027
INFO - 04/15/25 16:44:59 - 0:13:23 - Epoch 1855: train_loss=6.912412643432617
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1856: train_loss=6.899274826049805
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1857: train_loss=6.892465591430664
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1858: train_loss=6.883735656738281
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1859: train_loss=6.88398551940918
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1860: train_loss=6.93060827255249
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1861: train_loss=6.928779602050781
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1862: train_loss=6.914016246795654
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1863: train_loss=6.898484706878662
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1864: train_loss=6.906350135803223
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1865: train_loss=6.904412269592285
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1866: train_loss=6.892188549041748
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1867: train_loss=6.888131618499756
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1868: train_loss=6.898449420928955
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1869: train_loss=6.899600982666016
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1870: train_loss=6.879352569580078
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1871: train_loss=6.88806676864624
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1872: train_loss=6.893481254577637
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1873: train_loss=6.891763687133789
INFO - 04/15/25 16:45:00 - 0:13:23 - Epoch 1874: train_loss=6.885776996612549
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1875: train_loss=6.885534286499023
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1876: train_loss=6.875857830047607
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1877: train_loss=6.868038177490234
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1878: train_loss=6.875711441040039
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1879: train_loss=6.861876964569092
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1880: train_loss=6.885233402252197
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1881: train_loss=6.891847133636475
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1882: train_loss=6.900736331939697
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1883: train_loss=6.89762020111084
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1884: train_loss=6.895909309387207
INFO - 04/15/25 16:45:00 - 0:13:24 - Epoch 1885: train_loss=6.898274898529053
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1886: train_loss=6.896236896514893
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1887: train_loss=6.893818378448486
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1888: train_loss=6.881833553314209
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1889: train_loss=6.878188610076904
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1890: train_loss=6.881786346435547
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1891: train_loss=6.880964756011963
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1892: train_loss=6.868434429168701
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1893: train_loss=6.861786842346191
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1894: train_loss=6.841911792755127
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1895: train_loss=6.840561389923096
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1896: train_loss=6.8367109298706055
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1897: train_loss=6.832358360290527
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1898: train_loss=6.835240364074707
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1899: train_loss=6.831592559814453
INFO - 04/15/25 16:45:01 - 0:13:24 - Epoch 1900: train_loss=6.830981731414795
INFO - 04/15/25 16:45:01 - 0:13:24 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:01 - 0:13:24 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1900: ACC: 0.0, NMI: 0.39113562431981613, F1: 0.0, ARI: 0.2062353377398582
INFO - 04/15/25 16:45:01 - 0:13:25 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1901: train_loss=6.822429656982422
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1902: train_loss=6.865166187286377
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1903: train_loss=6.842082500457764
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1904: train_loss=6.846904754638672
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1905: train_loss=6.837272644042969
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1906: train_loss=6.837672710418701
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1907: train_loss=6.846867084503174
INFO - 04/15/25 16:45:01 - 0:13:25 - Epoch 1908: train_loss=6.830307483673096
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1909: train_loss=6.8318400382995605
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1910: train_loss=6.839648246765137
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1911: train_loss=6.825531005859375
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1912: train_loss=6.827426910400391
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1913: train_loss=6.8180131912231445
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1914: train_loss=6.82043981552124
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1915: train_loss=6.830613613128662
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1916: train_loss=6.818161964416504
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1917: train_loss=6.878232479095459
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1918: train_loss=6.858234405517578
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1919: train_loss=6.838318347930908
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1920: train_loss=6.8384108543396
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1921: train_loss=6.840007781982422
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1922: train_loss=6.833129405975342
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1923: train_loss=6.824312210083008
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1924: train_loss=6.809908866882324
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1925: train_loss=6.807888984680176
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1926: train_loss=6.812981128692627
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1927: train_loss=6.808049201965332
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1928: train_loss=6.790610313415527
INFO - 04/15/25 16:45:02 - 0:13:25 - Epoch 1929: train_loss=6.782459735870361
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1930: train_loss=6.758302211761475
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1931: train_loss=6.760303497314453
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1932: train_loss=6.749579429626465
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1933: train_loss=6.74327278137207
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1934: train_loss=6.736337184906006
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1935: train_loss=6.711568355560303
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1936: train_loss=6.705413818359375
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1937: train_loss=6.703090190887451
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1938: train_loss=6.694808006286621
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1939: train_loss=6.688857078552246
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1940: train_loss=6.678158760070801
INFO - 04/15/25 16:45:02 - 0:13:26 - Epoch 1941: train_loss=6.675106048583984
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1942: train_loss=6.678023815155029
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1943: train_loss=6.667120933532715
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1944: train_loss=6.662232875823975
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1945: train_loss=6.656630039215088
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1946: train_loss=6.658828258514404
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1947: train_loss=6.6536383628845215
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1948: train_loss=6.654338359832764
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1949: train_loss=6.6483283042907715
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1950: train_loss=6.652257919311523
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1951: train_loss=6.65071439743042
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1952: train_loss=6.649652004241943
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1953: train_loss=6.648171901702881
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1954: train_loss=6.6399407386779785
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1955: train_loss=6.645463466644287
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1956: train_loss=6.644289016723633
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1957: train_loss=6.645013809204102
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1958: train_loss=6.645890712738037
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1959: train_loss=6.6461710929870605
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1960: train_loss=6.642336368560791
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1961: train_loss=6.643657207489014
INFO - 04/15/25 16:45:03 - 0:13:26 - Epoch 1962: train_loss=6.649107933044434
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1963: train_loss=6.645501136779785
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1964: train_loss=6.635378837585449
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1965: train_loss=6.643794536590576
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1966: train_loss=6.639036178588867
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1967: train_loss=6.661110877990723
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1968: train_loss=6.668913841247559
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1969: train_loss=6.692121505737305
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1970: train_loss=6.708600044250488
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1971: train_loss=6.729597091674805
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1972: train_loss=6.727599143981934
INFO - 04/15/25 16:45:03 - 0:13:27 - Epoch 1973: train_loss=6.716678142547607
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1974: train_loss=6.702025890350342
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1975: train_loss=6.685500144958496
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1976: train_loss=6.6686787605285645
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1977: train_loss=6.666616916656494
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1978: train_loss=6.669384479522705
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1979: train_loss=6.665831565856934
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1980: train_loss=6.665212631225586
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1981: train_loss=6.6633219718933105
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1982: train_loss=6.669839859008789
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1983: train_loss=6.6560750007629395
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1984: train_loss=6.655518054962158
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1985: train_loss=6.670787334442139
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1986: train_loss=6.671542644500732
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1987: train_loss=6.685325622558594
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1988: train_loss=6.6702351570129395
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1989: train_loss=6.657638072967529
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1990: train_loss=6.651506423950195
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1991: train_loss=6.639081954956055
INFO - 04/15/25 16:45:04 - 0:13:27 - Epoch 1992: train_loss=6.613409996032715
INFO - 04/15/25 16:45:04 - 0:13:28 - Epoch 1993: train_loss=6.615318298339844
INFO - 04/15/25 16:45:04 - 0:13:28 - Epoch 1994: train_loss=6.601444721221924
INFO - 04/15/25 16:45:04 - 0:13:28 - Epoch 1995: train_loss=6.599989414215088
INFO - 04/15/25 16:45:04 - 0:13:28 - Epoch 1996: train_loss=6.59790563583374
INFO - 04/15/25 16:45:04 - 0:13:28 - Epoch 1997: train_loss=6.6060051918029785
INFO - 04/15/25 16:45:04 - 0:13:28 - Epoch 1998: train_loss=6.556480884552002
INFO - 04/15/25 16:45:04 - 0:13:28 - Epoch 1999: train_loss=6.514443397521973
INFO - 04/15/25 16:45:04 - 0:13:28 - Epoch 2000: train_loss=6.463675498962402
INFO - 04/15/25 16:45:04 - 0:13:28 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:04 - 0:13:28 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2000: ACC: 0.0, NMI: 0.41551374819045267, F1: 0.0, ARI: 0.22449969876920933
INFO - 04/15/25 16:45:05 - 0:13:28 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2001: train_loss=6.431074619293213
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2002: train_loss=6.426010608673096
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2003: train_loss=6.406790733337402
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2004: train_loss=6.408250331878662
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2005: train_loss=6.4117584228515625
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2006: train_loss=6.409090518951416
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2007: train_loss=6.381896495819092
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2008: train_loss=6.387527942657471
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2009: train_loss=6.38883638381958
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2010: train_loss=6.389907360076904
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2011: train_loss=6.37905216217041
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2012: train_loss=6.3800368309021
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2013: train_loss=6.378933906555176
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2014: train_loss=6.3807902336120605
INFO - 04/15/25 16:45:05 - 0:13:28 - Epoch 2015: train_loss=6.378505229949951
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2016: train_loss=6.377486228942871
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2017: train_loss=6.380537033081055
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2018: train_loss=6.378763198852539
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2019: train_loss=6.374650001525879
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2020: train_loss=6.372011661529541
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2021: train_loss=6.371225833892822
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2022: train_loss=6.368017196655273
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2023: train_loss=6.365787029266357
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2024: train_loss=6.3676323890686035
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2025: train_loss=6.363229751586914
INFO - 04/15/25 16:45:05 - 0:13:29 - Epoch 2026: train_loss=6.361135005950928
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2027: train_loss=6.360470771789551
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2028: train_loss=6.35584831237793
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2029: train_loss=6.355837345123291
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2030: train_loss=6.3691253662109375
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2031: train_loss=6.341504096984863
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2032: train_loss=6.359642505645752
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2033: train_loss=6.323403835296631
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2034: train_loss=6.313807964324951
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2035: train_loss=6.315227508544922
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2036: train_loss=6.317028045654297
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2037: train_loss=6.314902305603027
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2038: train_loss=6.31510066986084
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2039: train_loss=6.311485290527344
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2040: train_loss=6.317155838012695
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2041: train_loss=6.317328453063965
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2042: train_loss=6.308191299438477
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2043: train_loss=6.31287145614624
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2044: train_loss=6.306611061096191
INFO - 04/15/25 16:45:06 - 0:13:29 - Epoch 2045: train_loss=6.312148094177246
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2046: train_loss=6.31160831451416
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2047: train_loss=6.298285484313965
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2048: train_loss=6.308427333831787
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2049: train_loss=6.3073410987854
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2050: train_loss=6.297749996185303
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2051: train_loss=6.293359279632568
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2052: train_loss=6.297317028045654
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2053: train_loss=6.291759490966797
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2054: train_loss=6.294537544250488
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2055: train_loss=6.295577526092529
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2056: train_loss=6.289020538330078
INFO - 04/15/25 16:45:06 - 0:13:30 - Epoch 2057: train_loss=6.291999340057373
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2058: train_loss=6.2917866706848145
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2059: train_loss=6.28696870803833
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2060: train_loss=6.289852619171143
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2061: train_loss=6.287200927734375
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2062: train_loss=6.288941383361816
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2063: train_loss=6.288389205932617
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2064: train_loss=6.283435344696045
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2065: train_loss=6.284677982330322
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2066: train_loss=6.285115718841553
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2067: train_loss=6.284135818481445
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2068: train_loss=6.286559104919434
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2069: train_loss=6.287984371185303
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2070: train_loss=6.28413724899292
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2071: train_loss=6.284175872802734
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2072: train_loss=6.28445291519165
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2073: train_loss=6.283915996551514
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2074: train_loss=6.284274101257324
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2075: train_loss=6.28662633895874
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2076: train_loss=6.283912658691406
INFO - 04/15/25 16:45:07 - 0:13:30 - Epoch 2077: train_loss=6.283604621887207
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2078: train_loss=6.285037040710449
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2079: train_loss=6.282471179962158
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2080: train_loss=6.282217502593994
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2081: train_loss=6.28143835067749
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2082: train_loss=6.28609037399292
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2083: train_loss=6.284341335296631
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2084: train_loss=6.282105922698975
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2085: train_loss=6.282027721405029
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2086: train_loss=6.281882286071777
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2087: train_loss=6.28120231628418
INFO - 04/15/25 16:45:07 - 0:13:31 - Epoch 2088: train_loss=6.283966541290283
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2089: train_loss=6.280850410461426
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2090: train_loss=6.285116195678711
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2091: train_loss=6.283248424530029
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2092: train_loss=6.279407024383545
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2093: train_loss=6.278470993041992
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2094: train_loss=6.2834649085998535
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2095: train_loss=6.282882213592529
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2096: train_loss=6.279966354370117
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2097: train_loss=6.279420852661133
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2098: train_loss=6.282067775726318
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2099: train_loss=6.281330108642578
INFO - 04/15/25 16:45:08 - 0:13:31 - Epoch 2100: train_loss=6.279841899871826
INFO - 04/15/25 16:45:08 - 0:13:31 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:08 - 0:13:31 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2100: ACC: 0.0, NMI: 0.4480900834708323, F1: 0.0, ARI: 0.276894599944444
INFO - 04/15/25 16:45:08 - 0:13:32 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2101: train_loss=6.278848171234131
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2102: train_loss=6.281472206115723
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2103: train_loss=6.28176736831665
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2104: train_loss=6.277520179748535
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2105: train_loss=6.2772626876831055
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2106: train_loss=6.28123140335083
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2107: train_loss=6.280037879943848
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2108: train_loss=6.279539108276367
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2109: train_loss=6.279446601867676
INFO - 04/15/25 16:45:08 - 0:13:32 - Epoch 2110: train_loss=6.2830891609191895
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2111: train_loss=6.278434753417969
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2112: train_loss=6.284010410308838
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2113: train_loss=6.28509521484375
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2114: train_loss=6.283102512359619
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2115: train_loss=6.2829999923706055
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2116: train_loss=6.282812118530273
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2117: train_loss=6.281527519226074
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2118: train_loss=6.2852067947387695
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2119: train_loss=6.285483360290527
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2120: train_loss=6.2802276611328125
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2121: train_loss=6.2808918952941895
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2122: train_loss=6.282132625579834
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2123: train_loss=6.281557083129883
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2124: train_loss=6.285449504852295
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2125: train_loss=6.2854719161987305
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2126: train_loss=6.27979040145874
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2127: train_loss=6.281927585601807
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2128: train_loss=6.280904293060303
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2129: train_loss=6.281157970428467
INFO - 04/15/25 16:45:09 - 0:13:32 - Epoch 2130: train_loss=6.280853748321533
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2131: train_loss=6.280996322631836
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2132: train_loss=6.265280246734619
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2133: train_loss=6.264891147613525
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2134: train_loss=6.265059947967529
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2135: train_loss=6.264063835144043
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2136: train_loss=6.263835430145264
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2137: train_loss=6.267848491668701
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2138: train_loss=6.26430606842041
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2139: train_loss=6.2646002769470215
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2140: train_loss=6.263981819152832
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2141: train_loss=6.260941505432129
INFO - 04/15/25 16:45:09 - 0:13:33 - Epoch 2142: train_loss=6.263599395751953
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2143: train_loss=6.265563011169434
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2144: train_loss=6.263670444488525
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2145: train_loss=6.265227317810059
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2146: train_loss=6.259515762329102
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2147: train_loss=6.263007164001465
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2148: train_loss=6.262383460998535
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2149: train_loss=6.2661943435668945
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2150: train_loss=6.263462543487549
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2151: train_loss=6.26652717590332
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2152: train_loss=6.266162872314453
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2153: train_loss=6.262459754943848
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2154: train_loss=6.262622833251953
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2155: train_loss=6.265339374542236
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2156: train_loss=6.26289701461792
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2157: train_loss=6.258864879608154
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2158: train_loss=6.266903877258301
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2159: train_loss=6.25664758682251
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2160: train_loss=6.2646894454956055
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2161: train_loss=6.263576984405518
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2162: train_loss=6.264510154724121
INFO - 04/15/25 16:45:10 - 0:13:33 - Epoch 2163: train_loss=6.267092227935791
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2164: train_loss=6.25540018081665
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2165: train_loss=6.265092372894287
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2166: train_loss=6.262778282165527
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2167: train_loss=6.263801097869873
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2168: train_loss=6.261508941650391
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2169: train_loss=6.260927677154541
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2170: train_loss=6.260319232940674
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2171: train_loss=6.26295804977417
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2172: train_loss=6.262964248657227
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2173: train_loss=6.261759281158447
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2174: train_loss=6.26088285446167
INFO - 04/15/25 16:45:10 - 0:13:34 - Epoch 2175: train_loss=6.261216163635254
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2176: train_loss=6.261275291442871
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2177: train_loss=6.253114223480225
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2178: train_loss=6.262887001037598
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2179: train_loss=6.258328437805176
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2180: train_loss=6.267784118652344
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2181: train_loss=6.267902374267578
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2182: train_loss=6.251245498657227
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2183: train_loss=6.272621154785156
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2184: train_loss=6.274704456329346
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2185: train_loss=6.2663421630859375
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2186: train_loss=6.265559196472168
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2187: train_loss=6.268654823303223
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2188: train_loss=6.265915870666504
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2189: train_loss=6.263309478759766
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2190: train_loss=6.265085697174072
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2191: train_loss=6.264467239379883
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2192: train_loss=6.256425857543945
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2193: train_loss=6.25667142868042
INFO - 04/15/25 16:45:11 - 0:13:34 - Epoch 2194: train_loss=6.264437198638916
INFO - 04/15/25 16:45:11 - 0:13:35 - Epoch 2195: train_loss=6.2585601806640625
INFO - 04/15/25 16:45:11 - 0:13:35 - Epoch 2196: train_loss=6.267192840576172
INFO - 04/15/25 16:45:11 - 0:13:35 - Epoch 2197: train_loss=6.264458179473877
INFO - 04/15/25 16:45:11 - 0:13:35 - Epoch 2198: train_loss=6.2573137283325195
INFO - 04/15/25 16:45:11 - 0:13:35 - Epoch 2199: train_loss=6.260890960693359
INFO - 04/15/25 16:45:11 - 0:13:35 - Epoch 2200: train_loss=6.268836975097656
INFO - 04/15/25 16:45:11 - 0:13:35 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:13 - 0:13:35 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2200: ACC: 0.0, NMI: 0.4272606791867283, F1: 0.0, ARI: 0.2324478479696594
INFO - 04/15/25 16:45:13 - 0:13:36 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2201: train_loss=6.261580944061279
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2202: train_loss=6.266220569610596
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2203: train_loss=6.268056869506836
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2204: train_loss=6.2607951164245605
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2205: train_loss=6.264871597290039
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2206: train_loss=6.264036178588867
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2207: train_loss=6.2587690353393555
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2208: train_loss=6.257330417633057
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2209: train_loss=6.262784957885742
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2210: train_loss=6.249649524688721
INFO - 04/15/25 16:45:13 - 0:13:36 - Epoch 2211: train_loss=6.288620948791504
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2212: train_loss=6.265112400054932
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2213: train_loss=6.265041351318359
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2214: train_loss=6.265679359436035
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2215: train_loss=6.2654314041137695
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2216: train_loss=6.265141487121582
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2217: train_loss=6.268290042877197
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2218: train_loss=6.267856121063232
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2219: train_loss=6.264564037322998
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2220: train_loss=6.2651591300964355
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2221: train_loss=6.265709400177002
INFO - 04/15/25 16:45:13 - 0:13:37 - Epoch 2222: train_loss=6.265170097351074
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2223: train_loss=6.263030052185059
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2224: train_loss=6.264249324798584
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2225: train_loss=6.261863708496094
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2226: train_loss=6.265451908111572
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2227: train_loss=6.262042045593262
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2228: train_loss=6.260646343231201
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2229: train_loss=6.262415885925293
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2230: train_loss=6.2615766525268555
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2231: train_loss=6.2611589431762695
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2232: train_loss=6.260148048400879
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2233: train_loss=6.258530139923096
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2234: train_loss=6.260791778564453
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2235: train_loss=6.258211135864258
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2236: train_loss=6.262160301208496
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2237: train_loss=6.259822368621826
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2238: train_loss=6.257601261138916
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2239: train_loss=6.259199142456055
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2240: train_loss=6.25809907913208
INFO - 04/15/25 16:45:14 - 0:13:37 - Epoch 2241: train_loss=6.258975028991699
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2242: train_loss=6.256559371948242
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2243: train_loss=6.255692005157471
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2244: train_loss=6.258551597595215
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2245: train_loss=6.256197929382324
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2246: train_loss=6.258965492248535
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2247: train_loss=6.256145477294922
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2248: train_loss=6.259918212890625
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2249: train_loss=6.258286476135254
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2250: train_loss=6.257209777832031
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2251: train_loss=6.25721549987793
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2252: train_loss=6.256080150604248
INFO - 04/15/25 16:45:14 - 0:13:38 - Epoch 2253: train_loss=6.254315376281738
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2254: train_loss=6.255906105041504
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2255: train_loss=6.253928184509277
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2256: train_loss=6.2574920654296875
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2257: train_loss=6.2560625076293945
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2258: train_loss=6.255087852478027
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2259: train_loss=6.254298210144043
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2260: train_loss=6.254016876220703
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2261: train_loss=6.253982067108154
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2262: train_loss=6.253255367279053
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2263: train_loss=6.252198696136475
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2264: train_loss=6.25465202331543
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2265: train_loss=6.249852180480957
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2266: train_loss=6.251049041748047
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2267: train_loss=6.248095989227295
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2268: train_loss=6.24821138381958
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2269: train_loss=6.247394561767578
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2270: train_loss=6.2456135749816895
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2271: train_loss=6.246795654296875
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2272: train_loss=6.245783805847168
INFO - 04/15/25 16:45:15 - 0:13:38 - Epoch 2273: train_loss=6.248806476593018
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2274: train_loss=6.246730804443359
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2275: train_loss=6.2472124099731445
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2276: train_loss=6.247711658477783
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2277: train_loss=6.244985580444336
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2278: train_loss=6.2455220222473145
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2279: train_loss=6.245730876922607
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2280: train_loss=6.244763374328613
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2281: train_loss=6.245380878448486
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2282: train_loss=6.244442939758301
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2283: train_loss=6.247385025024414
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2284: train_loss=6.246192932128906
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2285: train_loss=6.2433366775512695
INFO - 04/15/25 16:45:15 - 0:13:39 - Epoch 2286: train_loss=6.243668556213379
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2287: train_loss=6.246214866638184
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2288: train_loss=6.244436740875244
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2289: train_loss=6.2448320388793945
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2290: train_loss=6.245314598083496
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2291: train_loss=6.244484901428223
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2292: train_loss=6.242790222167969
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2293: train_loss=6.250513076782227
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2294: train_loss=6.245763778686523
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2295: train_loss=6.244829177856445
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2296: train_loss=6.245828628540039
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2297: train_loss=6.244039058685303
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2298: train_loss=6.244737148284912
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2299: train_loss=6.244083404541016
INFO - 04/15/25 16:45:16 - 0:13:39 - Epoch 2300: train_loss=6.242095470428467
INFO - 04/15/25 16:45:16 - 0:13:39 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:16 - 0:13:39 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2300: ACC: 0.0, NMI: 0.4277902877023972, F1: 0.0, ARI: 0.1987355356293735
INFO - 04/15/25 16:45:16 - 0:13:40 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2301: train_loss=6.25204610824585
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2302: train_loss=6.250913143157959
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2303: train_loss=6.242673873901367
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2304: train_loss=6.249034881591797
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2305: train_loss=6.248642921447754
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2306: train_loss=6.243938446044922
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2307: train_loss=6.247730255126953
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2308: train_loss=6.246948719024658
INFO - 04/15/25 16:45:16 - 0:13:40 - Epoch 2309: train_loss=6.241876602172852
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2310: train_loss=6.234120845794678
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2311: train_loss=6.240868091583252
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2312: train_loss=6.246314525604248
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2313: train_loss=6.252523422241211
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2314: train_loss=6.24160099029541
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2315: train_loss=6.247061252593994
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2316: train_loss=6.235683917999268
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2317: train_loss=6.230435371398926
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2318: train_loss=6.244246482849121
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2319: train_loss=6.236601829528809
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2320: train_loss=6.242063522338867
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2321: train_loss=6.238856315612793
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2322: train_loss=6.2380571365356445
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2323: train_loss=6.236311435699463
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2324: train_loss=6.238727569580078
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2325: train_loss=6.236330032348633
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2326: train_loss=6.239977836608887
INFO - 04/15/25 16:45:17 - 0:13:40 - Epoch 2327: train_loss=6.238489151000977
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2328: train_loss=6.23276948928833
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2329: train_loss=6.232058048248291
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2330: train_loss=6.2281293869018555
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2331: train_loss=6.225541114807129
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2332: train_loss=6.226449489593506
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2333: train_loss=6.226734638214111
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2334: train_loss=6.224584579467773
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2335: train_loss=6.223352432250977
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2336: train_loss=6.223501205444336
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2337: train_loss=6.223559379577637
INFO - 04/15/25 16:45:17 - 0:13:41 - Epoch 2338: train_loss=6.222718715667725
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2339: train_loss=6.223241806030273
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2340: train_loss=6.221135139465332
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2341: train_loss=6.221872806549072
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2342: train_loss=6.220411777496338
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2343: train_loss=6.222581386566162
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2344: train_loss=6.220530033111572
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2345: train_loss=6.221879959106445
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2346: train_loss=6.219906330108643
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2347: train_loss=6.222447395324707
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2348: train_loss=6.221890449523926
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2349: train_loss=6.224081039428711
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2350: train_loss=6.2191691398620605
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2351: train_loss=6.224136829376221
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2352: train_loss=6.222136974334717
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2353: train_loss=6.22257137298584
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2354: train_loss=6.221334457397461
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2355: train_loss=6.224305629730225
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2356: train_loss=6.224421501159668
INFO - 04/15/25 16:45:18 - 0:13:41 - Epoch 2357: train_loss=6.2235212326049805
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2358: train_loss=6.219061851501465
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2359: train_loss=6.223884582519531
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2360: train_loss=6.221015930175781
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2361: train_loss=6.228589057922363
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2362: train_loss=6.224769115447998
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2363: train_loss=6.224973678588867
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2364: train_loss=6.224816799163818
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2365: train_loss=6.223199844360352
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2366: train_loss=6.222641468048096
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2367: train_loss=6.225832939147949
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2368: train_loss=6.223720073699951
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2369: train_loss=6.223423480987549
INFO - 04/15/25 16:45:18 - 0:13:42 - Epoch 2370: train_loss=6.222201347351074
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2371: train_loss=6.2240142822265625
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2372: train_loss=6.222721099853516
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2373: train_loss=6.222726345062256
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2374: train_loss=6.222031593322754
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2375: train_loss=6.2215256690979
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2376: train_loss=6.21928071975708
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2377: train_loss=6.221485137939453
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2378: train_loss=6.220900535583496
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2379: train_loss=6.218109607696533
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2380: train_loss=6.216203689575195
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2381: train_loss=6.22098445892334
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2382: train_loss=6.219958782196045
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2383: train_loss=6.218583583831787
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2384: train_loss=6.217135906219482
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2385: train_loss=6.218912124633789
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2386: train_loss=6.217584133148193
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2387: train_loss=6.219701290130615
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2388: train_loss=6.220188140869141
INFO - 04/15/25 16:45:19 - 0:13:42 - Epoch 2389: train_loss=6.215845584869385
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2390: train_loss=6.215407848358154
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2391: train_loss=6.218287944793701
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2392: train_loss=6.218563556671143
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2393: train_loss=6.217690467834473
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2394: train_loss=6.218618869781494
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2395: train_loss=6.214354515075684
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2396: train_loss=6.2124528884887695
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2397: train_loss=6.220466613769531
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2398: train_loss=6.219292640686035
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2399: train_loss=6.212884426116943
INFO - 04/15/25 16:45:19 - 0:13:43 - Epoch 2400: train_loss=6.213070869445801
INFO - 04/15/25 16:45:19 - 0:13:43 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:20 - 0:13:43 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2400: ACC: 0.0, NMI: 0.4107113580945757, F1: 0.0, ARI: 0.2281443566844946
INFO - 04/15/25 16:45:20 - 0:13:43 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2401: train_loss=6.21528434753418
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2402: train_loss=6.211661338806152
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2403: train_loss=6.219356536865234
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2404: train_loss=6.221887111663818
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2405: train_loss=6.21280574798584
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2406: train_loss=6.214489936828613
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2407: train_loss=6.213339805603027
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2408: train_loss=6.212789535522461
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2409: train_loss=6.217676162719727
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2410: train_loss=6.217014789581299
INFO - 04/15/25 16:45:20 - 0:13:43 - Epoch 2411: train_loss=6.213108539581299
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2412: train_loss=6.213459491729736
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2413: train_loss=6.213741302490234
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2414: train_loss=6.211888313293457
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2415: train_loss=6.21586799621582
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2416: train_loss=6.216429233551025
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2417: train_loss=6.210745334625244
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2418: train_loss=6.211617469787598
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2419: train_loss=6.212855339050293
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2420: train_loss=6.210511207580566
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2421: train_loss=6.214145183563232
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2422: train_loss=6.2119951248168945
INFO - 04/15/25 16:45:20 - 0:13:44 - Epoch 2423: train_loss=6.211726665496826
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2424: train_loss=6.210622787475586
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2425: train_loss=6.213450908660889
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2426: train_loss=6.21079683303833
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2427: train_loss=6.2140326499938965
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2428: train_loss=6.220149040222168
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2429: train_loss=6.223060131072998
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2430: train_loss=6.32145357131958
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2431: train_loss=6.281798362731934
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2432: train_loss=6.315522193908691
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2433: train_loss=6.3549933433532715
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2434: train_loss=6.399591445922852
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2435: train_loss=6.438159465789795
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2436: train_loss=6.466928958892822
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2437: train_loss=6.412789344787598
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2438: train_loss=6.398260593414307
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2439: train_loss=6.405510902404785
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2440: train_loss=6.421163082122803
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2441: train_loss=6.431712627410889
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2442: train_loss=6.3913254737854
INFO - 04/15/25 16:45:21 - 0:13:44 - Epoch 2443: train_loss=6.384237289428711
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2444: train_loss=6.381093502044678
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2445: train_loss=6.38222074508667
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2446: train_loss=6.387012958526611
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2447: train_loss=6.386486053466797
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2448: train_loss=6.395343780517578
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2449: train_loss=6.370553016662598
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2450: train_loss=6.378084182739258
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2451: train_loss=6.374989032745361
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2452: train_loss=6.373044967651367
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2453: train_loss=6.368835926055908
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2454: train_loss=6.368048667907715
INFO - 04/15/25 16:45:21 - 0:13:45 - Epoch 2455: train_loss=6.372373580932617
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2456: train_loss=6.371463298797607
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2457: train_loss=6.366209983825684
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2458: train_loss=6.365986347198486
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2459: train_loss=6.368533134460449
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2460: train_loss=6.36621618270874
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2461: train_loss=6.36374568939209
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2462: train_loss=6.365250587463379
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2463: train_loss=6.366272449493408
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2464: train_loss=6.362041473388672
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2465: train_loss=6.363441467285156
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2466: train_loss=6.363672256469727
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2467: train_loss=6.3610029220581055
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2468: train_loss=6.3547773361206055
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2469: train_loss=6.361182689666748
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2470: train_loss=6.358797550201416
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2471: train_loss=6.359605312347412
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2472: train_loss=6.358770847320557
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2473: train_loss=6.353588104248047
INFO - 04/15/25 16:45:22 - 0:13:45 - Epoch 2474: train_loss=6.353292942047119
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2475: train_loss=6.356383323669434
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2476: train_loss=6.356179237365723
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2477: train_loss=6.355003356933594
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2478: train_loss=6.355072975158691
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2479: train_loss=6.353776931762695
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2480: train_loss=6.354449272155762
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2481: train_loss=6.353361129760742
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2482: train_loss=6.351291656494141
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2483: train_loss=6.353053569793701
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2484: train_loss=6.353058338165283
INFO - 04/15/25 16:45:22 - 0:13:46 - Epoch 2485: train_loss=6.35211706161499
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2486: train_loss=6.352713108062744
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2487: train_loss=6.351354122161865
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2488: train_loss=6.351076602935791
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2489: train_loss=6.349575996398926
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2490: train_loss=6.351357460021973
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2491: train_loss=6.350988388061523
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2492: train_loss=6.34968376159668
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2493: train_loss=6.349569320678711
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2494: train_loss=6.348600387573242
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2495: train_loss=6.347541809082031
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2496: train_loss=6.3505048751831055
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2497: train_loss=6.345041275024414
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2498: train_loss=6.378166675567627
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2499: train_loss=6.35239315032959
INFO - 04/15/25 16:45:23 - 0:13:46 - Epoch 2500: train_loss=6.351523399353027
INFO - 04/15/25 16:45:23 - 0:13:46 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:23 - 0:13:46 - Decoding cost time:  0.130 s
INFO - 04/15/25 16:45:23 - 0:13:47 - Epoch 2500: ACC: 0.0, NMI: 0.47379333967654996, F1: 0.0, ARI: 0.3031370982893406
INFO - 04/15/25 16:45:23 - 0:13:47 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:23 - 0:13:47 - Epoch 2501: train_loss=6.3521881103515625
INFO - 04/15/25 16:45:23 - 0:13:47 - Epoch 2502: train_loss=6.35064172744751
INFO - 04/15/25 16:45:23 - 0:13:47 - Epoch 2503: train_loss=6.349924087524414
INFO - 04/15/25 16:45:23 - 0:13:47 - Epoch 2504: train_loss=6.349708080291748
INFO - 04/15/25 16:45:23 - 0:13:47 - Epoch 2505: train_loss=6.3598175048828125
INFO - 04/15/25 16:45:23 - 0:13:47 - Epoch 2506: train_loss=6.352973461151123
INFO - 04/15/25 16:45:23 - 0:13:47 - Epoch 2507: train_loss=6.3511505126953125
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2508: train_loss=6.350584030151367
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2509: train_loss=6.352827072143555
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2510: train_loss=6.3500142097473145
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2511: train_loss=6.352249622344971
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2512: train_loss=6.35305643081665
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2513: train_loss=6.348362922668457
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2514: train_loss=6.3490142822265625
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2515: train_loss=6.346739768981934
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2516: train_loss=6.344657897949219
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2517: train_loss=6.344744682312012
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2518: train_loss=6.342989921569824
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2519: train_loss=6.342979431152344
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2520: train_loss=6.342252254486084
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2521: train_loss=6.341763496398926
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2522: train_loss=6.340920925140381
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2523: train_loss=6.340369701385498
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2524: train_loss=6.339890480041504
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2525: train_loss=6.339979648590088
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2526: train_loss=6.338218688964844
INFO - 04/15/25 16:45:24 - 0:13:47 - Epoch 2527: train_loss=6.339685440063477
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2528: train_loss=6.337634563446045
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2529: train_loss=6.3372321128845215
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2530: train_loss=6.336722373962402
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2531: train_loss=6.336775779724121
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2532: train_loss=6.3365254402160645
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2533: train_loss=6.336469650268555
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2534: train_loss=6.33593225479126
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2535: train_loss=6.33477258682251
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2536: train_loss=6.334536552429199
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2537: train_loss=6.335886001586914
INFO - 04/15/25 16:45:24 - 0:13:48 - Epoch 2538: train_loss=6.332981586456299
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2539: train_loss=6.3373284339904785
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2540: train_loss=6.336241245269775
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2541: train_loss=6.3334059715271
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2542: train_loss=6.327118873596191
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2543: train_loss=6.32895040512085
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2544: train_loss=6.320663928985596
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2545: train_loss=6.327293395996094
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2546: train_loss=6.322892189025879
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2547: train_loss=6.309357643127441
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2548: train_loss=6.331999778747559
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2549: train_loss=6.3158278465271
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2550: train_loss=6.317451477050781
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2551: train_loss=6.3135809898376465
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2552: train_loss=6.321376800537109
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2553: train_loss=6.307849884033203
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2554: train_loss=6.304357528686523
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2555: train_loss=6.316025257110596
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2556: train_loss=6.313334941864014
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2557: train_loss=6.289015293121338
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2558: train_loss=6.280488014221191
INFO - 04/15/25 16:45:25 - 0:13:48 - Epoch 2559: train_loss=6.279412746429443
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2560: train_loss=6.268450736999512
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2561: train_loss=6.273330211639404
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2562: train_loss=6.266346454620361
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2563: train_loss=6.2761993408203125
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2564: train_loss=6.275218486785889
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2565: train_loss=6.265583038330078
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2566: train_loss=6.276412487030029
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2567: train_loss=6.27307653427124
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2568: train_loss=6.263692855834961
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2569: train_loss=6.2608842849731445
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2570: train_loss=6.269217014312744
INFO - 04/15/25 16:45:25 - 0:13:49 - Epoch 2571: train_loss=6.267031192779541
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2572: train_loss=6.265130996704102
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2573: train_loss=6.265774726867676
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2574: train_loss=6.26357889175415
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2575: train_loss=6.261566638946533
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2576: train_loss=6.2553253173828125
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2577: train_loss=6.261866569519043
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2578: train_loss=6.258327007293701
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2579: train_loss=6.257949352264404
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2580: train_loss=6.258957862854004
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2581: train_loss=6.256562232971191
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2582: train_loss=6.257791996002197
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2583: train_loss=6.256313323974609
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2584: train_loss=6.250493049621582
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2585: train_loss=6.255877494812012
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2586: train_loss=6.255582332611084
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2587: train_loss=6.2550225257873535
INFO - 04/15/25 16:45:26 - 0:13:49 - Epoch 2588: train_loss=6.247270584106445
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2589: train_loss=6.253042221069336
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2590: train_loss=6.252854347229004
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2591: train_loss=6.251194953918457
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2592: train_loss=6.254803657531738
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2593: train_loss=6.246442794799805
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2594: train_loss=6.242388725280762
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2595: train_loss=6.242237567901611
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2596: train_loss=6.251579284667969
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2597: train_loss=6.248873710632324
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2598: train_loss=6.252536773681641
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2599: train_loss=6.244357585906982
INFO - 04/15/25 16:45:26 - 0:13:50 - Epoch 2600: train_loss=6.247451305389404
INFO - 04/15/25 16:45:26 - 0:13:50 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:27 - 0:13:50 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2600: ACC: 0.0, NMI: 0.45847005820873116, F1: 0.0, ARI: 0.28419207453855777
INFO - 04/15/25 16:45:27 - 0:13:50 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2601: train_loss=6.246846675872803
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2602: train_loss=6.247660160064697
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2603: train_loss=6.245180606842041
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2604: train_loss=6.246124744415283
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2605: train_loss=6.246244430541992
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2606: train_loss=6.240726470947266
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2607: train_loss=6.238743305206299
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2608: train_loss=6.245543479919434
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2609: train_loss=6.242231845855713
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2610: train_loss=6.235701560974121
INFO - 04/15/25 16:45:27 - 0:13:50 - Epoch 2611: train_loss=6.243041038513184
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2612: train_loss=6.241938591003418
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2613: train_loss=6.241361141204834
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2614: train_loss=6.239787578582764
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2615: train_loss=6.231749534606934
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2616: train_loss=6.24092435836792
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2617: train_loss=6.2386474609375
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2618: train_loss=6.2406511306762695
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2619: train_loss=6.241971969604492
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2620: train_loss=6.238975524902344
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2621: train_loss=6.236980438232422
INFO - 04/15/25 16:45:27 - 0:13:51 - Epoch 2622: train_loss=6.225977420806885
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2623: train_loss=6.229289531707764
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2624: train_loss=6.222817897796631
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2625: train_loss=6.2178850173950195
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2626: train_loss=6.221172332763672
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2627: train_loss=6.221802711486816
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2628: train_loss=6.218569278717041
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2629: train_loss=6.21774959564209
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2630: train_loss=6.219200611114502
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2631: train_loss=6.210716247558594
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2632: train_loss=6.219187259674072
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2633: train_loss=6.218541145324707
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2634: train_loss=6.217930316925049
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2635: train_loss=6.217380523681641
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2636: train_loss=6.2180962562561035
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2637: train_loss=6.215959548950195
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2638: train_loss=6.220373630523682
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2639: train_loss=6.21916389465332
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2640: train_loss=6.213900566101074
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2641: train_loss=6.215252876281738
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2642: train_loss=6.217060565948486
INFO - 04/15/25 16:45:28 - 0:13:51 - Epoch 2643: train_loss=6.214120864868164
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2644: train_loss=6.219765663146973
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2645: train_loss=6.212589263916016
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2646: train_loss=6.216355800628662
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2647: train_loss=6.217883586883545
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2648: train_loss=6.2140607833862305
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2649: train_loss=6.2181501388549805
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2650: train_loss=6.219397068023682
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2651: train_loss=6.216444492340088
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2652: train_loss=6.217175006866455
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2653: train_loss=6.21732759475708
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2654: train_loss=6.215119361877441
INFO - 04/15/25 16:45:28 - 0:13:52 - Epoch 2655: train_loss=6.2148637771606445
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2656: train_loss=6.21304988861084
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2657: train_loss=6.226609706878662
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2658: train_loss=6.216291427612305
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2659: train_loss=6.214773178100586
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2660: train_loss=6.216134071350098
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2661: train_loss=6.215667724609375
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2662: train_loss=6.215328216552734
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2663: train_loss=6.215663433074951
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2664: train_loss=6.212949275970459
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2665: train_loss=6.214554786682129
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2666: train_loss=6.212689399719238
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2667: train_loss=6.210953712463379
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2668: train_loss=6.212017059326172
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2669: train_loss=6.203070163726807
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2670: train_loss=6.1960320472717285
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2671: train_loss=6.2024006843566895
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2672: train_loss=6.192933559417725
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2673: train_loss=6.185702323913574
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2674: train_loss=6.177524089813232
INFO - 04/15/25 16:45:29 - 0:13:52 - Epoch 2675: train_loss=6.181053638458252
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2676: train_loss=6.175989627838135
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2677: train_loss=6.173125743865967
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2678: train_loss=6.172291278839111
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2679: train_loss=6.166818141937256
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2680: train_loss=6.159852981567383
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2681: train_loss=6.164989471435547
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2682: train_loss=6.15207052230835
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2683: train_loss=6.156951904296875
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2684: train_loss=6.152435302734375
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2685: train_loss=6.146134376525879
INFO - 04/15/25 16:45:29 - 0:13:53 - Epoch 2686: train_loss=6.1513285636901855
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2687: train_loss=6.148576259613037
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2688: train_loss=6.148172855377197
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2689: train_loss=6.147196292877197
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2690: train_loss=6.142490863800049
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2691: train_loss=6.144684791564941
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2692: train_loss=6.140710353851318
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2693: train_loss=6.145559787750244
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2694: train_loss=6.141470432281494
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2695: train_loss=6.140586853027344
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2696: train_loss=6.138207912445068
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2697: train_loss=6.13785982131958
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2698: train_loss=6.139077186584473
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2699: train_loss=6.1378912925720215
INFO - 04/15/25 16:45:30 - 0:13:53 - Epoch 2700: train_loss=6.137979984283447
INFO - 04/15/25 16:45:30 - 0:13:53 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:30 - 0:13:53 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2700: ACC: 0.0, NMI: 0.3988942534028645, F1: 0.0, ARI: 0.18229718545912954
INFO - 04/15/25 16:45:30 - 0:13:54 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2701: train_loss=6.137235641479492
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2702: train_loss=6.136031150817871
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2703: train_loss=6.134367942810059
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2704: train_loss=6.136254787445068
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2705: train_loss=6.134695053100586
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2706: train_loss=6.12538480758667
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2707: train_loss=6.132493495941162
INFO - 04/15/25 16:45:30 - 0:13:54 - Epoch 2708: train_loss=6.133368968963623
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2709: train_loss=6.131731986999512
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2710: train_loss=6.129711627960205
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2711: train_loss=6.129950523376465
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2712: train_loss=6.130075454711914
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2713: train_loss=6.129178524017334
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2714: train_loss=6.132995128631592
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2715: train_loss=6.1308979988098145
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2716: train_loss=6.129110336303711
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2717: train_loss=6.1286773681640625
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2718: train_loss=6.128458499908447
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2719: train_loss=6.124060153961182
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2720: train_loss=6.12966775894165
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2721: train_loss=6.128211498260498
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2722: train_loss=6.127336502075195
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2723: train_loss=6.126811981201172
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2724: train_loss=6.125254154205322
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2725: train_loss=6.123104572296143
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2726: train_loss=6.126559257507324
INFO - 04/15/25 16:45:31 - 0:13:54 - Epoch 2727: train_loss=6.124074935913086
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2728: train_loss=6.1267547607421875
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2729: train_loss=6.125829696655273
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2730: train_loss=6.119413375854492
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2731: train_loss=6.123623847961426
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2732: train_loss=6.12238883972168
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2733: train_loss=6.119539737701416
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2734: train_loss=6.1226606369018555
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2735: train_loss=6.11323356628418
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2736: train_loss=6.122694969177246
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2737: train_loss=6.107165813446045
INFO - 04/15/25 16:45:31 - 0:13:55 - Epoch 2738: train_loss=6.094594955444336
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2739: train_loss=6.084415435791016
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2740: train_loss=6.076942443847656
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2741: train_loss=6.064083576202393
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2742: train_loss=6.04052734375
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2743: train_loss=6.031322956085205
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2744: train_loss=6.0273051261901855
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2745: train_loss=6.027039051055908
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2746: train_loss=6.025940895080566
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2747: train_loss=6.023070812225342
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2748: train_loss=6.01824951171875
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2749: train_loss=6.0187273025512695
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2750: train_loss=6.014622211456299
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2751: train_loss=6.011094570159912
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2752: train_loss=6.012391090393066
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2753: train_loss=6.00648832321167
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2754: train_loss=6.007922172546387
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2755: train_loss=6.013294696807861
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2756: train_loss=6.006208896636963
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2757: train_loss=6.007863521575928
INFO - 04/15/25 16:45:32 - 0:13:55 - Epoch 2758: train_loss=6.0240254402160645
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2759: train_loss=6.009698390960693
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2760: train_loss=6.005605697631836
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2761: train_loss=6.0023884773254395
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2762: train_loss=6.0087151527404785
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2763: train_loss=6.0146894454956055
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2764: train_loss=6.020167827606201
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2765: train_loss=6.003087520599365
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2766: train_loss=6.003023147583008
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2767: train_loss=6.001622200012207
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2768: train_loss=6.002142906188965
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2769: train_loss=6.002561092376709
INFO - 04/15/25 16:45:32 - 0:13:56 - Epoch 2770: train_loss=6.001830101013184
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2771: train_loss=5.9987897872924805
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2772: train_loss=5.998026371002197
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2773: train_loss=5.997001647949219
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2774: train_loss=5.994680881500244
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2775: train_loss=5.995650768280029
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2776: train_loss=5.994450092315674
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2777: train_loss=5.993099689483643
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2778: train_loss=5.9944167137146
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2779: train_loss=5.993134021759033
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2780: train_loss=5.993609428405762
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2781: train_loss=5.990957736968994
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2782: train_loss=5.992029666900635
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2783: train_loss=5.989294052124023
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2784: train_loss=5.991384983062744
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2785: train_loss=5.989311695098877
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2786: train_loss=5.990265846252441
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2787: train_loss=5.988321781158447
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2788: train_loss=5.989206314086914
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2789: train_loss=5.988408088684082
INFO - 04/15/25 16:45:33 - 0:13:56 - Epoch 2790: train_loss=5.98795223236084
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2791: train_loss=5.987372875213623
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2792: train_loss=5.987481117248535
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2793: train_loss=5.986543655395508
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2794: train_loss=5.985716819763184
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2795: train_loss=5.98544454574585
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2796: train_loss=5.98611307144165
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2797: train_loss=5.98445463180542
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2798: train_loss=5.985156059265137
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2799: train_loss=5.984701633453369
INFO - 04/15/25 16:45:33 - 0:13:57 - Epoch 2800: train_loss=5.984163284301758
INFO - 04/15/25 16:45:33 - 0:13:57 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:34 - 0:13:57 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2800: ACC: 0.0, NMI: 0.4205564307999092, F1: 0.0, ARI: 0.25129446081867646
INFO - 04/15/25 16:45:34 - 0:13:57 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2801: train_loss=5.983021259307861
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2802: train_loss=5.983922958374023
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2803: train_loss=5.983607769012451
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2804: train_loss=5.981945514678955
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2805: train_loss=5.981564521789551
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2806: train_loss=5.982661247253418
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2807: train_loss=5.981363296508789
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2808: train_loss=5.9827561378479
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2809: train_loss=5.98190450668335
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2810: train_loss=5.980602741241455
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2811: train_loss=5.980555534362793
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2812: train_loss=5.9802961349487305
INFO - 04/15/25 16:45:34 - 0:13:57 - Epoch 2813: train_loss=5.979646682739258
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2814: train_loss=5.980733871459961
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2815: train_loss=5.980518341064453
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2816: train_loss=5.979776382446289
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2817: train_loss=5.978541374206543
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2818: train_loss=5.980186462402344
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2819: train_loss=5.97961950302124
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2820: train_loss=5.978767395019531
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2821: train_loss=5.978328704833984
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2822: train_loss=5.979074478149414
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2823: train_loss=5.979033470153809
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2824: train_loss=5.978672981262207
INFO - 04/15/25 16:45:34 - 0:13:58 - Epoch 2825: train_loss=5.977529048919678
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2826: train_loss=5.979300498962402
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2827: train_loss=5.978823661804199
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2828: train_loss=5.977315902709961
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2829: train_loss=5.977049827575684
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2830: train_loss=5.978763580322266
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2831: train_loss=5.978204250335693
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2832: train_loss=5.976926803588867
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2833: train_loss=5.9765625
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2834: train_loss=5.978481292724609
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2835: train_loss=5.978069305419922
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2836: train_loss=5.975782871246338
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2837: train_loss=5.975344181060791
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2838: train_loss=5.97817325592041
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2839: train_loss=5.977804660797119
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2840: train_loss=5.975712299346924
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2841: train_loss=5.975533962249756
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2842: train_loss=5.97674036026001
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2843: train_loss=5.976315975189209
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2844: train_loss=5.97622013092041
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2845: train_loss=5.975686550140381
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2846: train_loss=5.976047515869141
INFO - 04/15/25 16:45:35 - 0:13:58 - Epoch 2847: train_loss=5.9759521484375
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2848: train_loss=5.976110458374023
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2849: train_loss=5.9762115478515625
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2850: train_loss=5.97527551651001
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2851: train_loss=5.975052356719971
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2852: train_loss=5.976284027099609
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2853: train_loss=5.975016117095947
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2854: train_loss=5.975442886352539
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2855: train_loss=5.975467205047607
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2856: train_loss=5.974441051483154
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2857: train_loss=5.973720073699951
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2858: train_loss=5.975811004638672
INFO - 04/15/25 16:45:35 - 0:13:59 - Epoch 2859: train_loss=5.975728511810303
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2860: train_loss=5.975226879119873
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2861: train_loss=5.974861145019531
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2862: train_loss=5.975183963775635
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2863: train_loss=5.974970817565918
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2864: train_loss=5.975764751434326
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2865: train_loss=5.974885940551758
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2866: train_loss=5.974440097808838
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2867: train_loss=5.97451114654541
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2868: train_loss=5.974602699279785
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2869: train_loss=5.973765850067139
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2870: train_loss=5.975416660308838
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2871: train_loss=5.97471809387207
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2872: train_loss=5.9734296798706055
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2873: train_loss=5.973939895629883
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2874: train_loss=5.9749064445495605
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2875: train_loss=5.97429084777832
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2876: train_loss=5.974892616271973
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2877: train_loss=5.976285934448242
INFO - 04/15/25 16:45:36 - 0:13:59 - Epoch 2878: train_loss=5.972617149353027
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2879: train_loss=5.97391414642334
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2880: train_loss=5.973358631134033
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2881: train_loss=5.973010540008545
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2882: train_loss=5.974897384643555
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2883: train_loss=5.9735307693481445
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2884: train_loss=5.974804878234863
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2885: train_loss=5.975316047668457
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2886: train_loss=5.9734625816345215
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2887: train_loss=5.974483489990234
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2888: train_loss=5.973496913909912
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2889: train_loss=5.9728474617004395
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2890: train_loss=5.97480583190918
INFO - 04/15/25 16:45:36 - 0:14:00 - Epoch 2891: train_loss=5.974353790283203
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2892: train_loss=5.973203659057617
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2893: train_loss=5.972492694854736
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2894: train_loss=5.97328519821167
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2895: train_loss=5.972288608551025
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2896: train_loss=5.974388122558594
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2897: train_loss=5.973797798156738
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2898: train_loss=5.973390579223633
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2899: train_loss=5.97361421585083
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2900: train_loss=5.973037242889404
INFO - 04/15/25 16:45:37 - 0:14:00 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:37 - 0:14:00 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2900: ACC: 0.0, NMI: 0.46386412022632745, F1: 0.0, ARI: 0.25911565524287605
INFO - 04/15/25 16:45:37 - 0:14:00 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2901: train_loss=5.9724297523498535
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2902: train_loss=5.974007606506348
INFO - 04/15/25 16:45:37 - 0:14:00 - Epoch 2903: train_loss=5.973530292510986
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2904: train_loss=5.972434997558594
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2905: train_loss=5.971930980682373
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2906: train_loss=5.973635196685791
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2907: train_loss=5.973239898681641
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2908: train_loss=5.972732067108154
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2909: train_loss=5.97227144241333
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2910: train_loss=5.97271728515625
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2911: train_loss=5.972261428833008
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2912: train_loss=5.972708225250244
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2913: train_loss=5.972200393676758
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2914: train_loss=5.972605228424072
INFO - 04/15/25 16:45:37 - 0:14:01 - Epoch 2915: train_loss=5.972392559051514
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2916: train_loss=5.972506999969482
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2917: train_loss=5.971395969390869
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2918: train_loss=5.9726386070251465
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2919: train_loss=5.972161769866943
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2920: train_loss=5.972986698150635
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2921: train_loss=5.972418308258057
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2922: train_loss=5.972987174987793
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2923: train_loss=5.972294330596924
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2924: train_loss=5.971767902374268
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2925: train_loss=5.971664905548096
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2926: train_loss=5.973135471343994
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2927: train_loss=5.972229957580566
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2928: train_loss=5.971736431121826
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2929: train_loss=5.971240043640137
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2930: train_loss=5.9731926918029785
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2931: train_loss=5.971999645233154
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2932: train_loss=5.972285270690918
INFO - 04/15/25 16:45:38 - 0:14:01 - Epoch 2933: train_loss=5.972158908843994
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2934: train_loss=5.97316837310791
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2935: train_loss=5.972302436828613
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2936: train_loss=5.971134185791016
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2937: train_loss=5.971118450164795
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2938: train_loss=5.97166633605957
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2939: train_loss=5.97053861618042
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2940: train_loss=5.973087787628174
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2941: train_loss=5.972137928009033
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2942: train_loss=5.969996929168701
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2943: train_loss=5.970180988311768
INFO - 04/15/25 16:45:38 - 0:14:02 - Epoch 2944: train_loss=5.971444129943848
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2945: train_loss=5.970028877258301
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2946: train_loss=5.971275329589844
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2947: train_loss=5.971395492553711
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2948: train_loss=5.969315052032471
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2949: train_loss=5.968770503997803
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2950: train_loss=5.970575332641602
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2951: train_loss=5.971117973327637
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2952: train_loss=5.9702982902526855
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2953: train_loss=5.970180511474609
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2954: train_loss=5.969921112060547
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2955: train_loss=5.969414710998535
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2956: train_loss=5.971067428588867
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2957: train_loss=5.970041751861572
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2958: train_loss=5.969749450683594
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2959: train_loss=5.9697723388671875
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2960: train_loss=5.969761371612549
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2961: train_loss=5.969099044799805
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2962: train_loss=5.970191955566406
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2963: train_loss=5.969666004180908
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2964: train_loss=5.968945026397705
INFO - 04/15/25 16:45:39 - 0:14:02 - Epoch 2965: train_loss=5.969972133636475
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2966: train_loss=5.969510555267334
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2967: train_loss=5.969585418701172
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2968: train_loss=5.970449447631836
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2969: train_loss=5.970637798309326
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2970: train_loss=5.969733238220215
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2971: train_loss=5.969628810882568
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2972: train_loss=5.970113277435303
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2973: train_loss=5.969106197357178
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2974: train_loss=5.970875263214111
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2975: train_loss=5.970247745513916
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2976: train_loss=5.969963073730469
INFO - 04/15/25 16:45:39 - 0:14:03 - Epoch 2977: train_loss=5.969851016998291
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2978: train_loss=5.968596458435059
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2979: train_loss=5.968169689178467
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2980: train_loss=5.969862937927246
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2981: train_loss=5.969066143035889
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2982: train_loss=5.968254566192627
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2983: train_loss=5.968266010284424
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2984: train_loss=5.968190670013428
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2985: train_loss=5.967963218688965
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2986: train_loss=5.9682512283325195
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2987: train_loss=5.9683732986450195
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2988: train_loss=5.967843532562256
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2989: train_loss=5.967261791229248
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2990: train_loss=5.968635559082031
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2991: train_loss=5.968323707580566
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2992: train_loss=5.967724800109863
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2993: train_loss=5.966861724853516
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2994: train_loss=5.968369483947754
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2995: train_loss=5.968184471130371
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2996: train_loss=5.967845916748047
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2997: train_loss=5.967803001403809
INFO - 04/15/25 16:45:40 - 0:14:03 - Epoch 2998: train_loss=5.9677653312683105
INFO - 04/15/25 16:45:40 - 0:14:04 - Epoch 2999: train_loss=5.967859745025635
INFO - 04/15/25 16:45:40 - 0:14:04 - Epoch 3000: train_loss=5.9684739112854
INFO - 04/15/25 16:45:40 - 0:14:04 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:40 - 0:14:04 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:45:40 - 0:14:04 - Epoch 3000: ACC: 0.0, NMI: 0.38935867340591335, F1: 0.0, ARI: 0.16492038362631992
INFO - 04/15/25 16:45:40 - 0:14:04 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:40 - 0:14:04 - Epoch 3001: train_loss=5.967204570770264
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3002: train_loss=5.970172882080078
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3003: train_loss=5.970749855041504
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3004: train_loss=5.966754913330078
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3005: train_loss=5.972053050994873
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3006: train_loss=5.974124431610107
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3007: train_loss=5.970779895782471
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3008: train_loss=5.969419002532959
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3009: train_loss=5.972165107727051
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3010: train_loss=5.96858549118042
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3011: train_loss=5.970478534698486
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3012: train_loss=5.971235752105713
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3013: train_loss=5.967932224273682
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3014: train_loss=5.970014572143555
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3015: train_loss=5.970756530761719
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3016: train_loss=5.9677934646606445
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3017: train_loss=5.969663143157959
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3018: train_loss=5.97068452835083
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3019: train_loss=5.967682361602783
INFO - 04/15/25 16:45:41 - 0:14:04 - Epoch 3020: train_loss=5.969515323638916
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3021: train_loss=5.969690322875977
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3022: train_loss=5.967800617218018
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3023: train_loss=5.968980312347412
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3024: train_loss=5.968762397766113
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3025: train_loss=5.967964172363281
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3026: train_loss=5.968249320983887
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3027: train_loss=5.968574047088623
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3028: train_loss=5.967939853668213
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3029: train_loss=5.968311786651611
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3030: train_loss=5.9680986404418945
INFO - 04/15/25 16:45:41 - 0:14:05 - Epoch 3031: train_loss=5.966655731201172
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3032: train_loss=5.967171669006348
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3033: train_loss=5.967957496643066
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3034: train_loss=5.966212749481201
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3035: train_loss=5.968062400817871
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3036: train_loss=5.967496395111084
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3037: train_loss=5.967496871948242
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3038: train_loss=5.967705726623535
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3039: train_loss=5.966729164123535
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3040: train_loss=5.967623233795166
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3041: train_loss=5.967308044433594
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3042: train_loss=5.967325210571289
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3043: train_loss=5.966968059539795
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3044: train_loss=5.967087745666504
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3045: train_loss=5.967834949493408
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3046: train_loss=5.967025279998779
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3047: train_loss=5.9672932624816895
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3048: train_loss=5.966651916503906
INFO - 04/15/25 16:45:42 - 0:14:05 - Epoch 3049: train_loss=5.967342376708984
INFO - 04/15/25 16:45:44 - 0:14:05 - Epoch 3050: train_loss=5.966238975524902
INFO - 04/15/25 16:45:44 - 0:14:07 - Epoch 3051: train_loss=5.968166828155518
INFO - 04/15/25 16:45:44 - 0:14:07 - Epoch 3052: train_loss=5.967599868774414
INFO - 04/15/25 16:45:44 - 0:14:07 - Epoch 3053: train_loss=5.966785430908203
INFO - 04/15/25 16:45:44 - 0:14:07 - Epoch 3054: train_loss=5.96650505065918
INFO - 04/15/25 16:45:44 - 0:14:07 - Epoch 3055: train_loss=5.9660773277282715
INFO - 04/15/25 16:45:44 - 0:14:07 - Epoch 3056: train_loss=5.965664386749268
INFO - 04/15/25 16:45:44 - 0:14:07 - Epoch 3057: train_loss=5.967834949493408
INFO - 04/15/25 16:45:44 - 0:14:07 - Epoch 3058: train_loss=5.9665069580078125
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3059: train_loss=5.969451427459717
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3060: train_loss=5.967482089996338
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3061: train_loss=5.968667030334473
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3062: train_loss=5.969104766845703
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3063: train_loss=5.96641731262207
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3064: train_loss=5.966748237609863
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3065: train_loss=5.968495845794678
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3066: train_loss=5.967448711395264
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3067: train_loss=5.967946529388428
INFO - 04/15/25 16:45:44 - 0:14:08 - Epoch 3068: train_loss=5.967159748077393
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3069: train_loss=5.967656135559082
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3070: train_loss=5.96732234954834
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3071: train_loss=5.965909004211426
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3072: train_loss=5.965479373931885
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3073: train_loss=5.966190338134766
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3074: train_loss=5.965231895446777
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3075: train_loss=5.9644575119018555
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3076: train_loss=5.963719367980957
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3077: train_loss=5.964334487915039
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3078: train_loss=5.963630676269531
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3079: train_loss=5.963906288146973
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3080: train_loss=5.963461875915527
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3081: train_loss=5.962859153747559
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3082: train_loss=5.962326526641846
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3083: train_loss=5.963381290435791
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3084: train_loss=5.962884902954102
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3085: train_loss=5.963342666625977
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3086: train_loss=5.9634270668029785
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3087: train_loss=5.961866855621338
INFO - 04/15/25 16:45:45 - 0:14:08 - Epoch 3088: train_loss=5.961550235748291
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3089: train_loss=5.963432312011719
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3090: train_loss=5.963301181793213
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3091: train_loss=5.961602687835693
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3092: train_loss=5.961359024047852
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3093: train_loss=5.96290922164917
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3094: train_loss=5.962382793426514
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3095: train_loss=5.961790561676025
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3096: train_loss=5.961481094360352
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3097: train_loss=5.962655544281006
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3098: train_loss=5.961855888366699
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3099: train_loss=5.961750030517578
INFO - 04/15/25 16:45:45 - 0:14:09 - Epoch 3100: train_loss=5.961535930633545
INFO - 04/15/25 16:45:45 - 0:14:09 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:46 - 0:14:09 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3100: ACC: 0.0, NMI: 0.4333282236129222, F1: 0.0, ARI: 0.25082444564656625
INFO - 04/15/25 16:45:46 - 0:14:09 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3101: train_loss=5.962231159210205
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3102: train_loss=5.961764812469482
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3103: train_loss=5.961280345916748
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3104: train_loss=5.960855484008789
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3105: train_loss=5.962075710296631
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3106: train_loss=5.961620330810547
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3107: train_loss=5.961113452911377
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3108: train_loss=5.960334777832031
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3109: train_loss=5.962396144866943
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3110: train_loss=5.961703777313232
INFO - 04/15/25 16:45:46 - 0:14:09 - Epoch 3111: train_loss=5.961577415466309
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3112: train_loss=5.961374282836914
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3113: train_loss=5.961550712585449
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3114: train_loss=5.961212635040283
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3115: train_loss=5.962613105773926
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3116: train_loss=5.9627532958984375
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3117: train_loss=5.96098518371582
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3118: train_loss=5.960718154907227
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3119: train_loss=5.963773727416992
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3120: train_loss=5.965109825134277
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3121: train_loss=5.964577674865723
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3122: train_loss=5.964574813842773
INFO - 04/15/25 16:45:46 - 0:14:10 - Epoch 3123: train_loss=5.963608264923096
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3124: train_loss=5.963648796081543
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3125: train_loss=5.963927745819092
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3126: train_loss=5.963812828063965
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3127: train_loss=5.9648051261901855
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3128: train_loss=5.962995529174805
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3129: train_loss=5.964151382446289
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3130: train_loss=5.9637627601623535
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3131: train_loss=5.9629130363464355
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3132: train_loss=5.962760925292969
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3133: train_loss=5.9627556800842285
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3134: train_loss=5.961786270141602
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3135: train_loss=5.963476657867432
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3136: train_loss=5.963072299957275
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3137: train_loss=5.961455345153809
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3138: train_loss=5.961108207702637
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3139: train_loss=5.961935997009277
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3140: train_loss=5.96107292175293
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3141: train_loss=5.96254825592041
INFO - 04/15/25 16:45:47 - 0:14:10 - Epoch 3142: train_loss=5.962357997894287
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3143: train_loss=5.962349891662598
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3144: train_loss=5.962253570556641
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3145: train_loss=5.962441444396973
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3146: train_loss=5.961930274963379
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3147: train_loss=5.962987422943115
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3148: train_loss=5.961548328399658
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3149: train_loss=5.963601589202881
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3150: train_loss=5.96293830871582
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3151: train_loss=5.961355209350586
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3152: train_loss=5.960700511932373
INFO - 04/15/25 16:45:47 - 0:14:11 - Epoch 3153: train_loss=5.962002277374268
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3154: train_loss=5.961040019989014
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3155: train_loss=5.9631781578063965
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3156: train_loss=5.9628586769104
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3157: train_loss=5.959941864013672
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3158: train_loss=5.960882663726807
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3159: train_loss=5.96021842956543
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3160: train_loss=5.960118770599365
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3161: train_loss=5.960494518280029
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3162: train_loss=5.959566593170166
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3163: train_loss=5.960693359375
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3164: train_loss=5.959239482879639
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3165: train_loss=5.960642337799072
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3166: train_loss=5.95966911315918
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3167: train_loss=5.960826873779297
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3168: train_loss=5.9601898193359375
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3169: train_loss=5.960211753845215
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3170: train_loss=5.959920883178711
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3171: train_loss=5.959804058074951
INFO - 04/15/25 16:45:48 - 0:14:11 - Epoch 3172: train_loss=5.959411144256592
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3173: train_loss=5.960251331329346
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3174: train_loss=5.959519863128662
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3175: train_loss=5.960335731506348
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3176: train_loss=5.960737228393555
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3177: train_loss=5.958975791931152
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3178: train_loss=5.958890914916992
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3179: train_loss=5.959726333618164
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3180: train_loss=5.958611011505127
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3181: train_loss=5.960840702056885
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3182: train_loss=5.9613938331604
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3183: train_loss=5.959141731262207
INFO - 04/15/25 16:45:48 - 0:14:12 - Epoch 3184: train_loss=5.959760665893555
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3185: train_loss=5.959893703460693
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3186: train_loss=5.959798812866211
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3187: train_loss=5.960397720336914
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3188: train_loss=5.959733963012695
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3189: train_loss=5.960242748260498
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3190: train_loss=5.959517955780029
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3191: train_loss=5.960804462432861
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3192: train_loss=5.960063934326172
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3193: train_loss=5.960422992706299
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3194: train_loss=5.960409164428711
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3195: train_loss=5.959832668304443
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3196: train_loss=5.959506034851074
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3197: train_loss=5.9608845710754395
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3198: train_loss=5.960916519165039
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3199: train_loss=5.959516525268555
INFO - 04/15/25 16:45:49 - 0:14:12 - Epoch 3200: train_loss=5.959228515625
INFO - 04/15/25 16:45:49 - 0:14:12 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:49 - 0:14:13 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:45:49 - 0:14:13 - Epoch 3200: ACC: 0.0, NMI: 0.31809059785668, F1: 0.0, ARI: 0.0920379124888864
INFO - 04/15/25 16:45:49 - 0:14:13 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:49 - 0:14:13 - Epoch 3201: train_loss=5.9603705406188965
INFO - 04/15/25 16:45:49 - 0:14:13 - Epoch 3202: train_loss=5.959895610809326
INFO - 04/15/25 16:45:49 - 0:14:13 - Epoch 3203: train_loss=5.959815979003906
INFO - 04/15/25 16:45:49 - 0:14:13 - Epoch 3204: train_loss=5.959668159484863
INFO - 04/15/25 16:45:49 - 0:14:13 - Epoch 3205: train_loss=5.959472179412842
INFO - 04/15/25 16:45:49 - 0:14:13 - Epoch 3206: train_loss=5.9594879150390625
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3207: train_loss=5.9600090980529785
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3208: train_loss=5.960092544555664
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3209: train_loss=5.9594268798828125
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3210: train_loss=5.959415435791016
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3211: train_loss=5.95968770980835
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3212: train_loss=5.959102630615234
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3213: train_loss=5.959792613983154
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3214: train_loss=5.959688186645508
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3215: train_loss=5.958804130554199
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3216: train_loss=5.958243370056152
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3217: train_loss=5.960531234741211
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3218: train_loss=5.960028648376465
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3219: train_loss=5.958062171936035
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3220: train_loss=5.958152770996094
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3221: train_loss=5.959291934967041
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3222: train_loss=5.958914756774902
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3223: train_loss=5.9590864181518555
INFO - 04/15/25 16:45:50 - 0:14:13 - Epoch 3224: train_loss=5.9605302810668945
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3225: train_loss=5.961386680603027
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3226: train_loss=5.964443683624268
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3227: train_loss=5.961097717285156
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3228: train_loss=5.965176582336426
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3229: train_loss=5.96402645111084
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3230: train_loss=5.962925910949707
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3231: train_loss=5.962388038635254
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3232: train_loss=5.962360382080078
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3233: train_loss=5.961025238037109
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3234: train_loss=5.960428714752197
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3235: train_loss=5.960554599761963
INFO - 04/15/25 16:45:50 - 0:14:14 - Epoch 3236: train_loss=5.959469318389893
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3237: train_loss=5.960751533508301
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3238: train_loss=5.960017681121826
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3239: train_loss=5.960687637329102
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3240: train_loss=5.960268020629883
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3241: train_loss=5.959714889526367
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3242: train_loss=5.9599480628967285
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3243: train_loss=5.960282802581787
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3244: train_loss=5.9590840339660645
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3245: train_loss=5.959830284118652
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3246: train_loss=5.959211349487305
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3247: train_loss=5.958913326263428
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3248: train_loss=5.9585137367248535
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3249: train_loss=5.959001064300537
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3250: train_loss=5.958440780639648
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3251: train_loss=5.959658622741699
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3252: train_loss=5.958686828613281
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3253: train_loss=5.959348201751709
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3254: train_loss=5.959265232086182
INFO - 04/15/25 16:45:51 - 0:14:14 - Epoch 3255: train_loss=5.959068775177002
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3256: train_loss=5.958935260772705
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3257: train_loss=5.958519458770752
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3258: train_loss=5.958327293395996
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3259: train_loss=6.021645545959473
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3260: train_loss=6.126101016998291
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3261: train_loss=6.216644763946533
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3262: train_loss=6.118484020233154
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3263: train_loss=6.181784629821777
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3264: train_loss=6.255578517913818
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3265: train_loss=6.415811538696289
INFO - 04/15/25 16:45:51 - 0:14:15 - Epoch 3266: train_loss=6.574192523956299
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3267: train_loss=6.840995788574219
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3268: train_loss=6.91745662689209
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3269: train_loss=6.957655906677246
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3270: train_loss=6.9342851638793945
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3271: train_loss=6.901009559631348
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3272: train_loss=6.872337341308594
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3273: train_loss=6.835171222686768
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3274: train_loss=6.8749260902404785
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3275: train_loss=6.81220817565918
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3276: train_loss=6.758437156677246
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3277: train_loss=6.73151159286499
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3278: train_loss=6.731080532073975
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3279: train_loss=6.758095741271973
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3280: train_loss=6.673813819885254
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3281: train_loss=6.6673688888549805
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3282: train_loss=6.671896457672119
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3283: train_loss=6.654257774353027
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3284: train_loss=6.652775764465332
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3285: train_loss=6.64763879776001
INFO - 04/15/25 16:45:52 - 0:14:15 - Epoch 3286: train_loss=6.636648654937744
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3287: train_loss=6.629770755767822
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3288: train_loss=6.6355791091918945
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3289: train_loss=6.644977569580078
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3290: train_loss=6.730916500091553
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3291: train_loss=6.764883041381836
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3292: train_loss=6.770064830780029
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3293: train_loss=6.738719940185547
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3294: train_loss=6.7318196296691895
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3295: train_loss=6.772909641265869
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3296: train_loss=6.744616985321045
INFO - 04/15/25 16:45:52 - 0:14:16 - Epoch 3297: train_loss=6.797680854797363
INFO - 04/15/25 16:45:53 - 0:14:16 - Epoch 3298: train_loss=6.811216354370117
INFO - 04/15/25 16:45:53 - 0:14:16 - Epoch 3299: train_loss=6.786166667938232
INFO - 04/15/25 16:45:53 - 0:14:16 - Epoch 3300: train_loss=6.7690043449401855
INFO - 04/15/25 16:45:53 - 0:14:16 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:53 - 0:14:16 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:45:53 - 0:14:16 - ------------------Saving best model-------------------
INFO - 04/15/25 16:45:53 - 0:14:16 - Epoch 3300: ACC: 0.0, NMI: 0.5114280661123772, F1: 0.0, ARI: 0.3069589376035292
INFO - 04/15/25 16:45:53 - 0:14:16 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:53 - 0:14:16 - Epoch 3301: train_loss=6.771559715270996
INFO - 04/15/25 16:45:53 - 0:14:16 - Epoch 3302: train_loss=6.7581610679626465
INFO - 04/15/25 16:45:53 - 0:14:16 - Epoch 3303: train_loss=6.7522711753845215
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3304: train_loss=6.7479047775268555
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3305: train_loss=6.744923114776611
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3306: train_loss=6.745174884796143
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3307: train_loss=6.742730140686035
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3308: train_loss=6.740556240081787
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3309: train_loss=6.739711761474609
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3310: train_loss=6.740233898162842
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3311: train_loss=6.739799499511719
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3312: train_loss=6.737766265869141
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3313: train_loss=6.73583984375
INFO - 04/15/25 16:45:53 - 0:14:17 - Epoch 3314: train_loss=6.734121322631836
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3315: train_loss=6.730590343475342
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3316: train_loss=6.727175235748291
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3317: train_loss=6.728932857513428
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3318: train_loss=6.729391098022461
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3319: train_loss=6.728056907653809
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3320: train_loss=6.726787567138672
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3321: train_loss=6.724960803985596
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3322: train_loss=6.723494052886963
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3323: train_loss=6.724542140960693
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3324: train_loss=6.723929405212402
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3325: train_loss=6.723887920379639
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3326: train_loss=6.723419189453125
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3327: train_loss=6.72194242477417
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3328: train_loss=6.721436500549316
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3329: train_loss=6.720542907714844
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3330: train_loss=6.72058629989624
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3331: train_loss=6.71986198425293
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3332: train_loss=6.719820976257324
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3333: train_loss=6.718968868255615
INFO - 04/15/25 16:45:54 - 0:14:17 - Epoch 3334: train_loss=6.718304634094238
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3335: train_loss=6.718415260314941
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3336: train_loss=6.718271255493164
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3337: train_loss=6.717467308044434
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3338: train_loss=6.717006683349609
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3339: train_loss=6.718228816986084
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3340: train_loss=6.71771764755249
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3341: train_loss=6.716067790985107
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3342: train_loss=6.718374252319336
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3343: train_loss=6.7168073654174805
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3344: train_loss=6.716652870178223
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3345: train_loss=6.715448379516602
INFO - 04/15/25 16:45:54 - 0:14:18 - Epoch 3346: train_loss=6.71455192565918
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3347: train_loss=6.714702129364014
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3348: train_loss=6.714143753051758
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3349: train_loss=6.714438438415527
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3350: train_loss=6.713868618011475
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3351: train_loss=6.713728427886963
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3352: train_loss=6.713133811950684
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3353: train_loss=6.71296501159668
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3354: train_loss=6.712213039398193
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3355: train_loss=6.7133355140686035
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3356: train_loss=6.712409496307373
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3357: train_loss=6.7125115394592285
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3358: train_loss=6.7126851081848145
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3359: train_loss=6.711559295654297
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3360: train_loss=6.713972568511963
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3361: train_loss=6.712172508239746
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3362: train_loss=6.713890552520752
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3363: train_loss=6.713416576385498
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3364: train_loss=6.7121100425720215
INFO - 04/15/25 16:45:55 - 0:14:18 - Epoch 3365: train_loss=6.71197509765625
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3366: train_loss=6.711801052093506
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3367: train_loss=6.711409091949463
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3368: train_loss=6.711181640625
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3369: train_loss=6.710667610168457
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3370: train_loss=6.711420059204102
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3371: train_loss=6.710346221923828
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3372: train_loss=6.71147346496582
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3373: train_loss=6.710456848144531
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3374: train_loss=6.711179733276367
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3375: train_loss=6.710683345794678
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3376: train_loss=6.709733963012695
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3377: train_loss=6.709473133087158
INFO - 04/15/25 16:45:55 - 0:14:19 - Epoch 3378: train_loss=6.709366321563721
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3379: train_loss=6.7085795402526855
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3380: train_loss=6.709602355957031
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3381: train_loss=6.709017753601074
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3382: train_loss=6.707863807678223
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3383: train_loss=6.707144737243652
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3384: train_loss=6.708313941955566
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3385: train_loss=6.7075419425964355
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3386: train_loss=6.706299304962158
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3387: train_loss=6.707213878631592
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3388: train_loss=6.704195976257324
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3389: train_loss=6.714354991912842
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3390: train_loss=6.713376522064209
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3391: train_loss=6.705156326293945
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3392: train_loss=6.70701789855957
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3393: train_loss=6.705216884613037
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3394: train_loss=6.706268787384033
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3395: train_loss=6.70342493057251
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3396: train_loss=6.702702045440674
INFO - 04/15/25 16:45:56 - 0:14:19 - Epoch 3397: train_loss=6.6992058753967285
INFO - 04/15/25 16:45:56 - 0:14:20 - Epoch 3398: train_loss=6.6993408203125
INFO - 04/15/25 16:45:56 - 0:14:20 - Epoch 3399: train_loss=6.698393821716309
INFO - 04/15/25 16:45:56 - 0:14:20 - Epoch 3400: train_loss=6.6963725090026855
INFO - 04/15/25 16:45:56 - 0:14:20 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:45:56 - 0:14:20 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:45:56 - 0:14:20 - Epoch 3400: ACC: 0.0, NMI: 0.4796177008096862, F1: 0.0, ARI: 0.2958746239231945
INFO - 04/15/25 16:45:56 - 0:14:20 - -------------------------------------------------------------------------
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3401: train_loss=6.697451591491699
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3402: train_loss=6.6952667236328125
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3403: train_loss=6.692471027374268
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3404: train_loss=6.692446708679199
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3405: train_loss=6.692135810852051
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3406: train_loss=6.691539764404297
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3407: train_loss=6.691233158111572
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3408: train_loss=6.690767288208008
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3409: train_loss=6.690826892852783
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3410: train_loss=6.690404891967773
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3411: train_loss=6.690079689025879
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3412: train_loss=6.689880847930908
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3413: train_loss=6.690726280212402
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3414: train_loss=6.690508842468262
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3415: train_loss=6.689859867095947
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3416: train_loss=6.689205169677734
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3417: train_loss=6.689233303070068
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3418: train_loss=6.689126968383789
INFO - 04/15/25 16:45:57 - 0:14:20 - Epoch 3419: train_loss=6.688713073730469
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3420: train_loss=6.688111782073975
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3421: train_loss=6.688851356506348
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3422: train_loss=6.6884026527404785
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3423: train_loss=6.687922954559326
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3424: train_loss=6.687848091125488
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3425: train_loss=6.688391208648682
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3426: train_loss=6.687727451324463
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3427: train_loss=6.687966346740723
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3428: train_loss=6.688272953033447
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3429: train_loss=6.6871466636657715
INFO - 04/15/25 16:45:57 - 0:14:21 - Epoch 3430: train_loss=6.689095497131348
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3431: train_loss=6.68850040435791
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3432: train_loss=6.688131332397461
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3433: train_loss=6.687668323516846
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3434: train_loss=6.688328742980957
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3435: train_loss=6.687439918518066
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3436: train_loss=6.688131809234619
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3437: train_loss=6.688258171081543
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3438: train_loss=6.68631649017334
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3439: train_loss=6.686420440673828
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3440: train_loss=6.686666965484619
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3441: train_loss=6.685619354248047
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3442: train_loss=6.688172817230225
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3443: train_loss=6.688110828399658
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3444: train_loss=6.6857829093933105
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3445: train_loss=6.686470985412598
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3446: train_loss=6.686626434326172
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3447: train_loss=6.686408042907715
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3448: train_loss=6.685751438140869
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3449: train_loss=6.686473369598389
INFO - 04/15/25 16:45:58 - 0:14:21 - Epoch 3450: train_loss=6.685647010803223
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3451: train_loss=6.686253070831299
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3452: train_loss=6.685357570648193
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3453: train_loss=6.68547248840332
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3454: train_loss=6.6863508224487305
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3455: train_loss=6.68511438369751
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3456: train_loss=6.687129020690918
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3457: train_loss=6.6867170333862305
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3458: train_loss=6.685555934906006
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3459: train_loss=6.685362339019775
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3460: train_loss=6.685644149780273
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3461: train_loss=6.685056209564209
INFO - 04/15/25 16:45:58 - 0:14:22 - Epoch 3462: train_loss=6.685107707977295
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3463: train_loss=6.684614658355713
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3464: train_loss=6.684746265411377
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3465: train_loss=6.684041500091553
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3466: train_loss=6.6846537590026855
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3467: train_loss=6.684072494506836
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3468: train_loss=6.684039115905762
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3469: train_loss=6.683707237243652
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3470: train_loss=6.683072566986084
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3471: train_loss=6.682599067687988
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3472: train_loss=6.684158802032471
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3473: train_loss=6.683529376983643
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3474: train_loss=6.683775901794434
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3475: train_loss=6.68369197845459
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3476: train_loss=6.68274450302124
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3477: train_loss=6.682258605957031
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3478: train_loss=6.683847904205322
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3479: train_loss=6.683349132537842
INFO - 04/15/25 16:45:59 - 0:14:22 - Epoch 3480: train_loss=6.682340145111084
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3481: train_loss=6.682355880737305
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3482: train_loss=6.682727336883545
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3483: train_loss=6.682260513305664
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3484: train_loss=6.682665824890137
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3485: train_loss=6.682476043701172
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3486: train_loss=6.68186616897583
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3487: train_loss=6.681339263916016
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3488: train_loss=6.682699203491211
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3489: train_loss=6.6823201179504395
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3490: train_loss=6.68120813369751
INFO - 04/15/25 16:45:59 - 0:14:23 - Epoch 3491: train_loss=6.680993556976318
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3492: train_loss=6.682343006134033
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3493: train_loss=6.6820478439331055
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3494: train_loss=6.681159973144531
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3495: train_loss=6.680901527404785
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3496: train_loss=6.681926727294922
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3497: train_loss=6.6815185546875
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3498: train_loss=6.680966377258301
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3499: train_loss=6.680547714233398
INFO - 04/15/25 16:46:00 - 0:14:23 - Epoch 3500: train_loss=6.681316375732422
INFO - 04/15/25 16:46:00 - 0:14:23 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:00 - 0:14:23 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:46:01 - 0:14:24 - ------------------Saving best model-------------------
INFO - 04/15/25 16:46:01 - 0:14:25 - Epoch 3500: ACC: 0.0, NMI: 0.5118076681041146, F1: 0.0, ARI: 0.3350512234039584
INFO - 04/15/25 16:46:01 - 0:14:25 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:01 - 0:14:25 - Epoch 3501: train_loss=6.68109130859375
INFO - 04/15/25 16:46:01 - 0:14:25 - Epoch 3502: train_loss=6.680894374847412
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3503: train_loss=6.680196285247803
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3504: train_loss=6.6807427406311035
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3505: train_loss=6.680363655090332
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3506: train_loss=6.680747985839844
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3507: train_loss=6.680509567260742
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3508: train_loss=6.680010795593262
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3509: train_loss=6.67963981628418
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3510: train_loss=6.6803460121154785
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3511: train_loss=6.679788589477539
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3512: train_loss=6.679763317108154
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3513: train_loss=6.67946720123291
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3514: train_loss=6.67973518371582
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3515: train_loss=6.67917537689209
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3516: train_loss=6.680091381072998
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3517: train_loss=6.679997444152832
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3518: train_loss=6.678884506225586
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3519: train_loss=6.678467750549316
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3520: train_loss=6.680277347564697
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3521: train_loss=6.679899215698242
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3522: train_loss=6.678329944610596
INFO - 04/15/25 16:46:02 - 0:14:25 - Epoch 3523: train_loss=6.67901611328125
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3524: train_loss=6.679894924163818
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3525: train_loss=6.679837703704834
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3526: train_loss=6.678446292877197
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3527: train_loss=6.678521633148193
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3528: train_loss=6.679350852966309
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3529: train_loss=6.678686618804932
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3530: train_loss=6.679776191711426
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3531: train_loss=6.679530143737793
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3532: train_loss=6.678319931030273
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3533: train_loss=6.678012847900391
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3534: train_loss=6.679407596588135
INFO - 04/15/25 16:46:02 - 0:14:26 - Epoch 3535: train_loss=6.678437232971191
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3536: train_loss=6.678244590759277
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3537: train_loss=6.678133964538574
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3538: train_loss=6.677919864654541
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3539: train_loss=6.677850246429443
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3540: train_loss=6.678438663482666
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3541: train_loss=6.678220272064209
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3542: train_loss=6.677649021148682
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3543: train_loss=6.677440643310547
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3544: train_loss=6.678048133850098
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3545: train_loss=6.677675247192383
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3546: train_loss=6.67784309387207
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3547: train_loss=6.677523612976074
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3548: train_loss=6.677346229553223
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3549: train_loss=6.677067279815674
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3550: train_loss=6.677465915679932
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3551: train_loss=6.677137851715088
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3552: train_loss=6.6772613525390625
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3553: train_loss=6.676919937133789
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3554: train_loss=6.67722225189209
INFO - 04/15/25 16:46:03 - 0:14:26 - Epoch 3555: train_loss=6.676867961883545
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3556: train_loss=6.6769585609436035
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3557: train_loss=6.677007675170898
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3558: train_loss=6.6766815185546875
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3559: train_loss=6.676623821258545
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3560: train_loss=6.677089691162109
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3561: train_loss=6.677051067352295
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3562: train_loss=6.676440238952637
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3563: train_loss=6.676123142242432
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3564: train_loss=6.677402973175049
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3565: train_loss=6.677248477935791
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3566: train_loss=6.675829887390137
INFO - 04/15/25 16:46:03 - 0:14:27 - Epoch 3567: train_loss=6.67551326751709
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3568: train_loss=6.67756462097168
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3569: train_loss=6.677106857299805
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3570: train_loss=6.675477504730225
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3571: train_loss=6.675335884094238
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3572: train_loss=6.677098274230957
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3573: train_loss=6.676530838012695
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3574: train_loss=6.675851821899414
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3575: train_loss=6.675781726837158
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3576: train_loss=6.676720142364502
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3577: train_loss=6.676604270935059
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3578: train_loss=6.6750569343566895
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3579: train_loss=6.6746110916137695
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3580: train_loss=6.6766743659973145
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3581: train_loss=6.675983428955078
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3582: train_loss=6.675598621368408
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3583: train_loss=6.675259113311768
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3584: train_loss=6.675626277923584
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3585: train_loss=6.675215244293213
INFO - 04/15/25 16:46:04 - 0:14:27 - Epoch 3586: train_loss=6.675684452056885
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3587: train_loss=6.675356388092041
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3588: train_loss=6.675514221191406
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3589: train_loss=6.675299167633057
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3590: train_loss=6.675182342529297
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3591: train_loss=6.6748576164245605
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3592: train_loss=6.67571496963501
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3593: train_loss=6.675582408905029
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3594: train_loss=6.674481391906738
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3595: train_loss=6.674076080322266
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3596: train_loss=6.675808906555176
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3597: train_loss=6.6756367683410645
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3598: train_loss=6.674662113189697
INFO - 04/15/25 16:46:04 - 0:14:28 - Epoch 3599: train_loss=6.674417018890381
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3600: train_loss=6.675532817840576
INFO - 04/15/25 16:46:05 - 0:14:28 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:05 - 0:14:28 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3600: ACC: 0.0, NMI: 0.4906136996153273, F1: 0.0, ARI: 0.3003582171646016
INFO - 04/15/25 16:46:05 - 0:14:28 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3601: train_loss=6.6752753257751465
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3602: train_loss=6.674797058105469
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3603: train_loss=6.674438953399658
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3604: train_loss=6.675553321838379
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3605: train_loss=6.675308704376221
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3606: train_loss=6.6741180419921875
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3607: train_loss=6.673490524291992
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3608: train_loss=6.675759792327881
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3609: train_loss=6.675680160522461
INFO - 04/15/25 16:46:05 - 0:14:28 - Epoch 3610: train_loss=6.672983646392822
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3611: train_loss=6.673676490783691
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3612: train_loss=6.673731327056885
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3613: train_loss=6.67292594909668
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3614: train_loss=6.674442291259766
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3615: train_loss=6.67319393157959
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3616: train_loss=6.674933910369873
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3617: train_loss=6.674420356750488
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3618: train_loss=6.674056053161621
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3619: train_loss=6.674824237823486
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3620: train_loss=6.674208641052246
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3621: train_loss=6.674127578735352
INFO - 04/15/25 16:46:05 - 0:14:29 - Epoch 3622: train_loss=6.674617290496826
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3623: train_loss=6.674430847167969
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3624: train_loss=6.6747727394104
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3625: train_loss=6.674631595611572
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3626: train_loss=6.6744842529296875
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3627: train_loss=6.674230098724365
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3628: train_loss=6.674858570098877
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3629: train_loss=6.674509525299072
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3630: train_loss=6.674444198608398
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3631: train_loss=6.673920631408691
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3632: train_loss=6.674598693847656
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3633: train_loss=6.674245834350586
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3634: train_loss=6.673724174499512
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3635: train_loss=6.673263072967529
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3636: train_loss=6.674187183380127
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3637: train_loss=6.673954010009766
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3638: train_loss=6.6728668212890625
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3639: train_loss=6.672942161560059
INFO - 04/15/25 16:46:06 - 0:14:29 - Epoch 3640: train_loss=6.673927307128906
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3641: train_loss=6.673872947692871
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3642: train_loss=6.672850608825684
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3643: train_loss=6.672796249389648
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3644: train_loss=6.673792839050293
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3645: train_loss=6.673337459564209
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3646: train_loss=6.67356014251709
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3647: train_loss=6.673223495483398
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3648: train_loss=6.67373514175415
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3649: train_loss=6.673116207122803
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3650: train_loss=6.673020362854004
INFO - 04/15/25 16:46:06 - 0:14:30 - Epoch 3651: train_loss=6.672764778137207
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3652: train_loss=6.673786640167236
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3653: train_loss=6.673453330993652
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3654: train_loss=6.672669887542725
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3655: train_loss=6.6728034019470215
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3656: train_loss=6.673681259155273
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3657: train_loss=6.673376083374023
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3658: train_loss=6.672674655914307
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3659: train_loss=6.672303676605225
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3660: train_loss=6.673464298248291
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3661: train_loss=6.673205375671387
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3662: train_loss=6.672625541687012
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3663: train_loss=6.672056674957275
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3664: train_loss=6.673748970031738
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3665: train_loss=6.673642158508301
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3666: train_loss=6.672908782958984
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3667: train_loss=6.672832012176514
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3668: train_loss=6.673773765563965
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3669: train_loss=6.673475742340088
INFO - 04/15/25 16:46:07 - 0:14:30 - Epoch 3670: train_loss=6.6732964515686035
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3671: train_loss=6.673192977905273
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3672: train_loss=6.673125743865967
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3673: train_loss=6.672685623168945
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3674: train_loss=6.673398494720459
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3675: train_loss=6.673064708709717
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3676: train_loss=6.672537803649902
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3677: train_loss=6.672179222106934
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3678: train_loss=6.67286491394043
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3679: train_loss=6.672484397888184
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3680: train_loss=6.671865940093994
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3681: train_loss=6.671871185302734
INFO - 04/15/25 16:46:07 - 0:14:31 - Epoch 3682: train_loss=6.672201633453369
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3683: train_loss=6.671790599822998
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3684: train_loss=6.672057151794434
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3685: train_loss=6.671806335449219
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3686: train_loss=6.67179012298584
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3687: train_loss=6.671567916870117
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3688: train_loss=6.67186164855957
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3689: train_loss=6.671449661254883
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3690: train_loss=6.67177677154541
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3691: train_loss=6.671539306640625
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3692: train_loss=6.671411514282227
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3693: train_loss=6.671172142028809
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3694: train_loss=6.6715168952941895
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3695: train_loss=6.671295642852783
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3696: train_loss=6.671572208404541
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3697: train_loss=6.671319007873535
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3698: train_loss=6.6711344718933105
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3699: train_loss=6.6709465980529785
INFO - 04/15/25 16:46:08 - 0:14:31 - Epoch 3700: train_loss=6.671926975250244
INFO - 04/15/25 16:46:08 - 0:14:31 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:08 - 0:14:32 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:46:08 - 0:14:32 - Epoch 3700: ACC: 0.0, NMI: 0.507079573046315, F1: 0.0, ARI: 0.31319283232080314
INFO - 04/15/25 16:46:08 - 0:14:32 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:08 - 0:14:32 - Epoch 3701: train_loss=6.6719183921813965
INFO - 04/15/25 16:46:08 - 0:14:32 - Epoch 3702: train_loss=6.670229911804199
INFO - 04/15/25 16:46:08 - 0:14:32 - Epoch 3703: train_loss=6.669657230377197
INFO - 04/15/25 16:46:08 - 0:14:32 - Epoch 3704: train_loss=6.672874450683594
INFO - 04/15/25 16:46:08 - 0:14:32 - Epoch 3705: train_loss=6.67277717590332
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3706: train_loss=6.669775009155273
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3707: train_loss=6.672731399536133
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3708: train_loss=6.67278528213501
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3709: train_loss=6.6707282066345215
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3710: train_loss=6.671780586242676
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3711: train_loss=6.671886444091797
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3712: train_loss=6.67152214050293
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3713: train_loss=6.670395374298096
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3714: train_loss=6.671803951263428
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3715: train_loss=6.671720027923584
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3716: train_loss=6.670285224914551
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3717: train_loss=6.67067813873291
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3718: train_loss=6.670653820037842
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3719: train_loss=6.6705241203308105
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3720: train_loss=6.671329498291016
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3721: train_loss=6.671148300170898
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3722: train_loss=6.671011447906494
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3723: train_loss=6.670623302459717
INFO - 04/15/25 16:46:09 - 0:14:32 - Epoch 3724: train_loss=6.6718363761901855
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3725: train_loss=6.670175075531006
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3726: train_loss=6.673020839691162
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3727: train_loss=6.672783374786377
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3728: train_loss=6.670134544372559
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3729: train_loss=6.672151565551758
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3730: train_loss=6.6716389656066895
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3731: train_loss=6.670981407165527
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3732: train_loss=6.6705708503723145
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3733: train_loss=6.671063423156738
INFO - 04/15/25 16:46:09 - 0:14:33 - Epoch 3734: train_loss=6.670292854309082
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3735: train_loss=6.671298503875732
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3736: train_loss=6.671577453613281
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3737: train_loss=6.670088768005371
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3738: train_loss=6.6713643074035645
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3739: train_loss=6.6717848777771
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3740: train_loss=6.670923709869385
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3741: train_loss=6.671098709106445
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3742: train_loss=6.671671390533447
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3743: train_loss=6.669878959655762
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3744: train_loss=6.671847343444824
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3745: train_loss=6.671951770782471
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3746: train_loss=6.669942855834961
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3747: train_loss=6.672448635101318
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3748: train_loss=6.67357873916626
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3749: train_loss=6.672255992889404
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3750: train_loss=6.669642448425293
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3751: train_loss=6.671365737915039
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3752: train_loss=6.671292304992676
INFO - 04/15/25 16:46:10 - 0:14:33 - Epoch 3753: train_loss=6.669832706451416
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3754: train_loss=6.670591831207275
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3755: train_loss=6.670507431030273
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3756: train_loss=6.669322490692139
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3757: train_loss=6.669859409332275
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3758: train_loss=6.669488906860352
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3759: train_loss=6.6692681312561035
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3760: train_loss=6.66953706741333
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3761: train_loss=6.669064521789551
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3762: train_loss=6.669095993041992
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3763: train_loss=6.668989181518555
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3764: train_loss=6.669129371643066
INFO - 04/15/25 16:46:10 - 0:14:34 - Epoch 3765: train_loss=6.66863489151001
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3766: train_loss=6.6690168380737305
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3767: train_loss=6.668630599975586
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3768: train_loss=6.668827056884766
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3769: train_loss=6.668586254119873
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3770: train_loss=6.669316291809082
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3771: train_loss=6.668365001678467
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3772: train_loss=6.6689276695251465
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3773: train_loss=6.669112682342529
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3774: train_loss=6.669195652008057
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3775: train_loss=6.669183731079102
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3776: train_loss=6.669425964355469
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3777: train_loss=6.669837474822998
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3778: train_loss=6.66923713684082
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3779: train_loss=6.6700334548950195
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3780: train_loss=6.669806957244873
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3781: train_loss=6.669696807861328
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3782: train_loss=6.669869422912598
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3783: train_loss=6.669366359710693
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3784: train_loss=6.669338703155518
INFO - 04/15/25 16:46:11 - 0:14:34 - Epoch 3785: train_loss=6.669252395629883
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3786: train_loss=6.6692962646484375
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3787: train_loss=6.6693806648254395
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3788: train_loss=6.6694231033325195
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3789: train_loss=6.66903829574585
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3790: train_loss=6.6690263748168945
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3791: train_loss=6.66863489151001
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3792: train_loss=6.669007301330566
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3793: train_loss=6.668734550476074
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3794: train_loss=6.668828010559082
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3795: train_loss=6.668660640716553
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3796: train_loss=6.668544292449951
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3797: train_loss=6.668300151824951
INFO - 04/15/25 16:46:11 - 0:14:35 - Epoch 3798: train_loss=6.667883396148682
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3799: train_loss=6.668709754943848
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3800: train_loss=6.668430805206299
INFO - 04/15/25 16:46:12 - 0:14:35 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:12 - 0:14:35 - Decoding cost time:  0.117 s
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3800: ACC: 0.0, NMI: 0.4830113884674506, F1: 0.0, ARI: 0.3037252550008034
INFO - 04/15/25 16:46:12 - 0:14:35 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3801: train_loss=6.66793155670166
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3802: train_loss=6.668989181518555
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3803: train_loss=6.668271064758301
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3804: train_loss=6.6688642501831055
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3805: train_loss=6.668186664581299
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3806: train_loss=6.669143199920654
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3807: train_loss=6.668037414550781
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3808: train_loss=6.670285701751709
INFO - 04/15/25 16:46:12 - 0:14:35 - Epoch 3809: train_loss=6.670351982116699
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3810: train_loss=6.667720317840576
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3811: train_loss=6.669503688812256
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3812: train_loss=6.669182300567627
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3813: train_loss=6.668729305267334
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3814: train_loss=6.6691389083862305
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3815: train_loss=6.669261455535889
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3816: train_loss=6.669530868530273
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3817: train_loss=6.668327808380127
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3818: train_loss=6.668527126312256
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3819: train_loss=6.669149398803711
INFO - 04/15/25 16:46:12 - 0:14:36 - Epoch 3820: train_loss=6.668519973754883
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3821: train_loss=6.669572830200195
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3822: train_loss=6.669501304626465
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3823: train_loss=6.6690826416015625
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3824: train_loss=6.668619632720947
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3825: train_loss=6.669676780700684
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3826: train_loss=6.669384479522705
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3827: train_loss=6.668122291564941
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3828: train_loss=6.6679253578186035
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3829: train_loss=6.669112682342529
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3830: train_loss=6.668099403381348
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3831: train_loss=6.669365406036377
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3832: train_loss=6.6694769859313965
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3833: train_loss=6.666966915130615
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3834: train_loss=6.667943000793457
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3835: train_loss=6.67043399810791
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3836: train_loss=6.6698503494262695
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3837: train_loss=6.670818328857422
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3838: train_loss=6.672431468963623
INFO - 04/15/25 16:46:13 - 0:14:36 - Epoch 3839: train_loss=6.669361591339111
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3840: train_loss=6.701486587524414
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3841: train_loss=6.673160552978516
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3842: train_loss=6.718800067901611
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3843: train_loss=6.71154260635376
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3844: train_loss=6.673892974853516
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3845: train_loss=6.674435138702393
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3846: train_loss=6.694483757019043
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3847: train_loss=6.6911797523498535
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3848: train_loss=6.73291015625
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3849: train_loss=6.76641845703125
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3850: train_loss=6.776832103729248
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3851: train_loss=6.780307769775391
INFO - 04/15/25 16:46:13 - 0:14:37 - Epoch 3852: train_loss=6.760341644287109
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3853: train_loss=6.76585578918457
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3854: train_loss=6.784976482391357
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3855: train_loss=6.7496137619018555
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3856: train_loss=6.759241104125977
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3857: train_loss=6.834158897399902
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3858: train_loss=6.831906795501709
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3859: train_loss=6.908627510070801
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3860: train_loss=6.868459701538086
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3861: train_loss=6.785536766052246
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3862: train_loss=6.770281791687012
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3863: train_loss=6.793485641479492
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3864: train_loss=6.753688812255859
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3865: train_loss=6.753926753997803
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3866: train_loss=6.7257280349731445
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3867: train_loss=6.741552829742432
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3868: train_loss=6.768154621124268
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3869: train_loss=6.878707408905029
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3870: train_loss=6.837548732757568
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3871: train_loss=6.87214469909668
INFO - 04/15/25 16:46:14 - 0:14:37 - Epoch 3872: train_loss=6.909424304962158
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3873: train_loss=6.87708044052124
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3874: train_loss=6.873581409454346
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3875: train_loss=6.898993492126465
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3876: train_loss=6.876911640167236
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3877: train_loss=6.869128227233887
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3878: train_loss=6.8630290031433105
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3879: train_loss=6.867888927459717
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3880: train_loss=6.852670669555664
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3881: train_loss=6.844634056091309
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3882: train_loss=6.8341546058654785
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3883: train_loss=6.830849647521973
INFO - 04/15/25 16:46:14 - 0:14:38 - Epoch 3884: train_loss=6.836819648742676
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3885: train_loss=6.836651802062988
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3886: train_loss=6.846950054168701
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3887: train_loss=6.855886936187744
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3888: train_loss=6.9188079833984375
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3889: train_loss=7.333310604095459
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3890: train_loss=6.837747573852539
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3891: train_loss=6.934881687164307
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3892: train_loss=7.051838397979736
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3893: train_loss=7.123170852661133
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3894: train_loss=7.121799468994141
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3895: train_loss=7.028223514556885
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3896: train_loss=7.008598327636719
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3897: train_loss=7.029601573944092
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3898: train_loss=7.010134696960449
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3899: train_loss=7.034363269805908
INFO - 04/15/25 16:46:15 - 0:14:38 - Epoch 3900: train_loss=7.030179977416992
INFO - 04/15/25 16:46:15 - 0:14:38 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:15 - 0:14:38 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3900: ACC: 0.0, NMI: 0.4748816245817535, F1: 0.0, ARI: 0.3074297254545567
INFO - 04/15/25 16:46:15 - 0:14:39 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3901: train_loss=7.004703044891357
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3902: train_loss=7.03336238861084
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3903: train_loss=7.019793510437012
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3904: train_loss=7.013308048248291
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3905: train_loss=7.005117416381836
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3906: train_loss=6.9989166259765625
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3907: train_loss=6.994220733642578
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3908: train_loss=6.988805770874023
INFO - 04/15/25 16:46:15 - 0:14:39 - Epoch 3909: train_loss=6.984944820404053
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3910: train_loss=6.980715274810791
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3911: train_loss=6.978071689605713
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3912: train_loss=6.977487087249756
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3913: train_loss=6.9754486083984375
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3914: train_loss=6.972799301147461
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3915: train_loss=6.967353343963623
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3916: train_loss=6.965218544006348
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3917: train_loss=6.967126846313477
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3918: train_loss=6.967941761016846
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3919: train_loss=6.964781284332275
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3920: train_loss=6.961362361907959
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3921: train_loss=6.958964824676514
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3922: train_loss=6.958696365356445
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3923: train_loss=6.958621025085449
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3924: train_loss=6.957866191864014
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3925: train_loss=6.956376552581787
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3926: train_loss=6.953801155090332
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3927: train_loss=6.9527363777160645
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3928: train_loss=6.957610130310059
INFO - 04/15/25 16:46:16 - 0:14:39 - Epoch 3929: train_loss=7.030255317687988
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3930: train_loss=6.962069034576416
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3931: train_loss=6.976187705993652
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3932: train_loss=6.9864068031311035
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3933: train_loss=6.99314022064209
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3934: train_loss=6.992208003997803
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3935: train_loss=6.985682010650635
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3936: train_loss=6.98164701461792
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3937: train_loss=6.979075908660889
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3938: train_loss=6.974573612213135
INFO - 04/15/25 16:46:16 - 0:14:40 - Epoch 3939: train_loss=6.973917007446289
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3940: train_loss=6.9711594581604
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3941: train_loss=6.9633564949035645
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3942: train_loss=6.96121072769165
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3943: train_loss=6.962984561920166
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3944: train_loss=6.963511943817139
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3945: train_loss=6.963040351867676
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3946: train_loss=6.959897041320801
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3947: train_loss=6.95524263381958
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3948: train_loss=6.95754861831665
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3949: train_loss=6.959756851196289
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3950: train_loss=6.95841121673584
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3951: train_loss=6.955199241638184
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3952: train_loss=6.954163074493408
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3953: train_loss=6.952836990356445
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3954: train_loss=6.950488090515137
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3955: train_loss=6.950061321258545
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3956: train_loss=6.948996067047119
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3957: train_loss=6.947422027587891
INFO - 04/15/25 16:46:17 - 0:14:40 - Epoch 3958: train_loss=6.9472856521606445
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3959: train_loss=6.945702075958252
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3960: train_loss=6.945801734924316
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3961: train_loss=6.9456305503845215
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3962: train_loss=6.944605827331543
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3963: train_loss=6.943959712982178
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3964: train_loss=6.944309711456299
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3965: train_loss=6.944494247436523
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3966: train_loss=6.942371368408203
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3967: train_loss=6.943408012390137
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3968: train_loss=6.9431986808776855
INFO - 04/15/25 16:46:17 - 0:14:41 - Epoch 3969: train_loss=6.941930770874023
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3970: train_loss=6.942410469055176
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3971: train_loss=6.9415740966796875
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3972: train_loss=6.941811561584473
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3973: train_loss=6.941252708435059
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3974: train_loss=6.940828800201416
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3975: train_loss=6.940420150756836
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3976: train_loss=6.940201759338379
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3977: train_loss=6.939931869506836
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3978: train_loss=6.9391889572143555
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3979: train_loss=6.9399919509887695
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3980: train_loss=6.93940544128418
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3981: train_loss=6.939113140106201
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3982: train_loss=6.939128875732422
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3983: train_loss=6.938417434692383
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3984: train_loss=6.939234256744385
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3985: train_loss=6.938746929168701
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3986: train_loss=6.938599109649658
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3987: train_loss=6.937851428985596
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3988: train_loss=6.938573837280273
INFO - 04/15/25 16:46:18 - 0:14:41 - Epoch 3989: train_loss=6.9374098777771
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3990: train_loss=6.938798427581787
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3991: train_loss=6.938440322875977
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3992: train_loss=6.936837673187256
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3993: train_loss=6.936881065368652
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3994: train_loss=6.936969757080078
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3995: train_loss=6.93616247177124
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3996: train_loss=6.937436103820801
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3997: train_loss=6.936972618103027
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3998: train_loss=6.936130046844482
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 3999: train_loss=6.935826778411865
INFO - 04/15/25 16:46:18 - 0:14:42 - Epoch 4000: train_loss=6.936012268066406
INFO - 04/15/25 16:46:18 - 0:14:42 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:19 - 0:14:42 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:46:19 - 0:14:42 - ------------------Saving best model-------------------
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4000: ACC: 0.0, NMI: 0.5295897901148221, F1: 0.0, ARI: 0.37137908534073244
INFO - 04/15/25 16:46:23 - 0:14:46 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4001: train_loss=6.935323715209961
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4002: train_loss=6.9362897872924805
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4003: train_loss=6.935927867889404
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4004: train_loss=6.9349284172058105
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4005: train_loss=6.934650421142578
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4006: train_loss=6.935237884521484
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4007: train_loss=6.934814453125
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4008: train_loss=6.934746742248535
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4009: train_loss=6.934159278869629
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4010: train_loss=6.934895038604736
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4011: train_loss=6.93469762802124
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4012: train_loss=6.933282375335693
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4013: train_loss=6.932664394378662
INFO - 04/15/25 16:46:23 - 0:14:46 - Epoch 4014: train_loss=6.935104846954346
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4015: train_loss=6.934861660003662
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4016: train_loss=6.93213415145874
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4017: train_loss=6.932092666625977
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4018: train_loss=6.933765411376953
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4019: train_loss=6.932847023010254
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4020: train_loss=6.9336161613464355
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4021: train_loss=6.933629989624023
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4022: train_loss=6.931590557098389
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4023: train_loss=6.931382656097412
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4024: train_loss=6.9331769943237305
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4025: train_loss=6.932469367980957
INFO - 04/15/25 16:46:23 - 0:14:47 - Epoch 4026: train_loss=6.932161331176758
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4027: train_loss=6.9320902824401855
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4028: train_loss=6.931319236755371
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4029: train_loss=6.930711269378662
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4030: train_loss=6.932642936706543
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4031: train_loss=6.932455062866211
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4032: train_loss=6.930116176605225
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4033: train_loss=6.93000602722168
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4034: train_loss=6.9316725730896
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4035: train_loss=6.930727005004883
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4036: train_loss=6.931349277496338
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4037: train_loss=6.931358814239502
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4038: train_loss=6.929683685302734
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4039: train_loss=6.9293599128723145
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4040: train_loss=6.931004524230957
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4041: train_loss=6.930144309997559
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4042: train_loss=6.930537700653076
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4043: train_loss=6.930728912353516
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4044: train_loss=6.928353786468506
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4045: train_loss=6.928112030029297
INFO - 04/15/25 16:46:24 - 0:14:47 - Epoch 4046: train_loss=6.928474426269531
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4047: train_loss=6.928207874298096
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4048: train_loss=6.928956985473633
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4049: train_loss=6.927804470062256
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4050: train_loss=6.928185939788818
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4051: train_loss=6.927342891693115
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4052: train_loss=6.929289817810059
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4053: train_loss=6.928926944732666
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4054: train_loss=6.928184509277344
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4055: train_loss=6.9279937744140625
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4056: train_loss=6.928115367889404
INFO - 04/15/25 16:46:24 - 0:14:48 - Epoch 4057: train_loss=6.92750358581543
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4058: train_loss=6.92725133895874
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4059: train_loss=6.927646636962891
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4060: train_loss=6.926345348358154
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4061: train_loss=6.92777681350708
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4062: train_loss=6.927502155303955
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4063: train_loss=6.926785469055176
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4064: train_loss=6.927304744720459
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4065: train_loss=6.927136421203613
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4066: train_loss=6.926798343658447
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4067: train_loss=6.9264116287231445
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4068: train_loss=6.926505088806152
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4069: train_loss=6.926412582397461
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4070: train_loss=6.928512096405029
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4071: train_loss=6.935525894165039
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4072: train_loss=6.928017616271973
INFO - 04/15/25 16:46:25 - 0:14:48 - Epoch 4073: train_loss=6.943847179412842
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4074: train_loss=6.929840087890625
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4075: train_loss=6.968513488769531
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4076: train_loss=6.9652814865112305
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4077: train_loss=6.961285591125488
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4078: train_loss=6.956927299499512
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4079: train_loss=6.948732852935791
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4080: train_loss=6.941835403442383
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4081: train_loss=6.94325590133667
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4082: train_loss=6.944132328033447
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4083: train_loss=6.943000793457031
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4084: train_loss=6.940897464752197
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4085: train_loss=6.9390058517456055
INFO - 04/15/25 16:46:25 - 0:14:49 - Epoch 4086: train_loss=6.940837860107422
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4087: train_loss=6.94236946105957
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4088: train_loss=6.940773963928223
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4089: train_loss=6.937817573547363
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4090: train_loss=6.93571138381958
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4091: train_loss=6.936020374298096
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4092: train_loss=6.935872554779053
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4093: train_loss=6.9337477684021
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4094: train_loss=6.932714939117432
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4095: train_loss=6.934648036956787
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4096: train_loss=6.934542179107666
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4097: train_loss=6.932591438293457
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4098: train_loss=6.932264804840088
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4099: train_loss=6.932347774505615
INFO - 04/15/25 16:46:26 - 0:14:49 - Epoch 4100: train_loss=6.931022644042969
INFO - 04/15/25 16:46:26 - 0:14:49 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:26 - 0:14:49 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:46:26 - 0:14:50 - ------------------Saving best model-------------------
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4100: ACC: 0.0, NMI: 0.5342175245449703, F1: 0.0, ARI: 0.37305787484280933
INFO - 04/15/25 16:46:30 - 0:14:53 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4101: train_loss=6.932013511657715
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4102: train_loss=6.932084083557129
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4103: train_loss=6.9300642013549805
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4104: train_loss=6.9309210777282715
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4105: train_loss=6.930955410003662
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4106: train_loss=6.929828643798828
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4107: train_loss=6.930360317230225
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4108: train_loss=6.929394721984863
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4109: train_loss=6.9298176765441895
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4110: train_loss=6.929469585418701
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4111: train_loss=6.929121971130371
INFO - 04/15/25 16:46:30 - 0:14:53 - Epoch 4112: train_loss=6.928927898406982
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4113: train_loss=6.928553581237793
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4114: train_loss=6.928399085998535
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4115: train_loss=6.92842435836792
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4116: train_loss=6.928045749664307
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4117: train_loss=6.928483486175537
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4118: train_loss=6.927642822265625
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4119: train_loss=6.928704261779785
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4120: train_loss=6.927724361419678
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4121: train_loss=6.928650856018066
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4122: train_loss=6.9287943840026855
INFO - 04/15/25 16:46:30 - 0:14:54 - Epoch 4123: train_loss=6.926522254943848
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4124: train_loss=6.927647113800049
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4125: train_loss=6.92682409286499
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4126: train_loss=6.927154064178467
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4127: train_loss=6.926666736602783
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4128: train_loss=6.926360130310059
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4129: train_loss=6.927026271820068
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4130: train_loss=6.926323413848877
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4131: train_loss=6.927197456359863
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4132: train_loss=6.926468372344971
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4133: train_loss=6.92723274230957
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4134: train_loss=6.926784038543701
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4135: train_loss=6.926365375518799
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4136: train_loss=6.926163673400879
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4137: train_loss=6.9262237548828125
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4138: train_loss=6.925963401794434
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4139: train_loss=6.926174163818359
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4140: train_loss=6.925710201263428
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4141: train_loss=6.926285743713379
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4142: train_loss=6.926163673400879
INFO - 04/15/25 16:46:31 - 0:14:54 - Epoch 4143: train_loss=6.925180912017822
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4144: train_loss=6.924912452697754
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4145: train_loss=6.926065921783447
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4146: train_loss=6.925653457641602
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4147: train_loss=6.925201892852783
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4148: train_loss=6.924850940704346
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4149: train_loss=6.9255828857421875
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4150: train_loss=6.925522327423096
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4151: train_loss=6.924656867980957
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4152: train_loss=6.924261093139648
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4153: train_loss=6.9256415367126465
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4154: train_loss=6.9255499839782715
INFO - 04/15/25 16:46:31 - 0:14:55 - Epoch 4155: train_loss=6.923933982849121
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4156: train_loss=6.92399263381958
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4157: train_loss=6.924830913543701
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4158: train_loss=6.924621105194092
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4159: train_loss=6.924886226654053
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4160: train_loss=6.924751281738281
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4161: train_loss=6.923791408538818
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4162: train_loss=6.923442840576172
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4163: train_loss=6.925112724304199
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4164: train_loss=6.924923896789551
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4165: train_loss=6.9232401847839355
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4166: train_loss=6.923062801361084
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4167: train_loss=6.924583435058594
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4168: train_loss=6.923998832702637
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4169: train_loss=6.9240875244140625
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4170: train_loss=6.924193382263184
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4171: train_loss=6.92293119430542
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4172: train_loss=6.922553062438965
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4173: train_loss=6.924299716949463
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4174: train_loss=6.923915386199951
INFO - 04/15/25 16:46:32 - 0:14:55 - Epoch 4175: train_loss=6.923162460327148
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4176: train_loss=6.923112392425537
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4177: train_loss=6.923367023468018
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4178: train_loss=6.922761917114258
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4179: train_loss=6.923757553100586
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4180: train_loss=6.92349910736084
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4181: train_loss=6.922844886779785
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4182: train_loss=6.922823905944824
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4183: train_loss=6.9228973388671875
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4184: train_loss=6.922371864318848
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4185: train_loss=6.923649787902832
INFO - 04/15/25 16:46:32 - 0:14:56 - Epoch 4186: train_loss=6.923691272735596
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4187: train_loss=6.921698570251465
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4188: train_loss=6.921874523162842
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4189: train_loss=6.92270565032959
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4190: train_loss=6.9218902587890625
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4191: train_loss=6.923678398132324
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4192: train_loss=6.9239044189453125
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4193: train_loss=6.920646667480469
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4194: train_loss=6.92326545715332
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4195: train_loss=6.9224677085876465
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4196: train_loss=6.922433376312256
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4197: train_loss=6.922605037689209
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4198: train_loss=6.921554088592529
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4199: train_loss=6.921014785766602
INFO - 04/15/25 16:46:33 - 0:14:56 - Epoch 4200: train_loss=6.9229960441589355
INFO - 04/15/25 16:46:33 - 0:14:56 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:33 - 0:14:56 - Decoding cost time:  0.115 s
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4200: ACC: 0.0, NMI: 0.5075634942470862, F1: 0.0, ARI: 0.337043293928408
INFO - 04/15/25 16:46:33 - 0:14:57 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4201: train_loss=6.9227986335754395
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4202: train_loss=6.921166896820068
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4203: train_loss=6.9211955070495605
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4204: train_loss=6.921989917755127
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4205: train_loss=6.921309471130371
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4206: train_loss=6.922562599182129
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4207: train_loss=6.922755241394043
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4208: train_loss=6.920583724975586
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4209: train_loss=6.921796798706055
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4210: train_loss=6.921100616455078
INFO - 04/15/25 16:46:33 - 0:14:57 - Epoch 4211: train_loss=6.9215521812438965
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4212: train_loss=6.921544075012207
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4213: train_loss=6.920684337615967
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4214: train_loss=6.921191692352295
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4215: train_loss=6.920682907104492
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4216: train_loss=6.9213032722473145
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4217: train_loss=6.920729637145996
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4218: train_loss=6.921453475952148
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4219: train_loss=6.921224594116211
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4220: train_loss=6.920862674713135
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4221: train_loss=6.920700550079346
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4222: train_loss=6.9209818840026855
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4223: train_loss=6.920458793640137
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4224: train_loss=6.921116352081299
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4225: train_loss=6.920877933502197
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4226: train_loss=6.920588970184326
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4227: train_loss=6.920447826385498
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4228: train_loss=6.920586585998535
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4229: train_loss=6.919970989227295
INFO - 04/15/25 16:46:34 - 0:14:57 - Epoch 4230: train_loss=6.9209089279174805
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4231: train_loss=6.920252799987793
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4232: train_loss=6.920928478240967
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4233: train_loss=6.920858860015869
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4234: train_loss=6.919914722442627
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4235: train_loss=6.91992712020874
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4236: train_loss=6.920334339141846
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4237: train_loss=6.919751167297363
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4238: train_loss=6.9207763671875
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4239: train_loss=6.920645236968994
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4240: train_loss=6.919476509094238
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4241: train_loss=6.9195146560668945
INFO - 04/15/25 16:46:34 - 0:14:58 - Epoch 4242: train_loss=6.920063018798828
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4243: train_loss=6.919364929199219
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4244: train_loss=6.920785903930664
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4245: train_loss=6.920680046081543
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4246: train_loss=6.919066429138184
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4247: train_loss=6.9190473556518555
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4248: train_loss=6.919525146484375
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4249: train_loss=6.918692111968994
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4250: train_loss=6.92022180557251
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4251: train_loss=6.920060634613037
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4252: train_loss=6.919065475463867
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4253: train_loss=6.919400691986084
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4254: train_loss=6.9189043045043945
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4255: train_loss=6.9195098876953125
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4256: train_loss=6.918936252593994
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4257: train_loss=6.9197492599487305
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4258: train_loss=6.919588565826416
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4259: train_loss=6.9189581871032715
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4260: train_loss=6.9187493324279785
INFO - 04/15/25 16:46:35 - 0:14:58 - Epoch 4261: train_loss=6.919339179992676
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4262: train_loss=6.9189324378967285
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4263: train_loss=6.919524192810059
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4264: train_loss=6.919349670410156
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4265: train_loss=6.918774604797363
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4266: train_loss=6.918835639953613
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4267: train_loss=6.918853282928467
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4268: train_loss=6.9183502197265625
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4269: train_loss=6.91911506652832
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4270: train_loss=6.91855001449585
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4271: train_loss=6.9192118644714355
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4272: train_loss=6.919096946716309
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4273: train_loss=6.918525218963623
INFO - 04/15/25 16:46:35 - 0:14:59 - Epoch 4274: train_loss=6.91838264465332
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4275: train_loss=6.918625831604004
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4276: train_loss=6.918163299560547
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4277: train_loss=6.918815612792969
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4278: train_loss=6.918219566345215
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4279: train_loss=6.919075012207031
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4280: train_loss=6.918890476226807
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4281: train_loss=6.9180402755737305
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4282: train_loss=6.918022155761719
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4283: train_loss=6.918308258056641
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4284: train_loss=6.91775369644165
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4285: train_loss=6.918889999389648
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4286: train_loss=6.91873025894165
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4287: train_loss=6.917616844177246
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4288: train_loss=6.917600154876709
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4289: train_loss=6.918251037597656
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4290: train_loss=6.917645454406738
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4291: train_loss=6.9186553955078125
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4292: train_loss=6.918492317199707
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4293: train_loss=6.917501926422119
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4294: train_loss=6.917541980743408
INFO - 04/15/25 16:46:36 - 0:14:59 - Epoch 4295: train_loss=6.917830467224121
INFO - 04/15/25 16:46:36 - 0:15:00 - Epoch 4296: train_loss=6.917222023010254
INFO - 04/15/25 16:46:36 - 0:15:00 - Epoch 4297: train_loss=6.918466567993164
INFO - 04/15/25 16:46:36 - 0:15:00 - Epoch 4298: train_loss=6.91806173324585
INFO - 04/15/25 16:46:36 - 0:15:00 - Epoch 4299: train_loss=6.917492866516113
INFO - 04/15/25 16:46:36 - 0:15:00 - Epoch 4300: train_loss=6.917465686798096
INFO - 04/15/25 16:46:36 - 0:15:00 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:36 - 0:15:00 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4300: ACC: 0.0, NMI: 0.48801022792660315, F1: 0.0, ARI: 0.3275346802019479
INFO - 04/15/25 16:46:37 - 0:15:00 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4301: train_loss=6.917634963989258
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4302: train_loss=6.917206287384033
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4303: train_loss=6.918198585510254
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4304: train_loss=6.917789936065674
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4305: train_loss=6.917436122894287
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4306: train_loss=6.917407512664795
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4307: train_loss=6.917389392852783
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4308: train_loss=6.917014122009277
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4309: train_loss=6.917762279510498
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4310: train_loss=6.9174933433532715
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4311: train_loss=6.917320728302002
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4312: train_loss=6.9171881675720215
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4313: train_loss=6.917355537414551
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4314: train_loss=6.916968822479248
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4315: train_loss=6.917405605316162
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4316: train_loss=6.917214393615723
INFO - 04/15/25 16:46:37 - 0:15:00 - Epoch 4317: train_loss=6.9171142578125
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4318: train_loss=6.916984558105469
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4319: train_loss=6.916981220245361
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4320: train_loss=6.916605472564697
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4321: train_loss=6.917516231536865
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4322: train_loss=6.9174723625183105
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4323: train_loss=6.916146755218506
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4324: train_loss=6.915773868560791
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4325: train_loss=6.9180803298950195
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4326: train_loss=6.918035984039307
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4327: train_loss=6.915670871734619
INFO - 04/15/25 16:46:37 - 0:15:01 - Epoch 4328: train_loss=6.917029857635498
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4329: train_loss=6.915781021118164
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4330: train_loss=6.9178361892700195
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4331: train_loss=6.917845726013184
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4332: train_loss=6.915980339050293
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4333: train_loss=6.91731595993042
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4334: train_loss=6.917003154754639
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4335: train_loss=6.916574478149414
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4336: train_loss=6.91646671295166
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4337: train_loss=6.9165120124816895
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4338: train_loss=6.916435718536377
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4339: train_loss=6.916066646575928
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4340: train_loss=6.916120529174805
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4341: train_loss=6.915919303894043
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4342: train_loss=6.916069507598877
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4343: train_loss=6.915628433227539
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4344: train_loss=6.9158430099487305
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4345: train_loss=6.9155707359313965
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4346: train_loss=6.915439605712891
INFO - 04/15/25 16:46:38 - 0:15:01 - Epoch 4347: train_loss=6.916138648986816
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4348: train_loss=6.915495872497559
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4349: train_loss=6.916579723358154
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4350: train_loss=6.916280269622803
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4351: train_loss=6.916036128997803
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4352: train_loss=6.91598653793335
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4353: train_loss=6.915975093841553
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4354: train_loss=6.915844440460205
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4355: train_loss=6.915585041046143
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4356: train_loss=6.915148735046387
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4357: train_loss=6.916441917419434
INFO - 04/15/25 16:46:38 - 0:15:02 - Epoch 4358: train_loss=6.916121482849121
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4359: train_loss=6.915596961975098
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4360: train_loss=6.915653228759766
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4361: train_loss=6.915647029876709
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4362: train_loss=6.915246963500977
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4363: train_loss=6.915963172912598
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4364: train_loss=6.9153852462768555
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4365: train_loss=6.916024684906006
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4366: train_loss=6.916094779968262
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4367: train_loss=6.91495418548584
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4368: train_loss=6.915144443511963
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4369: train_loss=6.915133476257324
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4370: train_loss=6.9146881103515625
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4371: train_loss=6.915674686431885
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4372: train_loss=6.915131568908691
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4373: train_loss=6.915764808654785
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4374: train_loss=6.915858745574951
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4375: train_loss=6.914669990539551
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4376: train_loss=6.915274620056152
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4377: train_loss=6.9147233963012695
INFO - 04/15/25 16:46:39 - 0:15:02 - Epoch 4378: train_loss=6.915431022644043
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4379: train_loss=6.915034294128418
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4380: train_loss=6.915393829345703
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4381: train_loss=6.915469169616699
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4382: train_loss=6.914360046386719
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4383: train_loss=6.914294242858887
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4384: train_loss=6.915041923522949
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4385: train_loss=6.9144463539123535
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4386: train_loss=6.915478229522705
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4387: train_loss=6.915466785430908
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4388: train_loss=6.914167881011963
INFO - 04/15/25 16:46:39 - 0:15:03 - Epoch 4389: train_loss=6.914519309997559
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4390: train_loss=6.914234161376953
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4391: train_loss=6.914085388183594
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4392: train_loss=6.914668083190918
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4393: train_loss=6.913915634155273
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4394: train_loss=6.915512561798096
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4395: train_loss=6.915226936340332
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4396: train_loss=6.914249897003174
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4397: train_loss=6.914190292358398
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4398: train_loss=6.914778232574463
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4399: train_loss=6.914305686950684
INFO - 04/15/25 16:46:40 - 0:15:03 - Epoch 4400: train_loss=6.9149088859558105
INFO - 04/15/25 16:46:40 - 0:15:03 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:40 - 0:15:03 - Decoding cost time:  0.115 s
INFO - 04/15/25 16:46:40 - 0:15:04 - Epoch 4400: ACC: 0.0, NMI: 0.4750679073039715, F1: 0.0, ARI: 0.30440432444671245
INFO - 04/15/25 16:46:40 - 0:15:04 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4401: train_loss=6.914907932281494
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4402: train_loss=6.914224147796631
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4403: train_loss=6.914167881011963
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4404: train_loss=6.914651870727539
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4405: train_loss=6.914095401763916
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4406: train_loss=6.914529800415039
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4407: train_loss=6.914402961730957
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4408: train_loss=6.914233684539795
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4409: train_loss=6.914029598236084
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4410: train_loss=6.914303779602051
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4411: train_loss=6.91404390335083
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4412: train_loss=6.91411018371582
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4413: train_loss=6.9138689041137695
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4414: train_loss=6.914019584655762
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4415: train_loss=6.913842678070068
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4416: train_loss=6.914009094238281
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4417: train_loss=6.913853645324707
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4418: train_loss=6.913973808288574
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4419: train_loss=6.9136481285095215
INFO - 04/15/25 16:46:41 - 0:15:04 - Epoch 4420: train_loss=6.914182186126709
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4421: train_loss=6.914135932922363
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4422: train_loss=6.913568496704102
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4423: train_loss=6.913421154022217
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4424: train_loss=6.914186954498291
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4425: train_loss=6.914065837860107
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4426: train_loss=6.91358757019043
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4427: train_loss=6.913414478302002
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4428: train_loss=6.913814544677734
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4429: train_loss=6.913567543029785
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4430: train_loss=6.91372013092041
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4431: train_loss=6.913617134094238
INFO - 04/15/25 16:46:41 - 0:15:05 - Epoch 4432: train_loss=6.913486957550049
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4433: train_loss=6.913388252258301
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4434: train_loss=6.913435935974121
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4435: train_loss=6.91322660446167
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4436: train_loss=6.913729667663574
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4437: train_loss=6.913456916809082
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4438: train_loss=6.913407325744629
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4439: train_loss=6.913443088531494
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4440: train_loss=6.913078784942627
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4441: train_loss=6.912693500518799
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4442: train_loss=6.914306163787842
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4443: train_loss=6.91450309753418
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4444: train_loss=6.912450790405273
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4445: train_loss=6.915223598480225
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4446: train_loss=6.9159440994262695
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4447: train_loss=6.913995742797852
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4448: train_loss=6.913877964019775
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4449: train_loss=6.915029048919678
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4450: train_loss=6.913681983947754
INFO - 04/15/25 16:46:42 - 0:15:05 - Epoch 4451: train_loss=6.913509845733643
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4452: train_loss=6.914381980895996
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4453: train_loss=6.912671089172363
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4454: train_loss=6.914444446563721
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4455: train_loss=6.915325164794922
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4456: train_loss=6.913631439208984
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4457: train_loss=6.913549900054932
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4458: train_loss=6.914505481719971
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4459: train_loss=6.913238525390625
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4460: train_loss=6.913646221160889
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4461: train_loss=6.914477825164795
INFO - 04/15/25 16:46:42 - 0:15:06 - Epoch 4462: train_loss=6.912811756134033
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4463: train_loss=6.913801670074463
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4464: train_loss=6.914534568786621
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4465: train_loss=6.912991523742676
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4466: train_loss=6.913571357727051
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4467: train_loss=6.91417932510376
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4468: train_loss=6.913025856018066
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4469: train_loss=6.913275241851807
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4470: train_loss=6.913755893707275
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4471: train_loss=6.912655830383301
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4472: train_loss=6.913091659545898
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4473: train_loss=6.913154602050781
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4474: train_loss=6.912692070007324
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4475: train_loss=6.912461757659912
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4476: train_loss=6.9127631187438965
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4477: train_loss=6.912394046783447
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4478: train_loss=6.91247034072876
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4479: train_loss=6.912634372711182
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4480: train_loss=6.911707401275635
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4481: train_loss=6.911727428436279
INFO - 04/15/25 16:46:43 - 0:15:06 - Epoch 4482: train_loss=6.912527084350586
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4483: train_loss=6.912217617034912
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4484: train_loss=6.912336349487305
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4485: train_loss=6.912421703338623
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4486: train_loss=6.911983489990234
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4487: train_loss=6.911898136138916
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4488: train_loss=6.912323951721191
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4489: train_loss=6.912040710449219
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4490: train_loss=6.912265300750732
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4491: train_loss=6.912215709686279
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4492: train_loss=6.912391185760498
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4493: train_loss=6.911995887756348
INFO - 04/15/25 16:46:43 - 0:15:07 - Epoch 4494: train_loss=6.912147045135498
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4495: train_loss=6.911975383758545
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4496: train_loss=6.912271022796631
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4497: train_loss=6.912303924560547
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4498: train_loss=6.911570072174072
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4499: train_loss=6.91129732131958
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4500: train_loss=6.912389755249023
INFO - 04/15/25 16:46:44 - 0:15:07 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:44 - 0:15:07 - Decoding cost time:  0.116 s
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4500: ACC: 0.0, NMI: 0.47584898577478907, F1: 0.0, ARI: 0.3049032103764552
INFO - 04/15/25 16:46:44 - 0:15:07 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4501: train_loss=6.91184139251709
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4502: train_loss=6.912075519561768
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4503: train_loss=6.9121856689453125
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4504: train_loss=6.911218643188477
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4505: train_loss=6.911440372467041
INFO - 04/15/25 16:46:44 - 0:15:07 - Epoch 4506: train_loss=6.911459922790527
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4507: train_loss=6.911019802093506
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4508: train_loss=6.911499500274658
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4509: train_loss=6.91111946105957
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4510: train_loss=6.911478519439697
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4511: train_loss=6.910878658294678
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4512: train_loss=6.912333965301514
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4513: train_loss=6.912593364715576
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4514: train_loss=6.910993576049805
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4515: train_loss=6.912972927093506
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4516: train_loss=6.913957118988037
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4517: train_loss=6.912877082824707
INFO - 04/15/25 16:46:44 - 0:15:08 - Epoch 4518: train_loss=6.9109296798706055
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4519: train_loss=6.912805080413818
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4520: train_loss=6.913373947143555
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4521: train_loss=6.911809921264648
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4522: train_loss=6.911932945251465
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4523: train_loss=6.912689208984375
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4524: train_loss=6.912133693695068
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4525: train_loss=6.911317825317383
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4526: train_loss=6.911999702453613
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4527: train_loss=6.911667823791504
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4528: train_loss=6.911171913146973
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4529: train_loss=6.911290168762207
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4530: train_loss=6.911139488220215
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4531: train_loss=6.911008358001709
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4532: train_loss=6.910893440246582
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4533: train_loss=6.911508083343506
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4534: train_loss=6.910794734954834
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4535: train_loss=6.91164493560791
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4536: train_loss=6.911526203155518
INFO - 04/15/25 16:46:45 - 0:15:08 - Epoch 4537: train_loss=6.9111008644104
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4538: train_loss=6.910985469818115
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4539: train_loss=6.911186695098877
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4540: train_loss=6.910425662994385
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4541: train_loss=6.911463260650635
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4542: train_loss=6.910752296447754
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4543: train_loss=6.911642551422119
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4544: train_loss=6.911318302154541
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4545: train_loss=6.911130905151367
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4546: train_loss=6.91105842590332
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4547: train_loss=6.911053657531738
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4548: train_loss=6.910742282867432
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4549: train_loss=6.911311626434326
INFO - 04/15/25 16:46:45 - 0:15:09 - Epoch 4550: train_loss=6.9109015464782715
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4551: train_loss=6.9112067222595215
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4552: train_loss=6.910809516906738
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4553: train_loss=6.911388874053955
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4554: train_loss=6.911232948303223
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4555: train_loss=6.910756587982178
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4556: train_loss=6.910715579986572
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4557: train_loss=6.911126613616943
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4558: train_loss=6.910765171051025
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4559: train_loss=6.91115140914917
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4560: train_loss=6.911096096038818
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4561: train_loss=6.910531997680664
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4562: train_loss=6.9103193283081055
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4563: train_loss=6.911265850067139
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4564: train_loss=6.911005973815918
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4565: train_loss=6.910459995269775
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4566: train_loss=6.910340309143066
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4567: train_loss=6.911027908325195
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4568: train_loss=6.910679817199707
INFO - 04/15/25 16:46:46 - 0:15:09 - Epoch 4569: train_loss=6.910712718963623
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4570: train_loss=6.910667419433594
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4571: train_loss=6.91060733795166
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4572: train_loss=6.910207748413086
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4573: train_loss=6.911057472229004
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4574: train_loss=6.911122798919678
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4575: train_loss=6.909892559051514
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4576: train_loss=6.9096903800964355
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4577: train_loss=6.911173343658447
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4578: train_loss=6.910959243774414
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4579: train_loss=6.909998416900635
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4580: train_loss=6.909999370574951
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4581: train_loss=6.910467624664307
INFO - 04/15/25 16:46:46 - 0:15:10 - Epoch 4582: train_loss=6.90994930267334
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4583: train_loss=6.911008358001709
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4584: train_loss=6.910853862762451
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4585: train_loss=6.909825801849365
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4586: train_loss=6.910002708435059
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4587: train_loss=6.9099602699279785
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4588: train_loss=6.909782886505127
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4589: train_loss=6.909882545471191
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4590: train_loss=6.909628868103027
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4591: train_loss=6.90947961807251
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4592: train_loss=6.909966945648193
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4593: train_loss=6.909316062927246
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4594: train_loss=6.910170078277588
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4595: train_loss=6.909444808959961
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4596: train_loss=6.91055154800415
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4597: train_loss=6.910576820373535
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4598: train_loss=6.909232139587402
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4599: train_loss=6.910364151000977
INFO - 04/15/25 16:46:47 - 0:15:10 - Epoch 4600: train_loss=6.909693717956543
INFO - 04/15/25 16:46:47 - 0:15:10 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:47 - 0:15:11 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:46:47 - 0:15:11 - Epoch 4600: ACC: 0.0, NMI: 0.47584898577478907, F1: 0.0, ARI: 0.3049032103764552
INFO - 04/15/25 16:46:47 - 0:15:11 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:47 - 0:15:11 - Epoch 4601: train_loss=6.9105939865112305
INFO - 04/15/25 16:46:47 - 0:15:11 - Epoch 4602: train_loss=6.91081428527832
INFO - 04/15/25 16:46:47 - 0:15:11 - Epoch 4603: train_loss=6.908884048461914
INFO - 04/15/25 16:46:47 - 0:15:11 - Epoch 4604: train_loss=6.910693168640137
INFO - 04/15/25 16:46:47 - 0:15:11 - Epoch 4605: train_loss=6.910463809967041
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4606: train_loss=6.909048080444336
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4607: train_loss=6.909650802612305
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4608: train_loss=6.909124374389648
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4609: train_loss=6.9093852043151855
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4610: train_loss=6.909376621246338
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4611: train_loss=6.90891170501709
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4612: train_loss=6.9093170166015625
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4613: train_loss=6.909091472625732
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4614: train_loss=6.908668041229248
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4615: train_loss=6.90900182723999
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4616: train_loss=6.908614158630371
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4617: train_loss=6.90971040725708
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4618: train_loss=6.909248352050781
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4619: train_loss=6.909418106079102
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4620: train_loss=6.909449100494385
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4621: train_loss=6.909148693084717
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4622: train_loss=6.909222602844238
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4623: train_loss=6.909063339233398
INFO - 04/15/25 16:46:48 - 0:15:11 - Epoch 4624: train_loss=6.909034252166748
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4625: train_loss=6.909139633178711
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4626: train_loss=6.908608913421631
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4627: train_loss=6.910078048706055
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4628: train_loss=6.909775733947754
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4629: train_loss=6.9092020988464355
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4630: train_loss=6.909021854400635
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4631: train_loss=6.909713268280029
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4632: train_loss=6.909132957458496
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4633: train_loss=6.909791469573975
INFO - 04/15/25 16:46:48 - 0:15:12 - Epoch 4634: train_loss=6.909818649291992
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4635: train_loss=6.908688545227051
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4636: train_loss=6.908604145050049
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4637: train_loss=6.90933895111084
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4638: train_loss=6.908720016479492
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4639: train_loss=6.909958839416504
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4640: train_loss=6.909857273101807
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4641: train_loss=6.908774375915527
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4642: train_loss=6.90900993347168
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4643: train_loss=6.908813953399658
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4644: train_loss=6.908689498901367
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4645: train_loss=6.908641338348389
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4646: train_loss=6.908740043640137
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4647: train_loss=6.9082183837890625
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4648: train_loss=6.9093804359436035
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4649: train_loss=6.908567428588867
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4650: train_loss=6.910027980804443
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4651: train_loss=6.910342216491699
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4652: train_loss=6.907445907592773
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4653: train_loss=6.909711837768555
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4654: train_loss=6.908971786499023
INFO - 04/15/25 16:46:49 - 0:15:12 - Epoch 4655: train_loss=6.9094696044921875
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4656: train_loss=6.909578323364258
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4657: train_loss=6.908015727996826
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4658: train_loss=6.908164978027344
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4659: train_loss=6.908932209014893
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4660: train_loss=6.9081034660339355
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4661: train_loss=6.909998893737793
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4662: train_loss=6.910261631011963
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4663: train_loss=6.907691955566406
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4664: train_loss=6.911736011505127
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4665: train_loss=6.913308620452881
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4666: train_loss=6.9118852615356445
INFO - 04/15/25 16:46:49 - 0:15:13 - Epoch 4667: train_loss=6.908380508422852
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4668: train_loss=6.911430358886719
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4669: train_loss=6.913059711456299
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4670: train_loss=6.912117004394531
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4671: train_loss=6.909276008605957
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4672: train_loss=6.910445690155029
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4673: train_loss=6.911771774291992
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4674: train_loss=6.91081428527832
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4675: train_loss=6.909360885620117
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4676: train_loss=6.909924507141113
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4677: train_loss=6.910143852233887
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4678: train_loss=6.909294605255127
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4679: train_loss=6.90925407409668
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4680: train_loss=6.90956974029541
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4681: train_loss=6.908854007720947
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4682: train_loss=6.908853530883789
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4683: train_loss=6.909176826477051
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4684: train_loss=6.908127307891846
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4685: train_loss=6.908912658691406
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4686: train_loss=6.908913612365723
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4687: train_loss=6.908162593841553
INFO - 04/15/25 16:46:50 - 0:15:13 - Epoch 4688: train_loss=6.908418655395508
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4689: train_loss=6.908107757568359
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4690: train_loss=6.908226490020752
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4691: train_loss=6.907528877258301
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4692: train_loss=6.907857894897461
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4693: train_loss=6.9076032638549805
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4694: train_loss=6.907583713531494
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4695: train_loss=6.907656669616699
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4696: train_loss=6.907231330871582
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4697: train_loss=6.908371925354004
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4698: train_loss=6.90812873840332
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4699: train_loss=6.907463073730469
INFO - 04/15/25 16:46:50 - 0:15:14 - Epoch 4700: train_loss=6.907495498657227
INFO - 04/15/25 16:46:50 - 0:15:14 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:51 - 0:15:14 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4700: ACC: 0.0, NMI: 0.4806859320360045, F1: 0.0, ARI: 0.3064934031613302
INFO - 04/15/25 16:46:51 - 0:15:14 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4701: train_loss=6.907737731933594
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4702: train_loss=6.907309532165527
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4703: train_loss=6.908034801483154
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4704: train_loss=6.907689094543457
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4705: train_loss=6.90776252746582
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4706: train_loss=6.9076385498046875
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4707: train_loss=6.9077653884887695
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4708: train_loss=6.9074883460998535
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4709: train_loss=6.9078240394592285
INFO - 04/15/25 16:46:51 - 0:15:14 - Epoch 4710: train_loss=6.907712459564209
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4711: train_loss=6.9073591232299805
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4712: train_loss=6.907201766967773
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4713: train_loss=6.90777063369751
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4714: train_loss=6.907454967498779
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4715: train_loss=6.907449245452881
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4716: train_loss=6.9074249267578125
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4717: train_loss=6.907515048980713
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4718: train_loss=6.907434463500977
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4719: train_loss=6.9073052406311035
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4720: train_loss=6.907044887542725
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4721: train_loss=6.907755374908447
INFO - 04/15/25 16:46:51 - 0:15:15 - Epoch 4722: train_loss=6.907586574554443
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4723: train_loss=6.907007694244385
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4724: train_loss=6.906868934631348
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4725: train_loss=6.9077253341674805
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4726: train_loss=6.9075775146484375
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4727: train_loss=6.9070329666137695
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4728: train_loss=6.906947135925293
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4729: train_loss=6.907519340515137
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4730: train_loss=6.907395362854004
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4731: train_loss=6.906822204589844
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4732: train_loss=6.906662940979004
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4733: train_loss=6.907504081726074
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4734: train_loss=6.907133102416992
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4735: train_loss=6.907169818878174
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4736: train_loss=6.907137870788574
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4737: train_loss=6.906818866729736
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4738: train_loss=6.906698226928711
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4739: train_loss=6.907251834869385
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4740: train_loss=6.906975269317627
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4741: train_loss=6.906946182250977
INFO - 04/15/25 16:46:52 - 0:15:15 - Epoch 4742: train_loss=6.906858921051025
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4743: train_loss=6.90703010559082
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4744: train_loss=6.906691551208496
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4745: train_loss=6.907087326049805
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4746: train_loss=6.907099723815918
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4747: train_loss=6.906504154205322
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4748: train_loss=6.906400203704834
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4749: train_loss=6.907134532928467
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4750: train_loss=6.906874656677246
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4751: train_loss=6.90666389465332
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4752: train_loss=6.906518459320068
INFO - 04/15/25 16:46:52 - 0:15:16 - Epoch 4753: train_loss=6.906916618347168
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4754: train_loss=6.906684398651123
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4755: train_loss=6.906687259674072
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4756: train_loss=6.906596660614014
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4757: train_loss=6.906639099121094
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4758: train_loss=6.906536102294922
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4759: train_loss=6.906589508056641
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4760: train_loss=6.906343460083008
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4761: train_loss=6.9068498611450195
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4762: train_loss=6.906681060791016
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4763: train_loss=6.906216621398926
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4764: train_loss=6.906027793884277
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4765: train_loss=6.906769752502441
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4766: train_loss=6.906538963317871
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4767: train_loss=6.906303882598877
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4768: train_loss=6.906162738800049
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4769: train_loss=6.906478404998779
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4770: train_loss=6.906223297119141
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4771: train_loss=6.906435012817383
INFO - 04/15/25 16:46:53 - 0:15:16 - Epoch 4772: train_loss=6.906285285949707
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4773: train_loss=6.906203746795654
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4774: train_loss=6.905914783477783
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4775: train_loss=6.906700611114502
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4776: train_loss=6.906643867492676
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4777: train_loss=6.9055657386779785
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4778: train_loss=6.905550479888916
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4779: train_loss=6.906424522399902
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4780: train_loss=6.906116962432861
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4781: train_loss=6.906131744384766
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4782: train_loss=6.906003475189209
INFO - 04/15/25 16:46:53 - 0:15:17 - Epoch 4783: train_loss=6.9061408042907715
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4784: train_loss=6.906049728393555
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4785: train_loss=6.905818462371826
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4786: train_loss=6.9055094718933105
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4787: train_loss=6.906548023223877
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4788: train_loss=6.9066267013549805
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4789: train_loss=6.905124664306641
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4790: train_loss=6.905295372009277
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4791: train_loss=6.905885696411133
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4792: train_loss=6.905285358428955
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4793: train_loss=6.906835556030273
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4794: train_loss=6.90687370300293
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4795: train_loss=6.905027389526367
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4796: train_loss=6.906919956207275
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4797: train_loss=6.906894683837891
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4798: train_loss=6.905092716217041
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4799: train_loss=6.906570911407471
INFO - 04/15/25 16:46:54 - 0:15:17 - Epoch 4800: train_loss=6.9063591957092285
INFO - 04/15/25 16:46:54 - 0:15:17 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:54 - 0:15:18 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:46:54 - 0:15:18 - Epoch 4800: ACC: 0.0, NMI: 0.4806859320360045, F1: 0.0, ARI: 0.3064934031613302
INFO - 04/15/25 16:46:54 - 0:15:18 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:54 - 0:15:18 - Epoch 4801: train_loss=6.905472755432129
INFO - 04/15/25 16:46:54 - 0:15:18 - Epoch 4802: train_loss=6.905817031860352
INFO - 04/15/25 16:46:54 - 0:15:18 - Epoch 4803: train_loss=6.905521869659424
INFO - 04/15/25 16:46:54 - 0:15:18 - Epoch 4804: train_loss=6.905522346496582
INFO - 04/15/25 16:46:54 - 0:15:18 - Epoch 4805: train_loss=6.905600547790527
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4806: train_loss=6.9053192138671875
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4807: train_loss=6.905454635620117
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4808: train_loss=6.90540885925293
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4809: train_loss=6.905447006225586
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4810: train_loss=6.905210971832275
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4811: train_loss=6.9053053855896
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4812: train_loss=6.904980659484863
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4813: train_loss=6.905310153961182
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4814: train_loss=6.90508508682251
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4815: train_loss=6.905182361602783
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4816: train_loss=6.9049482345581055
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4817: train_loss=6.904930114746094
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4818: train_loss=6.905028343200684
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4819: train_loss=6.904485702514648
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4820: train_loss=6.905564308166504
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4821: train_loss=6.9052958488464355
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4822: train_loss=6.90503454208374
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4823: train_loss=6.905008792877197
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4824: train_loss=6.904879093170166
INFO - 04/15/25 16:46:55 - 0:15:18 - Epoch 4825: train_loss=6.904918670654297
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4826: train_loss=6.9047112464904785
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4827: train_loss=6.905116081237793
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4828: train_loss=6.904699325561523
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4829: train_loss=6.9053778648376465
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4830: train_loss=6.905313491821289
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4831: train_loss=6.904738903045654
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4832: train_loss=6.904806137084961
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4833: train_loss=6.904800891876221
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4834: train_loss=6.904358386993408
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4835: train_loss=6.904840469360352
INFO - 04/15/25 16:46:55 - 0:15:19 - Epoch 4836: train_loss=6.9043731689453125
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4837: train_loss=6.904820919036865
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4838: train_loss=6.904439449310303
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4839: train_loss=6.9048004150390625
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4840: train_loss=6.904589653015137
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4841: train_loss=6.904643535614014
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4842: train_loss=6.9047017097473145
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4843: train_loss=6.904186725616455
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4844: train_loss=6.904896259307861
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4845: train_loss=6.9041314125061035
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4846: train_loss=6.904974937438965
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4847: train_loss=6.90435791015625
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4848: train_loss=6.90510892868042
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4849: train_loss=6.905154228210449
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4850: train_loss=6.904215335845947
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4851: train_loss=6.9044599533081055
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4852: train_loss=6.904397010803223
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4853: train_loss=6.904128074645996
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4854: train_loss=6.904636383056641
INFO - 04/15/25 16:46:56 - 0:15:19 - Epoch 4855: train_loss=6.9040913581848145
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4856: train_loss=6.905078887939453
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4857: train_loss=6.905014991760254
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4858: train_loss=6.904141902923584
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4859: train_loss=6.90440034866333
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4860: train_loss=6.905532360076904
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4861: train_loss=6.911334037780762
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4862: train_loss=6.9088263511657715
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4863: train_loss=6.920995235443115
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4864: train_loss=7.014276504516602
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4865: train_loss=6.9704976081848145
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4866: train_loss=6.946616172790527
INFO - 04/15/25 16:46:56 - 0:15:20 - Epoch 4867: train_loss=6.95494270324707
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4868: train_loss=6.963371276855469
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4869: train_loss=6.952801704406738
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4870: train_loss=7.014581680297852
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4871: train_loss=7.042588710784912
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4872: train_loss=7.023576259613037
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4873: train_loss=7.070132732391357
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4874: train_loss=7.0758161544799805
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4875: train_loss=7.011196136474609
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4876: train_loss=6.997824192047119
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4877: train_loss=7.0024847984313965
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4878: train_loss=6.995674133300781
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4879: train_loss=6.998594284057617
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4880: train_loss=6.991606712341309
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4881: train_loss=6.97959041595459
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4882: train_loss=6.972573280334473
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4883: train_loss=6.992569446563721
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4884: train_loss=6.977431297302246
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4885: train_loss=7.010604381561279
INFO - 04/15/25 16:46:57 - 0:15:20 - Epoch 4886: train_loss=6.955037593841553
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4887: train_loss=6.949587345123291
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4888: train_loss=6.948984146118164
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4889: train_loss=7.039951324462891
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4890: train_loss=6.981569766998291
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4891: train_loss=6.966325759887695
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4892: train_loss=6.975955486297607
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4893: train_loss=6.984849452972412
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4894: train_loss=6.981051921844482
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4895: train_loss=6.978889465332031
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4896: train_loss=6.9753947257995605
INFO - 04/15/25 16:46:57 - 0:15:21 - Epoch 4897: train_loss=6.9620256423950195
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4898: train_loss=6.954422473907471
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4899: train_loss=6.954739093780518
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4900: train_loss=6.9591522216796875
INFO - 04/15/25 16:46:58 - 0:15:21 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:46:58 - 0:15:21 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4900: ACC: 0.0, NMI: 0.5190610518683737, F1: 0.0, ARI: 0.34983235966429127
INFO - 04/15/25 16:46:58 - 0:15:21 - -------------------------------------------------------------------------
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4901: train_loss=6.9624505043029785
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4902: train_loss=6.9600725173950195
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4903: train_loss=6.956227779388428
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4904: train_loss=6.953374862670898
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4905: train_loss=6.951112747192383
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4906: train_loss=6.949910640716553
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4907: train_loss=6.949940204620361
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4908: train_loss=6.949525833129883
INFO - 04/15/25 16:46:58 - 0:15:21 - Epoch 4909: train_loss=6.9477386474609375
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4910: train_loss=6.944551467895508
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4911: train_loss=6.945279598236084
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4912: train_loss=6.945939064025879
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4913: train_loss=6.944788932800293
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4914: train_loss=6.942373275756836
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4915: train_loss=6.939691066741943
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4916: train_loss=6.938433647155762
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4917: train_loss=6.937491416931152
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4918: train_loss=6.935359477996826
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4919: train_loss=6.933446884155273
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4920: train_loss=6.9341254234313965
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4921: train_loss=6.933599472045898
INFO - 04/15/25 16:46:58 - 0:15:22 - Epoch 4922: train_loss=6.931446552276611
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4923: train_loss=6.931719779968262
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4924: train_loss=6.932034492492676
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4925: train_loss=6.931066513061523
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4926: train_loss=6.930947303771973
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4927: train_loss=6.930315017700195
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4928: train_loss=6.930069446563721
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4929: train_loss=6.930450916290283
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4930: train_loss=6.929030895233154
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4931: train_loss=6.929917335510254
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4932: train_loss=6.929618835449219
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4933: train_loss=6.92885160446167
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4934: train_loss=6.928969860076904
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4935: train_loss=6.927810192108154
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4936: train_loss=6.928286552429199
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4937: train_loss=6.927855968475342
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4938: train_loss=6.927496433258057
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4939: train_loss=6.9274444580078125
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4940: train_loss=6.927145957946777
INFO - 04/15/25 16:46:59 - 0:15:22 - Epoch 4941: train_loss=6.927018642425537
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4942: train_loss=6.9269514083862305
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4943: train_loss=6.926386833190918
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4944: train_loss=6.927252769470215
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4945: train_loss=6.926583290100098
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4946: train_loss=6.92719030380249
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4947: train_loss=6.926656723022461
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4948: train_loss=6.926673889160156
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4949: train_loss=6.926437854766846
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4950: train_loss=6.926368713378906
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4951: train_loss=6.9259748458862305
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4952: train_loss=6.926298141479492
INFO - 04/15/25 16:46:59 - 0:15:23 - Epoch 4953: train_loss=6.926184177398682
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4954: train_loss=6.9256510734558105
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4955: train_loss=6.925595760345459
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4956: train_loss=6.932438850402832
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4957: train_loss=6.984349250793457
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4958: train_loss=7.072768211364746
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4959: train_loss=6.971104621887207
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4960: train_loss=7.196338653564453
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4961: train_loss=7.180506706237793
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4962: train_loss=7.167222023010254
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4963: train_loss=7.162628650665283
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4964: train_loss=7.177097320556641
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4965: train_loss=7.153136253356934
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4966: train_loss=7.141848087310791
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4967: train_loss=7.1309661865234375
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4968: train_loss=7.119958877563477
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4969: train_loss=7.111693859100342
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4970: train_loss=7.10837459564209
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4971: train_loss=7.1012983322143555
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4972: train_loss=7.0901265144348145
INFO - 04/15/25 16:47:00 - 0:15:23 - Epoch 4973: train_loss=7.087239742279053
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4974: train_loss=7.082276344299316
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4975: train_loss=7.077953338623047
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4976: train_loss=7.071388244628906
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4977: train_loss=7.075941562652588
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4978: train_loss=7.060005187988281
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4979: train_loss=7.0588459968566895
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4980: train_loss=7.055052757263184
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4981: train_loss=7.078335285186768
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4982: train_loss=7.050501823425293
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4983: train_loss=7.0605549812316895
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4984: train_loss=7.055654525756836
INFO - 04/15/25 16:47:00 - 0:15:24 - Epoch 4985: train_loss=7.0520830154418945
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4986: train_loss=7.048027992248535
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4987: train_loss=7.042032241821289
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4988: train_loss=7.034890174865723
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4989: train_loss=7.032565116882324
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4990: train_loss=7.035841941833496
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4991: train_loss=7.036162853240967
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4992: train_loss=7.032156944274902
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4993: train_loss=7.029031276702881
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4994: train_loss=7.028623580932617
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4995: train_loss=7.027084827423096
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4996: train_loss=7.026333332061768
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4997: train_loss=7.027626037597656
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4998: train_loss=7.028028964996338
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 4999: train_loss=7.026111602783203
INFO - 04/15/25 16:47:01 - 0:15:24 - Epoch 5000: train_loss=7.023216247558594
INFO - 04/15/25 16:47:01 - 0:15:24 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:47:01 - 0:15:24 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:47:01 - 0:15:25 - Epoch 5000: ACC: 0.0, NMI: 0.5075389729393673, F1: 0.0, ARI: 0.3428442582864524
INFO - 04/15/25 16:47:01 - 0:15:25 - -------------------------------------------------------------------------
INFO - 04/15/25 16:47:01 - 0:15:25 - ------------------Loading best model-------------------
INFO - 04/15/25 16:47:23 - 0:15:46 - Best Results according to nmi: ACC: 0.0, NMI: 0.5342175245449703, F1: 0.0, ARI: 0.37305787484280933 
                                     
INFO - 04/15/25 16:47:23 - 0:15:46 - Best Results according to ari: ACC: 0.0, NMI: 0.5342175245449703, F1: 0.0, ARI: 0.37305787484280933 
                                     
INFO - 04/15/25 16:47:23 - 0:15:46 - 
                                     train iters 4
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 1: train_loss=5.847848415374756
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 2: train_loss=2.90360689163208
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 3: train_loss=2.040433406829834
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 4: train_loss=1.3254594802856445
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 5: train_loss=1.2787563800811768
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 6: train_loss=1.1152863502502441
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 7: train_loss=0.8744084239006042
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 8: train_loss=0.713432788848877
INFO - 04/15/25 16:47:23 - 0:15:46 - Epoch 9: train_loss=0.6258476972579956
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 10: train_loss=0.5839555859565735
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 11: train_loss=0.5558525323867798
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 12: train_loss=0.5158685445785522
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 13: train_loss=0.4575663208961487
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 14: train_loss=0.40164804458618164
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 15: train_loss=0.38443994522094727
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 16: train_loss=0.38598668575286865
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 17: train_loss=0.38158971071243286
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 18: train_loss=0.367521733045578
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 19: train_loss=0.34458962082862854
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 20: train_loss=0.31948816776275635
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 21: train_loss=0.3089996576309204
INFO - 04/15/25 16:47:23 - 0:15:47 - Epoch 22: train_loss=0.31316518783569336
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 23: train_loss=0.3154532313346863
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 24: train_loss=0.3105393052101135
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 25: train_loss=0.2987046241760254
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 26: train_loss=0.2830567955970764
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 27: train_loss=0.278333842754364
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 28: train_loss=0.28254422545433044
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 29: train_loss=0.2811935245990753
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 30: train_loss=0.2779035270214081
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 31: train_loss=0.2723884880542755
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 32: train_loss=0.26323145627975464
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 33: train_loss=0.26150014996528625
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 34: train_loss=0.26573917269706726
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 35: train_loss=0.265211820602417
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 36: train_loss=0.25832289457321167
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 37: train_loss=0.25028136372566223
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 38: train_loss=0.2548828125
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 39: train_loss=0.25531142950057983
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 40: train_loss=0.2518646717071533
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 41: train_loss=0.24732069671154022
INFO - 04/15/25 16:47:24 - 0:15:47 - Epoch 42: train_loss=0.24712198972702026
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 43: train_loss=0.2492973506450653
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 44: train_loss=0.2466292679309845
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 45: train_loss=0.24274377524852753
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 46: train_loss=0.24461738765239716
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 47: train_loss=0.24582871794700623
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 48: train_loss=0.242614284157753
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 49: train_loss=0.23989883065223694
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 50: train_loss=0.24438752233982086
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 51: train_loss=0.2414933145046234
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 52: train_loss=0.2420375645160675
INFO - 04/15/25 16:47:24 - 0:15:48 - Epoch 53: train_loss=0.2372778058052063
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 54: train_loss=0.23934529721736908
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 55: train_loss=0.23705463111400604
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 56: train_loss=0.23610565066337585
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 57: train_loss=0.23673857748508453
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 58: train_loss=0.2340194135904312
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 59: train_loss=0.23707769811153412
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 60: train_loss=0.23380377888679504
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 61: train_loss=0.2349272519350052
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 62: train_loss=0.23269538581371307
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 63: train_loss=0.23376062512397766
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 64: train_loss=0.23035944998264313
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 65: train_loss=0.23332630097866058
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 66: train_loss=0.2280145287513733
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 67: train_loss=0.2328047901391983
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 68: train_loss=0.2293633222579956
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 69: train_loss=0.23043183982372284
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 70: train_loss=0.22787563502788544
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 71: train_loss=0.22951559722423553
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 72: train_loss=0.2267184853553772
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 73: train_loss=0.22806201875209808
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 74: train_loss=0.22704268991947174
INFO - 04/15/25 16:47:25 - 0:15:48 - Epoch 75: train_loss=0.2267972230911255
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 76: train_loss=0.22795255482196808
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 77: train_loss=0.22426310181617737
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 78: train_loss=0.2282598316669464
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 79: train_loss=0.22474555671215057
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 80: train_loss=0.2248591035604477
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 81: train_loss=0.22233302891254425
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 82: train_loss=0.22698700428009033
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 83: train_loss=0.22456979751586914
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 84: train_loss=0.2232181280851364
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 85: train_loss=0.22436603903770447
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 86: train_loss=0.22203600406646729
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 87: train_loss=0.22222603857517242
INFO - 04/15/25 16:47:25 - 0:15:49 - Epoch 88: train_loss=0.22304022312164307
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 89: train_loss=0.219716414809227
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 90: train_loss=0.2223433405160904
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 91: train_loss=0.21896813809871674
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 92: train_loss=0.22319649159908295
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 93: train_loss=0.21895937621593475
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 94: train_loss=0.21910914778709412
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 95: train_loss=0.21918153762817383
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 96: train_loss=0.22345654666423798
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 97: train_loss=0.21846643090248108
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 98: train_loss=0.2195512354373932
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 99: train_loss=0.2216493934392929
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 100: train_loss=0.21620462834835052
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 101: train_loss=0.2266998589038849
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 102: train_loss=0.22040623426437378
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 103: train_loss=0.228061705827713
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 104: train_loss=0.2236028015613556
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 105: train_loss=0.22720125317573547
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 106: train_loss=0.2261592447757721
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 107: train_loss=0.21940907835960388
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 108: train_loss=0.22194679081439972
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 109: train_loss=0.21634601056575775
INFO - 04/15/25 16:47:26 - 0:15:49 - Epoch 110: train_loss=0.22306907176971436
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 111: train_loss=0.21508777141571045
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 112: train_loss=0.22628244757652283
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 113: train_loss=0.21768128871917725
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 114: train_loss=0.23099400103092194
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 115: train_loss=0.229201078414917
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 116: train_loss=0.21720126271247864
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 117: train_loss=0.21993771195411682
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 118: train_loss=0.21828702092170715
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 119: train_loss=0.21511562168598175
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 120: train_loss=0.22146904468536377
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 121: train_loss=0.21536879241466522
INFO - 04/15/25 16:47:26 - 0:15:50 - Epoch 122: train_loss=0.22506627440452576
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 123: train_loss=0.2235090583562851
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 124: train_loss=0.21626713871955872
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 125: train_loss=0.2171764075756073
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 126: train_loss=0.2170560210943222
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 127: train_loss=0.21395757794380188
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 128: train_loss=0.2189946174621582
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 129: train_loss=0.21487277746200562
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 130: train_loss=0.2197566032409668
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 131: train_loss=0.2185179442167282
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 132: train_loss=0.2148454487323761
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 133: train_loss=0.21455709636211395
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 134: train_loss=0.21466326713562012
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 135: train_loss=0.21250000596046448
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 136: train_loss=0.21474233269691467
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 137: train_loss=0.21155934035778046
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 138: train_loss=0.21609506011009216
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 139: train_loss=0.21382717788219452
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 140: train_loss=0.21400129795074463
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 141: train_loss=0.21264304220676422
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 142: train_loss=0.2136492282152176
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 143: train_loss=0.2121882140636444
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 144: train_loss=0.21310743689537048
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 145: train_loss=0.21111150085926056
INFO - 04/15/25 16:47:27 - 0:15:50 - Epoch 146: train_loss=0.21408730745315552
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 147: train_loss=0.2132386863231659
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 148: train_loss=0.2098771333694458
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 149: train_loss=0.20807404816150665
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 150: train_loss=0.21451176702976227
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 151: train_loss=0.2132820188999176
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 152: train_loss=0.2081623375415802
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 153: train_loss=0.20701538026332855
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 154: train_loss=0.21316607296466827
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 155: train_loss=0.21134403347969055
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 156: train_loss=0.20879854261875153
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 157: train_loss=0.2076815813779831
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 158: train_loss=0.2111111581325531
INFO - 04/15/25 16:47:27 - 0:15:51 - Epoch 159: train_loss=0.20973770320415497
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 160: train_loss=0.2084004431962967
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 161: train_loss=0.2071167230606079
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 162: train_loss=0.21009720861911774
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 163: train_loss=0.20886477828025818
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 164: train_loss=0.20748275518417358
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 165: train_loss=0.20599664747714996
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 166: train_loss=0.20996329188346863
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 167: train_loss=0.2090931236743927
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 168: train_loss=0.20533865690231323
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 169: train_loss=0.20405402779579163
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 170: train_loss=0.21018587052822113
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 171: train_loss=0.20883972942829132
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 172: train_loss=0.20473653078079224
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 173: train_loss=0.2056773155927658
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 174: train_loss=0.20610998570919037
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 175: train_loss=0.2035430669784546
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 176: train_loss=0.20775264501571655
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 177: train_loss=0.20517434179782867
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 178: train_loss=0.2078297734260559
INFO - 04/15/25 16:47:28 - 0:15:51 - Epoch 179: train_loss=0.20821863412857056
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 180: train_loss=0.20109732449054718
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 181: train_loss=0.20844300091266632
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 182: train_loss=0.19966600835323334
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 183: train_loss=0.20938467979431152
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 184: train_loss=0.1997576206922531
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 185: train_loss=0.21419374644756317
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 186: train_loss=0.21224038302898407
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 187: train_loss=0.20597943663597107
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 188: train_loss=0.20897012948989868
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 189: train_loss=0.20788975059986115
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 190: train_loss=0.20524412393569946
INFO - 04/15/25 16:47:28 - 0:15:52 - Epoch 191: train_loss=0.20526139438152313
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 192: train_loss=0.20409388840198517
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 193: train_loss=0.20421403646469116
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 194: train_loss=0.20346009731292725
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 195: train_loss=0.20061586797237396
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 196: train_loss=0.2061242163181305
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 197: train_loss=0.2047368884086609
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 198: train_loss=0.20147566497325897
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 199: train_loss=0.20499081909656525
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 200: train_loss=0.20090225338935852
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 201: train_loss=0.1989566832780838
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 202: train_loss=0.207676500082016
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 203: train_loss=0.2026536464691162
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 204: train_loss=0.20811863243579865
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 205: train_loss=0.20676438510417938
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 206: train_loss=0.20543494820594788
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 207: train_loss=0.20358087122440338
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 208: train_loss=0.205791175365448
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 209: train_loss=0.2016591727733612
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 210: train_loss=0.20743466913700104
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 211: train_loss=0.2022065818309784
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 212: train_loss=0.21060481667518616
INFO - 04/15/25 16:47:29 - 0:15:52 - Epoch 213: train_loss=0.2094663679599762
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 214: train_loss=0.2012328952550888
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 215: train_loss=0.2020292580127716
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 216: train_loss=0.2038586288690567
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 217: train_loss=0.20030921697616577
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 218: train_loss=0.2085670679807663
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 219: train_loss=0.20733177661895752
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 220: train_loss=0.20082172751426697
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 221: train_loss=0.20054268836975098
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 222: train_loss=0.20475360751152039
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 223: train_loss=0.2020760178565979
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 224: train_loss=0.20492731034755707
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 225: train_loss=0.204498291015625
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 226: train_loss=0.20027953386306763
INFO - 04/15/25 16:47:29 - 0:15:53 - Epoch 227: train_loss=0.19888781011104584
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 228: train_loss=0.20523689687252045
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 229: train_loss=0.203638955950737
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 230: train_loss=0.20076431334018707
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 231: train_loss=0.19979584217071533
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 232: train_loss=0.20338590443134308
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 233: train_loss=0.2019152194261551
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 234: train_loss=0.2007914036512375
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 235: train_loss=0.1996762454509735
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 236: train_loss=0.20234979689121246
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 237: train_loss=0.2010003924369812
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 238: train_loss=0.20074428617954254
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 239: train_loss=0.19968298077583313
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 240: train_loss=0.20111948251724243
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 241: train_loss=0.1999533623456955
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 242: train_loss=0.2003272920846939
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 243: train_loss=0.19905143976211548
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 244: train_loss=0.20096063613891602
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 245: train_loss=0.20006108283996582
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 246: train_loss=0.19921523332595825
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 247: train_loss=0.1979483664035797
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 248: train_loss=0.200938880443573
INFO - 04/15/25 16:47:30 - 0:15:53 - Epoch 249: train_loss=0.1999136507511139
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 250: train_loss=0.1984723061323166
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 251: train_loss=0.19728784263134003
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 252: train_loss=0.20054776966571808
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 253: train_loss=0.19940808415412903
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 254: train_loss=0.198089599609375
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 255: train_loss=0.19707021117210388
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 256: train_loss=0.19977590441703796
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 257: train_loss=0.19862115383148193
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 258: train_loss=0.19797131419181824
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 259: train_loss=0.19721382856369019
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 260: train_loss=0.1985766887664795
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 261: train_loss=0.19738757610321045
INFO - 04/15/25 16:47:30 - 0:15:54 - Epoch 262: train_loss=0.1983647644519806
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 263: train_loss=0.1973315179347992
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 264: train_loss=0.19794470071792603
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 265: train_loss=0.19704920053482056
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 266: train_loss=0.19757021963596344
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 267: train_loss=0.1963566392660141
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 268: train_loss=0.1979977935552597
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 269: train_loss=0.19710274040699005
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 270: train_loss=0.19698309898376465
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 271: train_loss=0.19604414701461792
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 272: train_loss=0.19750705361366272
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 273: train_loss=0.196496844291687
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 274: train_loss=0.19687610864639282
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 275: train_loss=0.19603875279426575
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 276: train_loss=0.19686783850193024
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 277: train_loss=0.19589564204216003
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 278: train_loss=0.1968236267566681
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 279: train_loss=0.19603554904460907
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 280: train_loss=0.19617301225662231
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 281: train_loss=0.19528988003730774
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 282: train_loss=0.19660378992557526
INFO - 04/15/25 16:47:31 - 0:15:54 - Epoch 283: train_loss=0.19575558602809906
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 284: train_loss=0.1958378553390503
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 285: train_loss=0.19498512148857117
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 286: train_loss=0.19621039927005768
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 287: train_loss=0.19531698524951935
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 288: train_loss=0.19570912420749664
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 289: train_loss=0.19500982761383057
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 290: train_loss=0.1956591159105301
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 291: train_loss=0.1952838897705078
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 292: train_loss=0.19549573957920074
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 293: train_loss=0.19635623693466187
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 294: train_loss=0.1938508152961731
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 295: train_loss=0.19761736690998077
INFO - 04/15/25 16:47:31 - 0:15:55 - Epoch 296: train_loss=0.19289472699165344
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 297: train_loss=0.19896864891052246
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 298: train_loss=0.19043393433094025
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 299: train_loss=0.20077301561832428
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 300: train_loss=0.19442960619926453
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 301: train_loss=0.198832705616951
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 302: train_loss=0.19943039119243622
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 303: train_loss=0.19374361634254456
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 304: train_loss=0.20713381469249725
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 305: train_loss=0.20642907917499542
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 306: train_loss=0.20012253522872925
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 307: train_loss=0.19781167805194855
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 308: train_loss=0.2055525779724121
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 309: train_loss=0.2028132975101471
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 310: train_loss=0.19811943173408508
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 311: train_loss=0.1976177990436554
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 312: train_loss=0.20108617842197418
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 313: train_loss=0.1948956698179245
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 314: train_loss=0.20810788869857788
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 315: train_loss=0.20713265240192413
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 316: train_loss=0.19358773529529572
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 317: train_loss=0.19696548581123352
INFO - 04/15/25 16:47:32 - 0:15:55 - Epoch 318: train_loss=0.19566550850868225
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 319: train_loss=0.19406799972057343
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 320: train_loss=0.19597189128398895
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 321: train_loss=0.19317790865898132
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 322: train_loss=0.19522333145141602
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 323: train_loss=0.19371356070041656
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 324: train_loss=0.1952231377363205
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 325: train_loss=0.1900247037410736
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 326: train_loss=0.20524507761001587
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 327: train_loss=0.20367969572544098
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 328: train_loss=0.19504190981388092
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 329: train_loss=0.19777911901474
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 330: train_loss=0.19724611937999725
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 331: train_loss=0.19419600069522858
INFO - 04/15/25 16:47:32 - 0:15:56 - Epoch 332: train_loss=0.19596926867961884
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 333: train_loss=0.19501766562461853
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 334: train_loss=0.19207985699176788
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 335: train_loss=0.198255255818367
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 336: train_loss=0.1898898035287857
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 337: train_loss=0.20787598192691803
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 338: train_loss=0.20789100229740143
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 339: train_loss=0.19259287416934967
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 340: train_loss=0.2041698843240738
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 341: train_loss=0.20384885370731354
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 342: train_loss=0.19818980991840363
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 343: train_loss=0.19766011834144592
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 344: train_loss=0.20011916756629944
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 345: train_loss=0.19789057970046997
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 346: train_loss=0.19560858607292175
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 347: train_loss=0.1967684030532837
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 348: train_loss=0.19513598084449768
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 349: train_loss=0.1932642012834549
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 350: train_loss=0.1955329179763794
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 351: train_loss=0.18998467922210693
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 352: train_loss=0.1929493248462677
INFO - 04/15/25 16:47:33 - 0:15:56 - Epoch 353: train_loss=0.19368095695972443
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 354: train_loss=0.18771296739578247
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 355: train_loss=0.20452558994293213
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 356: train_loss=0.20372524857521057
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 357: train_loss=0.19269831478595734
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 358: train_loss=0.19823822379112244
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 359: train_loss=0.19703182578086853
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 360: train_loss=0.19546188414096832
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 361: train_loss=0.19460970163345337
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 362: train_loss=0.19511717557907104
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 363: train_loss=0.19369082152843475
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 364: train_loss=0.19343480467796326
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 365: train_loss=0.1931818425655365
INFO - 04/15/25 16:47:33 - 0:15:57 - Epoch 366: train_loss=0.19219577312469482
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 367: train_loss=0.19106094539165497
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 368: train_loss=0.19544214010238647
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 369: train_loss=0.19324970245361328
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 370: train_loss=0.19511568546295166
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 371: train_loss=0.19296912848949432
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 372: train_loss=0.19592227041721344
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 373: train_loss=0.19333551824092865
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 374: train_loss=0.19596679508686066
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 375: train_loss=0.1947374939918518
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 376: train_loss=0.1940513402223587
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 377: train_loss=0.19383607804775238
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 378: train_loss=0.19281373918056488
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 379: train_loss=0.1931600272655487
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 380: train_loss=0.19087712466716766
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 381: train_loss=0.19503392279148102
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 382: train_loss=0.19057895243167877
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 383: train_loss=0.19924834370613098
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 384: train_loss=0.197916179895401
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 385: train_loss=0.19332490861415863
INFO - 04/15/25 16:47:34 - 0:15:57 - Epoch 386: train_loss=0.19342441856861115
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 387: train_loss=0.19496336579322815
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 388: train_loss=0.1931879222393036
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 389: train_loss=0.19530105590820312
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 390: train_loss=0.1945580095052719
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 391: train_loss=0.19344626367092133
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 392: train_loss=0.1920594871044159
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 393: train_loss=0.19580957293510437
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 394: train_loss=0.19381777942180634
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 395: train_loss=0.1950073540210724
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 396: train_loss=0.194743812084198
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 397: train_loss=0.19230668246746063
INFO - 04/15/25 16:47:34 - 0:15:58 - Epoch 398: train_loss=0.19094756245613098
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 399: train_loss=0.1959093064069748
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 400: train_loss=0.19423283636569977
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 401: train_loss=0.19344472885131836
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 402: train_loss=0.1928243339061737
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 403: train_loss=0.19338376820087433
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 404: train_loss=0.1922265589237213
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 405: train_loss=0.19405271112918854
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 406: train_loss=0.1927320808172226
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 407: train_loss=0.19377245008945465
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 408: train_loss=0.1929887980222702
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 409: train_loss=0.19274654984474182
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 410: train_loss=0.1914917379617691
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 411: train_loss=0.19417835772037506
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 412: train_loss=0.19341899454593658
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 413: train_loss=0.1916753202676773
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 414: train_loss=0.19055324792861938
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 415: train_loss=0.19448570907115936
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 416: train_loss=0.1935862898826599
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 417: train_loss=0.19119977951049805
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 418: train_loss=0.1902560144662857
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 419: train_loss=0.19412226974964142
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 420: train_loss=0.19316399097442627
INFO - 04/15/25 16:47:35 - 0:15:58 - Epoch 421: train_loss=0.19112372398376465
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 422: train_loss=0.1902523636817932
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 423: train_loss=0.19369591772556305
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 424: train_loss=0.1926993727684021
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 425: train_loss=0.19111670553684235
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 426: train_loss=0.19021126627922058
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 427: train_loss=0.193215474486351
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 428: train_loss=0.192252054810524
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 429: train_loss=0.1910209059715271
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 430: train_loss=0.19011688232421875
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 431: train_loss=0.1929057091474533
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 432: train_loss=0.1920052170753479
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 433: train_loss=0.19076716899871826
INFO - 04/15/25 16:47:35 - 0:15:59 - Epoch 434: train_loss=0.1897921860218048
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 435: train_loss=0.19286030530929565
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 436: train_loss=0.19206185638904572
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 437: train_loss=0.1902506947517395
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 438: train_loss=0.1893080472946167
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 439: train_loss=0.19295255839824677
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 440: train_loss=0.19217093288898468
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 441: train_loss=0.1898059844970703
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 442: train_loss=0.18883343040943146
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 443: train_loss=0.19298005104064941
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 444: train_loss=0.19219502806663513
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 445: train_loss=0.189358651638031
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 446: train_loss=0.18847742676734924
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 447: train_loss=0.19307972490787506
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 448: train_loss=0.19228890538215637
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 449: train_loss=0.18892452120780945
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 450: train_loss=0.18913160264492035
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 451: train_loss=0.1917414516210556
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 452: train_loss=0.18967890739440918
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 453: train_loss=0.19183321297168732
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 454: train_loss=0.19171558320522308
INFO - 04/15/25 16:47:36 - 0:15:59 - Epoch 455: train_loss=0.18802227079868317
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 456: train_loss=0.18882042169570923
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 457: train_loss=0.1934787482023239
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 458: train_loss=0.18953296542167664
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 459: train_loss=0.1957487314939499
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 460: train_loss=0.19460374116897583
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 461: train_loss=0.19296501576900482
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 462: train_loss=0.19188225269317627
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 463: train_loss=0.1929488629102707
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 464: train_loss=0.18893681466579437
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 465: train_loss=0.18702006340026855
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 466: train_loss=0.19819536805152893
INFO - 04/15/25 16:47:36 - 0:16:00 - Epoch 467: train_loss=0.19672060012817383
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 468: train_loss=0.191807821393013
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 469: train_loss=0.19226433336734772
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 470: train_loss=0.193801611661911
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 471: train_loss=0.18713542819023132
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 472: train_loss=0.19832652807235718
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 473: train_loss=0.19344015419483185
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 474: train_loss=0.19742752611637115
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 475: train_loss=0.1989513486623764
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 476: train_loss=0.18605010211467743
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 477: train_loss=0.18678495287895203
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 478: train_loss=0.1929982751607895
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 479: train_loss=0.18776103854179382
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 480: train_loss=0.19683301448822021
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 481: train_loss=0.19591417908668518
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 482: train_loss=0.19034536182880402
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 483: train_loss=0.19252091646194458
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 484: train_loss=0.19128578901290894
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 485: train_loss=0.19047600030899048
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 486: train_loss=0.18998567759990692
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 487: train_loss=0.19096021354198456
INFO - 04/15/25 16:47:37 - 0:16:00 - Epoch 488: train_loss=0.1883734166622162
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 489: train_loss=0.19316977262496948
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 490: train_loss=0.19023428857326508
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 491: train_loss=0.19334112107753754
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 492: train_loss=0.1919442117214203
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 493: train_loss=0.1918858289718628
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 494: train_loss=0.1905031055212021
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 495: train_loss=0.19199851155281067
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 496: train_loss=0.1898377537727356
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 497: train_loss=0.19206666946411133
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 498: train_loss=0.19015540182590485
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 499: train_loss=0.19156743586063385
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 500: train_loss=0.19063685834407806
INFO - 04/15/25 16:47:37 - 0:16:01 - Epoch 501: train_loss=0.18993330001831055
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 502: train_loss=0.1902998685836792
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 503: train_loss=0.18793566524982452
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 504: train_loss=0.1913604885339737
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 505: train_loss=0.18660220503807068
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 506: train_loss=0.1959865838289261
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 507: train_loss=0.19414135813713074
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 508: train_loss=0.19060856103897095
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 509: train_loss=0.19079075753688812
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 510: train_loss=0.1917213350534439
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 511: train_loss=0.18865232169628143
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 512: train_loss=0.19495868682861328
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 513: train_loss=0.1937250792980194
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 514: train_loss=0.18956385552883148
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 515: train_loss=0.18931794166564941
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 516: train_loss=0.1919289082288742
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 517: train_loss=0.1898120939731598
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 518: train_loss=0.19326269626617432
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 519: train_loss=0.19269339740276337
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 520: train_loss=0.18936483561992645
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 521: train_loss=0.18864063918590546
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 522: train_loss=0.19252778589725494
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 523: train_loss=0.19058465957641602
INFO - 04/15/25 16:47:38 - 0:16:01 - Epoch 524: train_loss=0.1918180286884308
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 525: train_loss=0.19149881601333618
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 526: train_loss=0.18922455608844757
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 527: train_loss=0.18797768652439117
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 528: train_loss=0.19298115372657776
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 529: train_loss=0.19188448786735535
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 530: train_loss=0.18927517533302307
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 531: train_loss=0.1886797547340393
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 532: train_loss=0.19148360192775726
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 533: train_loss=0.18999126553535461
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 534: train_loss=0.19094602763652802
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 535: train_loss=0.19042739272117615
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 536: train_loss=0.18939025700092316
INFO - 04/15/25 16:47:38 - 0:16:02 - Epoch 537: train_loss=0.18818148970603943
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 538: train_loss=0.19195199012756348
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 539: train_loss=0.19109293818473816
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 540: train_loss=0.18856331706047058
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 541: train_loss=0.18781448900699615
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 542: train_loss=0.19123592972755432
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 543: train_loss=0.18980136513710022
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 544: train_loss=0.189907044172287
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 545: train_loss=0.18941813707351685
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 546: train_loss=0.1893877238035202
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 547: train_loss=0.1882605254650116
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 548: train_loss=0.19066482782363892
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 549: train_loss=0.1896800994873047
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 550: train_loss=0.18914861977100372
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 551: train_loss=0.18843652307987213
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 552: train_loss=0.189714714884758
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 553: train_loss=0.18853627145290375
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 554: train_loss=0.19006502628326416
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 555: train_loss=0.18920163810253143
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 556: train_loss=0.18888446688652039
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 557: train_loss=0.18802034854888916
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 558: train_loss=0.189895361661911
INFO - 04/15/25 16:47:39 - 0:16:02 - Epoch 559: train_loss=0.18890047073364258
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 560: train_loss=0.18894241750240326
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 561: train_loss=0.18812280893325806
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 562: train_loss=0.18933039903640747
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 563: train_loss=0.18834072351455688
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 564: train_loss=0.1890372335910797
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 565: train_loss=0.1882193684577942
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 566: train_loss=0.18897072970867157
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 567: train_loss=0.1881004124879837
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 568: train_loss=0.1888323873281479
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 569: train_loss=0.18787892162799835
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 570: train_loss=0.18926012516021729
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 571: train_loss=0.18834218382835388
INFO - 04/15/25 16:47:39 - 0:16:03 - Epoch 572: train_loss=0.18841610848903656
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 573: train_loss=0.1876048892736435
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 574: train_loss=0.18898311257362366
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 575: train_loss=0.18826720118522644
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 576: train_loss=0.1881493479013443
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 577: train_loss=0.18722929060459137
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 578: train_loss=0.18905778229236603
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 579: train_loss=0.18838337063789368
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 580: train_loss=0.1879890114068985
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 581: train_loss=0.18680164217948914
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 582: train_loss=0.18933171033859253
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 583: train_loss=0.1886451691389084
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 584: train_loss=0.1872515231370926
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 585: train_loss=0.18632462620735168
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 586: train_loss=0.19000591337680817
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 587: train_loss=0.18976661562919617
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 588: train_loss=0.18527568876743317
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 589: train_loss=0.1839398294687271
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 590: train_loss=0.19185592234134674
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 591: train_loss=0.1914406269788742
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 592: train_loss=0.18359224498271942
INFO - 04/15/25 16:47:40 - 0:16:03 - Epoch 593: train_loss=0.18538586795330048
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 594: train_loss=0.187990203499794
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 595: train_loss=0.18425966799259186
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 596: train_loss=0.19433344900608063
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 597: train_loss=0.19529347121715546
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 598: train_loss=0.18482045829296112
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 599: train_loss=0.19618840515613556
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 600: train_loss=0.2005552053451538
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 601: train_loss=0.19194619357585907
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 602: train_loss=0.18991678953170776
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 603: train_loss=0.19550149142742157
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 604: train_loss=0.18845173716545105
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 605: train_loss=0.19179750978946686
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 606: train_loss=0.19614309072494507
INFO - 04/15/25 16:47:40 - 0:16:04 - Epoch 607: train_loss=0.18766430020332336
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 608: train_loss=0.19422346353530884
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 609: train_loss=0.1987934559583664
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 610: train_loss=0.1910225749015808
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 611: train_loss=0.18951939046382904
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 612: train_loss=0.19427677989006042
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 613: train_loss=0.18759553134441376
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 614: train_loss=0.1914469599723816
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 615: train_loss=0.19541007280349731
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 616: train_loss=0.18756279349327087
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 617: train_loss=0.19300176203250885
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 618: train_loss=0.1980554610490799
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 619: train_loss=0.19135789573192596
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 620: train_loss=0.18741664290428162
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 621: train_loss=0.19169020652770996
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 622: train_loss=0.18501439690589905
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 623: train_loss=0.19367998838424683
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 624: train_loss=0.19755548238754272
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 625: train_loss=0.18987613916397095
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 626: train_loss=0.18954473733901978
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 627: train_loss=0.1943419873714447
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 628: train_loss=0.18871153891086578
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 629: train_loss=0.18872767686843872
INFO - 04/15/25 16:47:41 - 0:16:04 - Epoch 630: train_loss=0.19213807582855225
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 631: train_loss=0.18492798507213593
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 632: train_loss=0.1937718540430069
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 633: train_loss=0.19815391302108765
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 634: train_loss=0.19121208786964417
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 635: train_loss=0.18768222630023956
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 636: train_loss=0.19228290021419525
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 637: train_loss=0.1889694482088089
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 638: train_loss=0.18644914031028748
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 639: train_loss=0.18844744563102722
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 640: train_loss=0.1825200617313385
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 641: train_loss=0.18695558607578278
INFO - 04/15/25 16:47:41 - 0:16:05 - Epoch 642: train_loss=0.18437524139881134
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 643: train_loss=0.1858145296573639
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 644: train_loss=0.186162531375885
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 645: train_loss=0.18355827033519745
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 646: train_loss=0.18643446266651154
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 647: train_loss=0.18455028533935547
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 648: train_loss=0.18705862760543823
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 649: train_loss=0.1873922348022461
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 650: train_loss=0.18301808834075928
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 651: train_loss=0.18561071157455444
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 652: train_loss=0.18441396951675415
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 653: train_loss=0.18479888141155243
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 654: train_loss=0.18355970084667206
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 655: train_loss=0.18590965867042542
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 656: train_loss=0.18481281399726868
INFO - 04/15/25 16:47:42 - 0:16:05 - Epoch 657: train_loss=0.18444587290287018
INFO - 04/15/25 16:47:42 - 0:16:06 - Epoch 658: train_loss=0.1851395219564438
INFO - 04/15/25 16:47:42 - 0:16:06 - Epoch 659: train_loss=0.18391399085521698
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 660: train_loss=0.18559327721595764
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 661: train_loss=0.18287906050682068
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 662: train_loss=0.187439426779747
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 663: train_loss=0.18622463941574097
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 664: train_loss=0.1851769983768463
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 665: train_loss=0.18615849316120148
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 666: train_loss=0.18353553116321564
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 667: train_loss=0.18589292466640472
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 668: train_loss=0.18584629893302917
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 669: train_loss=0.18230387568473816
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 670: train_loss=0.19075891375541687
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 671: train_loss=0.1890062689781189
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 672: train_loss=0.18827034533023834
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 673: train_loss=0.18648596107959747
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 674: train_loss=0.18988025188446045
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 675: train_loss=0.18854884803295135
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 676: train_loss=0.1884474903345108
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 677: train_loss=0.1865324079990387
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 678: train_loss=0.19079366326332092
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 679: train_loss=0.19107216596603394
INFO - 04/15/25 16:47:43 - 0:16:06 - Epoch 680: train_loss=0.18347415328025818
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 681: train_loss=0.18367086350917816
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 682: train_loss=0.18630512058734894
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 683: train_loss=0.1831614226102829
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 684: train_loss=0.18526031076908112
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 685: train_loss=0.18274076282978058
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 686: train_loss=0.19006739556789398
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 687: train_loss=0.18982931971549988
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 688: train_loss=0.18423473834991455
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 689: train_loss=0.18874622881412506
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 690: train_loss=0.18827715516090393
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 691: train_loss=0.18418991565704346
INFO - 04/15/25 16:47:43 - 0:16:07 - Epoch 692: train_loss=0.18482552468776703
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 693: train_loss=0.18488922715187073
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 694: train_loss=0.18468497693538666
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 695: train_loss=0.18387539684772491
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 696: train_loss=0.1826450526714325
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 697: train_loss=0.18760566413402557
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 698: train_loss=0.18635402619838715
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 699: train_loss=0.18591804802417755
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 700: train_loss=0.1857224404811859
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 701: train_loss=0.18485252559185028
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 702: train_loss=0.18657848238945007
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 703: train_loss=0.18202516436576843
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 704: train_loss=0.19107188284397125
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 705: train_loss=0.18878699839115143
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 706: train_loss=0.187676340341568
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 707: train_loss=0.18782009184360504
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 708: train_loss=0.1870562881231308
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 709: train_loss=0.18597085773944855
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 710: train_loss=0.18890397250652313
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 711: train_loss=0.18716131150722504
INFO - 04/15/25 16:47:44 - 0:16:07 - Epoch 712: train_loss=0.1886189728975296
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 713: train_loss=0.1886903941631317
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 714: train_loss=0.18464922904968262
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 715: train_loss=0.1835438460111618
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 716: train_loss=0.18963374197483063
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 717: train_loss=0.18776553869247437
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 718: train_loss=0.18744951486587524
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 719: train_loss=0.18692226707935333
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 720: train_loss=0.18750441074371338
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 721: train_loss=0.18647024035453796
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 722: train_loss=0.1878826767206192
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 723: train_loss=0.18718354403972626
INFO - 04/15/25 16:47:44 - 0:16:08 - Epoch 724: train_loss=0.1871602088212967
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 725: train_loss=0.18647846579551697
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 726: train_loss=0.1869920939207077
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 727: train_loss=0.1860220730304718
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 728: train_loss=0.1881115436553955
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 729: train_loss=0.1877993494272232
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 730: train_loss=0.18563449382781982
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 731: train_loss=0.18465575575828552
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 732: train_loss=0.18891651928424835
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 733: train_loss=0.18818305432796478
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 734: train_loss=0.18515928089618683
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 735: train_loss=0.1845562905073166
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 736: train_loss=0.18848666548728943
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 737: train_loss=0.18766267597675323
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 738: train_loss=0.18540026247501373
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 739: train_loss=0.18460999429225922
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 740: train_loss=0.18829965591430664
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 741: train_loss=0.18753932416439056
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 742: train_loss=0.1853906512260437
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 743: train_loss=0.18469145894050598
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 744: train_loss=0.18776394426822662
INFO - 04/15/25 16:47:45 - 0:16:08 - Epoch 745: train_loss=0.186903178691864
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 746: train_loss=0.18593832850456238
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 747: train_loss=0.18545614182949066
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 748: train_loss=0.18683487176895142
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 749: train_loss=0.18584059178829193
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 750: train_loss=0.1867108941078186
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 751: train_loss=0.18585069477558136
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 752: train_loss=0.1864689290523529
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 753: train_loss=0.1855461746454239
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 754: train_loss=0.18644379079341888
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 755: train_loss=0.1854507029056549
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 756: train_loss=0.18698778748512268
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 757: train_loss=0.18641771376132965
INFO - 04/15/25 16:47:45 - 0:16:09 - Epoch 758: train_loss=0.18532228469848633
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 759: train_loss=0.18455100059509277
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 760: train_loss=0.18716289103031158
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 761: train_loss=0.1864292174577713
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 762: train_loss=0.18559196591377258
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 763: train_loss=0.1851167231798172
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 764: train_loss=0.18650910258293152
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 765: train_loss=0.18614017963409424
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 766: train_loss=0.18558238446712494
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 767: train_loss=0.18504682183265686
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 768: train_loss=0.18654485046863556
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 769: train_loss=0.1862722635269165
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 770: train_loss=0.18501248955726624
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 771: train_loss=0.1840047389268875
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 772: train_loss=0.1876489371061325
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 773: train_loss=0.18730977177619934
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 774: train_loss=0.18318302929401398
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 775: train_loss=0.18277473747730255
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 776: train_loss=0.18834981322288513
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 777: train_loss=0.1868705004453659
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 778: train_loss=0.1853107362985611
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 779: train_loss=0.18526491522789001
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 780: train_loss=0.18449558317661285
INFO - 04/15/25 16:47:46 - 0:16:09 - Epoch 781: train_loss=0.18488538265228271
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 782: train_loss=0.18417643010616302
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 783: train_loss=0.18209023773670197
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 784: train_loss=0.18951521813869476
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 785: train_loss=0.18787294626235962
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 786: train_loss=0.1862255334854126
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 787: train_loss=0.1864033043384552
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 788: train_loss=0.1861605942249298
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 789: train_loss=0.18504184484481812
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 790: train_loss=0.18513286113739014
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 791: train_loss=0.18593060970306396
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 792: train_loss=0.18365438282489777
INFO - 04/15/25 16:47:46 - 0:16:10 - Epoch 793: train_loss=0.18927370011806488
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 794: train_loss=0.1883150190114975
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 795: train_loss=0.18596819043159485
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 796: train_loss=0.18583764135837555
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 797: train_loss=0.18694889545440674
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 798: train_loss=0.1834983229637146
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 799: train_loss=0.1884455680847168
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 800: train_loss=0.18446128070354462
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 801: train_loss=0.1915782243013382
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 802: train_loss=0.19196896255016327
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 803: train_loss=0.18336713314056396
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 804: train_loss=0.1893978714942932
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 805: train_loss=0.18804660439491272
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 806: train_loss=0.18553462624549866
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 807: train_loss=0.18721216917037964
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 808: train_loss=0.1856331080198288
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 809: train_loss=0.18642060458660126
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 810: train_loss=0.1861869990825653
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 811: train_loss=0.1853979527950287
INFO - 04/15/25 16:47:47 - 0:16:10 - Epoch 812: train_loss=0.18494735658168793
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 813: train_loss=0.18551528453826904
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 814: train_loss=0.1843709945678711
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 815: train_loss=0.18527862429618835
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 816: train_loss=0.18423853814601898
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 817: train_loss=0.18498577177524567
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 818: train_loss=0.18348947167396545
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 819: train_loss=0.1866309940814972
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 820: train_loss=0.18510404229164124
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 821: train_loss=0.18665064871311188
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 822: train_loss=0.1864335536956787
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 823: train_loss=0.18478308618068695
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 824: train_loss=0.1850922554731369
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 825: train_loss=0.18407152593135834
INFO - 04/15/25 16:47:47 - 0:16:11 - Epoch 826: train_loss=0.18533436954021454
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 827: train_loss=0.18288394808769226
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 828: train_loss=0.1866629421710968
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 829: train_loss=0.18462511897087097
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 830: train_loss=0.18656980991363525
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 831: train_loss=0.18598775565624237
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 832: train_loss=0.18493133783340454
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 833: train_loss=0.1855354905128479
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 834: train_loss=0.18390348553657532
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 835: train_loss=0.18718697130680084
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 836: train_loss=0.18622392416000366
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 837: train_loss=0.1854839026927948
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 838: train_loss=0.18524958193302155
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 839: train_loss=0.18524090945720673
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 840: train_loss=0.18466247618198395
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 841: train_loss=0.18474239110946655
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 842: train_loss=0.1846723109483719
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 843: train_loss=0.18327732384204865
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 844: train_loss=0.18667525053024292
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 845: train_loss=0.1842609941959381
INFO - 04/15/25 16:47:48 - 0:16:11 - Epoch 846: train_loss=0.18809941411018372
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 847: train_loss=0.18829643726348877
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 848: train_loss=0.18354099988937378
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 849: train_loss=0.1861952543258667
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 850: train_loss=0.1843641996383667
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 851: train_loss=0.1860128939151764
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 852: train_loss=0.18556682765483856
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 853: train_loss=0.18441396951675415
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 854: train_loss=0.18526726961135864
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 855: train_loss=0.18283319473266602
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 856: train_loss=0.1891111135482788
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 857: train_loss=0.18810854852199554
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 858: train_loss=0.1840740293264389
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 859: train_loss=0.1840531826019287
INFO - 04/15/25 16:47:48 - 0:16:12 - Epoch 860: train_loss=0.18562158942222595
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 861: train_loss=0.18349689245224
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 862: train_loss=0.18651939928531647
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 863: train_loss=0.1843922734260559
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 864: train_loss=0.18679620325565338
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 865: train_loss=0.1854795217514038
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 866: train_loss=0.186278834939003
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 867: train_loss=0.18510693311691284
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 868: train_loss=0.1864641159772873
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 869: train_loss=0.1849941909313202
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 870: train_loss=0.18697749078273773
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 871: train_loss=0.1861482858657837
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 872: train_loss=0.1854938417673111
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 873: train_loss=0.18516577780246735
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 874: train_loss=0.18543584644794464
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 875: train_loss=0.18453383445739746
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 876: train_loss=0.1859862506389618
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 877: train_loss=0.18503421545028687
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 878: train_loss=0.18592292070388794
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 879: train_loss=0.18537262082099915
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 880: train_loss=0.18522240221500397
INFO - 04/15/25 16:47:49 - 0:16:12 - Epoch 881: train_loss=0.18441440165042877
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 882: train_loss=0.18637889623641968
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 883: train_loss=0.18540814518928528
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 884: train_loss=0.18545357882976532
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 885: train_loss=0.18482807278633118
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 886: train_loss=0.18585634231567383
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 887: train_loss=0.18506017327308655
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 888: train_loss=0.18557316064834595
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 889: train_loss=0.18483257293701172
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 890: train_loss=0.1855635792016983
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 891: train_loss=0.18502023816108704
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 892: train_loss=0.1852021962404251
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 893: train_loss=0.1845443993806839
INFO - 04/15/25 16:47:49 - 0:16:13 - Epoch 894: train_loss=0.18574222922325134
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 895: train_loss=0.18514148890972137
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 896: train_loss=0.18495574593544006
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 897: train_loss=0.18440645933151245
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 898: train_loss=0.18562312424182892
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 899: train_loss=0.1849461793899536
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 900: train_loss=0.18506628274917603
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 901: train_loss=0.1844651848077774
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 902: train_loss=0.1854063719511032
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 903: train_loss=0.18476656079292297
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 904: train_loss=0.1850752979516983
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 905: train_loss=0.18439573049545288
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 906: train_loss=0.1853962391614914
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 907: train_loss=0.1848820596933365
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 908: train_loss=0.18472151458263397
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 909: train_loss=0.18408311903476715
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 910: train_loss=0.1855083405971527
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 911: train_loss=0.18505023419857025
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 912: train_loss=0.18437311053276062
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 913: train_loss=0.18366612493991852
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 914: train_loss=0.18586820363998413
INFO - 04/15/25 16:47:50 - 0:16:13 - Epoch 915: train_loss=0.18544575572013855
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 916: train_loss=0.18374919891357422
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 917: train_loss=0.18298661708831787
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 918: train_loss=0.1864413172006607
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 919: train_loss=0.18606425821781158
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 920: train_loss=0.18293216824531555
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 921: train_loss=0.182261124253273
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 922: train_loss=0.18702958524227142
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 923: train_loss=0.18656529486179352
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 924: train_loss=0.18256200850009918
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 925: train_loss=0.18208017945289612
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 926: train_loss=0.1866186559200287
INFO - 04/15/25 16:47:50 - 0:16:14 - Epoch 927: train_loss=0.18572573363780975
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 928: train_loss=0.18349483609199524
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 929: train_loss=0.18336476385593414
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 930: train_loss=0.1848926544189453
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 931: train_loss=0.1837795078754425
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 932: train_loss=0.1854369193315506
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 933: train_loss=0.18515385687351227
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 934: train_loss=0.18339002132415771
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 935: train_loss=0.182851180434227
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 936: train_loss=0.18555830419063568
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 937: train_loss=0.18456551432609558
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 938: train_loss=0.18442052602767944
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 939: train_loss=0.18418948352336884
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 940: train_loss=0.1839827448129654
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 941: train_loss=0.18315553665161133
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 942: train_loss=0.18533356487751007
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 943: train_loss=0.18483319878578186
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 944: train_loss=0.18359388411045074
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 945: train_loss=0.18317273259162903
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 946: train_loss=0.1848464161157608
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 947: train_loss=0.18398140370845795
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 948: train_loss=0.18440203368663788
INFO - 04/15/25 16:47:51 - 0:16:14 - Epoch 949: train_loss=0.18387214839458466
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 950: train_loss=0.18420037627220154
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 951: train_loss=0.18363913893699646
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 952: train_loss=0.18444755673408508
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 953: train_loss=0.18375760316848755
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 954: train_loss=0.18443606793880463
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 955: train_loss=0.18396031856536865
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 956: train_loss=0.18394114077091217
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 957: train_loss=0.18335042893886566
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 958: train_loss=0.18451471626758575
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 959: train_loss=0.18392781913280487
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 960: train_loss=0.18402718007564545
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 961: train_loss=0.18353275954723358
INFO - 04/15/25 16:47:51 - 0:16:15 - Epoch 962: train_loss=0.1841334104537964
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 963: train_loss=0.18346449732780457
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 964: train_loss=0.18417927622795105
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 965: train_loss=0.183576300740242
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 966: train_loss=0.18406063318252563
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 967: train_loss=0.18360115587711334
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 968: train_loss=0.18386967480182648
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 969: train_loss=0.1832183301448822
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 970: train_loss=0.18417736887931824
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 971: train_loss=0.18361914157867432
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 972: train_loss=0.18378946185112
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 973: train_loss=0.18330222368240356
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 974: train_loss=0.1838766187429428
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 975: train_loss=0.1833062320947647
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 976: train_loss=0.18390418589115143
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 977: train_loss=0.1833288073539734
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 978: train_loss=0.18391679227352142
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 979: train_loss=0.18349014222621918
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 980: train_loss=0.18354198336601257
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 981: train_loss=0.18296149373054504
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 982: train_loss=0.1840863674879074
INFO - 04/15/25 16:47:52 - 0:16:15 - Epoch 983: train_loss=0.1835886538028717
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 984: train_loss=0.1833944022655487
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 985: train_loss=0.18285654485225677
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 986: train_loss=0.18418246507644653
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 987: train_loss=0.1837766170501709
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 988: train_loss=0.18304312229156494
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 989: train_loss=0.18240533769130707
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 990: train_loss=0.1845238208770752
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 991: train_loss=0.1842518150806427
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 992: train_loss=0.18228690326213837
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 993: train_loss=0.18166784942150116
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 994: train_loss=0.18510717153549194
INFO - 04/15/25 16:47:52 - 0:16:16 - Epoch 995: train_loss=0.1847696602344513
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 996: train_loss=0.1816808432340622
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 997: train_loss=0.18138006329536438
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 998: train_loss=0.18536096811294556
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 999: train_loss=0.18438763916492462
INFO - 04/15/25 16:47:53 - 0:16:16 - --------------------------Training Start-------------------------
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 1: train_loss=10.083486557006836
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 2: train_loss=10.188672065734863
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 3: train_loss=10.172872543334961
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 4: train_loss=10.135285377502441
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 5: train_loss=10.098373413085938
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 6: train_loss=10.10220718383789
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 7: train_loss=10.109644889831543
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 8: train_loss=10.103693008422852
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 9: train_loss=10.090828895568848
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 10: train_loss=10.082671165466309
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 11: train_loss=10.084914207458496
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 12: train_loss=10.080584526062012
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 13: train_loss=10.078412055969238
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 14: train_loss=10.078269004821777
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 15: train_loss=10.077005386352539
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 16: train_loss=10.077794075012207
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 17: train_loss=10.074583053588867
INFO - 04/15/25 16:47:53 - 0:16:16 - Epoch 18: train_loss=10.071148872375488
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 19: train_loss=10.06917953491211
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 20: train_loss=10.067585945129395
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 21: train_loss=10.070306777954102
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 22: train_loss=10.069201469421387
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 23: train_loss=10.068742752075195
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 24: train_loss=10.066036224365234
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 25: train_loss=10.067126274108887
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 26: train_loss=10.066269874572754
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 27: train_loss=10.066752433776855
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 28: train_loss=10.066349983215332
INFO - 04/15/25 16:47:53 - 0:16:17 - Epoch 29: train_loss=10.066690444946289
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 30: train_loss=10.064786911010742
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 31: train_loss=10.065382957458496
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 32: train_loss=10.067828178405762
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 33: train_loss=10.064165115356445
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 34: train_loss=10.065476417541504
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 35: train_loss=10.066473007202148
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 36: train_loss=10.065006256103516
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 37: train_loss=10.062071800231934
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 38: train_loss=10.06508731842041
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 39: train_loss=10.06611156463623
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 40: train_loss=10.063566207885742
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 41: train_loss=10.066780090332031
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 42: train_loss=10.062965393066406
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 43: train_loss=10.066173553466797
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 44: train_loss=10.063600540161133
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 45: train_loss=10.067473411560059
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 46: train_loss=10.065997123718262
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 47: train_loss=10.065794944763184
INFO - 04/15/25 16:47:54 - 0:16:17 - Epoch 48: train_loss=10.066014289855957
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 49: train_loss=10.063481330871582
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 50: train_loss=10.065423965454102
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 51: train_loss=10.062199592590332
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 52: train_loss=10.065373420715332
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 53: train_loss=10.06303596496582
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 54: train_loss=10.066471099853516
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 55: train_loss=10.06556510925293
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 56: train_loss=10.063288688659668
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 57: train_loss=10.064824104309082
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 58: train_loss=10.062196731567383
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 59: train_loss=10.065925598144531
INFO - 04/15/25 16:47:54 - 0:16:18 - Epoch 60: train_loss=10.061784744262695
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 61: train_loss=10.065438270568848
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 62: train_loss=10.0628662109375
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 63: train_loss=10.06698226928711
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 64: train_loss=10.067334175109863
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 65: train_loss=10.062524795532227
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 66: train_loss=10.067201614379883
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 67: train_loss=10.066025733947754
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 68: train_loss=10.064559936523438
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 69: train_loss=10.066445350646973
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 70: train_loss=10.06593132019043
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 71: train_loss=10.0642671585083
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 72: train_loss=10.066254615783691
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 73: train_loss=10.064981460571289
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 74: train_loss=10.065116882324219
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 75: train_loss=10.065261840820312
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 76: train_loss=10.06423568725586
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 77: train_loss=10.065677642822266
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 78: train_loss=10.064369201660156
INFO - 04/15/25 16:47:55 - 0:16:18 - Epoch 79: train_loss=10.065008163452148
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 80: train_loss=10.06364917755127
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 81: train_loss=10.064352989196777
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 82: train_loss=10.062056541442871
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 83: train_loss=10.066884994506836
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 84: train_loss=10.064319610595703
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 85: train_loss=10.067647933959961
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 86: train_loss=10.064202308654785
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 87: train_loss=10.070444107055664
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 88: train_loss=10.070405960083008
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 89: train_loss=10.062582969665527
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 90: train_loss=10.066645622253418
INFO - 04/15/25 16:47:55 - 0:16:19 - Epoch 91: train_loss=10.064632415771484
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 92: train_loss=10.065263748168945
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 93: train_loss=10.065037727355957
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 94: train_loss=10.063151359558105
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 95: train_loss=10.0670166015625
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 96: train_loss=10.062803268432617
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 97: train_loss=10.071333885192871
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 98: train_loss=10.072128295898438
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 99: train_loss=10.062403678894043
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 100: train_loss=10.072553634643555
INFO - 04/15/25 16:47:56 - 0:16:19 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:47:56 - 0:16:19 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:47:56 - 0:16:19 - ------------------Saving best model-------------------
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 100: ACC: 0.0, NMI: 0.11307727221121458, F1: 0.0, ARI: 0.007823663740570938
INFO - 04/15/25 16:47:56 - 0:16:19 - -------------------------------------------------------------------------
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 101: train_loss=10.074736595153809
INFO - 04/15/25 16:47:56 - 0:16:19 - Epoch 102: train_loss=10.066635131835938
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 103: train_loss=10.070330619812012
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 104: train_loss=10.073691368103027
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 105: train_loss=10.06857681274414
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 106: train_loss=10.067055702209473
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 107: train_loss=10.069512367248535
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 108: train_loss=10.068535804748535
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 109: train_loss=10.064151763916016
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 110: train_loss=10.069039344787598
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 111: train_loss=10.069416999816895
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 112: train_loss=10.06080150604248
INFO - 04/15/25 16:47:56 - 0:16:20 - Epoch 113: train_loss=10.073136329650879
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 114: train_loss=10.073934555053711
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 115: train_loss=10.063642501831055
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 116: train_loss=10.073254585266113
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 117: train_loss=10.076833724975586
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 118: train_loss=10.069478034973145
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 119: train_loss=10.068111419677734
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 120: train_loss=10.072615623474121
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 121: train_loss=10.067916870117188
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 122: train_loss=10.066011428833008
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 123: train_loss=10.069066047668457
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 124: train_loss=10.064332008361816
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 125: train_loss=10.067586898803711
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 126: train_loss=10.06778621673584
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 127: train_loss=10.064923286437988
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 128: train_loss=10.065863609313965
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 129: train_loss=10.065849304199219
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 130: train_loss=10.063541412353516
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 131: train_loss=10.065454483032227
INFO - 04/15/25 16:47:57 - 0:16:20 - Epoch 132: train_loss=10.06438159942627
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 133: train_loss=10.063694953918457
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 134: train_loss=10.063756942749023
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 135: train_loss=10.063434600830078
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 136: train_loss=10.062481880187988
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 137: train_loss=10.065003395080566
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 138: train_loss=10.064501762390137
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 139: train_loss=10.062793731689453
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 140: train_loss=10.062829971313477
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 141: train_loss=10.063159942626953
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 142: train_loss=10.06251335144043
INFO - 04/15/25 16:47:57 - 0:16:21 - Epoch 143: train_loss=10.062949180603027
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 144: train_loss=10.062132835388184
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 145: train_loss=10.063531875610352
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 146: train_loss=10.06239128112793
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 147: train_loss=10.064414024353027
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 148: train_loss=10.064191818237305
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 149: train_loss=10.061959266662598
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 150: train_loss=10.061697959899902
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 151: train_loss=10.063791275024414
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 152: train_loss=10.062707901000977
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 153: train_loss=10.063671112060547
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 154: train_loss=10.063633918762207
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 155: train_loss=10.061786651611328
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 156: train_loss=10.061697006225586
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 157: train_loss=10.064970016479492
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 158: train_loss=10.06381607055664
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 159: train_loss=10.062505722045898
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 160: train_loss=10.066694259643555
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 161: train_loss=10.061897277832031
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 162: train_loss=10.072393417358398
INFO - 04/15/25 16:47:58 - 0:16:21 - Epoch 163: train_loss=10.073592185974121
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 164: train_loss=10.065423965454102
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 165: train_loss=10.070232391357422
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 166: train_loss=10.069786071777344
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 167: train_loss=10.06906795501709
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 168: train_loss=10.067831039428711
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 169: train_loss=10.065289497375488
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 170: train_loss=10.067937850952148
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 171: train_loss=10.060781478881836
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 172: train_loss=10.07092571258545
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 173: train_loss=10.07244873046875
INFO - 04/15/25 16:47:58 - 0:16:22 - Epoch 174: train_loss=10.06599235534668
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 175: train_loss=10.067099571228027
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 176: train_loss=10.069360733032227
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 177: train_loss=10.067955017089844
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 178: train_loss=10.063989639282227
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 179: train_loss=10.067777633666992
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 180: train_loss=10.068136215209961
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 181: train_loss=10.063996315002441
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 182: train_loss=10.065646171569824
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 183: train_loss=10.067170143127441
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 184: train_loss=10.061756134033203
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 185: train_loss=10.070086479187012
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 186: train_loss=10.071964263916016
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 187: train_loss=10.065679550170898
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 188: train_loss=10.067103385925293
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 189: train_loss=10.068279266357422
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 190: train_loss=10.068253517150879
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 191: train_loss=10.064475059509277
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 192: train_loss=10.067636489868164
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 193: train_loss=10.069892883300781
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 194: train_loss=10.06324577331543
INFO - 04/15/25 16:47:59 - 0:16:22 - Epoch 195: train_loss=10.067792892456055
INFO - 04/15/25 16:47:59 - 0:16:23 - Epoch 196: train_loss=10.070169448852539
INFO - 04/15/25 16:47:59 - 0:16:23 - Epoch 197: train_loss=10.067079544067383
INFO - 04/15/25 16:47:59 - 0:16:23 - Epoch 198: train_loss=10.06386947631836
INFO - 04/15/25 16:47:59 - 0:16:23 - Epoch 199: train_loss=10.067327499389648
INFO - 04/15/25 16:47:59 - 0:16:23 - Epoch 200: train_loss=10.068303108215332
INFO - 04/15/25 16:47:59 - 0:16:23 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:47:59 - 0:16:23 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:48:00 - 0:16:23 - ------------------Saving best model-------------------
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 200: ACC: 0.0, NMI: 0.22651108049126395, F1: 0.0, ARI: 0.030570669559135615
INFO - 04/15/25 16:48:01 - 0:16:24 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 201: train_loss=10.062209129333496
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 202: train_loss=10.06787109375
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 203: train_loss=10.070441246032715
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 204: train_loss=10.06574535369873
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 205: train_loss=10.064435958862305
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 206: train_loss=10.066956520080566
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 207: train_loss=10.065658569335938
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 208: train_loss=10.062652587890625
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 209: train_loss=10.066128730773926
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 210: train_loss=10.06603717803955
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 211: train_loss=10.060067176818848
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 212: train_loss=10.06279468536377
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 213: train_loss=10.060395240783691
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 214: train_loss=10.066208839416504
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 215: train_loss=10.064018249511719
INFO - 04/15/25 16:48:01 - 0:16:24 - Epoch 216: train_loss=10.06578540802002
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 217: train_loss=10.065016746520996
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 218: train_loss=10.065460205078125
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 219: train_loss=10.064325332641602
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 220: train_loss=10.065563201904297
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 221: train_loss=10.065173149108887
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 222: train_loss=10.063791275024414
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 223: train_loss=10.063372611999512
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 224: train_loss=10.064629554748535
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 225: train_loss=10.06243896484375
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 226: train_loss=10.066253662109375
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 227: train_loss=10.064533233642578
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 228: train_loss=10.065401077270508
INFO - 04/15/25 16:48:01 - 0:16:25 - Epoch 229: train_loss=10.065134048461914
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 230: train_loss=10.063913345336914
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 231: train_loss=10.06367301940918
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 232: train_loss=10.064176559448242
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 233: train_loss=10.062739372253418
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 234: train_loss=10.064871788024902
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 235: train_loss=10.063092231750488
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 236: train_loss=10.065410614013672
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 237: train_loss=10.06434440612793
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 238: train_loss=10.06442642211914
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 239: train_loss=10.064048767089844
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 240: train_loss=10.063790321350098
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 241: train_loss=10.063307762145996
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 242: train_loss=10.063551902770996
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 243: train_loss=10.06299114227295
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 244: train_loss=10.062834739685059
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 245: train_loss=10.06311321258545
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 246: train_loss=10.061671257019043
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 247: train_loss=10.063740730285645
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 248: train_loss=10.061153411865234
INFO - 04/15/25 16:48:02 - 0:16:25 - Epoch 249: train_loss=10.065530776977539
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 250: train_loss=10.063908576965332
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 251: train_loss=10.064335823059082
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 252: train_loss=10.06434440612793
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 253: train_loss=10.062718391418457
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 254: train_loss=10.062849998474121
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 255: train_loss=10.06266975402832
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 256: train_loss=10.061966896057129
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 257: train_loss=10.063791275024414
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 258: train_loss=10.061850547790527
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 259: train_loss=10.066320419311523
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 260: train_loss=10.066436767578125
INFO - 04/15/25 16:48:02 - 0:16:26 - Epoch 261: train_loss=10.060701370239258
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 262: train_loss=10.064064979553223
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 263: train_loss=10.060491561889648
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 264: train_loss=10.068694114685059
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 265: train_loss=10.069412231445312
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 266: train_loss=10.061223983764648
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 267: train_loss=10.069808959960938
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 268: train_loss=10.072482109069824
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 269: train_loss=10.067286491394043
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 270: train_loss=10.064773559570312
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 271: train_loss=10.067366600036621
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 272: train_loss=10.066672325134277
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 273: train_loss=10.064168930053711
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 274: train_loss=10.064746856689453
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 275: train_loss=10.065898895263672
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 276: train_loss=10.063067436218262
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 277: train_loss=10.064505577087402
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 278: train_loss=10.06588363647461
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 279: train_loss=10.060249328613281
INFO - 04/15/25 16:48:03 - 0:16:26 - Epoch 280: train_loss=10.069977760314941
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 281: train_loss=10.073031425476074
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 282: train_loss=10.06750774383545
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 283: train_loss=10.063966751098633
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 284: train_loss=10.06748104095459
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 285: train_loss=10.066718101501465
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 286: train_loss=10.062219619750977
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 287: train_loss=10.067190170288086
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 288: train_loss=10.067399978637695
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 289: train_loss=10.062713623046875
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 290: train_loss=10.064823150634766
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 291: train_loss=10.065251350402832
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 292: train_loss=10.063603401184082
INFO - 04/15/25 16:48:03 - 0:16:27 - Epoch 293: train_loss=10.063462257385254
INFO - 04/15/25 16:48:04 - 0:16:27 - Epoch 294: train_loss=10.064154624938965
INFO - 04/15/25 16:48:04 - 0:16:27 - Epoch 295: train_loss=10.061796188354492
INFO - 04/15/25 16:48:04 - 0:16:27 - Epoch 296: train_loss=10.063457489013672
INFO - 04/15/25 16:48:04 - 0:16:27 - Epoch 297: train_loss=10.062878608703613
INFO - 04/15/25 16:48:04 - 0:16:27 - Epoch 298: train_loss=10.06195068359375
INFO - 04/15/25 16:48:04 - 0:16:27 - Epoch 299: train_loss=10.062305450439453
INFO - 04/15/25 16:48:04 - 0:16:27 - Epoch 300: train_loss=10.060672760009766
INFO - 04/15/25 16:48:04 - 0:16:27 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:04 - 0:16:27 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:48:04 - 0:16:27 - ------------------Saving best model-------------------
INFO - 04/15/25 16:48:06 - 0:16:29 - Epoch 300: ACC: 0.0, NMI: 0.27214214067736664, F1: 0.0, ARI: 0.039093739428674536
INFO - 04/15/25 16:48:06 - 0:16:29 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:06 - 0:16:29 - Epoch 301: train_loss=10.063210487365723
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 302: train_loss=10.059544563293457
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 303: train_loss=10.063681602478027
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 304: train_loss=10.06126880645752
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 305: train_loss=10.063690185546875
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 306: train_loss=10.06148910522461
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 307: train_loss=10.064098358154297
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 308: train_loss=10.061507225036621
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 309: train_loss=10.065451622009277
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 310: train_loss=10.065409660339355
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 311: train_loss=10.062274932861328
INFO - 04/15/25 16:48:06 - 0:16:30 - Epoch 312: train_loss=10.063634872436523
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 313: train_loss=10.063429832458496
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 314: train_loss=10.061954498291016
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 315: train_loss=10.06296443939209
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 316: train_loss=10.061168670654297
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 317: train_loss=10.062626838684082
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 318: train_loss=10.061196327209473
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 319: train_loss=10.061357498168945
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 320: train_loss=10.061836242675781
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 321: train_loss=10.061057090759277
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 322: train_loss=10.0595064163208
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 323: train_loss=10.06628704071045
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 324: train_loss=10.064495086669922
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 325: train_loss=10.064522743225098
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 326: train_loss=10.064284324645996
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 327: train_loss=10.063406944274902
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 328: train_loss=10.063158988952637
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 329: train_loss=10.063673973083496
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 330: train_loss=10.0624361038208
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 331: train_loss=10.063812255859375
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 332: train_loss=10.063131332397461
INFO - 04/15/25 16:48:07 - 0:16:30 - Epoch 333: train_loss=10.06293773651123
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 334: train_loss=10.0626802444458
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 335: train_loss=10.062555313110352
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 336: train_loss=10.062151908874512
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 337: train_loss=10.063295364379883
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 338: train_loss=10.061172485351562
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 339: train_loss=10.066754341125488
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 340: train_loss=10.06641960144043
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 341: train_loss=10.061182022094727
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 342: train_loss=10.063313484191895
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 343: train_loss=10.060955047607422
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 344: train_loss=10.065398216247559
INFO - 04/15/25 16:48:07 - 0:16:31 - Epoch 345: train_loss=10.06393051147461
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 346: train_loss=10.064094543457031
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 347: train_loss=10.063774108886719
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 348: train_loss=10.063691139221191
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 349: train_loss=10.062715530395508
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 350: train_loss=10.064553260803223
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 351: train_loss=10.062851905822754
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 352: train_loss=10.065156936645508
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 353: train_loss=10.064414978027344
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 354: train_loss=10.06361198425293
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 355: train_loss=10.06326675415039
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 356: train_loss=10.063871383666992
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 357: train_loss=10.062710762023926
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 358: train_loss=10.064484596252441
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 359: train_loss=10.06353759765625
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 360: train_loss=10.063879013061523
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 361: train_loss=10.063268661499023
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 362: train_loss=10.063722610473633
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 363: train_loss=10.062807083129883
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 364: train_loss=10.063794136047363
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 365: train_loss=10.062524795532227
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 366: train_loss=10.064213752746582
INFO - 04/15/25 16:48:08 - 0:16:31 - Epoch 367: train_loss=10.06297492980957
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 368: train_loss=10.064123153686523
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 369: train_loss=10.063250541687012
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 370: train_loss=10.063803672790527
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 371: train_loss=10.063002586364746
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 372: train_loss=10.06363582611084
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 373: train_loss=10.062699317932129
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 374: train_loss=10.063846588134766
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 375: train_loss=10.062629699707031
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 376: train_loss=10.063987731933594
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 377: train_loss=10.06297492980957
INFO - 04/15/25 16:48:08 - 0:16:32 - Epoch 378: train_loss=10.06386661529541
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 379: train_loss=10.063024520874023
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 380: train_loss=10.063704490661621
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 381: train_loss=10.062941551208496
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 382: train_loss=10.063639640808105
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 383: train_loss=10.062670707702637
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 384: train_loss=10.063706398010254
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 385: train_loss=10.062759399414062
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 386: train_loss=10.063769340515137
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 387: train_loss=10.062782287597656
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 388: train_loss=10.063671112060547
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 389: train_loss=10.062938690185547
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 390: train_loss=10.063471794128418
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 391: train_loss=10.062699317932129
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 392: train_loss=10.06348705291748
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 393: train_loss=10.062677383422852
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 394: train_loss=10.063453674316406
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 395: train_loss=10.062524795532227
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 396: train_loss=10.063410758972168
INFO - 04/15/25 16:48:09 - 0:16:32 - Epoch 397: train_loss=10.062650680541992
INFO - 04/15/25 16:48:09 - 0:16:33 - Epoch 398: train_loss=10.063202857971191
INFO - 04/15/25 16:48:09 - 0:16:33 - Epoch 399: train_loss=10.062448501586914
INFO - 04/15/25 16:48:09 - 0:16:33 - Epoch 400: train_loss=10.062952995300293
INFO - 04/15/25 16:48:09 - 0:16:33 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:09 - 0:16:33 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:48:09 - 0:16:33 - ------------------Saving best model-------------------
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 400: ACC: 0.0, NMI: 0.2798771854265597, F1: 0.0, ARI: 0.04501729375894023
INFO - 04/15/25 16:48:10 - 0:16:34 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 401: train_loss=10.062368392944336
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 402: train_loss=10.062524795532227
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 403: train_loss=10.062146186828613
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 404: train_loss=10.061980247497559
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 405: train_loss=10.06176471710205
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 406: train_loss=10.062224388122559
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 407: train_loss=10.060709953308105
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 408: train_loss=10.065345764160156
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 409: train_loss=10.06491756439209
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 410: train_loss=10.060968399047852
INFO - 04/15/25 16:48:10 - 0:16:34 - Epoch 411: train_loss=10.061654090881348
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 412: train_loss=10.061543464660645
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 413: train_loss=10.060846328735352
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 414: train_loss=10.063152313232422
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 415: train_loss=10.061145782470703
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 416: train_loss=10.065472602844238
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 417: train_loss=10.066059112548828
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 418: train_loss=10.06005859375
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 419: train_loss=10.066720962524414
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 420: train_loss=10.06768798828125
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 421: train_loss=10.060738563537598
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 422: train_loss=10.0696382522583
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 423: train_loss=10.07429313659668
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 424: train_loss=10.070780754089355
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 425: train_loss=10.06094741821289
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 426: train_loss=10.070954322814941
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 427: train_loss=10.077250480651855
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 428: train_loss=10.075882911682129
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 429: train_loss=10.067981719970703
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 430: train_loss=10.062185287475586
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 431: train_loss=10.067623138427734
INFO - 04/15/25 16:48:11 - 0:16:34 - Epoch 432: train_loss=10.066801071166992
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 433: train_loss=10.061254501342773
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 434: train_loss=10.066161155700684
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 435: train_loss=10.069238662719727
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 436: train_loss=10.066823959350586
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 437: train_loss=10.061899185180664
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 438: train_loss=10.065017700195312
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 439: train_loss=10.067172050476074
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 440: train_loss=10.065337181091309
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 441: train_loss=10.062877655029297
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 442: train_loss=10.063129425048828
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 443: train_loss=10.064141273498535
INFO - 04/15/25 16:48:11 - 0:16:35 - Epoch 444: train_loss=10.063650131225586
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 445: train_loss=10.062442779541016
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 446: train_loss=10.061789512634277
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 447: train_loss=10.06295394897461
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 448: train_loss=10.062127113342285
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 449: train_loss=10.061083793640137
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 450: train_loss=10.062657356262207
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 451: train_loss=10.06136703491211
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 452: train_loss=10.06159782409668
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 453: train_loss=10.062384605407715
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 454: train_loss=10.06113052368164
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 455: train_loss=10.061179161071777
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 456: train_loss=10.06252670288086
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 457: train_loss=10.061325073242188
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 458: train_loss=10.061145782470703
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 459: train_loss=10.063424110412598
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 460: train_loss=10.061561584472656
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 461: train_loss=10.064701080322266
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 462: train_loss=10.062175750732422
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 463: train_loss=10.066206932067871
INFO - 04/15/25 16:48:12 - 0:16:35 - Epoch 464: train_loss=10.065838813781738
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 465: train_loss=10.062308311462402
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 466: train_loss=10.062957763671875
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 467: train_loss=10.062504768371582
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 468: train_loss=10.061248779296875
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 469: train_loss=10.064988136291504
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 470: train_loss=10.063372611999512
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 471: train_loss=10.064507484436035
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 472: train_loss=10.064403533935547
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 473: train_loss=10.062369346618652
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 474: train_loss=10.062145233154297
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 475: train_loss=10.063787460327148
INFO - 04/15/25 16:48:12 - 0:16:36 - Epoch 476: train_loss=10.062835693359375
INFO - 04/15/25 16:48:13 - 0:16:36 - Epoch 477: train_loss=10.063873291015625
INFO - 04/15/25 16:48:13 - 0:16:36 - Epoch 478: train_loss=10.063314437866211
INFO - 04/15/25 16:48:13 - 0:16:36 - Epoch 479: train_loss=10.063166618347168
INFO - 04/15/25 16:48:13 - 0:16:36 - Epoch 480: train_loss=10.062677383422852
INFO - 04/15/25 16:48:16 - 0:16:36 - Epoch 481: train_loss=10.06342601776123
INFO - 04/15/25 16:48:16 - 0:16:39 - Epoch 482: train_loss=10.062895774841309
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 483: train_loss=10.063106536865234
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 484: train_loss=10.062607765197754
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 485: train_loss=10.063148498535156
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 486: train_loss=10.062463760375977
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 487: train_loss=10.063421249389648
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 488: train_loss=10.062966346740723
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 489: train_loss=10.062557220458984
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 490: train_loss=10.062073707580566
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 491: train_loss=10.063272476196289
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 492: train_loss=10.062755584716797
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 493: train_loss=10.062583923339844
INFO - 04/15/25 16:48:16 - 0:16:40 - Epoch 494: train_loss=10.062067031860352
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 495: train_loss=10.0631103515625
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 496: train_loss=10.062593460083008
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 497: train_loss=10.062549591064453
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 498: train_loss=10.062078475952148
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 499: train_loss=10.06285572052002
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 500: train_loss=10.062314987182617
INFO - 04/15/25 16:48:17 - 0:16:40 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:17 - 0:16:40 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 500: ACC: 0.0, NMI: 0.1831933073789099, F1: 0.0, ARI: 0.01715012530104225
INFO - 04/15/25 16:48:17 - 0:16:40 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 501: train_loss=10.062520027160645
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 502: train_loss=10.06203842163086
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 503: train_loss=10.062675476074219
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 504: train_loss=10.062277793884277
INFO - 04/15/25 16:48:17 - 0:16:40 - Epoch 505: train_loss=10.062324523925781
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 506: train_loss=10.06180477142334
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 507: train_loss=10.062773704528809
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 508: train_loss=10.062379837036133
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 509: train_loss=10.062042236328125
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 510: train_loss=10.06157398223877
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 511: train_loss=10.062739372253418
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 512: train_loss=10.062244415283203
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 513: train_loss=10.062044143676758
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 514: train_loss=10.061617851257324
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 515: train_loss=10.062461853027344
INFO - 04/15/25 16:48:17 - 0:16:41 - Epoch 516: train_loss=10.062026023864746
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 517: train_loss=10.062055587768555
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 518: train_loss=10.06170654296875
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 519: train_loss=10.06226921081543
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 520: train_loss=10.061857223510742
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 521: train_loss=10.062122344970703
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 522: train_loss=10.061674118041992
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 523: train_loss=10.062238693237305
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 524: train_loss=10.061823844909668
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 525: train_loss=10.061948776245117
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 526: train_loss=10.061554908752441
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 527: train_loss=10.062151908874512
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 528: train_loss=10.061712265014648
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 529: train_loss=10.06199836730957
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 530: train_loss=10.061690330505371
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 531: train_loss=10.061869621276855
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 532: train_loss=10.061412811279297
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 533: train_loss=10.062171936035156
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 534: train_loss=10.06177043914795
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 535: train_loss=10.061644554138184
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 536: train_loss=10.06119441986084
INFO - 04/15/25 16:48:18 - 0:16:41 - Epoch 537: train_loss=10.062186241149902
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 538: train_loss=10.061814308166504
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 539: train_loss=10.061525344848633
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 540: train_loss=10.061155319213867
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 541: train_loss=10.062100410461426
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 542: train_loss=10.06178092956543
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 543: train_loss=10.061458587646484
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 544: train_loss=10.061081886291504
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 545: train_loss=10.062073707580566
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 546: train_loss=10.061722755432129
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 547: train_loss=10.061352729797363
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 548: train_loss=10.061010360717773
INFO - 04/15/25 16:48:18 - 0:16:42 - Epoch 549: train_loss=10.062017440795898
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 550: train_loss=10.061602592468262
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 551: train_loss=10.061440467834473
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 552: train_loss=10.061141967773438
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 553: train_loss=10.061822891235352
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 554: train_loss=10.06157398223877
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 555: train_loss=10.06124210357666
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 556: train_loss=10.060829162597656
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 557: train_loss=10.062088966369629
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 558: train_loss=10.06185245513916
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 559: train_loss=10.060901641845703
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 560: train_loss=10.060502052307129
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 561: train_loss=10.06218147277832
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 562: train_loss=10.061812400817871
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 563: train_loss=10.060843467712402
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 564: train_loss=10.060519218444824
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 565: train_loss=10.062067985534668
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 566: train_loss=10.061655044555664
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 567: train_loss=10.06088638305664
INFO - 04/15/25 16:48:19 - 0:16:42 - Epoch 568: train_loss=10.060635566711426
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 569: train_loss=10.061875343322754
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 570: train_loss=10.061477661132812
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 571: train_loss=10.060870170593262
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 572: train_loss=10.060675621032715
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 573: train_loss=10.062005043029785
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 574: train_loss=10.061723709106445
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 575: train_loss=10.060234069824219
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 576: train_loss=10.06137466430664
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 577: train_loss=10.061983108520508
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 578: train_loss=10.060259819030762
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 579: train_loss=10.061957359313965
INFO - 04/15/25 16:48:19 - 0:16:43 - Epoch 580: train_loss=10.061561584472656
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 581: train_loss=10.060462951660156
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 582: train_loss=10.061788558959961
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 583: train_loss=10.060367584228516
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 584: train_loss=10.059828758239746
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 585: train_loss=10.06382942199707
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 586: train_loss=10.061074256896973
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 587: train_loss=10.065720558166504
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 588: train_loss=10.06515121459961
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 589: train_loss=10.063518524169922
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 590: train_loss=10.062931060791016
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 591: train_loss=10.064508438110352
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 592: train_loss=10.063773155212402
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 593: train_loss=10.062857627868652
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 594: train_loss=10.062721252441406
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 595: train_loss=10.062952041625977
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 596: train_loss=10.061508178710938
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 597: train_loss=10.063620567321777
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 598: train_loss=10.060935020446777
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 599: train_loss=10.065327644348145
INFO - 04/15/25 16:48:20 - 0:16:43 - Epoch 600: train_loss=10.064399719238281
INFO - 04/15/25 16:48:20 - 0:16:43 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:20 - 0:16:44 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:48:20 - 0:16:44 - Epoch 600: ACC: 0.0, NMI: 0.21378340299244428, F1: 0.0, ARI: 0.027332288385100628
INFO - 04/15/25 16:48:20 - 0:16:44 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:20 - 0:16:44 - Epoch 601: train_loss=10.062332153320312
INFO - 04/15/25 16:48:20 - 0:16:44 - Epoch 602: train_loss=10.062718391418457
INFO - 04/15/25 16:48:20 - 0:16:44 - Epoch 603: train_loss=10.06181526184082
INFO - 04/15/25 16:48:20 - 0:16:44 - Epoch 604: train_loss=10.062344551086426
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 605: train_loss=10.060977935791016
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 606: train_loss=10.062420845031738
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 607: train_loss=10.060484886169434
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 608: train_loss=10.063043594360352
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 609: train_loss=10.060860633850098
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 610: train_loss=10.065360069274902
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 611: train_loss=10.065434455871582
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 612: train_loss=10.059526443481445
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 613: train_loss=10.060483932495117
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 614: train_loss=10.062006950378418
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 615: train_loss=10.059375762939453
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 616: train_loss=10.066546440124512
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 617: train_loss=10.067164421081543
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 618: train_loss=10.059820175170898
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 619: train_loss=10.069147109985352
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 620: train_loss=10.07255744934082
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 621: train_loss=10.06816577911377
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 622: train_loss=10.06129264831543
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 623: train_loss=10.066227912902832
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 624: train_loss=10.067626953125
INFO - 04/15/25 16:48:21 - 0:16:44 - Epoch 625: train_loss=10.063858032226562
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 626: train_loss=10.062450408935547
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 627: train_loss=10.065263748168945
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 628: train_loss=10.062810897827148
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 629: train_loss=10.061866760253906
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 630: train_loss=10.063462257385254
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 631: train_loss=10.059103965759277
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 632: train_loss=10.066542625427246
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 633: train_loss=10.0682373046875
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 634: train_loss=10.064591407775879
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 635: train_loss=10.06261157989502
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 636: train_loss=10.064599990844727
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 637: train_loss=10.065077781677246
INFO - 04/15/25 16:48:21 - 0:16:45 - Epoch 638: train_loss=10.062243461608887
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 639: train_loss=10.063440322875977
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 640: train_loss=10.064367294311523
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 641: train_loss=10.062071800231934
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 642: train_loss=10.062600135803223
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 643: train_loss=10.063106536865234
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 644: train_loss=10.061899185180664
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 645: train_loss=10.062445640563965
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 646: train_loss=10.062372207641602
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 647: train_loss=10.06167221069336
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 648: train_loss=10.062126159667969
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 649: train_loss=10.061763763427734
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 650: train_loss=10.061235427856445
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 651: train_loss=10.062217712402344
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 652: train_loss=10.060653686523438
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 653: train_loss=10.062440872192383
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 654: train_loss=10.062272071838379
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 655: train_loss=10.06071662902832
INFO - 04/15/25 16:48:22 - 0:16:45 - Epoch 656: train_loss=10.063241958618164
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 657: train_loss=10.062506675720215
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 658: train_loss=10.062426567077637
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 659: train_loss=10.061596870422363
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 660: train_loss=10.061823844909668
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 661: train_loss=10.061461448669434
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 662: train_loss=10.061957359313965
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 663: train_loss=10.059950828552246
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 664: train_loss=10.065474510192871
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 665: train_loss=10.064947128295898
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 666: train_loss=10.063213348388672
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 667: train_loss=10.062373161315918
INFO - 04/15/25 16:48:22 - 0:16:46 - Epoch 668: train_loss=10.064312934875488
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 669: train_loss=10.064349174499512
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 670: train_loss=10.061429977416992
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 671: train_loss=10.061897277832031
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 672: train_loss=10.062250137329102
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 673: train_loss=10.060730934143066
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 674: train_loss=10.061762809753418
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 675: train_loss=10.060853958129883
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 676: train_loss=10.062308311462402
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 677: train_loss=10.06126594543457
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 678: train_loss=10.06264877319336
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 679: train_loss=10.061050415039062
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 680: train_loss=10.063410758972168
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 681: train_loss=10.061464309692383
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 682: train_loss=10.064141273498535
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 683: train_loss=10.064353942871094
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 684: train_loss=10.06070613861084
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 685: train_loss=10.06301212310791
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 686: train_loss=10.060112953186035
INFO - 04/15/25 16:48:23 - 0:16:46 - Epoch 687: train_loss=10.06611442565918
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 688: train_loss=10.065637588500977
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 689: train_loss=10.061437606811523
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 690: train_loss=10.062591552734375
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 691: train_loss=10.062076568603516
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 692: train_loss=10.061429023742676
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 693: train_loss=10.0619535446167
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 694: train_loss=10.061603546142578
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 695: train_loss=10.060532569885254
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 696: train_loss=10.063645362854004
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 697: train_loss=10.061521530151367
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 698: train_loss=10.06524658203125
INFO - 04/15/25 16:48:23 - 0:16:47 - Epoch 699: train_loss=10.065206527709961
INFO - 04/15/25 16:48:24 - 0:16:47 - Epoch 700: train_loss=10.061271667480469
INFO - 04/15/25 16:48:24 - 0:16:47 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:24 - 0:16:47 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:48:24 - 0:16:47 - ------------------Saving best model-------------------
INFO - 04/15/25 16:48:26 - 0:16:49 - Epoch 700: ACC: 0.0, NMI: 0.3897925150151317, F1: 0.0, ARI: 0.11147892558531089
INFO - 04/15/25 16:48:26 - 0:16:49 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:26 - 0:16:49 - Epoch 701: train_loss=10.061944007873535
INFO - 04/15/25 16:48:26 - 0:16:49 - Epoch 702: train_loss=10.062652587890625
INFO - 04/15/25 16:48:26 - 0:16:49 - Epoch 703: train_loss=10.06132698059082
INFO - 04/15/25 16:48:26 - 0:16:49 - Epoch 704: train_loss=10.064194679260254
INFO - 04/15/25 16:48:26 - 0:16:49 - Epoch 705: train_loss=10.064018249511719
INFO - 04/15/25 16:48:26 - 0:16:49 - Epoch 706: train_loss=10.061921119689941
INFO - 04/15/25 16:48:26 - 0:16:49 - Epoch 707: train_loss=10.061421394348145
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 708: train_loss=10.063767433166504
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 709: train_loss=10.062514305114746
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 710: train_loss=10.063082695007324
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 711: train_loss=10.0630521774292
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 712: train_loss=10.061984062194824
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 713: train_loss=10.061138153076172
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 714: train_loss=10.063827514648438
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 715: train_loss=10.06264877319336
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 716: train_loss=10.06308650970459
INFO - 04/15/25 16:48:26 - 0:16:50 - Epoch 717: train_loss=10.063138008117676
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 718: train_loss=10.0613374710083
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 719: train_loss=10.060660362243652
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 720: train_loss=10.06346607208252
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 721: train_loss=10.062052726745605
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 722: train_loss=10.063485145568848
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 723: train_loss=10.063432693481445
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 724: train_loss=10.060953140258789
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 725: train_loss=10.061013221740723
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 726: train_loss=10.062073707580566
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 727: train_loss=10.060585975646973
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 728: train_loss=10.063804626464844
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 729: train_loss=10.063262939453125
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 730: train_loss=10.061020851135254
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 731: train_loss=10.061063766479492
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 732: train_loss=10.062013626098633
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 733: train_loss=10.06074047088623
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 734: train_loss=10.063624382019043
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 735: train_loss=10.063426971435547
INFO - 04/15/25 16:48:27 - 0:16:50 - Epoch 736: train_loss=10.060209274291992
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 737: train_loss=10.059940338134766
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 738: train_loss=10.063187599182129
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 739: train_loss=10.062146186828613
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 740: train_loss=10.061930656433105
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 741: train_loss=10.061922073364258
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 742: train_loss=10.061114311218262
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 743: train_loss=10.06048583984375
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 744: train_loss=10.062695503234863
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 745: train_loss=10.062064170837402
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 746: train_loss=10.061116218566895
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 747: train_loss=10.060822486877441
INFO - 04/15/25 16:48:27 - 0:16:51 - Epoch 748: train_loss=10.06194019317627
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 749: train_loss=10.061347007751465
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 750: train_loss=10.06159782409668
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 751: train_loss=10.061189651489258
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 752: train_loss=10.061532020568848
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 753: train_loss=10.06104564666748
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 754: train_loss=10.061495780944824
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 755: train_loss=10.060946464538574
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 756: train_loss=10.06161117553711
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 757: train_loss=10.061127662658691
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 758: train_loss=10.061136245727539
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 759: train_loss=10.060586929321289
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 760: train_loss=10.06170654296875
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 761: train_loss=10.061373710632324
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 762: train_loss=10.060590744018555
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 763: train_loss=10.060201644897461
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 764: train_loss=10.06174087524414
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 765: train_loss=10.061137199401855
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 766: train_loss=10.060837745666504
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 767: train_loss=10.060442924499512
INFO - 04/15/25 16:48:28 - 0:16:51 - Epoch 768: train_loss=10.061091423034668
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 769: train_loss=10.060534477233887
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 770: train_loss=10.06116771697998
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 771: train_loss=10.060774803161621
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 772: train_loss=10.060636520385742
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 773: train_loss=10.060171127319336
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 774: train_loss=10.061113357543945
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 775: train_loss=10.060571670532227
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 776: train_loss=10.060595512390137
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 777: train_loss=10.060196876525879
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 778: train_loss=10.060791969299316
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 779: train_loss=10.060380935668945
INFO - 04/15/25 16:48:28 - 0:16:52 - Epoch 780: train_loss=10.060503959655762
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 781: train_loss=10.06015396118164
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 782: train_loss=10.060670852661133
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 783: train_loss=10.060345649719238
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 784: train_loss=10.06031608581543
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 785: train_loss=10.060044288635254
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 786: train_loss=10.060478210449219
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 787: train_loss=10.06039047241211
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 788: train_loss=10.060358047485352
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 789: train_loss=10.06114387512207
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 790: train_loss=10.058464050292969
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 791: train_loss=10.060864448547363
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 792: train_loss=10.060173034667969
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 793: train_loss=10.05884838104248
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 794: train_loss=10.061197280883789
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 795: train_loss=10.05859661102295
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 796: train_loss=10.060725212097168
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 797: train_loss=10.058937072753906
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 798: train_loss=10.06161880493164
INFO - 04/15/25 16:48:29 - 0:16:52 - Epoch 799: train_loss=10.061470985412598
INFO - 04/15/25 16:48:29 - 0:16:53 - Epoch 800: train_loss=10.058280944824219
INFO - 04/15/25 16:48:29 - 0:16:53 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:29 - 0:16:53 - Decoding cost time:  0.134 s
INFO - 04/15/25 16:48:29 - 0:16:53 - Epoch 800: ACC: 0.0, NMI: 0.3608954983000785, F1: 0.0, ARI: 0.0894959107476827
INFO - 04/15/25 16:48:29 - 0:16:53 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:29 - 0:16:53 - Epoch 801: train_loss=10.058835983276367
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 802: train_loss=10.060855865478516
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 803: train_loss=10.058926582336426
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 804: train_loss=10.062552452087402
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 805: train_loss=10.062387466430664
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 806: train_loss=10.059701919555664
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 807: train_loss=10.061705589294434
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 808: train_loss=10.061088562011719
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 809: train_loss=10.059621810913086
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 810: train_loss=10.059412002563477
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 811: train_loss=10.060478210449219
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 812: train_loss=10.059797286987305
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 813: train_loss=10.05991268157959
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 814: train_loss=10.060068130493164
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 815: train_loss=10.058197975158691
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 816: train_loss=10.061294555664062
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 817: train_loss=10.057523727416992
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 818: train_loss=10.06682014465332
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 819: train_loss=10.067768096923828
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 820: train_loss=10.058845520019531
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 821: train_loss=10.070249557495117
INFO - 04/15/25 16:48:30 - 0:16:53 - Epoch 822: train_loss=10.075589179992676
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 823: train_loss=10.070438385009766
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 824: train_loss=10.058560371398926
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 825: train_loss=10.070096015930176
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 826: train_loss=10.074126243591309
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 827: train_loss=10.069330215454102
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 828: train_loss=10.060986518859863
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 829: train_loss=10.066679954528809
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 830: train_loss=10.06967830657959
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 831: train_loss=10.066676139831543
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 832: train_loss=10.06129264831543
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 833: train_loss=10.064909934997559
INFO - 04/15/25 16:48:30 - 0:16:54 - Epoch 834: train_loss=10.067646026611328
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 835: train_loss=10.063671112060547
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 836: train_loss=10.060202598571777
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 837: train_loss=10.063471794128418
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 838: train_loss=10.05935001373291
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 839: train_loss=10.063776016235352
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 840: train_loss=10.065662384033203
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 841: train_loss=10.061270713806152
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 842: train_loss=10.062499046325684
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 843: train_loss=10.06461238861084
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 844: train_loss=10.061697959899902
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 845: train_loss=10.060245513916016
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 846: train_loss=10.061941146850586
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 847: train_loss=10.059921264648438
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 848: train_loss=10.060745239257812
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 849: train_loss=10.061615943908691
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 850: train_loss=10.057340621948242
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 851: train_loss=10.06447696685791
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 852: train_loss=10.06440544128418
INFO - 04/15/25 16:48:31 - 0:16:54 - Epoch 853: train_loss=10.06153392791748
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 854: train_loss=10.061210632324219
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 855: train_loss=10.062101364135742
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 856: train_loss=10.059480667114258
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 857: train_loss=10.061724662780762
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 858: train_loss=10.060836791992188
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 859: train_loss=10.05988883972168
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 860: train_loss=10.06261157989502
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 861: train_loss=10.061159133911133
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 862: train_loss=10.062007904052734
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 863: train_loss=10.059879302978516
INFO - 04/15/25 16:48:31 - 0:16:55 - Epoch 864: train_loss=10.061124801635742
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 865: train_loss=10.059053421020508
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 866: train_loss=10.058937072753906
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 867: train_loss=10.056351661682129
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 868: train_loss=10.061777114868164
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 869: train_loss=10.056285858154297
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 870: train_loss=10.059793472290039
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 871: train_loss=10.058867454528809
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 872: train_loss=10.058300018310547
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 873: train_loss=10.058660507202148
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 874: train_loss=10.058631896972656
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 875: train_loss=10.059308052062988
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 876: train_loss=10.056598663330078
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 877: train_loss=10.06129264831543
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 878: train_loss=10.057619094848633
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 879: train_loss=10.0614013671875
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 880: train_loss=10.060494422912598
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 881: train_loss=10.059456825256348
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 882: train_loss=10.061455726623535
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 883: train_loss=10.060282707214355
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 884: train_loss=10.061005592346191
INFO - 04/15/25 16:48:32 - 0:16:55 - Epoch 885: train_loss=10.059530258178711
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 886: train_loss=10.061846733093262
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 887: train_loss=10.058691024780273
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 888: train_loss=10.063410758972168
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 889: train_loss=10.061436653137207
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 890: train_loss=10.062581062316895
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 891: train_loss=10.061280250549316
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 892: train_loss=10.06242561340332
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 893: train_loss=10.06201171875
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 894: train_loss=10.059770584106445
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 895: train_loss=10.059261322021484
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 896: train_loss=10.06159496307373
INFO - 04/15/25 16:48:32 - 0:16:56 - Epoch 897: train_loss=10.059996604919434
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 898: train_loss=10.062349319458008
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 899: train_loss=10.061373710632324
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 900: train_loss=10.060685157775879
INFO - 04/15/25 16:48:33 - 0:16:56 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:33 - 0:16:56 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 900: ACC: 0.0, NMI: 0.3102594897073288, F1: 0.0, ARI: 0.05989832957621275
INFO - 04/15/25 16:48:33 - 0:16:56 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 901: train_loss=10.060367584228516
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 902: train_loss=10.06048583984375
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 903: train_loss=10.059433937072754
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 904: train_loss=10.061421394348145
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 905: train_loss=10.06054973602295
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 906: train_loss=10.06067180633545
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 907: train_loss=10.059816360473633
INFO - 04/15/25 16:48:33 - 0:16:56 - Epoch 908: train_loss=10.060759544372559
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 909: train_loss=10.059834480285645
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 910: train_loss=10.060834884643555
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 911: train_loss=10.060253143310547
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 912: train_loss=10.059614181518555
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 913: train_loss=10.058650016784668
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 914: train_loss=10.061593055725098
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 915: train_loss=10.06098747253418
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 916: train_loss=10.058643341064453
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 917: train_loss=10.057941436767578
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 918: train_loss=10.061667442321777
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 919: train_loss=10.06068229675293
INFO - 04/15/25 16:48:33 - 0:16:57 - Epoch 920: train_loss=10.058745384216309
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 921: train_loss=10.058116912841797
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 922: train_loss=10.060914993286133
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 923: train_loss=10.059972763061523
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 924: train_loss=10.059181213378906
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 925: train_loss=10.058647155761719
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 926: train_loss=10.06029987335205
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 927: train_loss=10.059369087219238
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 928: train_loss=10.05932903289795
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 929: train_loss=10.058738708496094
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 930: train_loss=10.059826850891113
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 931: train_loss=10.059077262878418
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 932: train_loss=10.059320449829102
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 933: train_loss=10.058712005615234
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 934: train_loss=10.059638023376465
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 935: train_loss=10.058940887451172
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 936: train_loss=10.058990478515625
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 937: train_loss=10.058280944824219
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 938: train_loss=10.059828758239746
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 939: train_loss=10.059104919433594
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 940: train_loss=10.058616638183594
INFO - 04/15/25 16:48:34 - 0:16:57 - Epoch 941: train_loss=10.057867050170898
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 942: train_loss=10.059795379638672
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 943: train_loss=10.059027671813965
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 944: train_loss=10.058402061462402
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 945: train_loss=10.057772636413574
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 946: train_loss=10.059453964233398
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 947: train_loss=10.05850601196289
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 948: train_loss=10.058661460876465
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 949: train_loss=10.058097839355469
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 950: train_loss=10.058884620666504
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 951: train_loss=10.058043479919434
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 952: train_loss=10.058908462524414
INFO - 04/15/25 16:48:34 - 0:16:58 - Epoch 953: train_loss=10.058133125305176
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 954: train_loss=10.05866527557373
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 955: train_loss=10.057998657226562
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 956: train_loss=10.058412551879883
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 957: train_loss=10.05771255493164
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 958: train_loss=10.058911323547363
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 959: train_loss=10.058253288269043
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 960: train_loss=10.05795669555664
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 961: train_loss=10.057267189025879
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 962: train_loss=10.058584213256836
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 963: train_loss=10.057615280151367
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 964: train_loss=10.058297157287598
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 965: train_loss=10.057768821716309
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 966: train_loss=10.057897567749023
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 967: train_loss=10.057268142700195
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 968: train_loss=10.05795669555664
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 969: train_loss=10.057088851928711
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 970: train_loss=10.058201789855957
INFO - 04/15/25 16:48:35 - 0:16:58 - Epoch 971: train_loss=10.05749225616455
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 972: train_loss=10.057470321655273
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 973: train_loss=10.056835174560547
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 974: train_loss=10.05804443359375
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 975: train_loss=10.057310104370117
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 976: train_loss=10.057350158691406
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 977: train_loss=10.056685447692871
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 978: train_loss=10.057717323303223
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 979: train_loss=10.057184219360352
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 980: train_loss=10.057029724121094
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 981: train_loss=10.056360244750977
INFO - 04/15/25 16:48:35 - 0:16:59 - Epoch 982: train_loss=10.057816505432129
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 983: train_loss=10.057302474975586
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 984: train_loss=10.05639362335205
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 985: train_loss=10.055644989013672
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 986: train_loss=10.05821704864502
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 987: train_loss=10.05780029296875
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 988: train_loss=10.05537223815918
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 989: train_loss=10.054696083068848
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 990: train_loss=10.058670043945312
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 991: train_loss=10.058196067810059
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 992: train_loss=10.05462646484375
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 993: train_loss=10.054024696350098
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 994: train_loss=10.058601379394531
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 995: train_loss=10.057767868041992
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 996: train_loss=10.055041313171387
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 997: train_loss=10.055170059204102
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 998: train_loss=10.056012153625488
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 999: train_loss=10.054450035095215
INFO - 04/15/25 16:48:36 - 0:16:59 - Epoch 1000: train_loss=10.058771133422852
INFO - 04/15/25 16:48:36 - 0:16:59 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:36 - 0:17:00 - Decoding cost time:  0.130 s
INFO - 04/15/25 16:48:36 - 0:17:00 - Epoch 1000: ACC: 0.0, NMI: 0.3573926186539699, F1: 0.0, ARI: 0.092068884511073
INFO - 04/15/25 16:48:36 - 0:17:00 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:36 - 0:17:00 - Epoch 1001: train_loss=10.058622360229492
INFO - 04/15/25 16:48:36 - 0:17:00 - Epoch 1002: train_loss=10.053743362426758
INFO - 04/15/25 16:48:36 - 0:17:00 - Epoch 1003: train_loss=10.058691024780273
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1004: train_loss=10.055269241333008
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1005: train_loss=10.060840606689453
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1006: train_loss=10.06106185913086
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1007: train_loss=10.056367874145508
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1008: train_loss=10.057686805725098
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1009: train_loss=10.05837631225586
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1010: train_loss=10.055031776428223
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1011: train_loss=10.060884475708008
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1012: train_loss=10.060912132263184
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1013: train_loss=10.054671287536621
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1014: train_loss=10.05755615234375
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1015: train_loss=10.057819366455078
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1016: train_loss=10.053350448608398
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1017: train_loss=10.062127113342285
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1018: train_loss=10.061758995056152
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1019: train_loss=10.054527282714844
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1020: train_loss=10.05777359008789
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1021: train_loss=10.057954788208008
INFO - 04/15/25 16:48:37 - 0:17:00 - Epoch 1022: train_loss=10.054038047790527
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1023: train_loss=10.061372756958008
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1024: train_loss=10.062308311462402
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1025: train_loss=10.055516242980957
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1026: train_loss=10.059062004089355
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1027: train_loss=10.059866905212402
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1028: train_loss=10.058555603027344
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1029: train_loss=10.053314208984375
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1030: train_loss=10.060564994812012
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1031: train_loss=10.056842803955078
INFO - 04/15/25 16:48:37 - 0:17:01 - Epoch 1032: train_loss=10.059967041015625
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1033: train_loss=10.059170722961426
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1034: train_loss=10.058552742004395
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1035: train_loss=10.056697845458984
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1036: train_loss=10.060145378112793
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1037: train_loss=10.059161186218262
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1038: train_loss=10.057018280029297
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1039: train_loss=10.055136680603027
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1040: train_loss=10.060778617858887
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1041: train_loss=10.058804512023926
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1042: train_loss=10.0574312210083
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1043: train_loss=10.057491302490234
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1044: train_loss=10.056403160095215
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1045: train_loss=10.055071830749512
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1046: train_loss=10.059223175048828
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1047: train_loss=10.058128356933594
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1048: train_loss=10.055816650390625
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1049: train_loss=10.05526065826416
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1050: train_loss=10.057811737060547
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1051: train_loss=10.056876182556152
INFO - 04/15/25 16:48:38 - 0:17:01 - Epoch 1052: train_loss=10.055826187133789
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1053: train_loss=10.05487060546875
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1054: train_loss=10.057506561279297
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1055: train_loss=10.056598663330078
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1056: train_loss=10.055612564086914
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1057: train_loss=10.054888725280762
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1058: train_loss=10.0568265914917
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1059: train_loss=10.055601119995117
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1060: train_loss=10.056078910827637
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1061: train_loss=10.055569648742676
INFO - 04/15/25 16:48:38 - 0:17:02 - Epoch 1062: train_loss=10.055441856384277
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1063: train_loss=10.054266929626465
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1064: train_loss=10.05667781829834
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1065: train_loss=10.054610252380371
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1066: train_loss=10.055187225341797
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1067: train_loss=10.054255485534668
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1068: train_loss=10.05569076538086
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1069: train_loss=10.054695129394531
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1070: train_loss=10.055830955505371
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1071: train_loss=10.054770469665527
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1072: train_loss=10.054815292358398
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1073: train_loss=10.053772926330566
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1074: train_loss=10.056282997131348
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1075: train_loss=10.055237770080566
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1076: train_loss=10.053987503051758
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1077: train_loss=10.053325653076172
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1078: train_loss=10.05522346496582
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1079: train_loss=10.053868293762207
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1080: train_loss=10.054862976074219
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1081: train_loss=10.054014205932617
INFO - 04/15/25 16:48:39 - 0:17:02 - Epoch 1082: train_loss=10.053895950317383
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1083: train_loss=10.053339958190918
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1084: train_loss=10.05369758605957
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1085: train_loss=10.052729606628418
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1086: train_loss=10.053720474243164
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1087: train_loss=10.052565574645996
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1088: train_loss=10.053683280944824
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1089: train_loss=10.052409172058105
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1090: train_loss=10.053694725036621
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1091: train_loss=10.052877426147461
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1092: train_loss=10.052913665771484
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1093: train_loss=10.052367210388184
INFO - 04/15/25 16:48:39 - 0:17:03 - Epoch 1094: train_loss=10.052565574645996
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1095: train_loss=10.051620483398438
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1096: train_loss=10.053425788879395
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1097: train_loss=10.052802085876465
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1098: train_loss=10.051456451416016
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1099: train_loss=10.0508451461792
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1100: train_loss=10.052868843078613
INFO - 04/15/25 16:48:40 - 0:17:03 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:40 - 0:17:03 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1100: ACC: 0.0, NMI: 0.3579379213064372, F1: 0.0, ARI: 0.14831454755572854
INFO - 04/15/25 16:48:40 - 0:17:03 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1101: train_loss=10.052336692810059
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1102: train_loss=10.052810668945312
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1103: train_loss=10.052667617797852
INFO - 04/15/25 16:48:40 - 0:17:03 - Epoch 1104: train_loss=10.050760269165039
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1105: train_loss=10.052572250366211
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1106: train_loss=10.048809051513672
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1107: train_loss=10.055255889892578
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1108: train_loss=10.05299186706543
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1109: train_loss=10.054635047912598
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1110: train_loss=10.052896499633789
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1111: train_loss=10.053430557250977
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1112: train_loss=10.050969123840332
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1113: train_loss=10.055014610290527
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1114: train_loss=10.05000114440918
INFO - 04/15/25 16:48:40 - 0:17:04 - Epoch 1115: train_loss=10.052726745605469
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1116: train_loss=10.051251411437988
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1117: train_loss=10.04978084564209
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1118: train_loss=10.053557395935059
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1119: train_loss=10.048507690429688
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1120: train_loss=10.061500549316406
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1121: train_loss=10.060932159423828
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1122: train_loss=10.050970077514648
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1123: train_loss=10.056585311889648
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1124: train_loss=10.057255744934082
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1125: train_loss=10.053387641906738
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1126: train_loss=10.054178237915039
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1127: train_loss=10.055612564086914
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1128: train_loss=10.049707412719727
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1129: train_loss=10.057806015014648
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1130: train_loss=10.056937217712402
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1131: train_loss=10.051841735839844
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1132: train_loss=10.05305004119873
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1133: train_loss=10.05409049987793
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1134: train_loss=10.050044059753418
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1135: train_loss=10.058038711547852
INFO - 04/15/25 16:48:41 - 0:17:04 - Epoch 1136: train_loss=10.058342933654785
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1137: train_loss=10.051207542419434
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1138: train_loss=10.054034233093262
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1139: train_loss=10.054572105407715
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1140: train_loss=10.053413391113281
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1141: train_loss=10.050676345825195
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1142: train_loss=10.051361083984375
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1143: train_loss=10.050262451171875
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1144: train_loss=10.051613807678223
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1145: train_loss=10.049148559570312
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1146: train_loss=10.053618431091309
INFO - 04/15/25 16:48:41 - 0:17:05 - Epoch 1147: train_loss=10.052717208862305
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1148: train_loss=10.050600051879883
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1149: train_loss=10.050792694091797
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1150: train_loss=10.050529479980469
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1151: train_loss=10.049132347106934
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1152: train_loss=10.050140380859375
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1153: train_loss=10.047713279724121
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1154: train_loss=10.053037643432617
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1155: train_loss=10.052388191223145
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1156: train_loss=10.048713684082031
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1157: train_loss=10.049443244934082
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1158: train_loss=10.048746109008789
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1159: train_loss=10.048627853393555
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1160: train_loss=10.048776626586914
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1161: train_loss=10.046009063720703
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1162: train_loss=10.054535865783691
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1163: train_loss=10.053035736083984
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1164: train_loss=10.05232048034668
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1165: train_loss=10.051862716674805
INFO - 04/15/25 16:48:42 - 0:17:05 - Epoch 1166: train_loss=10.050578117370605
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1167: train_loss=10.048441886901855
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1168: train_loss=10.05616283416748
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1169: train_loss=10.053201675415039
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1170: train_loss=10.053742408752441
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1171: train_loss=10.053163528442383
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1172: train_loss=10.051135063171387
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1173: train_loss=10.049479484558105
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1174: train_loss=10.056035041809082
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1175: train_loss=10.05375862121582
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1176: train_loss=10.050533294677734
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1177: train_loss=10.048660278320312
INFO - 04/15/25 16:48:42 - 0:17:06 - Epoch 1178: train_loss=10.056046485900879
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1179: train_loss=10.06142807006836
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1180: train_loss=10.047883987426758
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1181: train_loss=10.069116592407227
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1182: train_loss=10.07515811920166
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1183: train_loss=10.063769340515137
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1184: train_loss=10.052249908447266
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1185: train_loss=10.05946159362793
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1186: train_loss=10.056920051574707
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1187: train_loss=10.05517864227295
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1188: train_loss=10.054308891296387
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1189: train_loss=10.055362701416016
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1190: train_loss=10.051347732543945
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1191: train_loss=10.055536270141602
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1192: train_loss=10.054025650024414
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1193: train_loss=10.049431800842285
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1194: train_loss=10.048616409301758
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1195: train_loss=10.053096771240234
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1196: train_loss=10.051855087280273
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1197: train_loss=10.049432754516602
INFO - 04/15/25 16:48:43 - 0:17:06 - Epoch 1198: train_loss=10.046479225158691
INFO - 04/15/25 16:48:43 - 0:17:07 - Epoch 1199: train_loss=10.048468589782715
INFO - 04/15/25 16:48:43 - 0:17:07 - Epoch 1200: train_loss=10.042994499206543
INFO - 04/15/25 16:48:43 - 0:17:07 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:43 - 0:17:07 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1200: ACC: 0.0, NMI: 0.35722626108084266, F1: 0.0, ARI: 0.18798649134150125
INFO - 04/15/25 16:48:44 - 0:17:07 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1201: train_loss=10.042491912841797
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1202: train_loss=10.031081199645996
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1203: train_loss=10.028053283691406
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1204: train_loss=10.01890754699707
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1205: train_loss=10.02314281463623
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1206: train_loss=10.02322769165039
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1207: train_loss=10.030740737915039
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1208: train_loss=10.025367736816406
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1209: train_loss=10.021468162536621
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1210: train_loss=10.017231941223145
INFO - 04/15/25 16:48:44 - 0:17:07 - Epoch 1211: train_loss=10.018622398376465
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1212: train_loss=10.014331817626953
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1213: train_loss=10.015624046325684
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1214: train_loss=10.011968612670898
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1215: train_loss=10.01330280303955
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1216: train_loss=10.010866165161133
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1217: train_loss=10.013813018798828
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1218: train_loss=10.011900901794434
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1219: train_loss=10.011873245239258
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1220: train_loss=10.011286735534668
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1221: train_loss=10.010318756103516
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1222: train_loss=10.009695053100586
INFO - 04/15/25 16:48:44 - 0:17:08 - Epoch 1223: train_loss=10.01070785522461
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1224: train_loss=10.008888244628906
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1225: train_loss=10.012791633605957
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1226: train_loss=10.012275695800781
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1227: train_loss=10.009469985961914
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1228: train_loss=10.012123107910156
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1229: train_loss=10.007471084594727
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1230: train_loss=10.016529083251953
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1231: train_loss=10.011697769165039
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1232: train_loss=10.018999099731445
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1233: train_loss=10.017013549804688
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1234: train_loss=10.014349937438965
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1235: train_loss=10.013116836547852
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1236: train_loss=10.01389217376709
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1237: train_loss=9.994535446166992
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1238: train_loss=9.99131965637207
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1239: train_loss=9.986510276794434
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1240: train_loss=9.98344612121582
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1241: train_loss=9.982573509216309
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1242: train_loss=9.984817504882812
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1243: train_loss=9.980616569519043
INFO - 04/15/25 16:48:45 - 0:17:08 - Epoch 1244: train_loss=9.984114646911621
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1245: train_loss=9.979177474975586
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1246: train_loss=9.98460578918457
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1247: train_loss=9.98029613494873
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1248: train_loss=9.981674194335938
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1249: train_loss=9.979568481445312
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1250: train_loss=9.982802391052246
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1251: train_loss=9.98021411895752
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1252: train_loss=9.977540016174316
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1253: train_loss=9.975013732910156
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1254: train_loss=9.981630325317383
INFO - 04/15/25 16:48:45 - 0:17:09 - Epoch 1255: train_loss=9.97924518585205
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1256: train_loss=9.974493980407715
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1257: train_loss=9.973723411560059
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1258: train_loss=9.977656364440918
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1259: train_loss=9.974898338317871
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1260: train_loss=9.97541618347168
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1261: train_loss=9.973699569702148
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1262: train_loss=9.975595474243164
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1263: train_loss=9.974149703979492
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1264: train_loss=9.972672462463379
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1265: train_loss=9.972038269042969
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1266: train_loss=9.97240924835205
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1267: train_loss=9.970242500305176
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1268: train_loss=9.973213195800781
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1269: train_loss=9.971446990966797
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1270: train_loss=9.97146224975586
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1271: train_loss=9.970401763916016
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1272: train_loss=9.970410346984863
INFO - 04/15/25 16:48:46 - 0:17:09 - Epoch 1273: train_loss=9.969018936157227
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1274: train_loss=9.971102714538574
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1275: train_loss=9.969558715820312
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1276: train_loss=9.969094276428223
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1277: train_loss=9.96812629699707
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1278: train_loss=9.970131874084473
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1279: train_loss=9.968544006347656
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1280: train_loss=9.968009948730469
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1281: train_loss=9.966142654418945
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1282: train_loss=9.969518661499023
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1283: train_loss=9.967479705810547
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1284: train_loss=9.966608047485352
INFO - 04/15/25 16:48:46 - 0:17:10 - Epoch 1285: train_loss=9.965789794921875
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1286: train_loss=9.967352867126465
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1287: train_loss=9.965743064880371
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1288: train_loss=9.96561336517334
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1289: train_loss=9.964142799377441
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1290: train_loss=9.96410846710205
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1291: train_loss=9.960092544555664
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1292: train_loss=9.95938491821289
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1293: train_loss=9.950986862182617
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1294: train_loss=9.940013885498047
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1295: train_loss=9.935781478881836
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1296: train_loss=9.933324813842773
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1297: train_loss=9.94219970703125
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1298: train_loss=9.97116470336914
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1299: train_loss=9.956768035888672
INFO - 04/15/25 16:48:47 - 0:17:10 - Epoch 1300: train_loss=9.961886405944824
INFO - 04/15/25 16:48:47 - 0:17:10 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:47 - 0:17:10 - Decoding cost time:  0.124 s
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1300: ACC: 0.0, NMI: 0.3256643242757386, F1: 0.0, ARI: 0.1826765445322694
INFO - 04/15/25 16:48:47 - 0:17:11 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1301: train_loss=9.941577911376953
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1302: train_loss=9.973175048828125
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1303: train_loss=9.963616371154785
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1304: train_loss=9.964996337890625
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1305: train_loss=9.954202651977539
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1306: train_loss=9.947792053222656
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1307: train_loss=9.953044891357422
INFO - 04/15/25 16:48:47 - 0:17:11 - Epoch 1308: train_loss=9.945440292358398
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1309: train_loss=9.951798439025879
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1310: train_loss=9.952874183654785
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1311: train_loss=9.952271461486816
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1312: train_loss=9.948105812072754
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1313: train_loss=9.949358940124512
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1314: train_loss=9.947026252746582
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1315: train_loss=9.947402954101562
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1316: train_loss=9.9462890625
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1317: train_loss=9.94533634185791
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1318: train_loss=9.945375442504883
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1319: train_loss=9.943465232849121
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1320: train_loss=9.94440746307373
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1321: train_loss=9.943018913269043
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1322: train_loss=9.942055702209473
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1323: train_loss=9.940826416015625
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1324: train_loss=9.9371919631958
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1325: train_loss=9.94469165802002
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1326: train_loss=9.94301986694336
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1327: train_loss=9.939078330993652
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1328: train_loss=9.938692092895508
INFO - 04/15/25 16:48:48 - 0:17:11 - Epoch 1329: train_loss=9.939270973205566
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1330: train_loss=9.93679141998291
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1331: train_loss=9.942118644714355
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1332: train_loss=9.941455841064453
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1333: train_loss=9.935013771057129
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1334: train_loss=9.937174797058105
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1335: train_loss=9.935298919677734
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1336: train_loss=9.933370590209961
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1337: train_loss=9.936485290527344
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1338: train_loss=9.930429458618164
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1339: train_loss=9.929258346557617
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1340: train_loss=9.916921615600586
INFO - 04/15/25 16:48:48 - 0:17:12 - Epoch 1341: train_loss=9.909165382385254
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1342: train_loss=9.886287689208984
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1343: train_loss=9.876373291015625
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1344: train_loss=9.871272087097168
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1345: train_loss=9.86117935180664
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1346: train_loss=9.860674858093262
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1347: train_loss=9.833046913146973
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1348: train_loss=9.839563369750977
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1349: train_loss=9.817840576171875
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1350: train_loss=9.788093566894531
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1351: train_loss=9.780601501464844
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1352: train_loss=9.790521621704102
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1353: train_loss=9.772222518920898
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1354: train_loss=9.786699295043945
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1355: train_loss=9.779934883117676
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1356: train_loss=9.771482467651367
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1357: train_loss=9.769744873046875
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1358: train_loss=9.773489952087402
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1359: train_loss=9.762605667114258
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1360: train_loss=9.751713752746582
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1361: train_loss=9.741256713867188
INFO - 04/15/25 16:48:49 - 0:17:12 - Epoch 1362: train_loss=9.704022407531738
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1363: train_loss=9.702609062194824
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1364: train_loss=9.698169708251953
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1365: train_loss=9.707573890686035
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1366: train_loss=9.70452880859375
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1367: train_loss=9.700900077819824
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1368: train_loss=9.700940132141113
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1369: train_loss=9.697713851928711
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1370: train_loss=9.70662784576416
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1371: train_loss=9.701516151428223
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1372: train_loss=9.702554702758789
INFO - 04/15/25 16:48:49 - 0:17:13 - Epoch 1373: train_loss=9.697123527526855
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1374: train_loss=9.703619003295898
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1375: train_loss=9.69986343383789
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1376: train_loss=9.69717025756836
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1377: train_loss=9.69373893737793
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1378: train_loss=9.6965970993042
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1379: train_loss=9.69663143157959
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1380: train_loss=9.696474075317383
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1381: train_loss=9.691773414611816
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1382: train_loss=9.684771537780762
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1383: train_loss=9.678791046142578
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1384: train_loss=9.679646492004395
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1385: train_loss=9.671195030212402
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1386: train_loss=9.675838470458984
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1387: train_loss=9.671874046325684
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1388: train_loss=9.674192428588867
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1389: train_loss=9.672307968139648
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1390: train_loss=9.674378395080566
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1391: train_loss=9.693441390991211
INFO - 04/15/25 16:48:50 - 0:17:13 - Epoch 1392: train_loss=9.691314697265625
INFO - 04/15/25 16:48:50 - 0:17:14 - Epoch 1393: train_loss=9.688756942749023
INFO - 04/15/25 16:48:50 - 0:17:14 - Epoch 1394: train_loss=9.6735258102417
INFO - 04/15/25 16:48:50 - 0:17:14 - Epoch 1395: train_loss=9.671525955200195
INFO - 04/15/25 16:48:50 - 0:17:14 - Epoch 1396: train_loss=9.670981407165527
INFO - 04/15/25 16:48:50 - 0:17:14 - Epoch 1397: train_loss=9.671197891235352
INFO - 04/15/25 16:48:50 - 0:17:14 - Epoch 1398: train_loss=9.670634269714355
INFO - 04/15/25 16:48:50 - 0:17:14 - Epoch 1399: train_loss=9.672449111938477
INFO - 04/15/25 16:48:50 - 0:17:14 - Epoch 1400: train_loss=9.670366287231445
INFO - 04/15/25 16:48:50 - 0:17:14 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:50 - 0:17:14 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1400: ACC: 0.0, NMI: 0.24140159382053095, F1: 0.0, ARI: 0.0732340681293926
INFO - 04/15/25 16:48:51 - 0:17:14 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1401: train_loss=9.667577743530273
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1402: train_loss=9.663352966308594
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1403: train_loss=9.646394729614258
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1404: train_loss=9.613247871398926
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1405: train_loss=9.623387336730957
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1406: train_loss=9.602517127990723
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1407: train_loss=9.613173484802246
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1408: train_loss=9.60521411895752
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1409: train_loss=9.607108116149902
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1410: train_loss=9.60412311553955
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1411: train_loss=9.60518741607666
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1412: train_loss=9.604009628295898
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1413: train_loss=9.603226661682129
INFO - 04/15/25 16:48:51 - 0:17:14 - Epoch 1414: train_loss=9.60092830657959
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1415: train_loss=9.606033325195312
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1416: train_loss=9.603556632995605
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1417: train_loss=9.604747772216797
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1418: train_loss=9.600089073181152
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1419: train_loss=9.587376594543457
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1420: train_loss=9.580638885498047
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1421: train_loss=9.553720474243164
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1422: train_loss=9.549776077270508
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1423: train_loss=9.549188613891602
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1424: train_loss=9.549505233764648
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1425: train_loss=9.547470092773438
INFO - 04/15/25 16:48:51 - 0:17:15 - Epoch 1426: train_loss=9.550960540771484
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1427: train_loss=9.546165466308594
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1428: train_loss=9.551872253417969
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1429: train_loss=9.546460151672363
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1430: train_loss=9.552760124206543
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1431: train_loss=9.597105026245117
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1432: train_loss=9.560147285461426
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1433: train_loss=9.572182655334473
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1434: train_loss=9.652018547058105
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1435: train_loss=9.654546737670898
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1436: train_loss=9.644718170166016
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1437: train_loss=9.653849601745605
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1438: train_loss=9.660163879394531
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1439: train_loss=9.655951499938965
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1440: train_loss=9.643697738647461
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1441: train_loss=9.648499488830566
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1442: train_loss=9.648353576660156
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1443: train_loss=9.645977020263672
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1444: train_loss=9.646252632141113
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1445: train_loss=9.64568042755127
INFO - 04/15/25 16:48:52 - 0:17:15 - Epoch 1446: train_loss=9.643901824951172
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1447: train_loss=9.645543098449707
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1448: train_loss=9.64180850982666
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1449: train_loss=9.643020629882812
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1450: train_loss=9.642842292785645
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1451: train_loss=9.636881828308105
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1452: train_loss=9.64750862121582
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1453: train_loss=9.646010398864746
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1454: train_loss=9.638993263244629
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1455: train_loss=9.639690399169922
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1456: train_loss=9.638903617858887
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1457: train_loss=9.633471488952637
INFO - 04/15/25 16:48:52 - 0:17:16 - Epoch 1458: train_loss=9.635162353515625
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1459: train_loss=9.635019302368164
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1460: train_loss=9.629762649536133
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1461: train_loss=9.63642692565918
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1462: train_loss=9.63375473022461
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1463: train_loss=9.631573677062988
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1464: train_loss=9.63620376586914
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1465: train_loss=9.646658897399902
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1466: train_loss=9.662768363952637
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1467: train_loss=9.65583610534668
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1468: train_loss=9.650398254394531
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1469: train_loss=9.657032012939453
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1470: train_loss=9.663803100585938
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1471: train_loss=9.657268524169922
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1472: train_loss=9.661282539367676
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1473: train_loss=9.634294509887695
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1474: train_loss=9.622640609741211
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1475: train_loss=9.607870101928711
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1476: train_loss=9.606743812561035
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1477: train_loss=9.581639289855957
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1478: train_loss=9.587587356567383
INFO - 04/15/25 16:48:53 - 0:17:16 - Epoch 1479: train_loss=9.561702728271484
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1480: train_loss=9.550951957702637
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1481: train_loss=9.56306266784668
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1482: train_loss=9.541812896728516
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1483: train_loss=9.54261589050293
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1484: train_loss=9.545591354370117
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1485: train_loss=9.541903495788574
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1486: train_loss=9.542366027832031
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1487: train_loss=9.540597915649414
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1488: train_loss=9.535589218139648
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1489: train_loss=9.532923698425293
INFO - 04/15/25 16:48:53 - 0:17:17 - Epoch 1490: train_loss=9.533470153808594
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1491: train_loss=9.527486801147461
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1492: train_loss=9.531289100646973
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1493: train_loss=9.527896881103516
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1494: train_loss=9.527822494506836
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1495: train_loss=9.527092933654785
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1496: train_loss=9.521575927734375
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1497: train_loss=9.524441719055176
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1498: train_loss=9.516148567199707
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1499: train_loss=9.528421401977539
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1500: train_loss=9.528804779052734
INFO - 04/15/25 16:48:54 - 0:17:17 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:54 - 0:17:17 - Decoding cost time:  0.132 s
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1500: ACC: 0.0, NMI: 0.25599901026056804, F1: 0.0, ARI: 0.10628098958106613
INFO - 04/15/25 16:48:54 - 0:17:17 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:54 - 0:17:17 - Epoch 1501: train_loss=9.525948524475098
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1502: train_loss=9.5265474319458
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1503: train_loss=9.524534225463867
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1504: train_loss=9.52257251739502
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1505: train_loss=9.524670600891113
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1506: train_loss=9.520630836486816
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1507: train_loss=9.521111488342285
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1508: train_loss=9.5218505859375
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1509: train_loss=9.517899513244629
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1510: train_loss=9.518902778625488
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1511: train_loss=9.521430969238281
INFO - 04/15/25 16:48:54 - 0:17:18 - Epoch 1512: train_loss=9.517841339111328
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1513: train_loss=9.518359184265137
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1514: train_loss=9.51953125
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1515: train_loss=9.517518997192383
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1516: train_loss=9.518217086791992
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1517: train_loss=9.515420913696289
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1518: train_loss=9.51877498626709
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1519: train_loss=9.51794147491455
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1520: train_loss=9.51677417755127
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1521: train_loss=9.516229629516602
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1522: train_loss=9.512113571166992
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1523: train_loss=9.515898704528809
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1524: train_loss=9.512434959411621
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1525: train_loss=9.510139465332031
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1526: train_loss=9.510059356689453
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1527: train_loss=9.497208595275879
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1528: train_loss=9.482634544372559
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1529: train_loss=9.48302173614502
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1530: train_loss=9.48158073425293
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1531: train_loss=9.480941772460938
INFO - 04/15/25 16:48:55 - 0:17:18 - Epoch 1532: train_loss=9.480361938476562
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1533: train_loss=9.482536315917969
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1534: train_loss=9.48051643371582
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1535: train_loss=9.482196807861328
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1536: train_loss=9.480720520019531
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1537: train_loss=9.479215621948242
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1538: train_loss=9.463371276855469
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1539: train_loss=9.4522066116333
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1540: train_loss=9.404773712158203
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1541: train_loss=9.396699905395508
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1542: train_loss=9.370955467224121
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1543: train_loss=9.367180824279785
INFO - 04/15/25 16:48:55 - 0:17:19 - Epoch 1544: train_loss=9.367135047912598
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1545: train_loss=9.368618965148926
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1546: train_loss=9.365072250366211
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1547: train_loss=9.37045669555664
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1548: train_loss=9.368912696838379
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1549: train_loss=9.366424560546875
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1550: train_loss=9.367086410522461
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1551: train_loss=9.363615036010742
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1552: train_loss=9.366716384887695
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1553: train_loss=9.3641996383667
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1554: train_loss=9.364043235778809
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1555: train_loss=9.363398551940918
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1556: train_loss=9.362947463989258
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1557: train_loss=9.360916137695312
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1558: train_loss=9.363361358642578
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1559: train_loss=9.359070777893066
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1560: train_loss=9.362251281738281
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1561: train_loss=9.358312606811523
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1562: train_loss=9.36550521850586
INFO - 04/15/25 16:48:56 - 0:17:19 - Epoch 1563: train_loss=9.363680839538574
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1564: train_loss=9.35785961151123
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1565: train_loss=9.364070892333984
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1566: train_loss=9.362286567687988
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1567: train_loss=9.360488891601562
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1568: train_loss=9.361035346984863
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1569: train_loss=9.359588623046875
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1570: train_loss=9.35921859741211
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1571: train_loss=9.361686706542969
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1572: train_loss=9.359152793884277
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1573: train_loss=9.36242389678955
INFO - 04/15/25 16:48:56 - 0:17:20 - Epoch 1574: train_loss=9.360883712768555
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1575: train_loss=9.360175132751465
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1576: train_loss=9.359484672546387
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1577: train_loss=9.358107566833496
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1578: train_loss=9.358071327209473
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1579: train_loss=9.360904693603516
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1580: train_loss=9.357263565063477
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1581: train_loss=9.361833572387695
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1582: train_loss=9.364164352416992
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1583: train_loss=9.356345176696777
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1584: train_loss=9.345992088317871
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1585: train_loss=9.350069046020508
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1586: train_loss=9.329168319702148
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1587: train_loss=9.327848434448242
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1588: train_loss=9.322854042053223
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1589: train_loss=9.319122314453125
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1590: train_loss=9.314563751220703
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1591: train_loss=9.316267013549805
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1592: train_loss=9.311444282531738
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1593: train_loss=9.316019058227539
INFO - 04/15/25 16:48:57 - 0:17:20 - Epoch 1594: train_loss=9.316143989562988
INFO - 04/15/25 16:48:57 - 0:17:21 - Epoch 1595: train_loss=9.31146240234375
INFO - 04/15/25 16:48:57 - 0:17:21 - Epoch 1596: train_loss=9.3107328414917
INFO - 04/15/25 16:48:57 - 0:17:21 - Epoch 1597: train_loss=9.312478065490723
INFO - 04/15/25 16:48:57 - 0:17:21 - Epoch 1598: train_loss=9.309364318847656
INFO - 04/15/25 16:48:57 - 0:17:21 - Epoch 1599: train_loss=9.30756664276123
INFO - 04/15/25 16:48:57 - 0:17:21 - Epoch 1600: train_loss=9.309769630432129
INFO - 04/15/25 16:48:57 - 0:17:21 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:48:57 - 0:17:21 - Decoding cost time:  0.123 s
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1600: ACC: 0.0, NMI: 0.2413064617816206, F1: 0.0, ARI: 0.07454637504467702
INFO - 04/15/25 16:48:58 - 0:17:21 - -------------------------------------------------------------------------
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1601: train_loss=9.304359436035156
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1602: train_loss=9.3112154006958
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1603: train_loss=9.312150001525879
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1604: train_loss=9.309045791625977
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1605: train_loss=9.305035591125488
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1606: train_loss=9.308086395263672
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1607: train_loss=9.306655883789062
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1608: train_loss=9.306012153625488
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1609: train_loss=9.307653427124023
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1610: train_loss=9.304332733154297
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1611: train_loss=9.30683708190918
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1612: train_loss=9.304322242736816
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1613: train_loss=9.305131912231445
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1614: train_loss=9.306294441223145
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1615: train_loss=9.299901008605957
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1616: train_loss=9.305542945861816
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1617: train_loss=9.304258346557617
INFO - 04/15/25 16:48:58 - 0:17:21 - Epoch 1618: train_loss=9.305082321166992
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1619: train_loss=9.294315338134766
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1620: train_loss=9.30721378326416
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1621: train_loss=9.303121566772461
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1622: train_loss=9.30746078491211
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1623: train_loss=9.304462432861328
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1624: train_loss=9.308825492858887
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1625: train_loss=9.30312728881836
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1626: train_loss=9.303834915161133
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1627: train_loss=9.304632186889648
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1628: train_loss=9.305910110473633
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1629: train_loss=9.303410530090332
INFO - 04/15/25 16:48:58 - 0:17:22 - Epoch 1630: train_loss=9.303038597106934
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1631: train_loss=9.302421569824219
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1632: train_loss=9.302047729492188
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1633: train_loss=9.299921035766602
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1634: train_loss=9.305503845214844
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1635: train_loss=9.301884651184082
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1636: train_loss=9.306180000305176
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1637: train_loss=9.305439949035645
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1638: train_loss=9.300788879394531
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1639: train_loss=9.300287246704102
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1640: train_loss=9.304317474365234
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1641: train_loss=9.301652908325195
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1642: train_loss=9.304940223693848
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1643: train_loss=9.303977966308594
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1644: train_loss=9.302441596984863
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1645: train_loss=9.303937911987305
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1646: train_loss=9.301726341247559
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1647: train_loss=9.30600357055664
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1648: train_loss=9.301542282104492
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1649: train_loss=9.308123588562012
INFO - 04/15/25 16:48:59 - 0:17:22 - Epoch 1650: train_loss=9.307531356811523
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1651: train_loss=9.304265975952148
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1652: train_loss=9.309027671813965
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1653: train_loss=9.315220832824707
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1654: train_loss=9.313983917236328
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1655: train_loss=9.286786079406738
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1656: train_loss=9.285562515258789
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1657: train_loss=9.286252975463867
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1658: train_loss=9.285416603088379
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1659: train_loss=9.281286239624023
INFO - 04/15/25 16:48:59 - 0:17:23 - Epoch 1660: train_loss=9.277323722839355
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1661: train_loss=9.276012420654297
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1662: train_loss=9.262673377990723
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1663: train_loss=9.256952285766602
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1664: train_loss=9.255107879638672
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1665: train_loss=9.256608963012695
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1666: train_loss=9.252686500549316
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1667: train_loss=9.255226135253906
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1668: train_loss=9.248802185058594
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1669: train_loss=9.24587631225586
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1670: train_loss=9.242573738098145
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1671: train_loss=9.249065399169922
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1672: train_loss=9.243064880371094
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1673: train_loss=9.245867729187012
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1674: train_loss=9.242743492126465
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1675: train_loss=9.241724014282227
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1676: train_loss=9.237709045410156
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1677: train_loss=9.242549896240234
INFO - 04/15/25 16:49:00 - 0:17:23 - Epoch 1678: train_loss=9.242125511169434
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1679: train_loss=9.234251022338867
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1680: train_loss=9.234362602233887
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1681: train_loss=9.234369277954102
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1682: train_loss=9.234180450439453
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1683: train_loss=9.23035717010498
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1684: train_loss=9.235591888427734
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1685: train_loss=9.233538627624512
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1686: train_loss=9.231328964233398
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1687: train_loss=9.231280326843262
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1688: train_loss=9.239400863647461
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1689: train_loss=9.231888771057129
INFO - 04/15/25 16:49:00 - 0:17:24 - Epoch 1690: train_loss=9.227971076965332
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1691: train_loss=9.218971252441406
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1692: train_loss=9.216196060180664
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1693: train_loss=9.222304344177246
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1694: train_loss=9.276021957397461
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1695: train_loss=9.31913948059082
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1696: train_loss=9.39738941192627
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1697: train_loss=9.436388969421387
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1698: train_loss=9.37351131439209
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1699: train_loss=9.351505279541016
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1700: train_loss=9.357830047607422
INFO - 04/15/25 16:49:01 - 0:17:24 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:01 - 0:17:24 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:49:01 - 0:17:24 - ------------------Saving best model-------------------
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1700: ACC: 0.0, NMI: 0.42968710791231135, F1: 0.0, ARI: 0.22916694950159827
INFO - 04/15/25 16:49:01 - 0:17:24 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:01 - 0:17:24 - Epoch 1701: train_loss=9.333115577697754
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1702: train_loss=9.352861404418945
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1703: train_loss=9.410127639770508
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1704: train_loss=9.348783493041992
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1705: train_loss=9.317558288574219
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1706: train_loss=9.286382675170898
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1707: train_loss=9.275391578674316
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1708: train_loss=9.362597465515137
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1709: train_loss=9.297062873840332
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1710: train_loss=9.25467300415039
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1711: train_loss=9.231066703796387
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1712: train_loss=9.247674942016602
INFO - 04/15/25 16:49:01 - 0:17:25 - Epoch 1713: train_loss=9.272064208984375
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1714: train_loss=9.222055435180664
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1715: train_loss=9.248879432678223
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1716: train_loss=9.233335494995117
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1717: train_loss=9.271708488464355
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1718: train_loss=9.254520416259766
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1719: train_loss=9.204408645629883
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1720: train_loss=9.2410249710083
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1721: train_loss=9.23633861541748
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1722: train_loss=9.220070838928223
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1723: train_loss=9.193221092224121
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1724: train_loss=9.225400924682617
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1725: train_loss=9.18399715423584
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1726: train_loss=9.200871467590332
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1727: train_loss=9.210179328918457
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1728: train_loss=9.197652816772461
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1729: train_loss=9.162873268127441
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1730: train_loss=9.16443920135498
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1731: train_loss=9.13094425201416
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1732: train_loss=9.109143257141113
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1733: train_loss=9.137632369995117
INFO - 04/15/25 16:49:02 - 0:17:25 - Epoch 1734: train_loss=9.095294952392578
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1735: train_loss=9.09181022644043
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1736: train_loss=9.085168838500977
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1737: train_loss=9.084035873413086
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1738: train_loss=9.096969604492188
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1739: train_loss=9.084817886352539
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1740: train_loss=9.090209007263184
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1741: train_loss=9.086071014404297
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1742: train_loss=9.082049369812012
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1743: train_loss=9.088451385498047
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1744: train_loss=9.09347152709961
INFO - 04/15/25 16:49:02 - 0:17:26 - Epoch 1745: train_loss=9.087181091308594
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1746: train_loss=9.087156295776367
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1747: train_loss=9.085926055908203
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1748: train_loss=9.084695816040039
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1749: train_loss=9.0731840133667
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1750: train_loss=9.085583686828613
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1751: train_loss=9.083542823791504
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1752: train_loss=9.082427024841309
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1753: train_loss=9.074506759643555
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1754: train_loss=9.074983596801758
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1755: train_loss=9.074016571044922
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1756: train_loss=9.069499015808105
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1757: train_loss=9.086233139038086
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1758: train_loss=9.081287384033203
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1759: train_loss=9.082117080688477
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1760: train_loss=9.095976829528809
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1761: train_loss=9.119580268859863
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1762: train_loss=9.138030052185059
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1763: train_loss=9.12110424041748
INFO - 04/15/25 16:49:03 - 0:17:26 - Epoch 1764: train_loss=9.130151748657227
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1765: train_loss=9.087581634521484
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1766: train_loss=9.069849967956543
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1767: train_loss=9.079485893249512
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1768: train_loss=9.082182884216309
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1769: train_loss=9.080324172973633
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1770: train_loss=9.067915916442871
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1771: train_loss=9.054141998291016
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1772: train_loss=9.05942153930664
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1773: train_loss=9.066666603088379
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1774: train_loss=9.063453674316406
INFO - 04/15/25 16:49:03 - 0:17:27 - Epoch 1775: train_loss=9.051369667053223
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1776: train_loss=9.046969413757324
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1777: train_loss=9.053340911865234
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1778: train_loss=9.048460960388184
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1779: train_loss=9.04696273803711
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1780: train_loss=9.043890953063965
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1781: train_loss=9.041751861572266
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1782: train_loss=9.037033081054688
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1783: train_loss=9.038238525390625
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1784: train_loss=9.03615665435791
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1785: train_loss=9.030668258666992
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1786: train_loss=9.033005714416504
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1787: train_loss=9.032879829406738
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1788: train_loss=9.02662467956543
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1789: train_loss=9.032064437866211
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1790: train_loss=9.031168937683105
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1791: train_loss=9.023921966552734
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1792: train_loss=9.032936096191406
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1793: train_loss=9.025403022766113
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1794: train_loss=9.022178649902344
INFO - 04/15/25 16:49:04 - 0:17:27 - Epoch 1795: train_loss=9.023780822753906
INFO - 04/15/25 16:49:04 - 0:17:28 - Epoch 1796: train_loss=9.014555931091309
INFO - 04/15/25 16:49:04 - 0:17:28 - Epoch 1797: train_loss=9.024296760559082
INFO - 04/15/25 16:49:04 - 0:17:28 - Epoch 1798: train_loss=9.020249366760254
INFO - 04/15/25 16:49:04 - 0:17:28 - Epoch 1799: train_loss=9.026872634887695
INFO - 04/15/25 16:49:04 - 0:17:28 - Epoch 1800: train_loss=9.021573066711426
INFO - 04/15/25 16:49:04 - 0:17:28 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:04 - 0:17:28 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1800: ACC: 0.0, NMI: 0.3732196734269127, F1: 0.0, ARI: 0.1831702403045792
INFO - 04/15/25 16:49:05 - 0:17:28 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1801: train_loss=9.019647598266602
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1802: train_loss=9.020105361938477
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1803: train_loss=9.018345832824707
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1804: train_loss=9.020224571228027
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1805: train_loss=9.019339561462402
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1806: train_loss=9.017087936401367
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1807: train_loss=9.020134925842285
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1808: train_loss=9.012842178344727
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1809: train_loss=9.019359588623047
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1810: train_loss=9.018309593200684
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1811: train_loss=9.016718864440918
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1812: train_loss=9.015016555786133
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1813: train_loss=9.009295463562012
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1814: train_loss=9.012755393981934
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1815: train_loss=9.013091087341309
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1816: train_loss=9.016068458557129
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1817: train_loss=9.01120376586914
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1818: train_loss=9.012885093688965
INFO - 04/15/25 16:49:05 - 0:17:28 - Epoch 1819: train_loss=9.008652687072754
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1820: train_loss=9.011270523071289
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1821: train_loss=9.030641555786133
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1822: train_loss=9.009970664978027
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1823: train_loss=9.014200210571289
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1824: train_loss=9.011886596679688
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1825: train_loss=9.012840270996094
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1826: train_loss=9.01677417755127
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1827: train_loss=9.010441780090332
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1828: train_loss=9.01690673828125
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1829: train_loss=9.007622718811035
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1830: train_loss=9.017982482910156
INFO - 04/15/25 16:49:05 - 0:17:29 - Epoch 1831: train_loss=9.016243934631348
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1832: train_loss=9.014510154724121
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1833: train_loss=9.013096809387207
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1834: train_loss=9.014123916625977
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1835: train_loss=9.012012481689453
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1836: train_loss=9.017597198486328
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1837: train_loss=9.011652946472168
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1838: train_loss=9.009364128112793
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1839: train_loss=9.01198673248291
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1840: train_loss=9.0101900100708
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1841: train_loss=9.012052536010742
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1842: train_loss=9.00936508178711
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1843: train_loss=9.008014678955078
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1844: train_loss=9.006103515625
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1845: train_loss=9.010887145996094
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1846: train_loss=8.997625350952148
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1847: train_loss=8.992650985717773
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1848: train_loss=8.996427536010742
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1849: train_loss=8.997322082519531
INFO - 04/15/25 16:49:06 - 0:17:29 - Epoch 1850: train_loss=8.982641220092773
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1851: train_loss=8.986743927001953
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1852: train_loss=8.981289863586426
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1853: train_loss=8.982789993286133
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1854: train_loss=8.98556900024414
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1855: train_loss=8.978391647338867
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1856: train_loss=8.979619026184082
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1857: train_loss=8.974235534667969
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1858: train_loss=8.974027633666992
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1859: train_loss=8.973321914672852
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1860: train_loss=8.970735549926758
INFO - 04/15/25 16:49:06 - 0:17:30 - Epoch 1861: train_loss=8.975354194641113
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1862: train_loss=8.972143173217773
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1863: train_loss=8.979742050170898
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1864: train_loss=8.973662376403809
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1865: train_loss=8.97366714477539
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1866: train_loss=8.974516868591309
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1867: train_loss=8.970072746276855
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1868: train_loss=8.967440605163574
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1869: train_loss=8.973747253417969
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1870: train_loss=8.97121810913086
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1871: train_loss=8.97390079498291
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1872: train_loss=8.97026252746582
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1873: train_loss=8.972424507141113
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1874: train_loss=8.972345352172852
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1875: train_loss=8.96977424621582
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1876: train_loss=8.968138694763184
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1877: train_loss=8.971029281616211
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1878: train_loss=8.969420433044434
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1879: train_loss=8.97118091583252
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1880: train_loss=8.968932151794434
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1881: train_loss=8.96814250946045
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1882: train_loss=8.971022605895996
INFO - 04/15/25 16:49:07 - 0:17:30 - Epoch 1883: train_loss=8.970963478088379
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1884: train_loss=8.97912311553955
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1885: train_loss=8.972795486450195
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1886: train_loss=8.976551055908203
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1887: train_loss=8.968668937683105
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1888: train_loss=8.977885246276855
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1889: train_loss=8.97805118560791
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1890: train_loss=8.946990013122559
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1891: train_loss=8.983677864074707
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1892: train_loss=8.972187042236328
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1893: train_loss=8.976972579956055
INFO - 04/15/25 16:49:07 - 0:17:31 - Epoch 1894: train_loss=8.997065544128418
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1895: train_loss=8.992345809936523
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1896: train_loss=8.980817794799805
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1897: train_loss=8.9824857711792
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1898: train_loss=8.979178428649902
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1899: train_loss=8.987098693847656
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1900: train_loss=8.983319282531738
INFO - 04/15/25 16:49:08 - 0:17:31 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:08 - 0:17:31 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1900: ACC: 0.0, NMI: 0.40975574193720476, F1: 0.0, ARI: 0.1863760774833997
INFO - 04/15/25 16:49:08 - 0:17:31 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1901: train_loss=8.981036186218262
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1902: train_loss=8.982624053955078
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1903: train_loss=8.981561660766602
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1904: train_loss=8.981575965881348
INFO - 04/15/25 16:49:08 - 0:17:31 - Epoch 1905: train_loss=8.97925853729248
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1906: train_loss=8.981014251708984
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1907: train_loss=8.981710433959961
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1908: train_loss=8.976990699768066
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1909: train_loss=8.97647476196289
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1910: train_loss=8.977330207824707
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1911: train_loss=8.975255012512207
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1912: train_loss=8.978645324707031
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1913: train_loss=8.977972984313965
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1914: train_loss=8.976555824279785
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1915: train_loss=8.97495174407959
INFO - 04/15/25 16:49:08 - 0:17:32 - Epoch 1916: train_loss=8.974125862121582
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1917: train_loss=8.973661422729492
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1918: train_loss=8.973158836364746
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1919: train_loss=8.971945762634277
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1920: train_loss=8.971729278564453
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1921: train_loss=8.97019100189209
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1922: train_loss=8.975020408630371
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1923: train_loss=8.971372604370117
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1924: train_loss=8.962738990783691
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1925: train_loss=8.969870567321777
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1926: train_loss=8.970016479492188
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1927: train_loss=8.97043514251709
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1928: train_loss=8.964461326599121
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1929: train_loss=8.971660614013672
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1930: train_loss=8.96921443939209
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1931: train_loss=8.972939491271973
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1932: train_loss=8.967599868774414
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1933: train_loss=8.974143981933594
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1934: train_loss=8.97430419921875
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1935: train_loss=8.971529006958008
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1936: train_loss=8.972461700439453
INFO - 04/15/25 16:49:09 - 0:17:32 - Epoch 1937: train_loss=8.973039627075195
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1938: train_loss=8.969582557678223
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1939: train_loss=8.969168663024902
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1940: train_loss=8.967459678649902
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1941: train_loss=8.969922065734863
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1942: train_loss=8.97028636932373
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1943: train_loss=8.96291732788086
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1944: train_loss=8.968376159667969
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1945: train_loss=8.969465255737305
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1946: train_loss=8.967687606811523
INFO - 04/15/25 16:49:09 - 0:17:33 - Epoch 1947: train_loss=8.970989227294922
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1948: train_loss=8.968062400817871
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1949: train_loss=8.971658706665039
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1950: train_loss=8.968235969543457
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1951: train_loss=8.964374542236328
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1952: train_loss=8.969953536987305
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1953: train_loss=8.965645790100098
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1954: train_loss=8.97506332397461
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1955: train_loss=8.969701766967773
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1956: train_loss=8.971698760986328
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1957: train_loss=8.972519874572754
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1958: train_loss=8.972871780395508
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1959: train_loss=8.971765518188477
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1960: train_loss=8.971561431884766
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1961: train_loss=8.971863746643066
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1962: train_loss=8.971423149108887
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1963: train_loss=8.969090461730957
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1964: train_loss=8.959476470947266
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1965: train_loss=8.971811294555664
INFO - 04/15/25 16:49:10 - 0:17:33 - Epoch 1966: train_loss=8.95799446105957
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1967: train_loss=8.970428466796875
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1968: train_loss=8.971009254455566
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1969: train_loss=8.971551895141602
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1970: train_loss=8.973710060119629
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1971: train_loss=8.965665817260742
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1972: train_loss=8.969940185546875
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1973: train_loss=8.967535972595215
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1974: train_loss=8.97948932647705
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1975: train_loss=8.971941947937012
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1976: train_loss=8.969304084777832
INFO - 04/15/25 16:49:10 - 0:17:34 - Epoch 1977: train_loss=8.970987319946289
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1978: train_loss=8.969354629516602
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1979: train_loss=8.967146873474121
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1980: train_loss=8.973551750183105
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1981: train_loss=8.969367027282715
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1982: train_loss=8.966527938842773
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1983: train_loss=8.970111846923828
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1984: train_loss=8.968159675598145
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1985: train_loss=8.96712589263916
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1986: train_loss=8.96705436706543
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1987: train_loss=8.940881729125977
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1988: train_loss=8.966856956481934
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1989: train_loss=8.9668550491333
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1990: train_loss=8.96547794342041
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1991: train_loss=8.963611602783203
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1992: train_loss=8.965764999389648
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1993: train_loss=8.967646598815918
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1994: train_loss=8.970064163208008
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1995: train_loss=8.966657638549805
INFO - 04/15/25 16:49:11 - 0:17:34 - Epoch 1996: train_loss=8.943585395812988
INFO - 04/15/25 16:49:11 - 0:17:35 - Epoch 1997: train_loss=8.937560081481934
INFO - 04/15/25 16:49:11 - 0:17:35 - Epoch 1998: train_loss=8.953939437866211
INFO - 04/15/25 16:49:11 - 0:17:35 - Epoch 1999: train_loss=8.959864616394043
INFO - 04/15/25 16:49:11 - 0:17:35 - Epoch 2000: train_loss=8.949142456054688
INFO - 04/15/25 16:49:11 - 0:17:35 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:11 - 0:17:35 - Decoding cost time:  0.122 s
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2000: ACC: 0.0, NMI: 0.2662968811165426, F1: 0.0, ARI: 0.11662369581644627
INFO - 04/15/25 16:49:12 - 0:17:35 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2001: train_loss=8.962540626525879
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2002: train_loss=8.972066879272461
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2003: train_loss=8.971268653869629
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2004: train_loss=8.96851634979248
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2005: train_loss=8.972418785095215
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2006: train_loss=8.968944549560547
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2007: train_loss=8.971571922302246
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2008: train_loss=8.971015930175781
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2009: train_loss=8.973812103271484
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2010: train_loss=8.971595764160156
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2011: train_loss=8.967926025390625
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2012: train_loss=8.971166610717773
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2013: train_loss=8.96842098236084
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2014: train_loss=8.969615936279297
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2015: train_loss=8.971609115600586
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2016: train_loss=8.968077659606934
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2017: train_loss=8.96779727935791
INFO - 04/15/25 16:49:12 - 0:17:35 - Epoch 2018: train_loss=8.972360610961914
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2019: train_loss=8.971418380737305
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2020: train_loss=8.966197967529297
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2021: train_loss=8.966294288635254
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2022: train_loss=8.983648300170898
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2023: train_loss=8.927358627319336
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2024: train_loss=8.961376190185547
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2025: train_loss=8.972224235534668
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2026: train_loss=8.9712553024292
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2027: train_loss=9.024002075195312
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2028: train_loss=8.982365608215332
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2029: train_loss=9.00442123413086
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2030: train_loss=9.006712913513184
INFO - 04/15/25 16:49:12 - 0:17:36 - Epoch 2031: train_loss=9.030153274536133
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2032: train_loss=9.021424293518066
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2033: train_loss=9.01627254486084
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2034: train_loss=9.012923240661621
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2035: train_loss=9.004556655883789
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2036: train_loss=9.011788368225098
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2037: train_loss=9.005491256713867
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2038: train_loss=9.005319595336914
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2039: train_loss=8.998533248901367
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2040: train_loss=8.994743347167969
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2041: train_loss=8.989435195922852
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2042: train_loss=8.996659278869629
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2043: train_loss=9.00157356262207
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2044: train_loss=8.989615440368652
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2045: train_loss=8.997031211853027
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2046: train_loss=8.999650001525879
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2047: train_loss=8.989798545837402
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2048: train_loss=8.996602058410645
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2049: train_loss=8.997940063476562
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2050: train_loss=8.996559143066406
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2051: train_loss=8.978997230529785
INFO - 04/15/25 16:49:13 - 0:17:36 - Epoch 2052: train_loss=8.997374534606934
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2053: train_loss=8.974288940429688
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2054: train_loss=9.003143310546875
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2055: train_loss=8.9965181350708
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2056: train_loss=8.982681274414062
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2057: train_loss=8.997062683105469
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2058: train_loss=8.997737884521484
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2059: train_loss=8.986371040344238
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2060: train_loss=8.995641708374023
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2061: train_loss=8.99826431274414
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2062: train_loss=8.997346878051758
INFO - 04/15/25 16:49:13 - 0:17:37 - Epoch 2063: train_loss=8.998662948608398
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2064: train_loss=8.987602233886719
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2065: train_loss=9.000319480895996
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2066: train_loss=9.000970840454102
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2067: train_loss=8.986283302307129
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2068: train_loss=8.99586296081543
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2069: train_loss=8.982388496398926
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2070: train_loss=8.99817180633545
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2071: train_loss=8.996295928955078
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2072: train_loss=8.987842559814453
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2073: train_loss=8.996136665344238
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2074: train_loss=8.99109935760498
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2075: train_loss=8.987626075744629
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2076: train_loss=8.958508491516113
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2077: train_loss=8.99324893951416
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2078: train_loss=8.997121810913086
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2079: train_loss=8.99769401550293
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2080: train_loss=8.998095512390137
INFO - 04/15/25 16:49:14 - 0:17:37 - Epoch 2081: train_loss=8.993729591369629
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2082: train_loss=8.998764038085938
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2083: train_loss=8.991927146911621
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2084: train_loss=8.992900848388672
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2085: train_loss=8.987689971923828
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2086: train_loss=8.994624137878418
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2087: train_loss=8.9746675491333
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2088: train_loss=8.997031211853027
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2089: train_loss=8.99715518951416
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2090: train_loss=8.997456550598145
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2091: train_loss=8.989042282104492
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2092: train_loss=8.979757308959961
INFO - 04/15/25 16:49:14 - 0:17:38 - Epoch 2093: train_loss=8.99085807800293
INFO - 04/15/25 16:49:15 - 0:17:38 - Epoch 2094: train_loss=8.999494552612305
INFO - 04/15/25 16:49:15 - 0:17:38 - Epoch 2095: train_loss=8.989813804626465
INFO - 04/15/25 16:49:17 - 0:17:38 - Epoch 2096: train_loss=8.996198654174805
INFO - 04/15/25 16:49:17 - 0:17:40 - Epoch 2097: train_loss=8.984350204467773
INFO - 04/15/25 16:49:17 - 0:17:40 - Epoch 2098: train_loss=8.982421875
INFO - 04/15/25 16:49:17 - 0:17:40 - Epoch 2099: train_loss=8.991155624389648
INFO - 04/15/25 16:49:17 - 0:17:40 - Epoch 2100: train_loss=8.99929141998291
INFO - 04/15/25 16:49:17 - 0:17:40 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:17 - 0:17:41 - Decoding cost time:  0.133 s
INFO - 04/15/25 16:49:17 - 0:17:41 - Epoch 2100: ACC: 0.0, NMI: 0.2913507241242517, F1: 0.0, ARI: 0.11874737028325091
INFO - 04/15/25 16:49:17 - 0:17:41 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:17 - 0:17:41 - Epoch 2101: train_loss=8.990890502929688
INFO - 04/15/25 16:49:17 - 0:17:41 - Epoch 2102: train_loss=8.990579605102539
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2103: train_loss=8.991724967956543
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2104: train_loss=8.972504615783691
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2105: train_loss=8.995102882385254
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2106: train_loss=8.991768836975098
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2107: train_loss=8.988438606262207
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2108: train_loss=8.996431350708008
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2109: train_loss=8.989080429077148
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2110: train_loss=8.991256713867188
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2111: train_loss=8.991705894470215
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2112: train_loss=8.989709854125977
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2113: train_loss=8.983771324157715
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2114: train_loss=8.988306999206543
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2115: train_loss=8.993674278259277
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2116: train_loss=8.978245735168457
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2117: train_loss=8.986686706542969
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2118: train_loss=8.998695373535156
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2119: train_loss=8.968974113464355
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2120: train_loss=8.989238739013672
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2121: train_loss=8.993103981018066
INFO - 04/15/25 16:49:18 - 0:17:41 - Epoch 2122: train_loss=8.989419937133789
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2123: train_loss=8.979127883911133
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2124: train_loss=8.998826026916504
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2125: train_loss=8.980777740478516
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2126: train_loss=8.996821403503418
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2127: train_loss=8.9956693649292
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2128: train_loss=8.994222640991211
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2129: train_loss=8.996438980102539
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2130: train_loss=8.99635124206543
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2131: train_loss=8.983163833618164
INFO - 04/15/25 16:49:18 - 0:17:42 - Epoch 2132: train_loss=8.992650985717773
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2133: train_loss=8.989790916442871
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2134: train_loss=8.99427604675293
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2135: train_loss=8.991135597229004
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2136: train_loss=8.975680351257324
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2137: train_loss=8.989286422729492
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2138: train_loss=8.996994972229004
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2139: train_loss=8.981880187988281
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2140: train_loss=8.994129180908203
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2141: train_loss=8.994105339050293
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2142: train_loss=8.985568046569824
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2143: train_loss=8.997679710388184
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2144: train_loss=8.964919090270996
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2145: train_loss=9.005169868469238
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2146: train_loss=8.999238014221191
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2147: train_loss=8.993661880493164
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2148: train_loss=8.971006393432617
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2149: train_loss=8.985431671142578
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2150: train_loss=8.98388957977295
INFO - 04/15/25 16:49:19 - 0:17:42 - Epoch 2151: train_loss=8.982477188110352
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2152: train_loss=8.980752944946289
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2153: train_loss=8.964521408081055
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2154: train_loss=8.96483039855957
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2155: train_loss=8.94992733001709
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2156: train_loss=8.975504875183105
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2157: train_loss=8.961506843566895
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2158: train_loss=8.970771789550781
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2159: train_loss=8.956002235412598
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2160: train_loss=8.967708587646484
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2161: train_loss=8.967241287231445
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2162: train_loss=8.965178489685059
INFO - 04/15/25 16:49:19 - 0:17:43 - Epoch 2163: train_loss=8.977994918823242
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2164: train_loss=8.975748062133789
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2165: train_loss=8.97615909576416
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2166: train_loss=8.962815284729004
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2167: train_loss=8.972944259643555
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2168: train_loss=8.973048210144043
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2169: train_loss=8.966229438781738
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2170: train_loss=8.966120719909668
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2171: train_loss=8.978644371032715
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2172: train_loss=8.972994804382324
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2173: train_loss=8.965747833251953
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2174: train_loss=8.97846794128418
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2175: train_loss=8.965581893920898
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2176: train_loss=8.96474838256836
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2177: train_loss=8.936744689941406
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2178: train_loss=8.949962615966797
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2179: train_loss=8.91919994354248
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2180: train_loss=8.93029499053955
INFO - 04/15/25 16:49:20 - 0:17:43 - Epoch 2181: train_loss=8.930181503295898
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2182: train_loss=8.925159454345703
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2183: train_loss=8.935102462768555
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2184: train_loss=8.919160842895508
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2185: train_loss=8.917800903320312
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2186: train_loss=8.924934387207031
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2187: train_loss=8.931193351745605
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2188: train_loss=8.912064552307129
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2189: train_loss=8.922264099121094
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2190: train_loss=8.91450023651123
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2191: train_loss=8.912613868713379
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2192: train_loss=8.913622856140137
INFO - 04/15/25 16:49:20 - 0:17:44 - Epoch 2193: train_loss=8.892694473266602
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2194: train_loss=8.903199195861816
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2195: train_loss=8.904924392700195
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2196: train_loss=8.8931884765625
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2197: train_loss=8.901397705078125
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2198: train_loss=8.90003490447998
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2199: train_loss=8.908547401428223
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2200: train_loss=8.894131660461426
INFO - 04/15/25 16:49:21 - 0:17:44 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:21 - 0:17:44 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2200: ACC: 0.0, NMI: 0.2799453639214645, F1: 0.0, ARI: 0.10899777475850855
INFO - 04/15/25 16:49:21 - 0:17:44 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2201: train_loss=8.9041166305542
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2202: train_loss=8.90266227722168
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2203: train_loss=8.886756896972656
INFO - 04/15/25 16:49:21 - 0:17:44 - Epoch 2204: train_loss=8.89883804321289
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2205: train_loss=8.88817024230957
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2206: train_loss=8.898816108703613
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2207: train_loss=8.873244285583496
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2208: train_loss=8.904518127441406
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2209: train_loss=8.896879196166992
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2210: train_loss=8.891519546508789
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2211: train_loss=8.898367881774902
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2212: train_loss=8.899484634399414
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2213: train_loss=8.900007247924805
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2214: train_loss=8.905452728271484
INFO - 04/15/25 16:49:21 - 0:17:45 - Epoch 2215: train_loss=8.920894622802734
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2216: train_loss=8.90432357788086
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2217: train_loss=8.900742530822754
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2218: train_loss=8.889527320861816
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2219: train_loss=8.883066177368164
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2220: train_loss=8.866667747497559
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2221: train_loss=8.83902645111084
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2222: train_loss=8.828697204589844
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2223: train_loss=8.829549789428711
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2224: train_loss=8.833171844482422
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2225: train_loss=8.827384948730469
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2226: train_loss=8.836209297180176
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2227: train_loss=8.831331253051758
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2228: train_loss=8.828432083129883
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2229: train_loss=8.819376945495605
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2230: train_loss=8.825572967529297
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2231: train_loss=8.832862854003906
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2232: train_loss=8.832098960876465
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2233: train_loss=8.823296546936035
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2234: train_loss=8.821247100830078
INFO - 04/15/25 16:49:22 - 0:17:45 - Epoch 2235: train_loss=8.825230598449707
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2236: train_loss=8.823689460754395
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2237: train_loss=8.826854705810547
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2238: train_loss=8.818333625793457
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2239: train_loss=8.817075729370117
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2240: train_loss=8.819194793701172
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2241: train_loss=8.815633773803711
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2242: train_loss=8.819902420043945
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2243: train_loss=8.81595230102539
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2244: train_loss=8.81341552734375
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2245: train_loss=8.808171272277832
INFO - 04/15/25 16:49:22 - 0:17:46 - Epoch 2246: train_loss=8.817062377929688
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2247: train_loss=8.809087753295898
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2248: train_loss=8.813005447387695
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2249: train_loss=8.815242767333984
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2250: train_loss=8.809892654418945
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2251: train_loss=8.812311172485352
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2252: train_loss=8.808615684509277
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2253: train_loss=8.813312530517578
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2254: train_loss=8.806203842163086
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2255: train_loss=8.801596641540527
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2256: train_loss=8.803667068481445
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2257: train_loss=8.805313110351562
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2258: train_loss=8.7946138381958
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2259: train_loss=8.804739952087402
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2260: train_loss=8.798981666564941
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2261: train_loss=8.805116653442383
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2262: train_loss=8.797677040100098
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2263: train_loss=8.801960945129395
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2264: train_loss=8.804609298706055
INFO - 04/15/25 16:49:23 - 0:17:46 - Epoch 2265: train_loss=8.80721378326416
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2266: train_loss=8.800162315368652
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2267: train_loss=8.788971900939941
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2268: train_loss=8.801945686340332
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2269: train_loss=8.79928970336914
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2270: train_loss=8.801026344299316
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2271: train_loss=8.807439804077148
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2272: train_loss=8.797757148742676
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2273: train_loss=8.801631927490234
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2274: train_loss=8.796862602233887
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2275: train_loss=8.799373626708984
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2276: train_loss=8.788056373596191
INFO - 04/15/25 16:49:23 - 0:17:47 - Epoch 2277: train_loss=8.799365997314453
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2278: train_loss=8.799184799194336
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2279: train_loss=8.771585464477539
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2280: train_loss=8.800273895263672
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2281: train_loss=8.798779487609863
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2282: train_loss=8.795621871948242
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2283: train_loss=8.793953895568848
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2284: train_loss=8.762374877929688
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2285: train_loss=8.797613143920898
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2286: train_loss=8.797178268432617
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2287: train_loss=8.794885635375977
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2288: train_loss=8.797736167907715
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2289: train_loss=8.791654586791992
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2290: train_loss=8.77892017364502
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2291: train_loss=8.790298461914062
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2292: train_loss=8.79668140411377
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2293: train_loss=8.79197883605957
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2294: train_loss=8.794190406799316
INFO - 04/15/25 16:49:24 - 0:17:47 - Epoch 2295: train_loss=8.791008949279785
INFO - 04/15/25 16:49:24 - 0:17:48 - Epoch 2296: train_loss=8.790398597717285
INFO - 04/15/25 16:49:24 - 0:17:48 - Epoch 2297: train_loss=8.785239219665527
INFO - 04/15/25 16:49:24 - 0:17:48 - Epoch 2298: train_loss=8.79478931427002
INFO - 04/15/25 16:49:24 - 0:17:48 - Epoch 2299: train_loss=8.794159889221191
INFO - 04/15/25 16:49:24 - 0:17:48 - Epoch 2300: train_loss=8.792576789855957
INFO - 04/15/25 16:49:24 - 0:17:48 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:24 - 0:17:48 - Decoding cost time:  0.124 s
INFO - 04/15/25 16:49:25 - 0:17:49 - Epoch 2300: ACC: 0.0, NMI: 0.26981460731589524, F1: 0.0, ARI: 0.048052969144180196
INFO - 04/15/25 16:49:25 - 0:17:49 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:25 - 0:17:49 - Epoch 2301: train_loss=8.799643516540527
INFO - 04/15/25 16:49:25 - 0:17:49 - Epoch 2302: train_loss=8.788460731506348
INFO - 04/15/25 16:49:25 - 0:17:49 - Epoch 2303: train_loss=8.784707069396973
INFO - 04/15/25 16:49:25 - 0:17:49 - Epoch 2304: train_loss=8.790372848510742
INFO - 04/15/25 16:49:25 - 0:17:49 - Epoch 2305: train_loss=8.786175727844238
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2306: train_loss=8.791844367980957
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2307: train_loss=8.779692649841309
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2308: train_loss=8.793201446533203
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2309: train_loss=8.787759780883789
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2310: train_loss=8.792437553405762
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2311: train_loss=8.799667358398438
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2312: train_loss=8.802225112915039
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2313: train_loss=8.792205810546875
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2314: train_loss=8.79203987121582
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2315: train_loss=8.798250198364258
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2316: train_loss=8.793023109436035
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2317: train_loss=8.795706748962402
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2318: train_loss=8.787614822387695
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2319: train_loss=8.796358108520508
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2320: train_loss=8.791980743408203
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2321: train_loss=8.784836769104004
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2322: train_loss=8.796271324157715
INFO - 04/15/25 16:49:26 - 0:17:49 - Epoch 2323: train_loss=8.794167518615723
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2324: train_loss=8.791423797607422
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2325: train_loss=8.786057472229004
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2326: train_loss=8.783910751342773
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2327: train_loss=8.789755821228027
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2328: train_loss=8.784836769104004
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2329: train_loss=8.793676376342773
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2330: train_loss=8.79160213470459
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2331: train_loss=8.776866912841797
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2332: train_loss=8.766979217529297
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2333: train_loss=8.796111106872559
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2334: train_loss=8.795337677001953
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2335: train_loss=8.789076805114746
INFO - 04/15/25 16:49:26 - 0:17:50 - Epoch 2336: train_loss=8.786937713623047
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2337: train_loss=8.789746284484863
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2338: train_loss=8.77393627166748
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2339: train_loss=8.791872024536133
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2340: train_loss=8.784382820129395
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2341: train_loss=8.793633460998535
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2342: train_loss=8.768843650817871
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2343: train_loss=8.79116439819336
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2344: train_loss=8.79037094116211
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2345: train_loss=8.792165756225586
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2346: train_loss=8.791443824768066
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2347: train_loss=8.78619384765625
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2348: train_loss=8.785642623901367
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2349: train_loss=8.783259391784668
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2350: train_loss=8.793253898620605
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2351: train_loss=8.815743446350098
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2352: train_loss=8.776540756225586
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2353: train_loss=8.789859771728516
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2354: train_loss=8.77151107788086
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2355: train_loss=8.784672737121582
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2356: train_loss=8.78023624420166
INFO - 04/15/25 16:49:27 - 0:17:50 - Epoch 2357: train_loss=8.782994270324707
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2358: train_loss=8.783649444580078
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2359: train_loss=8.786107063293457
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2360: train_loss=8.780556678771973
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2361: train_loss=8.782697677612305
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2362: train_loss=8.776616096496582
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2363: train_loss=8.78492259979248
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2364: train_loss=8.787952423095703
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2365: train_loss=8.779996871948242
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2366: train_loss=8.77961540222168
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2367: train_loss=8.779614448547363
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2368: train_loss=8.793462753295898
INFO - 04/15/25 16:49:27 - 0:17:51 - Epoch 2369: train_loss=8.767036437988281
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2370: train_loss=8.768245697021484
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2371: train_loss=8.747573852539062
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2372: train_loss=8.783632278442383
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2373: train_loss=8.785751342773438
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2374: train_loss=8.757787704467773
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2375: train_loss=8.769243240356445
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2376: train_loss=8.773950576782227
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2377: train_loss=8.780668258666992
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2378: train_loss=8.780003547668457
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2379: train_loss=8.791611671447754
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2380: train_loss=8.774551391601562
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2381: train_loss=8.812385559082031
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2382: train_loss=8.806012153625488
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2383: train_loss=8.799131393432617
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2384: train_loss=8.829300880432129
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2385: train_loss=8.82586669921875
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2386: train_loss=8.825965881347656
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2387: train_loss=8.823177337646484
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2388: train_loss=8.817726135253906
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2389: train_loss=8.781062126159668
INFO - 04/15/25 16:49:28 - 0:17:51 - Epoch 2390: train_loss=8.797914505004883
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2391: train_loss=8.807044982910156
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2392: train_loss=8.827497482299805
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2393: train_loss=8.869726181030273
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2394: train_loss=8.843358039855957
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2395: train_loss=8.81878662109375
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2396: train_loss=8.812729835510254
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2397: train_loss=8.849160194396973
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2398: train_loss=8.85147476196289
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2399: train_loss=8.860645294189453
INFO - 04/15/25 16:49:28 - 0:17:52 - Epoch 2400: train_loss=8.854942321777344
INFO - 04/15/25 16:49:28 - 0:17:52 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:29 - 0:17:52 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2400: ACC: 0.0, NMI: 0.36173376433391535, F1: 0.0, ARI: 0.20175109893308646
INFO - 04/15/25 16:49:29 - 0:17:52 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2401: train_loss=8.859746932983398
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2402: train_loss=8.833234786987305
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2403: train_loss=8.85439395904541
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2404: train_loss=8.862306594848633
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2405: train_loss=8.845819473266602
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2406: train_loss=8.848166465759277
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2407: train_loss=8.848143577575684
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2408: train_loss=8.838478088378906
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2409: train_loss=8.822937965393066
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2410: train_loss=8.828428268432617
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2411: train_loss=8.831754684448242
INFO - 04/15/25 16:49:29 - 0:17:52 - Epoch 2412: train_loss=8.824247360229492
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2413: train_loss=8.823122024536133
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2414: train_loss=8.822040557861328
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2415: train_loss=8.811912536621094
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2416: train_loss=8.80901050567627
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2417: train_loss=8.805692672729492
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2418: train_loss=8.806928634643555
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2419: train_loss=8.80037784576416
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2420: train_loss=8.799257278442383
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2421: train_loss=8.795713424682617
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2422: train_loss=8.798754692077637
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2423: train_loss=8.798690795898438
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2424: train_loss=8.794363021850586
INFO - 04/15/25 16:49:29 - 0:17:53 - Epoch 2425: train_loss=8.793338775634766
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2426: train_loss=8.781534194946289
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2427: train_loss=8.791659355163574
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2428: train_loss=8.79494857788086
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2429: train_loss=8.78736400604248
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2430: train_loss=8.790708541870117
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2431: train_loss=8.785194396972656
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2432: train_loss=8.784866333007812
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2433: train_loss=8.789643287658691
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2434: train_loss=8.783609390258789
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2435: train_loss=8.788790702819824
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2436: train_loss=8.785988807678223
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2437: train_loss=8.789731979370117
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2438: train_loss=8.788594245910645
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2439: train_loss=8.773942947387695
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2440: train_loss=8.772676467895508
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2441: train_loss=8.785538673400879
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2442: train_loss=8.784621238708496
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2443: train_loss=8.78148365020752
INFO - 04/15/25 16:49:30 - 0:17:53 - Epoch 2444: train_loss=8.768939971923828
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2445: train_loss=8.771718978881836
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2446: train_loss=8.780004501342773
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2447: train_loss=8.782957077026367
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2448: train_loss=8.783123970031738
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2449: train_loss=8.770469665527344
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2450: train_loss=8.776081085205078
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2451: train_loss=8.78808307647705
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2452: train_loss=8.763406753540039
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2453: train_loss=8.772443771362305
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2454: train_loss=8.770296096801758
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2455: train_loss=8.766878128051758
INFO - 04/15/25 16:49:30 - 0:17:54 - Epoch 2456: train_loss=8.782157897949219
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2457: train_loss=8.78122329711914
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2458: train_loss=8.77487850189209
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2459: train_loss=8.76754379272461
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2460: train_loss=8.787153244018555
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2461: train_loss=8.782712936401367
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2462: train_loss=8.780722618103027
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2463: train_loss=8.78327465057373
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2464: train_loss=8.765369415283203
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2465: train_loss=8.778477668762207
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2466: train_loss=8.763189315795898
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2467: train_loss=8.762081146240234
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2468: train_loss=8.781949043273926
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2469: train_loss=8.765420913696289
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2470: train_loss=8.758866310119629
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2471: train_loss=8.763179779052734
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2472: train_loss=8.770685195922852
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2473: train_loss=8.776459693908691
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2474: train_loss=8.783027648925781
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2475: train_loss=8.765891075134277
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2476: train_loss=8.771512031555176
INFO - 04/15/25 16:49:31 - 0:17:54 - Epoch 2477: train_loss=8.788561820983887
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2478: train_loss=8.764229774475098
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2479: train_loss=8.774065017700195
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2480: train_loss=8.783151626586914
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2481: train_loss=8.780478477478027
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2482: train_loss=8.75924015045166
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2483: train_loss=8.770322799682617
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2484: train_loss=8.765301704406738
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2485: train_loss=8.784634590148926
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2486: train_loss=8.779507637023926
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2487: train_loss=8.78233814239502
INFO - 04/15/25 16:49:31 - 0:17:55 - Epoch 2488: train_loss=8.773234367370605
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2489: train_loss=8.762116432189941
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2490: train_loss=8.7703275680542
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2491: train_loss=8.788301467895508
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2492: train_loss=8.786819458007812
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2493: train_loss=8.77669906616211
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2494: train_loss=8.77224063873291
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2495: train_loss=8.762078285217285
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2496: train_loss=8.778852462768555
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2497: train_loss=8.749275207519531
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2498: train_loss=8.78702449798584
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2499: train_loss=8.784577369689941
INFO - 04/15/25 16:49:32 - 0:17:55 - Epoch 2500: train_loss=8.770709991455078
INFO - 04/15/25 16:49:32 - 0:17:55 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:32 - 0:17:55 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2500: ACC: 0.0, NMI: 0.27916588819026156, F1: 0.0, ARI: 0.13869799951584322
INFO - 04/15/25 16:49:32 - 0:17:56 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2501: train_loss=8.779866218566895
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2502: train_loss=8.765973091125488
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2503: train_loss=8.798316955566406
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2504: train_loss=8.779330253601074
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2505: train_loss=8.778144836425781
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2506: train_loss=8.787734985351562
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2507: train_loss=8.794279098510742
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2508: train_loss=8.789254188537598
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2509: train_loss=8.789499282836914
INFO - 04/15/25 16:49:32 - 0:17:56 - Epoch 2510: train_loss=8.78974723815918
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2511: train_loss=8.794586181640625
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2512: train_loss=8.779205322265625
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2513: train_loss=8.777952194213867
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2514: train_loss=8.795378684997559
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2515: train_loss=8.800484657287598
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2516: train_loss=8.7891845703125
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2517: train_loss=8.783166885375977
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2518: train_loss=8.806635856628418
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2519: train_loss=8.798941612243652
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2520: train_loss=8.798959732055664
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2521: train_loss=8.802465438842773
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2522: train_loss=8.792608261108398
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2523: train_loss=8.797847747802734
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2524: train_loss=8.7958984375
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2525: train_loss=8.795309066772461
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2526: train_loss=8.78784465789795
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2527: train_loss=8.788034439086914
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2528: train_loss=8.78899097442627
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2529: train_loss=8.801046371459961
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2530: train_loss=8.753771781921387
INFO - 04/15/25 16:49:33 - 0:17:56 - Epoch 2531: train_loss=8.772784233093262
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2532: train_loss=8.781821250915527
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2533: train_loss=8.749062538146973
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2534: train_loss=8.749320030212402
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2535: train_loss=8.768214225769043
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2536: train_loss=8.781006813049316
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2537: train_loss=8.780027389526367
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2538: train_loss=8.778846740722656
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2539: train_loss=8.776421546936035
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2540: train_loss=8.77690601348877
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2541: train_loss=8.776811599731445
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2542: train_loss=8.761157035827637
INFO - 04/15/25 16:49:33 - 0:17:57 - Epoch 2543: train_loss=8.794595718383789
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2544: train_loss=8.774223327636719
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2545: train_loss=8.775827407836914
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2546: train_loss=8.778738975524902
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2547: train_loss=8.758298873901367
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2548: train_loss=8.765427589416504
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2549: train_loss=8.737323760986328
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2550: train_loss=8.754672050476074
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2551: train_loss=8.733570098876953
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2552: train_loss=8.74693775177002
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2553: train_loss=8.747282028198242
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2554: train_loss=8.709644317626953
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2555: train_loss=8.749750137329102
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2556: train_loss=8.726863861083984
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2557: train_loss=8.739970207214355
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2558: train_loss=8.745217323303223
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2559: train_loss=8.731626510620117
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2560: train_loss=8.752715110778809
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2561: train_loss=8.738563537597656
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2562: train_loss=8.715448379516602
INFO - 04/15/25 16:49:34 - 0:17:57 - Epoch 2563: train_loss=8.727201461791992
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2564: train_loss=8.73071575164795
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2565: train_loss=8.7229642868042
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2566: train_loss=8.726993560791016
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2567: train_loss=8.721513748168945
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2568: train_loss=8.724319458007812
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2569: train_loss=8.716416358947754
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2570: train_loss=8.718236923217773
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2571: train_loss=8.69769287109375
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2572: train_loss=8.683046340942383
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2573: train_loss=8.71669864654541
INFO - 04/15/25 16:49:34 - 0:17:58 - Epoch 2574: train_loss=8.718731880187988
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2575: train_loss=8.701395034790039
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2576: train_loss=8.71007251739502
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2577: train_loss=8.701417922973633
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2578: train_loss=8.708305358886719
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2579: train_loss=8.703169822692871
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2580: train_loss=8.711809158325195
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2581: train_loss=8.709888458251953
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2582: train_loss=8.704316139221191
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2583: train_loss=8.707893371582031
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2584: train_loss=8.702557563781738
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2585: train_loss=8.704438209533691
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2586: train_loss=8.7100248336792
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2587: train_loss=8.817713737487793
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2588: train_loss=8.782247543334961
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2589: train_loss=8.894972801208496
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2590: train_loss=8.992490768432617
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2591: train_loss=9.075029373168945
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2592: train_loss=9.210687637329102
INFO - 04/15/25 16:49:35 - 0:17:58 - Epoch 2593: train_loss=9.354537963867188
INFO - 04/15/25 16:49:35 - 0:17:59 - Epoch 2594: train_loss=9.368280410766602
INFO - 04/15/25 16:49:35 - 0:17:59 - Epoch 2595: train_loss=9.267678260803223
INFO - 04/15/25 16:49:35 - 0:17:59 - Epoch 2596: train_loss=9.197728157043457
INFO - 04/15/25 16:49:35 - 0:17:59 - Epoch 2597: train_loss=9.159027099609375
INFO - 04/15/25 16:49:35 - 0:17:59 - Epoch 2598: train_loss=9.11856460571289
INFO - 04/15/25 16:49:35 - 0:17:59 - Epoch 2599: train_loss=9.103996276855469
INFO - 04/15/25 16:49:35 - 0:17:59 - Epoch 2600: train_loss=9.075817108154297
INFO - 04/15/25 16:49:35 - 0:17:59 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:35 - 0:17:59 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2600: ACC: 0.0, NMI: 0.3275485187610624, F1: 0.0, ARI: 0.16575898891966337
INFO - 04/15/25 16:49:36 - 0:17:59 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2601: train_loss=9.076833724975586
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2602: train_loss=9.059606552124023
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2603: train_loss=9.054962158203125
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2604: train_loss=9.049773216247559
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2605: train_loss=9.030902862548828
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2606: train_loss=9.031340599060059
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2607: train_loss=9.024815559387207
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2608: train_loss=9.017559051513672
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2609: train_loss=9.017691612243652
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2610: train_loss=9.001449584960938
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2611: train_loss=9.01108169555664
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2612: train_loss=9.035245895385742
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2613: train_loss=9.02042293548584
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2614: train_loss=9.032142639160156
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2615: train_loss=9.076626777648926
INFO - 04/15/25 16:49:36 - 0:17:59 - Epoch 2616: train_loss=9.07194995880127
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2617: train_loss=9.18968391418457
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2618: train_loss=9.117897033691406
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2619: train_loss=9.12110710144043
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2620: train_loss=9.107367515563965
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2621: train_loss=9.120932579040527
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2622: train_loss=9.148645401000977
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2623: train_loss=9.095831871032715
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2624: train_loss=9.016444206237793
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2625: train_loss=9.060334205627441
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2626: train_loss=9.074090003967285
INFO - 04/15/25 16:49:36 - 0:18:00 - Epoch 2627: train_loss=9.186128616333008
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2628: train_loss=9.05764102935791
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2629: train_loss=9.086841583251953
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2630: train_loss=9.114168167114258
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2631: train_loss=9.083407402038574
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2632: train_loss=9.098673820495605
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2633: train_loss=9.145560264587402
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2634: train_loss=9.317593574523926
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2635: train_loss=9.268799781799316
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2636: train_loss=9.207165718078613
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2637: train_loss=9.182291030883789
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2638: train_loss=9.168617248535156
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2639: train_loss=9.102566719055176
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2640: train_loss=9.081198692321777
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2641: train_loss=9.069805145263672
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2642: train_loss=9.062105178833008
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2643: train_loss=9.050809860229492
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2644: train_loss=9.02668571472168
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2645: train_loss=9.031713485717773
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2646: train_loss=9.03372573852539
INFO - 04/15/25 16:49:37 - 0:18:00 - Epoch 2647: train_loss=9.033164024353027
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2648: train_loss=9.027416229248047
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2649: train_loss=9.02295970916748
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2650: train_loss=9.01821231842041
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2651: train_loss=9.00931167602539
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2652: train_loss=9.006583213806152
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2653: train_loss=9.002181053161621
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2654: train_loss=9.002554893493652
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2655: train_loss=9.003884315490723
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2656: train_loss=8.993146896362305
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2657: train_loss=8.98639965057373
INFO - 04/15/25 16:49:37 - 0:18:01 - Epoch 2658: train_loss=8.993851661682129
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2659: train_loss=8.98576831817627
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2660: train_loss=8.97917652130127
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2661: train_loss=8.987547874450684
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2662: train_loss=8.976085662841797
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2663: train_loss=8.967745780944824
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2664: train_loss=8.982269287109375
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2665: train_loss=8.992419242858887
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2666: train_loss=8.989121437072754
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2667: train_loss=8.993574142456055
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2668: train_loss=8.978694915771484
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2669: train_loss=8.980417251586914
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2670: train_loss=8.976845741271973
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2671: train_loss=8.953046798706055
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2672: train_loss=8.972412109375
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2673: train_loss=8.972261428833008
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2674: train_loss=8.965909957885742
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2675: train_loss=8.971009254455566
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2676: train_loss=8.971427917480469
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2677: train_loss=8.972579956054688
INFO - 04/15/25 16:49:38 - 0:18:01 - Epoch 2678: train_loss=8.971335411071777
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2679: train_loss=8.960342407226562
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2680: train_loss=8.96458625793457
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2681: train_loss=8.980350494384766
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2682: train_loss=8.975274085998535
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2683: train_loss=8.95518970489502
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2684: train_loss=8.961312294006348
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2685: train_loss=8.949620246887207
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2686: train_loss=8.945760726928711
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2687: train_loss=8.957925796508789
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2688: train_loss=8.934228897094727
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2689: train_loss=8.956677436828613
INFO - 04/15/25 16:49:38 - 0:18:02 - Epoch 2690: train_loss=8.938216209411621
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2691: train_loss=8.95171070098877
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2692: train_loss=8.949479103088379
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2693: train_loss=8.955511093139648
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2694: train_loss=8.959927558898926
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2695: train_loss=8.966537475585938
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2696: train_loss=8.955730438232422
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2697: train_loss=8.968303680419922
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2698: train_loss=8.960200309753418
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2699: train_loss=8.963005065917969
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2700: train_loss=8.96053695678711
INFO - 04/15/25 16:49:39 - 0:18:02 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:39 - 0:18:02 - Decoding cost time:  0.132 s
INFO - 04/15/25 16:49:39 - 0:18:02 - Epoch 2700: ACC: 0.0, NMI: 0.28439137211685683, F1: 0.0, ARI: 0.07126168011009792
INFO - 04/15/25 16:49:39 - 0:18:02 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2701: train_loss=8.9730863571167
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2702: train_loss=8.950858116149902
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2703: train_loss=8.952409744262695
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2704: train_loss=8.95848560333252
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2705: train_loss=8.92760181427002
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2706: train_loss=8.95296573638916
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2707: train_loss=8.93942928314209
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2708: train_loss=8.926424026489258
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2709: train_loss=8.96694564819336
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2710: train_loss=8.956124305725098
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2711: train_loss=8.96900749206543
INFO - 04/15/25 16:49:39 - 0:18:03 - Epoch 2712: train_loss=8.947118759155273
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2713: train_loss=8.956680297851562
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2714: train_loss=8.940240859985352
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2715: train_loss=8.965415000915527
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2716: train_loss=8.944486618041992
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2717: train_loss=8.929025650024414
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2718: train_loss=8.960482597351074
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2719: train_loss=8.954190254211426
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2720: train_loss=8.953315734863281
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2721: train_loss=8.964861869812012
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2722: train_loss=8.953898429870605
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2723: train_loss=8.952428817749023
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2724: train_loss=8.937166213989258
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2725: train_loss=8.932369232177734
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2726: train_loss=8.946298599243164
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2727: train_loss=8.953603744506836
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2728: train_loss=8.951152801513672
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2729: train_loss=8.938102722167969
INFO - 04/15/25 16:49:40 - 0:18:03 - Epoch 2730: train_loss=8.933728218078613
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2731: train_loss=8.920573234558105
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2732: train_loss=8.939927101135254
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2733: train_loss=8.92721939086914
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2734: train_loss=8.925265312194824
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2735: train_loss=8.936836242675781
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2736: train_loss=8.927596092224121
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2737: train_loss=8.93028736114502
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2738: train_loss=8.936447143554688
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2739: train_loss=8.933114051818848
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2740: train_loss=8.921102523803711
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2741: train_loss=8.923622131347656
INFO - 04/15/25 16:49:40 - 0:18:04 - Epoch 2742: train_loss=8.907054901123047
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2743: train_loss=8.939580917358398
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2744: train_loss=8.917960166931152
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2745: train_loss=8.921525955200195
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2746: train_loss=8.907915115356445
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2747: train_loss=8.906452178955078
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2748: train_loss=8.910826683044434
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2749: train_loss=8.913178443908691
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2750: train_loss=8.901211738586426
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2751: train_loss=8.903251647949219
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2752: train_loss=8.910527229309082
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2753: train_loss=8.899463653564453
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2754: train_loss=8.886369705200195
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2755: train_loss=8.91071605682373
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2756: train_loss=8.891514778137207
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2757: train_loss=8.891555786132812
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2758: train_loss=8.889386177062988
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2759: train_loss=8.977866172790527
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2760: train_loss=8.94611930847168
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2761: train_loss=8.893610954284668
INFO - 04/15/25 16:49:41 - 0:18:04 - Epoch 2762: train_loss=8.876320838928223
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2763: train_loss=8.875823974609375
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2764: train_loss=8.867232322692871
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2765: train_loss=8.864974975585938
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2766: train_loss=8.856352806091309
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2767: train_loss=8.85387897491455
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2768: train_loss=8.853570938110352
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2769: train_loss=8.856289863586426
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2770: train_loss=8.833357810974121
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2771: train_loss=8.836276054382324
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2772: train_loss=8.83275318145752
INFO - 04/15/25 16:49:41 - 0:18:05 - Epoch 2773: train_loss=8.834781646728516
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2774: train_loss=8.81944465637207
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2775: train_loss=8.825493812561035
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2776: train_loss=8.832468032836914
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2777: train_loss=8.806971549987793
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2778: train_loss=8.822190284729004
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2779: train_loss=8.81958293914795
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2780: train_loss=8.81442642211914
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2781: train_loss=8.806622505187988
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2782: train_loss=8.810126304626465
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2783: train_loss=8.813465118408203
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2784: train_loss=8.802578926086426
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2785: train_loss=8.789708137512207
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2786: train_loss=8.792414665222168
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2787: train_loss=8.805821418762207
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2788: train_loss=8.803620338439941
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2789: train_loss=8.80543327331543
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2790: train_loss=8.816524505615234
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2791: train_loss=8.808101654052734
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2792: train_loss=8.809755325317383
INFO - 04/15/25 16:49:42 - 0:18:05 - Epoch 2793: train_loss=8.80251407623291
INFO - 04/15/25 16:49:42 - 0:18:06 - Epoch 2794: train_loss=8.775409698486328
INFO - 04/15/25 16:49:42 - 0:18:06 - Epoch 2795: train_loss=8.785595893859863
INFO - 04/15/25 16:49:42 - 0:18:06 - Epoch 2796: train_loss=8.778011322021484
INFO - 04/15/25 16:49:42 - 0:18:06 - Epoch 2797: train_loss=8.792694091796875
INFO - 04/15/25 16:49:42 - 0:18:06 - Epoch 2798: train_loss=8.790512084960938
INFO - 04/15/25 16:49:42 - 0:18:06 - Epoch 2799: train_loss=8.789427757263184
INFO - 04/15/25 16:49:42 - 0:18:06 - Epoch 2800: train_loss=8.765002250671387
INFO - 04/15/25 16:49:42 - 0:18:06 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:42 - 0:18:06 - Decoding cost time:  0.129 s
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2800: ACC: 0.0, NMI: 0.3567847615048957, F1: 0.0, ARI: 0.2040273384747741
INFO - 04/15/25 16:49:43 - 0:18:06 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2801: train_loss=8.784162521362305
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2802: train_loss=8.788354873657227
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2803: train_loss=8.775861740112305
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2804: train_loss=8.770452499389648
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2805: train_loss=8.788460731506348
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2806: train_loss=8.794598579406738
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2807: train_loss=8.781166076660156
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2808: train_loss=8.768594741821289
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2809: train_loss=8.78195571899414
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2810: train_loss=8.78382682800293
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2811: train_loss=8.773780822753906
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2812: train_loss=8.768341064453125
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2813: train_loss=8.778465270996094
INFO - 04/15/25 16:49:43 - 0:18:06 - Epoch 2814: train_loss=8.77383804321289
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2815: train_loss=8.774117469787598
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2816: train_loss=8.770572662353516
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2817: train_loss=8.779544830322266
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2818: train_loss=8.756574630737305
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2819: train_loss=8.763505935668945
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2820: train_loss=8.74174690246582
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2821: train_loss=8.754849433898926
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2822: train_loss=8.749874114990234
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2823: train_loss=8.72492790222168
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2824: train_loss=8.737823486328125
INFO - 04/15/25 16:49:43 - 0:18:07 - Epoch 2825: train_loss=8.724331855773926
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2826: train_loss=8.703263282775879
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2827: train_loss=8.715826988220215
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2828: train_loss=8.708276748657227
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2829: train_loss=8.711311340332031
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2830: train_loss=8.718921661376953
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2831: train_loss=8.703447341918945
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2832: train_loss=8.713025093078613
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2833: train_loss=8.712477684020996
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2834: train_loss=8.709552764892578
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2835: train_loss=8.700597763061523
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2836: train_loss=8.698001861572266
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2837: train_loss=8.695019721984863
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2838: train_loss=8.694133758544922
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2839: train_loss=8.689416885375977
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2840: train_loss=8.693258285522461
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2841: train_loss=8.692371368408203
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2842: train_loss=8.68442440032959
INFO - 04/15/25 16:49:44 - 0:18:07 - Epoch 2843: train_loss=8.705810546875
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2844: train_loss=8.701818466186523
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2845: train_loss=8.693076133728027
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2846: train_loss=8.688344955444336
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2847: train_loss=8.676559448242188
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2848: train_loss=8.699849128723145
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2849: train_loss=8.695484161376953
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2850: train_loss=8.684582710266113
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2851: train_loss=8.684158325195312
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2852: train_loss=8.692804336547852
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2853: train_loss=8.696087837219238
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2854: train_loss=8.68922233581543
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2855: train_loss=8.689447402954102
INFO - 04/15/25 16:49:44 - 0:18:08 - Epoch 2856: train_loss=8.686371803283691
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2857: train_loss=8.693957328796387
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2858: train_loss=8.690890312194824
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2859: train_loss=8.69125747680664
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2860: train_loss=8.697628021240234
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2861: train_loss=8.687202453613281
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2862: train_loss=8.694243431091309
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2863: train_loss=8.682024002075195
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2864: train_loss=8.676868438720703
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2865: train_loss=8.683609008789062
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2866: train_loss=8.696403503417969
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2867: train_loss=8.68565845489502
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2868: train_loss=8.692121505737305
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2869: train_loss=8.687800407409668
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2870: train_loss=8.67563533782959
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2871: train_loss=8.66952896118164
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2872: train_loss=8.688889503479004
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2873: train_loss=8.679849624633789
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2874: train_loss=8.68014144897461
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2875: train_loss=8.681775093078613
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2876: train_loss=8.679595947265625
INFO - 04/15/25 16:49:45 - 0:18:08 - Epoch 2877: train_loss=8.67319393157959
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2878: train_loss=8.675270080566406
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2879: train_loss=8.677128791809082
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2880: train_loss=8.672029495239258
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2881: train_loss=8.662554740905762
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2882: train_loss=8.669357299804688
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2883: train_loss=8.66364574432373
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2884: train_loss=8.665362358093262
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2885: train_loss=8.662760734558105
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2886: train_loss=8.675965309143066
INFO - 04/15/25 16:49:45 - 0:18:09 - Epoch 2887: train_loss=8.664312362670898
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2888: train_loss=8.64962387084961
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2889: train_loss=8.66623592376709
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2890: train_loss=8.676797866821289
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2891: train_loss=8.677367210388184
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2892: train_loss=8.67078971862793
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2893: train_loss=8.662877082824707
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2894: train_loss=8.654191970825195
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2895: train_loss=8.667719841003418
INFO - 04/15/25 16:49:46 - 0:18:09 - Epoch 2896: train_loss=8.670838356018066
INFO - 04/15/25 16:49:47 - 0:18:09 - Epoch 2897: train_loss=8.677207946777344
INFO - 04/15/25 16:49:47 - 0:18:10 - Epoch 2898: train_loss=8.656970977783203
INFO - 04/15/25 16:49:47 - 0:18:10 - Epoch 2899: train_loss=8.656075477600098
INFO - 04/15/25 16:49:47 - 0:18:10 - Epoch 2900: train_loss=8.664746284484863
INFO - 04/15/25 16:49:47 - 0:18:10 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:47 - 0:18:10 - Decoding cost time:  0.127 s
INFO - 04/15/25 16:49:47 - 0:18:10 - Epoch 2900: ACC: 0.0, NMI: 0.25492247707446186, F1: 0.0, ARI: 0.1024539795134177
INFO - 04/15/25 16:49:47 - 0:18:10 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:47 - 0:18:10 - Epoch 2901: train_loss=8.663046836853027
INFO - 04/15/25 16:49:47 - 0:18:10 - Epoch 2902: train_loss=8.658380508422852
INFO - 04/15/25 16:49:47 - 0:18:10 - Epoch 2903: train_loss=8.661079406738281
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2904: train_loss=8.642541885375977
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2905: train_loss=8.65561580657959
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2906: train_loss=8.66774845123291
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2907: train_loss=8.656964302062988
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2908: train_loss=8.635411262512207
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2909: train_loss=8.653252601623535
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2910: train_loss=8.662109375
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2911: train_loss=8.657987594604492
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2912: train_loss=8.640758514404297
INFO - 04/15/25 16:49:47 - 0:18:11 - Epoch 2913: train_loss=8.638967514038086
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2914: train_loss=8.646586418151855
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2915: train_loss=8.664423942565918
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2916: train_loss=8.652356147766113
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2917: train_loss=8.653499603271484
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2918: train_loss=8.63805866241455
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2919: train_loss=8.64991283416748
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2920: train_loss=8.642569541931152
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2921: train_loss=8.64221477508545
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2922: train_loss=8.64267349243164
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2923: train_loss=8.648427963256836
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2924: train_loss=8.647904396057129
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2925: train_loss=8.64208984375
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2926: train_loss=8.640572547912598
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2927: train_loss=8.63107681274414
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2928: train_loss=8.625455856323242
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2929: train_loss=8.60874080657959
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2930: train_loss=8.622360229492188
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2931: train_loss=8.63086223602295
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2932: train_loss=8.634174346923828
INFO - 04/15/25 16:49:48 - 0:18:11 - Epoch 2933: train_loss=8.62825870513916
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2934: train_loss=8.632843971252441
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2935: train_loss=8.600152969360352
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2936: train_loss=8.627543449401855
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2937: train_loss=8.635296821594238
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2938: train_loss=8.617754936218262
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2939: train_loss=8.633475303649902
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2940: train_loss=8.640331268310547
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2941: train_loss=8.648423194885254
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2942: train_loss=8.63909912109375
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2943: train_loss=8.636200904846191
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2944: train_loss=8.645509719848633
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2945: train_loss=8.643095016479492
INFO - 04/15/25 16:49:48 - 0:18:12 - Epoch 2946: train_loss=8.64629077911377
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2947: train_loss=8.615236282348633
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2948: train_loss=8.622855186462402
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2949: train_loss=8.631300926208496
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2950: train_loss=8.628334999084473
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2951: train_loss=8.616243362426758
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2952: train_loss=8.595342636108398
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2953: train_loss=8.59485912322998
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2954: train_loss=8.61805248260498
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2955: train_loss=8.600146293640137
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2956: train_loss=8.57839298248291
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2957: train_loss=8.561663627624512
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2958: train_loss=8.543526649475098
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2959: train_loss=8.540419578552246
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2960: train_loss=8.538479804992676
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2961: train_loss=8.525639533996582
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2962: train_loss=8.541162490844727
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2963: train_loss=8.510342597961426
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2964: train_loss=8.504470825195312
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2965: train_loss=8.516996383666992
INFO - 04/15/25 16:49:49 - 0:18:12 - Epoch 2966: train_loss=8.516213417053223
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2967: train_loss=8.501702308654785
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2968: train_loss=8.498209953308105
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2969: train_loss=8.504977226257324
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2970: train_loss=8.48988151550293
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2971: train_loss=8.501967430114746
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2972: train_loss=8.49161434173584
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2973: train_loss=8.502457618713379
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2974: train_loss=8.506702423095703
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2975: train_loss=8.508907318115234
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2976: train_loss=8.481873512268066
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2977: train_loss=8.485573768615723
INFO - 04/15/25 16:49:49 - 0:18:13 - Epoch 2978: train_loss=8.479459762573242
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2979: train_loss=8.4785795211792
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2980: train_loss=8.480667114257812
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2981: train_loss=8.47982120513916
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2982: train_loss=8.487062454223633
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2983: train_loss=8.466351509094238
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2984: train_loss=8.46274471282959
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2985: train_loss=8.475713729858398
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2986: train_loss=8.479920387268066
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2987: train_loss=8.45521354675293
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2988: train_loss=8.456682205200195
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2989: train_loss=8.461158752441406
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2990: train_loss=8.461973190307617
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2991: train_loss=8.45451545715332
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2992: train_loss=8.458093643188477
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2993: train_loss=8.460296630859375
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2994: train_loss=8.459921836853027
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2995: train_loss=8.46131706237793
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2996: train_loss=8.45017147064209
INFO - 04/15/25 16:49:50 - 0:18:13 - Epoch 2997: train_loss=8.442002296447754
INFO - 04/15/25 16:49:50 - 0:18:14 - Epoch 2998: train_loss=8.43222713470459
INFO - 04/15/25 16:49:50 - 0:18:14 - Epoch 2999: train_loss=8.448379516601562
INFO - 04/15/25 16:49:50 - 0:18:14 - Epoch 3000: train_loss=8.450071334838867
INFO - 04/15/25 16:49:50 - 0:18:14 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:50 - 0:18:14 - Decoding cost time:  0.121 s
INFO - 04/15/25 16:49:50 - 0:18:14 - Epoch 3000: ACC: 0.0, NMI: 0.30053252919545126, F1: 0.0, ARI: 0.09690793501173159
INFO - 04/15/25 16:49:50 - 0:18:14 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3001: train_loss=8.432689666748047
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3002: train_loss=8.429457664489746
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3003: train_loss=8.440214157104492
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3004: train_loss=8.429733276367188
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3005: train_loss=8.434466361999512
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3006: train_loss=8.43287181854248
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3007: train_loss=8.435506820678711
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3008: train_loss=8.443385124206543
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3009: train_loss=8.442293167114258
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3010: train_loss=8.445728302001953
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3011: train_loss=8.475115776062012
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3012: train_loss=8.48227310180664
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3013: train_loss=8.449798583984375
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3014: train_loss=8.460946083068848
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3015: train_loss=8.46143627166748
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3016: train_loss=8.442514419555664
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3017: train_loss=8.44377613067627
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3018: train_loss=8.45640754699707
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3019: train_loss=8.467164039611816
INFO - 04/15/25 16:49:51 - 0:18:14 - Epoch 3020: train_loss=8.453798294067383
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3021: train_loss=8.446266174316406
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3022: train_loss=8.42817211151123
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3023: train_loss=8.438533782958984
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3024: train_loss=8.442289352416992
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3025: train_loss=8.429054260253906
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3026: train_loss=8.434341430664062
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3027: train_loss=8.44083309173584
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3028: train_loss=8.435839653015137
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3029: train_loss=8.421345710754395
INFO - 04/15/25 16:49:51 - 0:18:15 - Epoch 3030: train_loss=8.41525936126709
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3031: train_loss=8.422957420349121
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3032: train_loss=8.433574676513672
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3033: train_loss=8.42448902130127
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3034: train_loss=8.439523696899414
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3035: train_loss=8.422980308532715
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3036: train_loss=8.424775123596191
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3037: train_loss=8.43348503112793
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3038: train_loss=8.411911964416504
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3039: train_loss=8.42566967010498
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3040: train_loss=8.427177429199219
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3041: train_loss=8.423482894897461
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3042: train_loss=8.42476749420166
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3043: train_loss=8.409319877624512
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3044: train_loss=8.419478416442871
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3045: train_loss=8.423312187194824
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3046: train_loss=8.422471046447754
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3047: train_loss=8.429190635681152
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3048: train_loss=8.429927825927734
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3049: train_loss=8.4324369430542
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3050: train_loss=8.432414054870605
INFO - 04/15/25 16:49:52 - 0:18:15 - Epoch 3051: train_loss=8.42876148223877
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3052: train_loss=8.420594215393066
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3053: train_loss=8.425093650817871
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3054: train_loss=8.4276704788208
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3055: train_loss=8.38342571258545
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3056: train_loss=8.415513038635254
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3057: train_loss=8.420226097106934
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3058: train_loss=8.42190170288086
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3059: train_loss=8.411896705627441
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3060: train_loss=8.417276382446289
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3061: train_loss=8.423957824707031
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3062: train_loss=8.412093162536621
INFO - 04/15/25 16:49:52 - 0:18:16 - Epoch 3063: train_loss=8.418313026428223
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3064: train_loss=8.408970832824707
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3065: train_loss=8.421928405761719
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3066: train_loss=8.425620079040527
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3067: train_loss=8.408196449279785
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3068: train_loss=8.42863655090332
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3069: train_loss=8.426758766174316
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3070: train_loss=8.417913436889648
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3071: train_loss=8.414159774780273
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3072: train_loss=8.418753623962402
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3073: train_loss=8.424787521362305
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3074: train_loss=8.425243377685547
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3075: train_loss=8.424951553344727
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3076: train_loss=8.426640510559082
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3077: train_loss=8.426048278808594
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3078: train_loss=8.42050838470459
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3079: train_loss=8.43769645690918
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3080: train_loss=8.423334121704102
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3081: train_loss=8.420225143432617
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3082: train_loss=8.42026138305664
INFO - 04/15/25 16:49:53 - 0:18:16 - Epoch 3083: train_loss=8.412102699279785
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3084: train_loss=8.392877578735352
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3085: train_loss=8.385122299194336
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3086: train_loss=8.362129211425781
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3087: train_loss=8.350128173828125
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3088: train_loss=8.358545303344727
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3089: train_loss=8.343347549438477
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3090: train_loss=8.359451293945312
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3091: train_loss=8.372344017028809
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3092: train_loss=8.371624946594238
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3093: train_loss=8.352241516113281
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3094: train_loss=8.337337493896484
INFO - 04/15/25 16:49:53 - 0:18:17 - Epoch 3095: train_loss=8.340126991271973
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3096: train_loss=8.339496612548828
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3097: train_loss=8.328556060791016
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3098: train_loss=8.320215225219727
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3099: train_loss=8.327775001525879
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3100: train_loss=8.338486671447754
INFO - 04/15/25 16:49:54 - 0:18:17 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:54 - 0:18:17 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3100: ACC: 0.0, NMI: 0.289985991197484, F1: 0.0, ARI: 0.11422970313930939
INFO - 04/15/25 16:49:54 - 0:18:17 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3101: train_loss=8.304132461547852
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3102: train_loss=8.298879623413086
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3103: train_loss=8.308477401733398
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3104: train_loss=8.293949127197266
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3105: train_loss=8.294389724731445
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3106: train_loss=8.288357734680176
INFO - 04/15/25 16:49:54 - 0:18:17 - Epoch 3107: train_loss=8.277961730957031
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3108: train_loss=8.254167556762695
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3109: train_loss=8.257043838500977
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3110: train_loss=8.260977745056152
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3111: train_loss=8.240865707397461
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3112: train_loss=8.302959442138672
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3113: train_loss=8.281573295593262
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3114: train_loss=8.363560676574707
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3115: train_loss=8.396163940429688
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3116: train_loss=8.408590316772461
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3117: train_loss=8.384668350219727
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3118: train_loss=8.3724365234375
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3119: train_loss=8.361491203308105
INFO - 04/15/25 16:49:54 - 0:18:18 - Epoch 3120: train_loss=8.357755661010742
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3121: train_loss=8.364686965942383
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3122: train_loss=8.335440635681152
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3123: train_loss=8.350180625915527
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3124: train_loss=8.306485176086426
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3125: train_loss=8.287567138671875
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3126: train_loss=8.289070129394531
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3127: train_loss=8.253562927246094
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3128: train_loss=8.284073829650879
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3129: train_loss=8.236139297485352
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3130: train_loss=8.280692100524902
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3131: train_loss=8.26656436920166
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3132: train_loss=8.239216804504395
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3133: train_loss=8.23788070678711
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3134: train_loss=8.237628936767578
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3135: train_loss=8.221275329589844
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3136: train_loss=8.213634490966797
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3137: train_loss=8.209025382995605
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3138: train_loss=8.19892692565918
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3139: train_loss=8.168266296386719
INFO - 04/15/25 16:49:55 - 0:18:18 - Epoch 3140: train_loss=8.16616439819336
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3141: train_loss=8.15134334564209
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3142: train_loss=8.150293350219727
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3143: train_loss=8.144871711730957
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3144: train_loss=8.144417762756348
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3145: train_loss=8.147032737731934
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3146: train_loss=8.132143020629883
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3147: train_loss=8.128493309020996
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3148: train_loss=8.121947288513184
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3149: train_loss=8.130168914794922
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3150: train_loss=8.124053001403809
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3151: train_loss=8.121546745300293
INFO - 04/15/25 16:49:55 - 0:18:19 - Epoch 3152: train_loss=8.119566917419434
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3153: train_loss=8.111124038696289
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3154: train_loss=8.11821174621582
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3155: train_loss=8.110272407531738
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3156: train_loss=8.102433204650879
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3157: train_loss=8.09792423248291
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3158: train_loss=8.106541633605957
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3159: train_loss=8.106552124023438
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3160: train_loss=8.100236892700195
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3161: train_loss=8.100728988647461
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3162: train_loss=8.08990478515625
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3163: train_loss=8.095139503479004
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3164: train_loss=8.08902645111084
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3165: train_loss=8.089563369750977
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3166: train_loss=8.086432456970215
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3167: train_loss=8.097979545593262
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3168: train_loss=8.105361938476562
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3169: train_loss=8.10108757019043
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3170: train_loss=8.108134269714355
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3171: train_loss=8.105708122253418
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3172: train_loss=8.101594924926758
INFO - 04/15/25 16:49:56 - 0:18:19 - Epoch 3173: train_loss=8.1048583984375
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3174: train_loss=8.10417366027832
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3175: train_loss=8.102736473083496
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3176: train_loss=8.095782279968262
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3177: train_loss=8.078967094421387
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3178: train_loss=8.083505630493164
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3179: train_loss=8.06070327758789
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3180: train_loss=8.067092895507812
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3181: train_loss=8.056310653686523
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3182: train_loss=8.051355361938477
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3183: train_loss=8.027566909790039
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3184: train_loss=8.011905670166016
INFO - 04/15/25 16:49:56 - 0:18:20 - Epoch 3185: train_loss=8.002148628234863
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3186: train_loss=8.006233215332031
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3187: train_loss=8.002326011657715
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3188: train_loss=7.987478733062744
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3189: train_loss=7.98518705368042
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3190: train_loss=7.983475685119629
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3191: train_loss=7.9871416091918945
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3192: train_loss=7.988762378692627
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3193: train_loss=7.984437942504883
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3194: train_loss=7.983286380767822
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3195: train_loss=7.982864856719971
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3196: train_loss=7.971250534057617
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3197: train_loss=7.978452205657959
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3198: train_loss=7.9824676513671875
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3199: train_loss=7.979220390319824
INFO - 04/15/25 16:49:57 - 0:18:20 - Epoch 3200: train_loss=7.984903335571289
INFO - 04/15/25 16:49:57 - 0:18:20 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:49:57 - 0:18:20 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3200: ACC: 0.0, NMI: 0.3149838834422838, F1: 0.0, ARI: 0.1517122241329757
INFO - 04/15/25 16:49:57 - 0:18:21 - -------------------------------------------------------------------------
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3201: train_loss=7.971529006958008
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3202: train_loss=7.943704128265381
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3203: train_loss=7.895014762878418
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3204: train_loss=7.81795072555542
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3205: train_loss=7.800540447235107
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3206: train_loss=7.771921634674072
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3207: train_loss=7.737541198730469
INFO - 04/15/25 16:49:57 - 0:18:21 - Epoch 3208: train_loss=7.72398042678833
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3209: train_loss=7.709850788116455
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3210: train_loss=7.704751014709473
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3211: train_loss=7.710577487945557
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3212: train_loss=7.695777893066406
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3213: train_loss=7.694347858428955
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3214: train_loss=7.690186500549316
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3215: train_loss=7.683319091796875
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3216: train_loss=7.678432464599609
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3217: train_loss=7.679546356201172
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3218: train_loss=7.6762590408325195
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3219: train_loss=7.661272048950195
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3220: train_loss=7.644025802612305
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3221: train_loss=7.640183448791504
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3222: train_loss=7.646696090698242
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3223: train_loss=7.633108615875244
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3224: train_loss=7.630351543426514
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3225: train_loss=7.633240699768066
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3226: train_loss=7.6262006759643555
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3227: train_loss=7.6246771812438965
INFO - 04/15/25 16:49:58 - 0:18:21 - Epoch 3228: train_loss=7.624086856842041
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3229: train_loss=7.6219305992126465
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3230: train_loss=7.61629056930542
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3231: train_loss=7.610812187194824
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3232: train_loss=7.610723495483398
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3233: train_loss=7.609561443328857
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3234: train_loss=7.612112522125244
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3235: train_loss=7.610245704650879
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3236: train_loss=7.6080851554870605
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3237: train_loss=7.606379985809326
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3238: train_loss=7.606630325317383
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3239: train_loss=7.6115946769714355
INFO - 04/15/25 16:49:58 - 0:18:22 - Epoch 3240: train_loss=7.602959632873535
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3241: train_loss=7.6002302169799805
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3242: train_loss=7.598227024078369
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3243: train_loss=7.601222038269043
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3244: train_loss=7.618207931518555
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3245: train_loss=7.597250461578369
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3246: train_loss=7.606658458709717
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3247: train_loss=7.6097025871276855
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3248: train_loss=7.607792854309082
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3249: train_loss=7.602261066436768
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3250: train_loss=7.600447177886963
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3251: train_loss=7.60203742980957
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3252: train_loss=7.60244083404541
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3253: train_loss=7.601943016052246
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3254: train_loss=7.6002349853515625
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3255: train_loss=7.598073959350586
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3256: train_loss=7.595646381378174
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3257: train_loss=7.601387977600098
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3258: train_loss=7.5904459953308105
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3259: train_loss=7.594616413116455
INFO - 04/15/25 16:49:59 - 0:18:22 - Epoch 3260: train_loss=7.591458797454834
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3261: train_loss=7.595099449157715
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3262: train_loss=7.596386909484863
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3263: train_loss=7.597275733947754
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3264: train_loss=7.59266471862793
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3265: train_loss=7.582735061645508
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3266: train_loss=7.57305908203125
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3267: train_loss=7.578503131866455
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3268: train_loss=7.564345836639404
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3269: train_loss=7.564640522003174
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3270: train_loss=7.57009220123291
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3271: train_loss=7.558849811553955
INFO - 04/15/25 16:49:59 - 0:18:23 - Epoch 3272: train_loss=7.569157600402832
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3273: train_loss=7.565536975860596
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3274: train_loss=7.563231468200684
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3275: train_loss=7.55906343460083
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3276: train_loss=7.5516180992126465
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3277: train_loss=7.554452419281006
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3278: train_loss=7.552050590515137
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3279: train_loss=7.5490336418151855
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3280: train_loss=7.55049991607666
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3281: train_loss=7.550824165344238
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3282: train_loss=7.548582077026367
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3283: train_loss=7.545586109161377
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3284: train_loss=7.547080039978027
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3285: train_loss=7.551445007324219
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3286: train_loss=7.5487165451049805
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3287: train_loss=7.545689105987549
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3288: train_loss=7.547188758850098
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3289: train_loss=7.544527530670166
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3290: train_loss=7.543403148651123
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3291: train_loss=7.543552875518799
INFO - 04/15/25 16:50:00 - 0:18:23 - Epoch 3292: train_loss=7.543056964874268
INFO - 04/15/25 16:50:00 - 0:18:24 - Epoch 3293: train_loss=7.545899868011475
INFO - 04/15/25 16:50:00 - 0:18:24 - Epoch 3294: train_loss=7.54507303237915
INFO - 04/15/25 16:50:00 - 0:18:24 - Epoch 3295: train_loss=7.54625129699707
INFO - 04/15/25 16:50:00 - 0:18:24 - Epoch 3296: train_loss=7.543006420135498
INFO - 04/15/25 16:50:00 - 0:18:24 - Epoch 3297: train_loss=7.547945976257324
INFO - 04/15/25 16:50:00 - 0:18:24 - Epoch 3298: train_loss=7.542277812957764
INFO - 04/15/25 16:50:00 - 0:18:24 - Epoch 3299: train_loss=7.55013370513916
INFO - 04/15/25 16:50:00 - 0:18:24 - Epoch 3300: train_loss=7.5466156005859375
INFO - 04/15/25 16:50:00 - 0:18:24 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:01 - 0:18:24 - Decoding cost time:  0.126 s
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3300: ACC: 0.0, NMI: 0.375892986122786, F1: 0.0, ARI: 0.16582284141194148
INFO - 04/15/25 16:50:01 - 0:18:24 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3301: train_loss=7.549165725708008
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3302: train_loss=7.546699523925781
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3303: train_loss=7.542423725128174
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3304: train_loss=7.538206100463867
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3305: train_loss=7.543785095214844
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3306: train_loss=7.542506694793701
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3307: train_loss=7.543147563934326
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3308: train_loss=7.542044639587402
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3309: train_loss=7.53981351852417
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3310: train_loss=7.537505149841309
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3311: train_loss=7.536769866943359
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3312: train_loss=7.539515972137451
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3313: train_loss=7.541550159454346
INFO - 04/15/25 16:50:01 - 0:18:24 - Epoch 3314: train_loss=7.542359352111816
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3315: train_loss=7.540524482727051
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3316: train_loss=7.538069725036621
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3317: train_loss=7.536779880523682
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3318: train_loss=7.534477710723877
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3319: train_loss=7.536111354827881
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3320: train_loss=7.541868686676025
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3321: train_loss=7.536484718322754
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3322: train_loss=7.535184860229492
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3323: train_loss=7.535559177398682
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3324: train_loss=7.534284591674805
INFO - 04/15/25 16:50:01 - 0:18:25 - Epoch 3325: train_loss=7.536079406738281
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3326: train_loss=7.53220796585083
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3327: train_loss=7.5346598625183105
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3328: train_loss=7.5327630043029785
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3329: train_loss=7.530325412750244
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3330: train_loss=7.530390739440918
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3331: train_loss=7.531674385070801
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3332: train_loss=7.531412124633789
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3333: train_loss=7.529968738555908
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3334: train_loss=7.5296549797058105
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3335: train_loss=7.528753757476807
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3336: train_loss=7.529083251953125
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3337: train_loss=7.52841854095459
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3338: train_loss=7.52770471572876
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3339: train_loss=7.529922008514404
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3340: train_loss=7.5282979011535645
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3341: train_loss=7.529943466186523
INFO - 04/15/25 16:50:02 - 0:18:25 - Epoch 3342: train_loss=7.528805255889893
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3343: train_loss=7.528403282165527
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3344: train_loss=7.527263641357422
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3345: train_loss=7.526287078857422
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3346: train_loss=7.528090476989746
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3347: train_loss=7.5296311378479
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3348: train_loss=7.529970169067383
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3349: train_loss=7.528668403625488
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3350: train_loss=7.526762962341309
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3351: train_loss=7.52498722076416
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3352: train_loss=7.525863170623779
INFO - 04/15/25 16:50:02 - 0:18:26 - Epoch 3353: train_loss=7.5267558097839355
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3354: train_loss=7.526067733764648
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3355: train_loss=7.524755477905273
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3356: train_loss=7.523916244506836
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3357: train_loss=7.524138450622559
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3358: train_loss=7.52454948425293
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3359: train_loss=7.523789882659912
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3360: train_loss=7.523112773895264
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3361: train_loss=7.522495746612549
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3362: train_loss=7.523150444030762
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3363: train_loss=7.52300500869751
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3364: train_loss=7.52244758605957
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3365: train_loss=7.522162914276123
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3366: train_loss=7.521784782409668
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3367: train_loss=7.521914005279541
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3368: train_loss=7.5210795402526855
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3369: train_loss=7.520441055297852
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3370: train_loss=7.521020412445068
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3371: train_loss=7.5242156982421875
INFO - 04/15/25 16:50:03 - 0:18:26 - Epoch 3372: train_loss=7.521677494049072
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3373: train_loss=7.521523475646973
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3374: train_loss=7.520151138305664
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3375: train_loss=7.519331455230713
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3376: train_loss=7.520458221435547
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3377: train_loss=7.519904613494873
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3378: train_loss=7.519322872161865
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3379: train_loss=7.519373893737793
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3380: train_loss=7.523628234863281
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3381: train_loss=7.520451545715332
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3382: train_loss=7.5203447341918945
INFO - 04/15/25 16:50:03 - 0:18:27 - Epoch 3383: train_loss=7.521409034729004
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3384: train_loss=7.52012300491333
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3385: train_loss=7.51923942565918
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3386: train_loss=7.519457817077637
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3387: train_loss=7.520224094390869
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3388: train_loss=7.5194315910339355
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3389: train_loss=7.518305778503418
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3390: train_loss=7.518255233764648
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3391: train_loss=7.51970100402832
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3392: train_loss=7.518919944763184
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3393: train_loss=7.519915580749512
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3394: train_loss=7.5186638832092285
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3395: train_loss=7.51630973815918
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3396: train_loss=7.521952152252197
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3397: train_loss=7.520742893218994
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3398: train_loss=7.517002105712891
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3399: train_loss=7.516253471374512
INFO - 04/15/25 16:50:04 - 0:18:27 - Epoch 3400: train_loss=7.521321773529053
INFO - 04/15/25 16:50:04 - 0:18:27 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:04 - 0:18:28 - Decoding cost time:  0.129 s
INFO - 04/15/25 16:50:04 - 0:18:28 - Epoch 3400: ACC: 0.0, NMI: 0.3654544220101545, F1: 0.0, ARI: 0.19335593542463858
INFO - 04/15/25 16:50:04 - 0:18:28 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:04 - 0:18:28 - Epoch 3401: train_loss=7.520995140075684
INFO - 04/15/25 16:50:04 - 0:18:28 - Epoch 3402: train_loss=7.5292510986328125
INFO - 04/15/25 16:50:04 - 0:18:28 - Epoch 3403: train_loss=7.528144359588623
INFO - 04/15/25 16:50:04 - 0:18:28 - Epoch 3404: train_loss=7.528140544891357
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3405: train_loss=7.5333123207092285
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3406: train_loss=7.530152320861816
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3407: train_loss=7.5204644203186035
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3408: train_loss=7.524897575378418
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3409: train_loss=7.526785850524902
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3410: train_loss=7.583601951599121
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3411: train_loss=7.556630611419678
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3412: train_loss=7.529207706451416
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3413: train_loss=7.5436811447143555
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3414: train_loss=7.536195278167725
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3415: train_loss=7.526543617248535
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3416: train_loss=7.534466743469238
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3417: train_loss=7.52202033996582
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3418: train_loss=7.523140907287598
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3419: train_loss=7.520828723907471
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3420: train_loss=7.530086040496826
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3421: train_loss=7.531729698181152
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3422: train_loss=7.532808780670166
INFO - 04/15/25 16:50:05 - 0:18:28 - Epoch 3423: train_loss=7.524839401245117
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3424: train_loss=7.523688316345215
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3425: train_loss=7.52862024307251
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3426: train_loss=7.520438194274902
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3427: train_loss=7.523202896118164
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3428: train_loss=7.520517826080322
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3429: train_loss=7.51885986328125
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3430: train_loss=7.519738674163818
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3431: train_loss=7.518192291259766
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3432: train_loss=7.515275001525879
INFO - 04/15/25 16:50:05 - 0:18:29 - Epoch 3433: train_loss=7.5168657302856445
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3434: train_loss=7.521112442016602
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3435: train_loss=7.517212390899658
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3436: train_loss=7.517922878265381
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3437: train_loss=7.517827987670898
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3438: train_loss=7.518527984619141
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3439: train_loss=7.518094539642334
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3440: train_loss=7.516660213470459
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3441: train_loss=7.513897895812988
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3442: train_loss=7.515592575073242
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3443: train_loss=7.516213417053223
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3444: train_loss=7.514668941497803
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3445: train_loss=7.5160746574401855
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3446: train_loss=7.516225814819336
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3447: train_loss=7.513767242431641
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3448: train_loss=7.512965202331543
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3449: train_loss=7.513578414916992
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3450: train_loss=7.512366771697998
INFO - 04/15/25 16:50:06 - 0:18:29 - Epoch 3451: train_loss=7.51289176940918
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3452: train_loss=7.511842727661133
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3453: train_loss=7.511299133300781
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3454: train_loss=7.51291561126709
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3455: train_loss=7.512126922607422
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3456: train_loss=7.510828018188477
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3457: train_loss=7.5109028816223145
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3458: train_loss=7.516016960144043
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3459: train_loss=7.510496139526367
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3460: train_loss=7.50875997543335
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3461: train_loss=7.510909080505371
INFO - 04/15/25 16:50:06 - 0:18:30 - Epoch 3462: train_loss=7.5092668533325195
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3463: train_loss=7.510002613067627
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3464: train_loss=7.5091447830200195
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3465: train_loss=7.509628772735596
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3466: train_loss=7.50926399230957
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3467: train_loss=7.509708881378174
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3468: train_loss=7.50967264175415
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3469: train_loss=7.508265972137451
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3470: train_loss=7.50911808013916
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3471: train_loss=7.5088348388671875
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3472: train_loss=7.510491847991943
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3473: train_loss=7.510447978973389
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3474: train_loss=7.509979724884033
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3475: train_loss=7.5081257820129395
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3476: train_loss=7.514002799987793
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3477: train_loss=7.509037971496582
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3478: train_loss=7.50587272644043
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3479: train_loss=7.509661674499512
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3480: train_loss=7.510574817657471
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3481: train_loss=7.508525848388672
INFO - 04/15/25 16:50:07 - 0:18:30 - Epoch 3482: train_loss=7.506130218505859
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3483: train_loss=7.508242607116699
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3484: train_loss=7.506172180175781
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3485: train_loss=7.508667945861816
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3486: train_loss=7.507480621337891
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3487: train_loss=7.508250713348389
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3488: train_loss=7.504295349121094
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3489: train_loss=7.51015567779541
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3490: train_loss=7.509749412536621
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3491: train_loss=7.510420799255371
INFO - 04/15/25 16:50:07 - 0:18:31 - Epoch 3492: train_loss=7.505341053009033
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3493: train_loss=7.5069451332092285
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3494: train_loss=7.508965492248535
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3495: train_loss=7.506991863250732
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3496: train_loss=7.503830909729004
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3497: train_loss=7.505987644195557
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3498: train_loss=7.510390758514404
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3499: train_loss=7.505513668060303
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3500: train_loss=7.5032806396484375
INFO - 04/15/25 16:50:08 - 0:18:31 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:08 - 0:18:31 - Decoding cost time:  0.140 s
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3500: ACC: 0.0, NMI: 0.25630708386192147, F1: 0.0, ARI: 0.07980163527480849
INFO - 04/15/25 16:50:08 - 0:18:31 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:08 - 0:18:31 - Epoch 3501: train_loss=7.5040435791015625
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3502: train_loss=7.503997802734375
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3503: train_loss=7.503849983215332
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3504: train_loss=7.503427982330322
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3505: train_loss=7.502410888671875
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3506: train_loss=7.5041680335998535
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3507: train_loss=7.503476619720459
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3508: train_loss=7.511176586151123
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3509: train_loss=7.5045485496521
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3510: train_loss=7.501682758331299
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3511: train_loss=7.504689693450928
INFO - 04/15/25 16:50:08 - 0:18:32 - Epoch 3512: train_loss=7.505185127258301
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3513: train_loss=7.506853103637695
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3514: train_loss=7.501560688018799
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3515: train_loss=7.503684043884277
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3516: train_loss=7.501917362213135
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3517: train_loss=7.505912780761719
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3518: train_loss=7.5028228759765625
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3519: train_loss=7.503627300262451
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3520: train_loss=7.501524448394775
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3521: train_loss=7.500563144683838
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3522: train_loss=7.501054286956787
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3523: train_loss=7.502518653869629
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3524: train_loss=7.501072883605957
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3525: train_loss=7.507360458374023
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3526: train_loss=7.500240325927734
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3527: train_loss=7.498245716094971
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3528: train_loss=7.5063157081604
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3529: train_loss=7.507132053375244
INFO - 04/15/25 16:50:09 - 0:18:32 - Epoch 3530: train_loss=7.50703763961792
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3531: train_loss=7.504560947418213
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3532: train_loss=7.498974323272705
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3533: train_loss=7.499765396118164
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3534: train_loss=7.502335071563721
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3535: train_loss=7.500517845153809
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3536: train_loss=7.502633094787598
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3537: train_loss=7.498230457305908
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3538: train_loss=7.498241901397705
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3539: train_loss=7.498564720153809
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3540: train_loss=7.498976707458496
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3541: train_loss=7.501436710357666
INFO - 04/15/25 16:50:09 - 0:18:33 - Epoch 3542: train_loss=7.495084285736084
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3543: train_loss=7.497176647186279
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3544: train_loss=7.500061511993408
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3545: train_loss=7.4935479164123535
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3546: train_loss=7.496759414672852
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3547: train_loss=7.492775917053223
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3548: train_loss=7.495253086090088
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3549: train_loss=7.4947710037231445
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3550: train_loss=7.499813556671143
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3551: train_loss=7.4993181228637695
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3552: train_loss=7.491811275482178
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3553: train_loss=7.498593330383301
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3554: train_loss=7.499726295471191
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3555: train_loss=7.506574630737305
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3556: train_loss=7.493112564086914
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3557: train_loss=7.494413375854492
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3558: train_loss=7.5262532234191895
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3559: train_loss=7.505207538604736
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3560: train_loss=7.522352695465088
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3561: train_loss=7.532283306121826
INFO - 04/15/25 16:50:10 - 0:18:33 - Epoch 3562: train_loss=7.532546520233154
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3563: train_loss=7.539295196533203
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3564: train_loss=7.564515590667725
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3565: train_loss=7.59643030166626
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3566: train_loss=7.697474956512451
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3567: train_loss=7.7780961990356445
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3568: train_loss=7.802059173583984
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3569: train_loss=7.8174262046813965
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3570: train_loss=7.801421165466309
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3571: train_loss=7.826213836669922
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3572: train_loss=7.87548828125
INFO - 04/15/25 16:50:10 - 0:18:34 - Epoch 3573: train_loss=7.848410606384277
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3574: train_loss=7.8272199630737305
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3575: train_loss=7.830102443695068
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3576: train_loss=7.968425273895264
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3577: train_loss=7.93955659866333
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3578: train_loss=7.9210638999938965
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3579: train_loss=7.83355712890625
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3580: train_loss=7.843334197998047
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3581: train_loss=7.848047733306885
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3582: train_loss=7.830120086669922
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3583: train_loss=7.8316731452941895
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3584: train_loss=7.834237098693848
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3585: train_loss=7.788724899291992
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3586: train_loss=7.778980731964111
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3587: train_loss=7.7784600257873535
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3588: train_loss=7.781791687011719
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3589: train_loss=7.793422222137451
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3590: train_loss=7.787370204925537
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3591: train_loss=7.771897792816162
INFO - 04/15/25 16:50:11 - 0:18:34 - Epoch 3592: train_loss=7.768238544464111
INFO - 04/15/25 16:50:11 - 0:18:35 - Epoch 3593: train_loss=7.7635698318481445
INFO - 04/15/25 16:50:11 - 0:18:35 - Epoch 3594: train_loss=7.74643087387085
INFO - 04/15/25 16:50:11 - 0:18:35 - Epoch 3595: train_loss=7.7392401695251465
INFO - 04/15/25 16:50:11 - 0:18:35 - Epoch 3596: train_loss=7.743828773498535
INFO - 04/15/25 16:50:11 - 0:18:35 - Epoch 3597: train_loss=7.741580486297607
INFO - 04/15/25 16:50:11 - 0:18:35 - Epoch 3598: train_loss=7.744008541107178
INFO - 04/15/25 16:50:11 - 0:18:35 - Epoch 3599: train_loss=7.736133575439453
INFO - 04/15/25 16:50:11 - 0:18:35 - Epoch 3600: train_loss=7.740466594696045
INFO - 04/15/25 16:50:11 - 0:18:35 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:12 - 0:18:35 - Decoding cost time:  0.136 s
INFO - 04/15/25 16:50:12 - 0:18:35 - ------------------Saving best model-------------------
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3600: ACC: 0.0, NMI: 0.45458428737412976, F1: 0.0, ARI: 0.2829054242203377
INFO - 04/15/25 16:50:12 - 0:18:35 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3601: train_loss=7.752233982086182
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3602: train_loss=7.754734516143799
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3603: train_loss=7.749963760375977
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3604: train_loss=7.749220848083496
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3605: train_loss=7.744757175445557
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3606: train_loss=7.7390289306640625
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3607: train_loss=7.731577396392822
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3608: train_loss=7.734184741973877
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3609: train_loss=7.738176345825195
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3610: train_loss=7.729581832885742
INFO - 04/15/25 16:50:12 - 0:18:35 - Epoch 3611: train_loss=7.722324848175049
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3612: train_loss=7.728039264678955
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3613: train_loss=7.750609397888184
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3614: train_loss=7.775598049163818
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3615: train_loss=7.80682897567749
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3616: train_loss=7.803624629974365
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3617: train_loss=7.79813814163208
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3618: train_loss=7.800222873687744
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3619: train_loss=7.792958736419678
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3620: train_loss=7.79195499420166
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3621: train_loss=7.781563758850098
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3622: train_loss=7.773049831390381
INFO - 04/15/25 16:50:12 - 0:18:36 - Epoch 3623: train_loss=7.763605117797852
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3624: train_loss=7.752607345581055
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3625: train_loss=7.743077278137207
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3626: train_loss=7.732895374298096
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3627: train_loss=7.726309299468994
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3628: train_loss=7.723995685577393
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3629: train_loss=7.7252326011657715
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3630: train_loss=7.725548267364502
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3631: train_loss=7.724738121032715
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3632: train_loss=7.722967624664307
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3633: train_loss=7.720556259155273
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3634: train_loss=7.718982219696045
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3635: train_loss=7.7176690101623535
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3636: train_loss=7.716213703155518
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3637: train_loss=7.71179723739624
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3638: train_loss=7.70958137512207
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3639: train_loss=7.7041096687316895
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3640: train_loss=7.702567100524902
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3641: train_loss=7.703479290008545
INFO - 04/15/25 16:50:13 - 0:18:36 - Epoch 3642: train_loss=7.703514575958252
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3643: train_loss=7.701711177825928
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3644: train_loss=7.698537826538086
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3645: train_loss=7.6961798667907715
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3646: train_loss=7.701048851013184
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3647: train_loss=7.6959614753723145
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3648: train_loss=7.69535493850708
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3649: train_loss=7.694708824157715
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3650: train_loss=7.695270538330078
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3651: train_loss=7.693068504333496
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3652: train_loss=7.690305709838867
INFO - 04/15/25 16:50:13 - 0:18:37 - Epoch 3653: train_loss=7.691366195678711
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3654: train_loss=7.691473484039307
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3655: train_loss=7.690619945526123
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3656: train_loss=7.688221454620361
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3657: train_loss=7.687830924987793
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3658: train_loss=7.688984394073486
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3659: train_loss=7.686013221740723
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3660: train_loss=7.686254978179932
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3661: train_loss=7.68794059753418
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3662: train_loss=7.688026428222656
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3663: train_loss=7.683638095855713
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3664: train_loss=7.688458442687988
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3665: train_loss=7.687399387359619
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3666: train_loss=7.684784889221191
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3667: train_loss=7.682196140289307
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3668: train_loss=7.682160377502441
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3669: train_loss=7.683037757873535
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3670: train_loss=7.681010723114014
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3671: train_loss=7.679498195648193
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3672: train_loss=7.679808139801025
INFO - 04/15/25 16:50:14 - 0:18:37 - Epoch 3673: train_loss=7.681363105773926
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3674: train_loss=7.682054042816162
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3675: train_loss=7.680537700653076
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3676: train_loss=7.676573753356934
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3677: train_loss=7.676275730133057
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3678: train_loss=7.673859596252441
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3679: train_loss=7.672211170196533
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3680: train_loss=7.674831867218018
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3681: train_loss=7.682640552520752
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3682: train_loss=7.679907321929932
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3683: train_loss=7.6749749183654785
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3684: train_loss=7.679110527038574
INFO - 04/15/25 16:50:14 - 0:18:38 - Epoch 3685: train_loss=7.709835052490234
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3686: train_loss=7.676868915557861
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3687: train_loss=7.675234794616699
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3688: train_loss=7.676927089691162
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3689: train_loss=7.67527437210083
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3690: train_loss=7.676049709320068
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3691: train_loss=7.674931049346924
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3692: train_loss=7.675698280334473
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3693: train_loss=7.674680709838867
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3694: train_loss=7.672313690185547
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3695: train_loss=7.674247741699219
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3696: train_loss=7.670403957366943
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3697: train_loss=7.67041015625
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3698: train_loss=7.66978120803833
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3699: train_loss=7.668339252471924
INFO - 04/15/25 16:50:15 - 0:18:38 - Epoch 3700: train_loss=7.673425197601318
INFO - 04/15/25 16:50:15 - 0:18:38 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:15 - 0:18:38 - Decoding cost time:  0.119 s
INFO - 04/15/25 16:50:15 - 0:18:39 - Epoch 3700: ACC: 0.0, NMI: 0.045768217545237716, F1: 0.0, ARI: 0.0006078295737404644
INFO - 04/15/25 16:50:15 - 0:18:39 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:15 - 0:18:39 - Epoch 3701: train_loss=7.668118000030518
INFO - 04/15/25 16:50:15 - 0:18:39 - Epoch 3702: train_loss=7.668222427368164
INFO - 04/15/25 16:50:15 - 0:18:39 - Epoch 3703: train_loss=7.666359901428223
INFO - 04/15/25 16:50:15 - 0:18:39 - Epoch 3704: train_loss=7.669366836547852
INFO - 04/15/25 16:50:15 - 0:18:39 - Epoch 3705: train_loss=7.668104648590088
INFO - 04/15/25 16:50:15 - 0:18:39 - Epoch 3706: train_loss=7.665127277374268
INFO - 04/15/25 16:50:15 - 0:18:39 - Epoch 3707: train_loss=7.667885780334473
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3708: train_loss=7.664676189422607
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3709: train_loss=7.663172721862793
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3710: train_loss=7.661166667938232
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3711: train_loss=7.661868095397949
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3712: train_loss=7.660824298858643
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3713: train_loss=7.659093856811523
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3714: train_loss=7.657817840576172
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3715: train_loss=7.661221504211426
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3716: train_loss=7.658258438110352
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3717: train_loss=7.658698081970215
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3718: train_loss=7.6545233726501465
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3719: train_loss=7.657842636108398
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3720: train_loss=7.655429840087891
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3721: train_loss=7.654659271240234
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3722: train_loss=7.6533684730529785
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3723: train_loss=7.655892372131348
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3724: train_loss=7.651602268218994
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3725: train_loss=7.661027908325195
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3726: train_loss=7.674373149871826
INFO - 04/15/25 16:50:16 - 0:18:39 - Epoch 3727: train_loss=7.659466743469238
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3728: train_loss=7.658929824829102
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3729: train_loss=7.658873558044434
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3730: train_loss=7.661409378051758
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3731: train_loss=7.6634111404418945
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3732: train_loss=7.662935733795166
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3733: train_loss=7.695525169372559
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3734: train_loss=7.660518646240234
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3735: train_loss=7.6706223487854
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3736: train_loss=7.675441741943359
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3737: train_loss=7.667773723602295
INFO - 04/15/25 16:50:16 - 0:18:40 - Epoch 3738: train_loss=7.666772842407227
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3739: train_loss=7.659742832183838
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3740: train_loss=7.670238494873047
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3741: train_loss=7.6623005867004395
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3742: train_loss=7.660248756408691
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3743: train_loss=7.6590142250061035
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3744: train_loss=7.653229236602783
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3745: train_loss=7.649733066558838
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3746: train_loss=7.651580810546875
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3747: train_loss=7.651898384094238
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3748: train_loss=7.655609130859375
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3749: train_loss=7.652164936065674
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3750: train_loss=7.652347564697266
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3751: train_loss=7.654831886291504
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3752: train_loss=7.658718109130859
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3753: train_loss=7.65555477142334
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3754: train_loss=7.655118942260742
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3755: train_loss=7.649337291717529
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3756: train_loss=7.654026031494141
INFO - 04/15/25 16:50:17 - 0:18:40 - Epoch 3757: train_loss=7.649433612823486
INFO - 04/15/25 16:50:18 - 0:18:41 - Epoch 3758: train_loss=7.644463539123535
INFO - 04/15/25 16:50:18 - 0:18:41 - Epoch 3759: train_loss=7.646718978881836
INFO - 04/15/25 16:50:18 - 0:18:41 - Epoch 3760: train_loss=7.6429972648620605
INFO - 04/15/25 16:50:18 - 0:18:41 - Epoch 3761: train_loss=7.641910076141357
INFO - 04/15/25 16:50:18 - 0:18:41 - Epoch 3762: train_loss=7.642068862915039
INFO - 04/15/25 16:50:18 - 0:18:41 - Epoch 3763: train_loss=7.646130561828613
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3764: train_loss=7.645177364349365
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3765: train_loss=7.657689571380615
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3766: train_loss=7.674863338470459
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3767: train_loss=7.670817852020264
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3768: train_loss=7.667545795440674
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3769: train_loss=7.657797813415527
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3770: train_loss=7.658483505249023
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3771: train_loss=7.65562629699707
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3772: train_loss=7.6592512130737305
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3773: train_loss=7.6507463455200195
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3774: train_loss=7.654124736785889
INFO - 04/15/25 16:50:18 - 0:18:42 - Epoch 3775: train_loss=7.645726203918457
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3776: train_loss=7.648990631103516
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3777: train_loss=7.645708084106445
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3778: train_loss=7.646551132202148
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3779: train_loss=7.64548397064209
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3780: train_loss=7.649326324462891
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3781: train_loss=7.639986515045166
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3782: train_loss=7.650557518005371
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3783: train_loss=7.647563934326172
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3784: train_loss=7.640217304229736
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3785: train_loss=7.63974666595459
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3786: train_loss=7.64789342880249
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3787: train_loss=7.642876148223877
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3788: train_loss=7.636542320251465
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3789: train_loss=7.6512980461120605
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3790: train_loss=7.648408889770508
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3791: train_loss=7.647751331329346
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3792: train_loss=7.649056911468506
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3793: train_loss=7.6445231437683105
INFO - 04/15/25 16:50:19 - 0:18:42 - Epoch 3794: train_loss=7.65625
INFO - 04/15/25 16:50:19 - 0:18:43 - Epoch 3795: train_loss=7.657138824462891
INFO - 04/15/25 16:50:19 - 0:18:43 - Epoch 3796: train_loss=7.655257225036621
INFO - 04/15/25 16:50:19 - 0:18:43 - Epoch 3797: train_loss=7.649628639221191
INFO - 04/15/25 16:50:19 - 0:18:43 - Epoch 3798: train_loss=7.644598960876465
INFO - 04/15/25 16:50:19 - 0:18:43 - Epoch 3799: train_loss=7.642617225646973
INFO - 04/15/25 16:50:19 - 0:18:43 - Epoch 3800: train_loss=7.645959854125977
INFO - 04/15/25 16:50:19 - 0:18:43 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:19 - 0:18:43 - Decoding cost time:  0.125 s
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3800: ACC: 0.0, NMI: 0.027934480743840317, F1: 0.0, ARI: 0.00010070263478518314
INFO - 04/15/25 16:50:20 - 0:18:43 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3801: train_loss=7.641297340393066
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3802: train_loss=7.637416362762451
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3803: train_loss=7.638179779052734
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3804: train_loss=7.635830879211426
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3805: train_loss=7.63910436630249
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3806: train_loss=7.636203289031982
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3807: train_loss=7.633997917175293
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3808: train_loss=7.632587909698486
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3809: train_loss=7.631876468658447
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3810: train_loss=7.630919933319092
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3811: train_loss=7.628249168395996
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3812: train_loss=7.627252101898193
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3813: train_loss=7.627420425415039
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3814: train_loss=7.641345024108887
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3815: train_loss=7.63044548034668
INFO - 04/15/25 16:50:20 - 0:18:43 - Epoch 3816: train_loss=7.637022972106934
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3817: train_loss=7.642152786254883
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3818: train_loss=7.6419830322265625
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3819: train_loss=7.6404876708984375
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3820: train_loss=7.641980171203613
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3821: train_loss=7.649627685546875
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3822: train_loss=7.650228500366211
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3823: train_loss=7.644198417663574
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3824: train_loss=7.639794826507568
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3825: train_loss=7.642923831939697
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3826: train_loss=7.639678955078125
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3827: train_loss=7.640275955200195
INFO - 04/15/25 16:50:20 - 0:18:44 - Epoch 3828: train_loss=7.637541770935059
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3829: train_loss=7.637897968292236
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3830: train_loss=7.635793685913086
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3831: train_loss=7.637069225311279
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3832: train_loss=7.633181095123291
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3833: train_loss=7.6270928382873535
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3834: train_loss=7.637839317321777
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3835: train_loss=7.632285118103027
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3836: train_loss=7.631627082824707
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3837: train_loss=7.622262001037598
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3838: train_loss=7.626818656921387
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3839: train_loss=7.622607707977295
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3840: train_loss=7.623574733734131
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3841: train_loss=7.630581378936768
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3842: train_loss=7.637777328491211
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3843: train_loss=7.650555610656738
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3844: train_loss=7.649898052215576
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3845: train_loss=7.645701885223389
INFO - 04/15/25 16:50:21 - 0:18:44 - Epoch 3846: train_loss=7.647562503814697
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3847: train_loss=7.649099826812744
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3848: train_loss=7.6479926109313965
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3849: train_loss=7.63917875289917
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3850: train_loss=7.636796474456787
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3851: train_loss=7.627018451690674
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3852: train_loss=7.634036064147949
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3853: train_loss=7.630589485168457
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3854: train_loss=7.631021022796631
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3855: train_loss=7.627973556518555
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3856: train_loss=7.626272678375244
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3857: train_loss=7.623159408569336
INFO - 04/15/25 16:50:21 - 0:18:45 - Epoch 3858: train_loss=7.623920917510986
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3859: train_loss=7.622467517852783
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3860: train_loss=7.621944427490234
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3861: train_loss=7.620175838470459
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3862: train_loss=7.621057033538818
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3863: train_loss=7.6355133056640625
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3864: train_loss=7.620537757873535
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3865: train_loss=7.623327732086182
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3866: train_loss=7.623255252838135
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3867: train_loss=7.6229352951049805
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3868: train_loss=7.626121997833252
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3869: train_loss=7.622583389282227
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3870: train_loss=7.623924255371094
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3871: train_loss=7.621395587921143
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3872: train_loss=7.620590686798096
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3873: train_loss=7.618707180023193
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3874: train_loss=7.616660118103027
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3875: train_loss=7.616048336029053
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3876: train_loss=7.621276378631592
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3877: train_loss=7.617466449737549
INFO - 04/15/25 16:50:22 - 0:18:45 - Epoch 3878: train_loss=7.615814208984375
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3879: train_loss=7.616140365600586
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3880: train_loss=7.613963603973389
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3881: train_loss=7.610669136047363
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3882: train_loss=7.610340595245361
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3883: train_loss=7.6095194816589355
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3884: train_loss=7.610770225524902
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3885: train_loss=7.6094160079956055
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3886: train_loss=7.620911121368408
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3887: train_loss=7.605715751647949
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3888: train_loss=7.609079360961914
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3889: train_loss=7.609263896942139
INFO - 04/15/25 16:50:22 - 0:18:46 - Epoch 3890: train_loss=7.608423709869385
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3891: train_loss=7.611891269683838
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3892: train_loss=7.608548641204834
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3893: train_loss=7.613344669342041
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3894: train_loss=7.612298965454102
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3895: train_loss=7.6100754737854
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3896: train_loss=7.61064338684082
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3897: train_loss=7.606999397277832
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3898: train_loss=7.611947059631348
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3899: train_loss=7.609058856964111
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3900: train_loss=7.6123738288879395
INFO - 04/15/25 16:50:23 - 0:18:46 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:23 - 0:18:46 - Decoding cost time:  0.128 s
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3900: ACC: 0.0, NMI: 0.04644735772556088, F1: 0.0, ARI: 0.0003257407164795539
INFO - 04/15/25 16:50:23 - 0:18:46 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:23 - 0:18:46 - Epoch 3901: train_loss=7.60605525970459
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3902: train_loss=7.605362892150879
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3903: train_loss=7.604594707489014
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3904: train_loss=7.603049278259277
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3905: train_loss=7.601750373840332
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3906: train_loss=7.601202011108398
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3907: train_loss=7.603724479675293
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3908: train_loss=7.620083808898926
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3909: train_loss=7.605271339416504
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3910: train_loss=7.605625152587891
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3911: train_loss=7.607823371887207
INFO - 04/15/25 16:50:23 - 0:18:47 - Epoch 3912: train_loss=7.609995365142822
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3913: train_loss=7.611607551574707
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3914: train_loss=7.613034725189209
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3915: train_loss=7.610363006591797
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3916: train_loss=7.609453201293945
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3917: train_loss=7.608055591583252
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3918: train_loss=7.605718612670898
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3919: train_loss=7.606921672821045
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3920: train_loss=7.609680652618408
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3921: train_loss=7.606328964233398
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3922: train_loss=7.608055114746094
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3923: train_loss=7.607672214508057
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3924: train_loss=7.61106014251709
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3925: train_loss=7.60274076461792
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3926: train_loss=7.600712776184082
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3927: train_loss=7.599490642547607
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3928: train_loss=7.611954689025879
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3929: train_loss=7.615114212036133
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3930: train_loss=7.5944108963012695
INFO - 04/15/25 16:50:24 - 0:18:47 - Epoch 3931: train_loss=7.6561079025268555
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3932: train_loss=7.693483829498291
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3933: train_loss=7.700692176818848
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3934: train_loss=7.7367753982543945
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3935: train_loss=7.745497703552246
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3936: train_loss=7.731748104095459
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3937: train_loss=7.741113185882568
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3938: train_loss=7.739174842834473
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3939: train_loss=7.732357978820801
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3940: train_loss=7.728810787200928
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3941: train_loss=7.730060577392578
INFO - 04/15/25 16:50:24 - 0:18:48 - Epoch 3942: train_loss=7.742726802825928
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3943: train_loss=7.747150421142578
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3944: train_loss=7.75637149810791
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3945: train_loss=7.762584686279297
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3946: train_loss=7.784425735473633
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3947: train_loss=7.785943984985352
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3948: train_loss=7.779069900512695
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3949: train_loss=7.835587024688721
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3950: train_loss=7.849710941314697
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3951: train_loss=7.830846309661865
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3952: train_loss=7.823849201202393
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3953: train_loss=7.811336040496826
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3954: train_loss=7.809999465942383
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3955: train_loss=7.795057773590088
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3956: train_loss=7.770987510681152
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3957: train_loss=7.748621463775635
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3958: train_loss=7.736122131347656
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3959: train_loss=7.721384525299072
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3960: train_loss=7.704477787017822
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3961: train_loss=7.684688568115234
INFO - 04/15/25 16:50:25 - 0:18:48 - Epoch 3962: train_loss=7.675151824951172
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3963: train_loss=7.666740417480469
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3964: train_loss=7.659775733947754
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3965: train_loss=7.652868747711182
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3966: train_loss=7.638182640075684
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3967: train_loss=7.6346025466918945
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3968: train_loss=7.632788181304932
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3969: train_loss=7.6301422119140625
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3970: train_loss=7.6310906410217285
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3971: train_loss=7.624176979064941
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3972: train_loss=7.617903232574463
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3973: train_loss=7.619213104248047
INFO - 04/15/25 16:50:25 - 0:18:49 - Epoch 3974: train_loss=7.608817100524902
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3975: train_loss=7.605920791625977
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3976: train_loss=7.601205825805664
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3977: train_loss=7.6089043617248535
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3978: train_loss=7.599727153778076
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3979: train_loss=7.599964141845703
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3980: train_loss=7.594316005706787
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3981: train_loss=7.593044281005859
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3982: train_loss=7.590681552886963
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3983: train_loss=7.589597225189209
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3984: train_loss=7.587908744812012
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3985: train_loss=7.582052707672119
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3986: train_loss=7.583912372589111
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3987: train_loss=7.580043315887451
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3988: train_loss=7.583810329437256
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3989: train_loss=7.582468509674072
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3990: train_loss=7.576075077056885
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3991: train_loss=7.575498104095459
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3992: train_loss=7.5774688720703125
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3993: train_loss=7.572399139404297
INFO - 04/15/25 16:50:26 - 0:18:49 - Epoch 3994: train_loss=7.569663047790527
INFO - 04/15/25 16:50:26 - 0:18:50 - Epoch 3995: train_loss=7.576049327850342
INFO - 04/15/25 16:50:26 - 0:18:50 - Epoch 3996: train_loss=7.567963123321533
INFO - 04/15/25 16:50:26 - 0:18:50 - Epoch 3997: train_loss=7.566434860229492
INFO - 04/15/25 16:50:26 - 0:18:50 - Epoch 3998: train_loss=7.5646796226501465
INFO - 04/15/25 16:50:26 - 0:18:50 - Epoch 3999: train_loss=7.562403678894043
INFO - 04/15/25 16:50:26 - 0:18:50 - Epoch 4000: train_loss=7.560976982116699
INFO - 04/15/25 16:50:26 - 0:18:50 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:26 - 0:18:50 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4000: ACC: 0.0, NMI: 0.11035099325946547, F1: 0.0, ARI: 0.008507353164081903
INFO - 04/15/25 16:50:27 - 0:18:50 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4001: train_loss=7.560669898986816
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4002: train_loss=7.557824611663818
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4003: train_loss=7.556005001068115
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4004: train_loss=7.566565990447998
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4005: train_loss=7.55422306060791
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4006: train_loss=7.558432579040527
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4007: train_loss=7.5541863441467285
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4008: train_loss=7.554656505584717
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4009: train_loss=7.554327964782715
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4010: train_loss=7.552901268005371
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4011: train_loss=7.549973487854004
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4012: train_loss=7.554795742034912
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4013: train_loss=7.551648139953613
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4014: train_loss=7.54948091506958
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4015: train_loss=7.548518657684326
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4016: train_loss=7.547454357147217
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4017: train_loss=7.547723293304443
INFO - 04/15/25 16:50:27 - 0:18:50 - Epoch 4018: train_loss=7.544646263122559
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4019: train_loss=7.542623519897461
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4020: train_loss=7.547898292541504
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4021: train_loss=7.557748794555664
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4022: train_loss=7.540655612945557
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4023: train_loss=7.549771308898926
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4024: train_loss=7.541763782501221
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4025: train_loss=7.547886371612549
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4026: train_loss=7.5409016609191895
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4027: train_loss=7.552527904510498
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4028: train_loss=7.540811061859131
INFO - 04/15/25 16:50:27 - 0:18:51 - Epoch 4029: train_loss=7.5376129150390625
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4030: train_loss=7.544277191162109
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4031: train_loss=7.556550025939941
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4032: train_loss=7.553871154785156
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4033: train_loss=7.557078838348389
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4034: train_loss=7.572436332702637
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4035: train_loss=7.550083160400391
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4036: train_loss=7.565338611602783
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4037: train_loss=7.567327976226807
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4038: train_loss=7.5652289390563965
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4039: train_loss=7.566829204559326
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4040: train_loss=7.566096782684326
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4041: train_loss=7.549082279205322
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4042: train_loss=7.557407379150391
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4043: train_loss=7.546871662139893
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4044: train_loss=7.549647331237793
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4045: train_loss=7.540858268737793
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4046: train_loss=7.538296222686768
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4047: train_loss=7.564663887023926
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4048: train_loss=7.571148872375488
INFO - 04/15/25 16:50:28 - 0:18:51 - Epoch 4049: train_loss=7.55694580078125
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4050: train_loss=7.5575056076049805
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4051: train_loss=7.571349143981934
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4052: train_loss=7.539029121398926
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4053: train_loss=7.533804893493652
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4054: train_loss=7.54213285446167
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4055: train_loss=7.535240173339844
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4056: train_loss=7.53682804107666
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4057: train_loss=7.540146827697754
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4058: train_loss=7.520596027374268
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4059: train_loss=7.519371509552002
INFO - 04/15/25 16:50:28 - 0:18:52 - Epoch 4060: train_loss=7.517007350921631
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4061: train_loss=7.524206638336182
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4062: train_loss=7.512683868408203
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4063: train_loss=7.511589527130127
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4064: train_loss=7.510051250457764
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4065: train_loss=7.512519836425781
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4066: train_loss=7.5042724609375
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4067: train_loss=7.506249904632568
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4068: train_loss=7.503904819488525
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4069: train_loss=7.521953105926514
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4070: train_loss=7.5028486251831055
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4071: train_loss=7.502562522888184
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4072: train_loss=7.521173477172852
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4073: train_loss=7.511869430541992
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4074: train_loss=7.524387836456299
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4075: train_loss=7.520991802215576
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4076: train_loss=7.511117935180664
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4077: train_loss=7.509562969207764
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4078: train_loss=7.507227897644043
INFO - 04/15/25 16:50:29 - 0:18:52 - Epoch 4079: train_loss=7.509215831756592
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4080: train_loss=7.513814449310303
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4081: train_loss=7.514311790466309
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4082: train_loss=7.509352207183838
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4083: train_loss=7.523594379425049
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4084: train_loss=7.520815849304199
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4085: train_loss=7.5073466300964355
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4086: train_loss=7.53421688079834
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4087: train_loss=7.508388996124268
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4088: train_loss=7.540950775146484
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4089: train_loss=7.522711753845215
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4090: train_loss=7.511784553527832
INFO - 04/15/25 16:50:29 - 0:18:53 - Epoch 4091: train_loss=7.5116143226623535
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4092: train_loss=7.5066986083984375
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4093: train_loss=7.508239269256592
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4094: train_loss=7.510576248168945
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4095: train_loss=7.500407695770264
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4096: train_loss=7.512786388397217
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4097: train_loss=7.51426362991333
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4098: train_loss=7.502082347869873
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4099: train_loss=7.506359577178955
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4100: train_loss=7.50738525390625
INFO - 04/15/25 16:50:30 - 0:18:53 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:30 - 0:18:53 - Decoding cost time:  0.118 s
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4100: ACC: 0.0, NMI: 0.034093026885261016, F1: 0.0, ARI: -0.0003105898288095405
INFO - 04/15/25 16:50:30 - 0:18:53 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4101: train_loss=7.50156307220459
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4102: train_loss=7.499354839324951
INFO - 04/15/25 16:50:30 - 0:18:53 - Epoch 4103: train_loss=7.509715557098389
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4104: train_loss=7.499293804168701
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4105: train_loss=7.502400875091553
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4106: train_loss=7.497308254241943
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4107: train_loss=7.49794340133667
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4108: train_loss=7.508282661437988
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4109: train_loss=7.490413188934326
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4110: train_loss=7.493420124053955
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4111: train_loss=7.498988151550293
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4112: train_loss=7.492218494415283
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4113: train_loss=7.48978328704834
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4114: train_loss=7.49143123626709
INFO - 04/15/25 16:50:30 - 0:18:54 - Epoch 4115: train_loss=7.488224506378174
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4116: train_loss=7.495007514953613
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4117: train_loss=7.499155521392822
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4118: train_loss=7.4853105545043945
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4119: train_loss=7.493932723999023
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4120: train_loss=7.497364044189453
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4121: train_loss=7.482051372528076
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4122: train_loss=7.493820667266846
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4123: train_loss=7.483750820159912
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4124: train_loss=7.491203308105469
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4125: train_loss=7.489816188812256
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4126: train_loss=7.498649597167969
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4127: train_loss=7.4983744621276855
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4128: train_loss=7.492158889770508
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4129: train_loss=7.49208402633667
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4130: train_loss=7.489406585693359
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4131: train_loss=7.488214492797852
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4132: train_loss=7.487865924835205
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4133: train_loss=7.486029148101807
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4134: train_loss=7.484133720397949
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4135: train_loss=7.489933967590332
INFO - 04/15/25 16:50:31 - 0:18:54 - Epoch 4136: train_loss=7.490223407745361
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4137: train_loss=7.485713005065918
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4138: train_loss=7.488195896148682
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4139: train_loss=7.490540027618408
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4140: train_loss=7.486983299255371
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4141: train_loss=7.486689567565918
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4142: train_loss=7.4914679527282715
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4143: train_loss=7.491283416748047
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4144: train_loss=7.4821696281433105
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4145: train_loss=7.486336708068848
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4146: train_loss=7.478786945343018
INFO - 04/15/25 16:50:31 - 0:18:55 - Epoch 4147: train_loss=7.497936725616455
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4148: train_loss=7.479637622833252
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4149: train_loss=7.48241662979126
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4150: train_loss=7.481525421142578
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4151: train_loss=7.48201322555542
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4152: train_loss=7.4791083335876465
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4153: train_loss=7.48139762878418
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4154: train_loss=7.481926918029785
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4155: train_loss=7.486321449279785
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4156: train_loss=7.4841742515563965
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4157: train_loss=7.510040760040283
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4158: train_loss=7.484767913818359
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4159: train_loss=7.493790149688721
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4160: train_loss=7.490049362182617
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4161: train_loss=7.48857307434082
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4162: train_loss=7.487551212310791
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4163: train_loss=7.486365795135498
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4164: train_loss=7.487579345703125
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4165: train_loss=7.488978385925293
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4166: train_loss=7.486343860626221
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4167: train_loss=7.4849534034729
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4168: train_loss=7.4846906661987305
INFO - 04/15/25 16:50:32 - 0:18:55 - Epoch 4169: train_loss=7.490062713623047
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4170: train_loss=7.482607364654541
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4171: train_loss=7.482387542724609
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4172: train_loss=7.48094367980957
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4173: train_loss=7.489656448364258
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4174: train_loss=7.478370189666748
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4175: train_loss=7.478090763092041
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4176: train_loss=7.48034143447876
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4177: train_loss=7.478206634521484
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4178: train_loss=7.4798383712768555
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4179: train_loss=7.476644039154053
INFO - 04/15/25 16:50:32 - 0:18:56 - Epoch 4180: train_loss=7.475279331207275
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4181: train_loss=7.474966049194336
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4182: train_loss=7.472938060760498
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4183: train_loss=7.48021125793457
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4184: train_loss=7.50583028793335
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4185: train_loss=7.480626583099365
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4186: train_loss=7.477892875671387
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4187: train_loss=7.479177474975586
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4188: train_loss=7.48206090927124
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4189: train_loss=7.483204364776611
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4190: train_loss=7.480188846588135
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4191: train_loss=7.478709697723389
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4192: train_loss=7.477288722991943
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4193: train_loss=7.476803302764893
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4194: train_loss=7.478208541870117
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4195: train_loss=7.478129863739014
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4196: train_loss=7.477837562561035
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4197: train_loss=7.476507186889648
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4198: train_loss=7.4773101806640625
INFO - 04/15/25 16:50:33 - 0:18:56 - Epoch 4199: train_loss=7.472882270812988
INFO - 04/15/25 16:50:33 - 0:18:57 - Epoch 4200: train_loss=7.477748870849609
INFO - 04/15/25 16:50:33 - 0:18:57 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:33 - 0:18:57 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:50:33 - 0:18:57 - Epoch 4200: ACC: 0.0, NMI: 0.03575097861433736, F1: 0.0, ARI: -0.00010759872736118957
INFO - 04/15/25 16:50:33 - 0:18:57 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:33 - 0:18:57 - Epoch 4201: train_loss=7.472090244293213
INFO - 04/15/25 16:50:33 - 0:18:57 - Epoch 4202: train_loss=7.471556663513184
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4203: train_loss=7.4700212478637695
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4204: train_loss=7.476995944976807
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4205: train_loss=7.470988750457764
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4206: train_loss=7.468571186065674
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4207: train_loss=7.470496654510498
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4208: train_loss=7.466397762298584
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4209: train_loss=7.466210842132568
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4210: train_loss=7.4690728187561035
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4211: train_loss=7.466682434082031
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4212: train_loss=7.465865612030029
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4213: train_loss=7.462095260620117
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4214: train_loss=7.465824127197266
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4215: train_loss=7.4691338539123535
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4216: train_loss=7.466333866119385
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4217: train_loss=7.471869945526123
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4218: train_loss=7.4654974937438965
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4219: train_loss=7.467833042144775
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4220: train_loss=7.461418151855469
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4221: train_loss=7.464594841003418
INFO - 04/15/25 16:50:34 - 0:18:57 - Epoch 4222: train_loss=7.467352867126465
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4223: train_loss=7.4641032218933105
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4224: train_loss=7.465463161468506
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4225: train_loss=7.467840194702148
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4226: train_loss=7.462811470031738
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4227: train_loss=7.461564540863037
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4228: train_loss=7.467828273773193
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4229: train_loss=7.464831352233887
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4230: train_loss=7.462581634521484
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4231: train_loss=7.460639953613281
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4232: train_loss=7.459114074707031
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4233: train_loss=7.462214469909668
INFO - 04/15/25 16:50:34 - 0:18:58 - Epoch 4234: train_loss=7.478203773498535
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4235: train_loss=7.464818477630615
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4236: train_loss=7.471672534942627
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4237: train_loss=7.471764087677002
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4238: train_loss=7.4754486083984375
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4239: train_loss=7.471194744110107
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4240: train_loss=7.47074031829834
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4241: train_loss=7.468283653259277
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4242: train_loss=7.472909927368164
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4243: train_loss=7.4652838706970215
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4244: train_loss=7.46457576751709
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4245: train_loss=7.487686634063721
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4246: train_loss=7.466607093811035
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4247: train_loss=7.4756388664245605
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4248: train_loss=7.475649833679199
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4249: train_loss=7.476479530334473
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4250: train_loss=7.4822282791137695
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4251: train_loss=7.473513603210449
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4252: train_loss=7.4742608070373535
INFO - 04/15/25 16:50:35 - 0:18:58 - Epoch 4253: train_loss=7.4719414710998535
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4254: train_loss=7.472089767456055
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4255: train_loss=7.491584300994873
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4256: train_loss=7.508865833282471
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4257: train_loss=7.493554592132568
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4258: train_loss=7.485260486602783
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4259: train_loss=7.494902610778809
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4260: train_loss=7.487969875335693
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4261: train_loss=7.494017601013184
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4262: train_loss=7.5054121017456055
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4263: train_loss=7.500010013580322
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4264: train_loss=7.490457057952881
INFO - 04/15/25 16:50:35 - 0:18:59 - Epoch 4265: train_loss=7.490762233734131
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4266: train_loss=7.493021011352539
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4267: train_loss=7.495028495788574
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4268: train_loss=7.492210865020752
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4269: train_loss=7.5069780349731445
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4270: train_loss=7.492258071899414
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4271: train_loss=7.519199848175049
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4272: train_loss=7.514797210693359
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4273: train_loss=7.504769325256348
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4274: train_loss=7.505047798156738
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4275: train_loss=7.5085978507995605
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4276: train_loss=7.506622314453125
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4277: train_loss=7.506513595581055
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4278: train_loss=7.501140594482422
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4279: train_loss=7.505460262298584
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4280: train_loss=7.498615264892578
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4281: train_loss=7.4991374015808105
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4282: train_loss=7.497963905334473
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4283: train_loss=7.501453876495361
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4284: train_loss=7.522052764892578
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4285: train_loss=7.5032453536987305
INFO - 04/15/25 16:50:36 - 0:18:59 - Epoch 4286: train_loss=7.511844635009766
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4287: train_loss=7.503201484680176
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4288: train_loss=7.525990962982178
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4289: train_loss=7.515895843505859
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4290: train_loss=7.516183853149414
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4291: train_loss=7.5142059326171875
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4292: train_loss=7.510462760925293
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4293: train_loss=7.521133899688721
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4294: train_loss=7.513267517089844
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4295: train_loss=7.524489879608154
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4296: train_loss=7.5068278312683105
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4297: train_loss=7.498035430908203
INFO - 04/15/25 16:50:36 - 0:19:00 - Epoch 4298: train_loss=7.500179767608643
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4299: train_loss=7.502938270568848
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4300: train_loss=7.499188423156738
INFO - 04/15/25 16:50:37 - 0:19:00 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:37 - 0:19:00 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4300: ACC: 0.0, NMI: 0.023018045172562576, F1: 0.0, ARI: -4.35334360746041e-05
INFO - 04/15/25 16:50:37 - 0:19:00 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4301: train_loss=7.494422435760498
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4302: train_loss=7.4927473068237305
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4303: train_loss=7.493964672088623
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4304: train_loss=7.504113674163818
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4305: train_loss=7.490475654602051
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4306: train_loss=7.506428241729736
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4307: train_loss=7.495410919189453
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4308: train_loss=7.502973556518555
INFO - 04/15/25 16:50:37 - 0:19:00 - Epoch 4309: train_loss=7.505352973937988
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4310: train_loss=7.535761833190918
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4311: train_loss=7.514370441436768
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4312: train_loss=7.515482425689697
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4313: train_loss=7.514535903930664
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4314: train_loss=7.512165069580078
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4315: train_loss=7.509748935699463
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4316: train_loss=7.508055686950684
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4317: train_loss=7.518949508666992
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4318: train_loss=7.514689922332764
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4319: train_loss=7.505448341369629
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4320: train_loss=7.508882999420166
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4321: train_loss=7.515619277954102
INFO - 04/15/25 16:50:37 - 0:19:01 - Epoch 4322: train_loss=7.504034519195557
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4323: train_loss=7.513756275177002
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4324: train_loss=7.510831356048584
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4325: train_loss=7.504335403442383
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4326: train_loss=7.5051422119140625
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4327: train_loss=7.507064342498779
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4328: train_loss=7.505776882171631
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4329: train_loss=7.510794162750244
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4330: train_loss=7.5085554122924805
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4331: train_loss=7.50099515914917
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4332: train_loss=7.495912551879883
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4333: train_loss=7.498012542724609
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4334: train_loss=7.497769355773926
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4335: train_loss=7.4943623542785645
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4336: train_loss=7.495112419128418
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4337: train_loss=7.496036052703857
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4338: train_loss=7.492166519165039
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4339: train_loss=7.491396903991699
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4340: train_loss=7.488035202026367
INFO - 04/15/25 16:50:38 - 0:19:01 - Epoch 4341: train_loss=7.487139701843262
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4342: train_loss=7.491235733032227
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4343: train_loss=7.492266654968262
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4344: train_loss=7.4900617599487305
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4345: train_loss=7.49579381942749
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4346: train_loss=7.488337516784668
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4347: train_loss=7.483633995056152
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4348: train_loss=7.481945514678955
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4349: train_loss=7.4832329750061035
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4350: train_loss=7.4842681884765625
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4351: train_loss=7.483251571655273
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4352: train_loss=7.503693103790283
INFO - 04/15/25 16:50:38 - 0:19:02 - Epoch 4353: train_loss=7.483333110809326
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4354: train_loss=7.486021995544434
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4355: train_loss=7.48251485824585
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4356: train_loss=7.480161666870117
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4357: train_loss=7.518387317657471
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4358: train_loss=7.485432147979736
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4359: train_loss=7.487143039703369
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4360: train_loss=7.488140106201172
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4361: train_loss=7.494665145874023
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4362: train_loss=7.48649787902832
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4363: train_loss=7.4867119789123535
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4364: train_loss=7.483481407165527
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4365: train_loss=7.48264741897583
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4366: train_loss=7.482330322265625
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4367: train_loss=7.498422145843506
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4368: train_loss=7.48434591293335
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4369: train_loss=7.483330726623535
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4370: train_loss=7.479621887207031
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4371: train_loss=7.478184700012207
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4372: train_loss=7.480751037597656
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4373: train_loss=7.4888434410095215
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4374: train_loss=7.488268852233887
INFO - 04/15/25 16:50:39 - 0:19:02 - Epoch 4375: train_loss=7.479938983917236
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4376: train_loss=7.482089996337891
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4377: train_loss=7.490838527679443
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4378: train_loss=7.486156940460205
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4379: train_loss=7.4816389083862305
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4380: train_loss=7.4800004959106445
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4381: train_loss=7.479559898376465
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4382: train_loss=7.479288101196289
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4383: train_loss=7.49487829208374
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4384: train_loss=7.480345726013184
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4385: train_loss=7.48532247543335
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4386: train_loss=7.4897027015686035
INFO - 04/15/25 16:50:39 - 0:19:03 - Epoch 4387: train_loss=7.4901885986328125
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4388: train_loss=7.491499423980713
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4389: train_loss=7.488447189331055
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4390: train_loss=7.488818645477295
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4391: train_loss=7.4899001121521
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4392: train_loss=7.495621204376221
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4393: train_loss=7.487368106842041
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4394: train_loss=7.490080833435059
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4395: train_loss=7.483447551727295
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4396: train_loss=7.488027572631836
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4397: train_loss=7.488850116729736
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4398: train_loss=7.489882469177246
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4399: train_loss=7.491255283355713
INFO - 04/15/25 16:50:40 - 0:19:03 - Epoch 4400: train_loss=7.492030143737793
INFO - 04/15/25 16:50:40 - 0:19:03 - -----------------------Evaluation Start---------------------
INFO - 04/15/25 16:50:40 - 0:19:03 - Decoding cost time:  0.120 s
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4400: ACC: 0.0, NMI: 0.029551346913786036, F1: 0.0, ARI: 0.00025554323717266476
INFO - 04/15/25 16:50:40 - 0:19:04 - -------------------------------------------------------------------------
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4401: train_loss=7.492854595184326
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4402: train_loss=7.485305309295654
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4403: train_loss=7.4908766746521
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4404: train_loss=7.482316017150879
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4405: train_loss=7.4882588386535645
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4406: train_loss=7.48234748840332
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4407: train_loss=7.486446380615234
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4408: train_loss=7.480230808258057
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4409: train_loss=7.478011608123779
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4410: train_loss=7.4754638671875
INFO - 04/15/25 16:50:40 - 0:19:04 - Epoch 4411: train_loss=7.477128028869629
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4412: train_loss=7.4767069816589355
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4413: train_loss=7.486488342285156
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4414: train_loss=7.475796699523926
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4415: train_loss=7.4736528396606445
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4416: train_loss=7.472539901733398
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4417: train_loss=7.472540855407715
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4418: train_loss=7.4755425453186035
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4419: train_loss=7.4705986976623535
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4420: train_loss=7.4689154624938965
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4421: train_loss=7.4753241539001465
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4422: train_loss=7.481780052185059
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4423: train_loss=7.499392509460449
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4424: train_loss=7.506748199462891
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4425: train_loss=7.49301290512085
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4426: train_loss=7.509586334228516
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4427: train_loss=7.503254413604736
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4428: train_loss=7.552913188934326
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4429: train_loss=7.514087677001953
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4430: train_loss=7.519093036651611
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4431: train_loss=7.642781734466553
INFO - 04/15/25 16:50:41 - 0:19:04 - Epoch 4432: train_loss=7.647032737731934
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4433: train_loss=7.671878814697266
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4434: train_loss=7.615181922912598
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4435: train_loss=7.686149597167969
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4436: train_loss=7.748017311096191
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4437: train_loss=7.82590389251709
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4438: train_loss=7.874317646026611
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4439: train_loss=7.843430519104004
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4440: train_loss=7.80252742767334
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4441: train_loss=7.756257057189941
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4442: train_loss=7.738279819488525
INFO - 04/15/25 16:50:41 - 0:19:05 - Epoch 4443: train_loss=7.7025041580200195
INFO - 04/15/25 16:50:42 - 0:19:05 - Epoch 4444: train_loss=7.686642169952393
INFO - 04/15/25 16:50:42 - 0:19:05 - Epoch 4445: train_loss=nan
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [6,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [4,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [0,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [13,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [11,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [7,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [14,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [5,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [2,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [1,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [3,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [8,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [12,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [10,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [15,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [9,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:94: operator(): block: [16,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
WARNING - 04/15/25 16:50:42 - 0:19:05 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:42 - 0:19:05 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 137, in train
                                            ari = exp.train()
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/exp.py", line 56, in train
                                            nmi, ari = self.train_clu(data, model, optimizer, logger, device, exp_iter)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/exp.py", line 97, in train_clu
                                            loss.backward()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/_tensor.py", line 626, in backward
                                            torch.autograd.backward(
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/autograd/__init__.py", line 347, in backward
                                            _engine_run_backward(
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
                                            return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
                                        RuntimeError: parallel_for: failed to synchronize: cudaErrorAssert: device-side assert triggered
                                        
                                        
/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py:128: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`
  print(torch.cuda.memory_cached() / 1024 ** 2)
WARNING - 04/15/25 16:50:44 - 0:19:08 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:44 - 0:19:08 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:45 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:45 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:09 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:09 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:46 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:46 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
INFO - 04/15/25 16:50:47 - 0:19:10 - Finished 50 trials.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:10 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:10 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:47 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:47 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:48 - 0:19:11 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:48 - 0:19:11 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:51 - 0:19:14 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:51 - 0:19:14 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:56 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:56 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:56 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:56 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
INFO - 04/15/25 16:50:57 - 0:19:20 - Finished 100 trials.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:20 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:20 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:57 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:57 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:21 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:21 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:22 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:22 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:22 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:22 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:22 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:22 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:22 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:22 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:22 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:22 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:50:58 - 0:19:22 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:50:58 - 0:19:22 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/numpy/lib/_function_base_impl.py:4779: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py:128: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`
  print(torch.cuda.memory_cached() / 1024 ** 2)
WARNING - 04/15/25 16:51:00 - 0:19:24 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:00 - 0:19:24 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
INFO - 04/15/25 16:51:06 - 0:19:30 - Finished 150 trials.
WARNING - 04/15/25 16:51:06 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:06 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:30 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:30 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:07 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:07 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:08 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:08 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:08 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:08 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:08 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:08 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:08 - 0:19:31 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:08 - 0:19:31 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/numpy/lib/_function_base_impl.py:4779: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py:128: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`
  print(torch.cuda.memory_cached() / 1024 ** 2)
WARNING - 04/15/25 16:51:10 - 0:19:33 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:10 - 0:19:33 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:11 - 0:19:34 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:11 - 0:19:34 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:42 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:42 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:43 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:43 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/numpy/lib/_function_base_impl.py:4779: RuntimeWarning: invalid value encountered in subtract
  diff_b_a = subtract(b, a)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/model/random_forest/random_forest.py:222: RuntimeWarning: Mean of empty slice
  preds_as_array = np.log(np.nanmean(np.exp(preds_as_array), axis=2) + VERY_SMALL_NUMBER)
/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py:128: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`
  print(torch.cuda.memory_cached() / 1024 ** 2)
WARNING - 04/15/25 16:51:19 - 0:19:43 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:43 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:43 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:43 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
WARNING - 04/15/25 16:51:19 - 0:19:43 - Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
WARNING - 04/15/25 16:51:19 - 0:19:43 - Traceback: Traceback (most recent call last):
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 190, in run
                                            rval = self(config_copy, target_function, kwargs)
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/smac/runner/target_function_runner.py", line 264, in __call__
                                            return algorithm(config, **algorithm_kwargs)
                                          File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 134, in train
                                            torch.cuda.empty_cache()
                                          File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/site-packages/torch/cuda/memory.py", line 218, in empty_cache
                                            torch._C._cuda_emptyCache()
                                        RuntimeError: CUDA error: device-side assert triggered
                                        CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
                                        For debugging consider passing CUDA_LAUNCH_BLOCKING=1
                                        Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
                                        
                                        
                                        
INFO - 04/15/25 16:51:19 - 0:19:43 - Finished 200 trials.
INFO - 04/15/25 16:51:19 - 0:19:43 - Configuration budget is exhausted:
INFO - 04/15/25 16:51:19 - 0:19:43 - --- Remaining wallclock time: inf
INFO - 04/15/25 16:51:19 - 0:19:43 - --- Remaining cpu time: inf
INFO - 04/15/25 16:51:19 - 0:19:43 - --- Remaining trials: 0
Traceback (most recent call last):
  File "/home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/./main_with_smac.py", line 164, in <module>
    json.dump(dict(incumbent), fp)
  File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/json/__init__.py", line 179, in dump
    for chunk in iterable:
  File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/json/encoder.py", line 431, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/json/encoder.py", line 405, in _iterencode_dict
    yield from chunks
  File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/json/encoder.py", line 438, in _iterencode
    o = _default(o)
  File "/home/hpc/v100dd/v100dd15/.conda/envs/clustering_env/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type int64 is not JSON serializable
=== JOB_STATISTICS ===
=== current date     : Tue Apr 15 16:51:28 CEST 2025
= Job-ID             : 2557724 on alex
= Job-Name           : lsenet_hpo
= Job-Command        : /home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering/fau_alex_job_script_hpo.sh
= Initial workdir    : /home/atuin/v100dd/v100dd15/python_code/deep_graph_clustering/deep_graph_clustering
= Queue/Partition    : a100
= Slurm account      : v100dd with QOS=normal
= Features           : a100_80
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:21:35
= Total RAM usage    : 10.6 GiB of assigned  GiB (%)
= Node list          : a0633
= Subm/Elig/Start/End: 2025-04-15T16:27:07 / 2025-04-15T16:27:07 / 2025-04-15T16:29:53 / 2025-04-15T16:51:28
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           30.2G   104.9G   209.7G        N/A      56K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-80GB, 00000000:49:00.0, 2019683, 37 %, 6 %, 64796 MiB, 1257909 ms
